<div id=toc></div>

# Table of Contents

- [astro-ph.IM](#astro-ph.IM) [Total: 20]
- [astro-ph.HE](#astro-ph.HE) [Total: 32]
- [gr-qc](#gr-qc) [Total: 20]
- [hep-ph](#hep-ph) [Total: 42]


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [1] [An Improved Machine Learning Approach for RFI Mitigation in FAST-SETI Survey Archival Data](https://arxiv.org/abs/2512.15809)
*Li-Li Zhao,Xiao-Hang Luan,Xin Chao,Yu-Chen Wang,Jian-Kang Li,Zhen-Zhao Tao,Tong-Jie Zhang,Hong-Feng Wang,Dan Werthimer*

Main category: astro-ph.IM

TL;DR: The paper proposes using the DBSCAN algorithm to mitigate residual RFI in FAST-SETI data, achieving a 77.87% removal rate with improved efficiency compared to previous methods, while preserving candidate signals.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of residual RFI in highly sensitive telescopes like FAST, which persists even after initial mitigation steps and complicates technosignature detection.

Method: Application of the DBSCAN clustering algorithm to identify and remove residual RFI from FAST-SETI archival data.

Result: Removed 36,977 residual RFIs (77.87% reduction), achieving a 7.44% higher removal rate and 24.85% faster execution than prior ML methods, while retaining one valid candidate signal.

Conclusion: DBSCAN effectively enhances RFI mitigation in SETI surveys by balancing higher removal efficiency and signal preservation, supporting its use in future commensal observations.

Abstract: The search for extraterrestrial intelligence (SETI) commensal surveys aim to scan the sky to detect technosignatures from extraterrestrial life. A major challenge in SETI is the effective mitigation of radio frequency interference (RFI), a critical step that is particularly vital for the highly sensitive Five-hundred-meter Aperture Spherical radio Telescope (FAST). While initial RFI mitigation (e.g., removal of persistent and drifting narrowband RFI) are essential, residual RFI often persists, posing significant challenges due to its complex and various nature. In this paper, we propose and apply an improved machine learning approach, the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm, to identify and mitigate residual RFI in FAST-SETI commensal survey archival data from July 2019. After initial RFI mitigation, we successfully identify and remove 36977 residual RFIs (accounting for $\sim$ 77.87\%) within approximately 1.678 seconds using the DBSCAN algorithm. This result shows that we have achieved a 7.44\% higher removal rate than previous machine learning methods, along with a 24.85\% reduction in execution time. We finally find interesting candidate signals consistent with previous studies, and retain one candidate signal following further analysis. Therefore, DBSCAN algorithm can mitigate more residual RFI with higher computational efficiency while preserving the candidate signals that we are interested in.

</details>


### [2] [Milky Way disc & Bulge in situ populations: ESO white paper - Expanding horizons call](https://arxiv.org/abs/2512.15812)
*M. Bergemann,G. Kordopatis,G. Casali,S. Khoperskov,P. McMillan,L. Marques,I. Minchev,E. Poggio,M. Schultheis,C. Viscasillas Vázquez,H. -F. Wang,V. Grisoni,V. Hill,R. Smiljanic*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The formation and evolution of the Milky Way's disc, bar, and bulge remain fundamentally limited by the lack of a contiguous, Galaxy-wide, high-precision chemo-dynamical map. Key open questions - including the survival or destruction of the primitive discs, the origin of the bulge's multi-component structure, the role of mergers and secular processes, and the coupling between stellar chemistry, dynamics, and the Galactic potential - cannot be fully resolved with current or planned facilities. Existing spectroscopic surveys provide either high resolution for small samples or wide coverage at insufficient resolution and depth, and none can obtain homogeneous abundances, precise 3D kinematics, and reliable ages for the millions of stars required, particularly in the obscured midplane, the far side of the bar, or the outer, low-density disc. A new wide-field, massively multiplexed, large-aperture spectroscopic facility, capable of both high- and low-resolution spectroscopy over tens of thousands of square degrees, is therefore essential. Such a facility would deliver the statistical power, sensitivity, and completeness needed to reconstruct the Galaxy's assembly history, constrain its gravitational potential, and establish the Milky Way as the definitive benchmark for galaxy evolution.

</details>


### [3] [Asteroseismology of white dwarfs in the 2040s](https://arxiv.org/abs/2512.15814)
*Murat Uzundag,Ingrid Pelisoli,Stephane Charpinet,Alejandro H. Corsico,Leandro G. Althaus,V. Van Grootel,Suzanna Randall,Thomas Kupfer,Roberto Raddi*

Main category: astro-ph.IM

TL;DR: The abstract discusses the importance of white dwarfs in astrophysics, focusing on asteroseismology as a tool to study their interiors. Challenges include discrepancies in mass determinations and unanswered questions about pulsation mechanisms. Future surveys with space-based photometry and ground-based spectroscopy will enhance our understanding.


<details>
  <summary>Details</summary>
Motivation: To utilize white dwarfs as cosmochronometers, study planetary system evolution, test non-standard physics, and investigate crystallization. Asteroseismology offers a unique method to probe internal structures, addressing gaps in understanding pulsation behavior, diffusion, convection, and mass determinations.

Method: Analyzing asteroseismic data from space missions by comparing observed pulsation periods with theoretical models to infer internal structure, mass, rotation, and magnetic fields. Future work will combine high-precision space photometry with ground-based spectroscopy.

Result: Identifies current challenges such as unexplained pulsation behavior, discrepancies between mass determination methods, and gaps in theoretical models. Highlights unresolved issues in diffusion, convection, and mode excitation.

Conclusion: Future large-scale surveys will increase observational data, improving asteroseismic analyses and resolving current uncertainties. Enhanced understanding of white dwarf interiors and evolution is anticipated through integrated observational strategies.

Abstract: White dwarfs, the final evolutionary stage of the vast majority of stars, serve as critical tools for cosmochronology, studies of planetary system evolution, and laboratories for non-standard physics, including exotic cooling channels and weakly interacting particles, as well as crystallization processes. Beyond surface properties accessible via spectroscopy and model atmospheres, global pulsations exhibited by white dwarfs during various evolutionary phases provide a direct window into their deep interiors. Asteroseismology, the comparison of observed pulsation periods with theoretical models, enables us to infer internal chemical stratification, total mass, rotation profiles, and magnetic field strengths. Despite major advances from space missions providing uninterrupted, high-precision photometry, key challenges remain: many predicted pulsators remain quiet, while others oscillate outside theoretical instability strips, highlighting gaps in our understanding of mode excitation, diffusion, and convective mixing. Determining the masses of white dwarfs, particularly for massive and hydrogen-deficient stars, remains uncertain, with discrepancies between spectroscopic, asteroseismic, astrometric, and photometric methods. In the coming decades, large-scale surveys combining high-precision space-based photometry with coordinated ground-based spectroscopic follow-up will dramatically increase both the number and quality of pulsating white dwarf observations.

</details>


### [4] [Sailing to the next safe harbour in our trip to the early Universe: The massive star population of metal-poor galaxies](https://arxiv.org/abs/2512.15817)
*N. Castro,M. Garcia,A. Herrero,A. A. C. Sander,A. F. McLeod,M. M. Roth,I. Negueruela,J. S. Vink*

Main category: astro-ph.IM

TL;DR: The study highlights the importance of very metal-poor massive stars in understanding the early Universe and reionization, but current observational limitations restrict comprehensive studies. Next-generation panoramic integral-field and multi-object spectrographs on large telescopes are proposed to enable systematic exploration of these stars across the Local Group.


<details>
  <summary>Details</summary>
Motivation: To overcome observational bottlenecks in studying very metal-poor massive stars, which are critical for modeling reionization and galactic chemical evolution but currently limited by telescope resolution and sensitivity.

Method: Proposing new telescope instruments (panoramic integral-field and high-multiplex spectrographs) to resolve metal-poor galaxies and systematically study massive stars across the Local Group.

Result: Future facilities will provide a comprehensive dataset on massive stellar populations in low-metallicity environments, enabling detailed modeling of their evolution and feedback mechanisms.

Conclusion: Next-generation instruments are essential for advancing understanding of massive star evolution and their role in cosmic structure formation, requiring dedicated large optical telescopes and advanced spectroscopic technologies.

Abstract: Very metal-poor massive stars in the Local Group are our best proxies for the Universe's first stars, making them essential for modeling reionization and early galactic chemical evolution. Studying such stars in our Local Universe is key to extrapolating our knowledge to more distant regions, where individual massive stars cannot be resolved but are dynamically and chemically shaping their environments. The MUSE integral field spectrograph has transformed massive star studies in the Milky Way and Magellanic Clouds, but resolving star-forming galaxies containing very metal-poor stars is at the limit of the current field of view and sensitivity. Therefore, only small dedicated efforts of selected regions are studied, providing us with snapshots of low-metallicity massive stars rather than a comprehensive picture. This scarcity is a major bottleneck for understanding and sufficiently modelling the evolution and feedback of massive stars across cosmic time. We therefore envision a new generation of panoramic integral-field spectrographs and high multiplex multi-object spectrographs mounted on dedicated large optical telescopes. Such facilities will not only allow to resolve very-metal-pool galaxies, but further enable the systematic exploration of the massive stellar content across the entire Local Group, thereby reaching a new era in massive star studies and understanding.

</details>


### [5] [Nova Explosions in 2040](https://arxiv.org/abs/2512.15821)
*Alessandro Ederoclite,Domitilla De Martino,Paul Groot,Elena Mason,Gloria Sala,Martín Guerrero,Thomas Kupfer,Anna Francesca Pala,Simone Scaringi,Noel Castro Segura*

Main category: astro-ph.IM

TL;DR: This paper discusses the future research directions for understanding nova explosions, emphasizing the need for advanced observational strategies and technologies to address key questions about ejecta properties, binary systems, and multi-wavelength emission.


<details>
  <summary>Details</summary>
Motivation: Nova explosions are critical for studying explosive nucleosynthesis and related astrophysical processes, but current knowledge is limited due to observational gaps and constraints.

Method: The paper outlines open scientific questions and proposes systematic high-resolution optical/near-infrared spectroscopy, combined with rapid-response multi-wavelength observations from eruption to quiescence.

Result: Identifies technological requirements and observational strategies necessary for transformative advances in understanding nova physics by the 2040s.

Conclusion: Future progress in nova research depends on implementing the proposed observational methods and technologies to fully resolve ejecta dynamics, binary interactions, and multi-wavelength emission mechanisms.

Abstract: Novae are thermonuclear explosions on the surface of accreting white dwarfs and are key laboratories for studying explosive nucleosynthesis, particle acceleration, shock physics, and binary evolution. Despite major progress driven by wide-field time-domain surveys and multi-wavelength facilities, our understanding of nova explosions remains limited by incomplete temporal coverage, heterogeneous spectroscopic follow-up, and poorly constrained ejecta properties. In this white paper we outline the open scientific questions that will define nova research in the 2040s, focusing on the mass, composition, geometry, and dynamics of the ejecta, the role of the underlying binary system, and the connection between nuclear burning, shocks, and emission across the electromagnetic spectrum. We argue that decisive progress requires rapid-response, high-cadence, multi-wavelength observations, anchored by systematic high-resolution optical and near-infrared spectroscopy from eruption to quiescence. Finally, we identify key technological requirements needed to enable transformative advances in the physics of nova explosions over the coming decades.

</details>


### [6] [Accretion and Ejection Physics at High Time Resolution](https://arxiv.org/abs/2512.15832)
*F. M. Vincentelli,P. Casella,A. Veledina,A. Ambrifi,M. C. Baglio,D. Buckley,N. Castro Segura,Y. Cavecchi,D. de Martino,M. del Santo,P. Gandhi,G. Iliano,R. La Paca,C. Malacaria,A. Marino,K. O'Brien,N. Rea,A. Sanna,S. Scaringi,T. Shahbaz,L. Zampieri*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accretion onto compact objects is one of the most fundamental phenomena in the astrophysics, powering some of the most luminous objects in the sky. Along with this, accretion has also a key impact on the evolution of the Universe, through the launch of powerful outflows that affect the surrounding medium. In the last years sub-second optical-infrared observations of accreting X-ray binaries have opened a new window in the study of inflow-outflow connection, discovering a wide range of previously unkown phenomena. Here we review the key open questions in accretion and ejection physics and discuss how a dedicated facility, equipped with photon-counting detectors and high spectral resolution from the UV to the mid-infrared, can enable transformative advances in our understanding of accretion processes.

</details>


### [7] [What Builds and Quenches the Most Massive Galaxies in the Early Universe?](https://arxiv.org/abs/2512.15836)
*Mengyuan Xiao,Longji Bing,Guilaine Lagache,Miroslava Dessauges-Zavadsky,Olivier Ilbert,Benjamin Magnelli,Pascal A. Oesch*

Main category: astro-ph.IM

TL;DR: The early universe rapidly formed massive galaxies, but their actual abundance, growth processes, and early quenching causes are not well understood. Current telescopes lack the necessary performance to study their cold gas, dust, and large-scale structures in sufficient detail. Next-generation facilities with large apertures, wide fields, and fast mapping speeds are needed to conduct deep far-infrared surveys required to answer these questions.


<details>
  <summary>Details</summary>
Motivation: To address uncertainties in the space density of massive galaxies, trace their baryon assembly, and understand early quenching mechanisms in the early universe.

Method: Propose next-gen telescopes with large apertures, wide fields, high mapping speeds to enable deep, large-scale far-infrared surveys.

Result: Expected to reveal the true abundance of massive early galaxies, map their cold gas/dust distributions, and identify physical processes driving their evolution and quenching.

Conclusion: Such advanced facilities are essential to resolve key questions about cosmic structure formation and galaxy evolution in the first few billion years post-Big Bang.

Abstract: The first few billion years of cosmic history witnessed the rapid emergence of the most massive galaxies, yet their true space density, baryon assembly pathways, and early quenching mechanisms remain poorly constrained. Current surveys lack the wide-field, rest-frame FIR sensitivity needed to obtain a complete census of massive systems and to trace their cold gas, dust, and diffuse emission on galactic and circumgalactic scales. A next-generation facility with a very large aperture, wide field of view, and high mapping speed is essential to carry out deep, degree-scale rest-frame FIR surveys. Such capabilities are required to determine how common massive galaxies are, how they assemble their baryons, and what physical processes drive their early transformation and quenching.

</details>


### [8] [Galaxies as stochastic systems: why the next breakthrough in galaxy evolution requires one hundred million spectra](https://arxiv.org/abs/2512.15841)
*Sandro Tacchella,Vasily Belokurov,Harry T. J. Bevins,Roberto Maiolino,Hiranya V. Peiris,Lucia Pozzetti,Mark T. Sargent*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Each galaxy is observed only once along its life, making galaxy evolution fundamentally an inverse statistical problem: time-dependent physics must be inferred from ensembles of single-epoch snapshots. To move beyond descriptive scaling relations toward physical regulation mechanisms of star formation, quenching, chemical enrichment and black hole growth, galaxies must be treated as realizations of a stochastic process whose hyper-parameters (e.g., correlation timescales, burstiness, duty cycles) are inferred hierarchically. This demands both depth and scale: continuum S/N sufficient for absorption-line ages and chemistry, and samples far larger than those in SDSS, DESI, 4MOST or MOONS, which provide either depth or size but not both across $0<z<3$. Once the relevant axes of mass, redshift, environment, structure and evolutionary phase are populated, the requirement naturally rises from $10^7$ to $\sim10^8$ galaxies. This is the regime where stochastic hyper-parameters can be well constrained and where comparisons to simulations and cosmological forward models become limited by theory rather than observations. We outline the science enabled by such a programme and the corresponding requirements for a future ESO wide-field spectroscopic facility capable of delivering tens to hundreds of millions of rest-UV-optical spectra over $0\lesssim z\lesssim3$.

</details>


### [9] [Hunting exomoons with a kilometric baseline interferometer](https://arxiv.org/abs/2512.15858)
*Thomas O. Winterhalder,Antoine Mérand,Sylvestre Lacour,Jens Kammerer,Guillaume Bourdarot,Frank Eisenhauer*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Despite numerous search campaigns based on a diverse set of observational techniques, exomoons - prospective satellites of extrasolar planets - remain an elusive and hard-to-pin-down class of objects. Yet, the case for intensifying this search is compelling: as in the Solar System, moons can act as proxies for studying planet formation and evolution, provide direct clues as to the migration history of the planetary hosts and, in favourable cases, offer potentially habitable environments. Here, we present an investigation into how the search for exomoons would benefit from a new interferometric facility operating in the optical wavelength domain and leveraging baselines substantially longer than the ones the VLTI is currently equipped with. We find that an interferometer providing an astrometric precision of 1$\,μ$as would be able to robustly detect Earth-mass and sub-Earth-mass exomoons on dynamically stable orbits around Jupiter-like planets at distances between 50 and 200 pc.

</details>


### [10] [Binarity Beyond Gaia: The case for a dedicated spectroscopic survey of binary stars](https://arxiv.org/abs/2512.15904)
*Borja Anguiano*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Stellar multiplicity is a fundamental ingredient of stellar astrophysics, yet binary statistics across the Galaxy remain poorly constrained. The \emph{Gaia} mission has revolutionised binary star astrophysics by delivering high-precision astrometry, photometry and global radial velocities, and by providing hundreds of thousands of non-single-star solutions in DR3. However, the RVS magnitude limit, mission time span and scanning law impose strong selection effects in period, mass ratio, inclination and semi-amplitude, leaving large regions of the binary parameter space either sparsely sampled or effectively inaccessible. In this white paper we outline the case for a dedicated, wide-field, multi-epoch spectroscopic survey explicitly optimised for binary science: deeper than the \emph{Gaia} RVS limit, with flexible cadence from hours to years, and with moderate to high spectral resolution. Using a simplified forward model of \emph{Gaia} DR5-like performance, we highlight the populations for which robust orbital solutions will be rare (ultra short period, very long period, low-amplitude and compact-object binaries), and show how a ``Binarity Beyond \emph{Gaia}'' survey would fill these gaps. Such a programme would deliver a bias correctable census of stellar multiplicity across the Milky Way and provide the spectroscopic backbone needed to exploit binary samples from \emph{Rubin}/LSST, \emph{Roman} and \emph{LISA}.

</details>


### [11] [Graph Neural Networks for Interferometer Simulations](https://arxiv.org/abs/2512.16051)
*Sidharth Kannan,Pooyan Goodarzi,Evangelos E. Papalexakis,Jonathan W. Richardson*

Main category: astro-ph.IM

TL;DR: This paper applies graph neural networks (GNNs) to simulate LIGO instrumentation, achieving 815x faster runtime than existing methods and providing a benchmark dataset.


<details>
  <summary>Details</summary>
Motivation: To leverage GNNs for faster and accurate simulation of complex optical physics in instrumentation design, addressing the need for efficient tools in high-energy physics and related fields.

Method: The authors use GNNs to model LIGO's optical systems, simulate three interferometer topologies, and compare performance against state-of-the-art simulation tools.

Result: GNN-based simulations achieved 815 times faster runtime while maintaining accuracy, and a new dataset was created for future benchmarking.

Conclusion: GNNs are viable for accelerating instrumentation design in physical sciences, offering a pathway for faster, scalable simulations and prompting further research in this area.

Abstract: In recent years, graph neural networks (GNNs) have shown tremendous promise in solving problems in high energy physics, materials science, and fluid dynamics. In this work, we introduce a new application for GNNs in the physical sciences: instrumentation design. As a case study, we apply GNNs to simulate models of the Laser Interferometer Gravitational-Wave Observatory (LIGO) and show that they are capable of accurately capturing the complex optical physics at play, while achieving runtimes 815 times faster than state of the art simulation packages. We discuss the unique challenges this problem provides for machine learning models. In addition, we provide a dataset of high-fidelity optical physics simulations for three interferometer topologies, which can be used as a benchmarking suite for future work in this direction.

</details>


### [12] [Expanding Horizons - Transforming Astronomy in the 2040s Time-Domain Multi-Messenger Astronomy in the 2040s: EM Follow-up of LGWA Sources](https://arxiv.org/abs/2512.16264)
*F. Patat,S. Piranomonte,S. Benetti,A. Bonforte,R. Della Ceca,G. Di Rico,A. Frigeri,J. Harms,M. Olivieri,A. Perali,P. Severgnini,A. Stallone,the LGWA Collaboration*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The coming decades will see gravitational-wave (GW) astronomy expand decisively into the mHz-Hz frequency range, opening access to a population of compact binaries that are currently invisible or only detectable moments before merger. The Lunar Gravitational Wave Antenna (LGWA) concept is designed to probe this gap, enabling continuous observation of compact binaries over months to years prior to coalescence, and detecting sources inaccessible to both space-based mHz detectors and current ground-based >10 Hz facilities. This new GW window fundamentally alters the landscape of time-domain multi-messenger astronomy. Rather than reacting to mergers after the fact, LGWA enables predictive, scheduled electromagnetic (EM) follow-up, transforming how compact-object mergers, their environments, and their astrophysical channels are studied. However, fully exploiting LGWA discoveries requires EM capabilities that do not exist today and are unlikely to be available by the 2030s, particularly for wide-area, rapid, spectroscopically rich follow-up at optical and near-infrared wavelengths. This White Paper identifies the key science cases enabled by LGWA that motivate new ground-based capabilities in the 2040s.

</details>


### [13] [Radio frequency interference identification using eigenvalue decomposition for multi-beam observations](https://arxiv.org/abs/2512.16278)
*Juntao Bai,Shi Dai,Na Wang,Stefan Osłowski,Shuangqiang Wang,George Hobbs,Jianping Yuan,Wenming Yan,Qijun Zhi,Lunhua Shang,Xin Xu,Shijun Dang,De Zhao*

Main category: astro-ph.IM

TL;DR: The paper introduces mRAID, a novel RFI mitigation method using eigenvalue decomposition of cross-correlation matrices from multi-beam data. Effective for pulsar/FRB searches, especially with FAST telescope, it offers parallelizable computation and improved efficiency over existing methods.


<details>
  <summary>Details</summary>
Motivation: Next-gen PAF receivers require efficient RFI mitigation for large surveys. Existing methods are computationally intensive.

Method: mRAID employs eigenvalue decomposition of the cross-correlation matrix (CCM) from multi-beam data to detect RFI. Processes are parallelizable due to independent time-frequency bin computations.

Result: When applied to FAST pulsar data, mRAID effectively identifies short-timescale RFI, improving search efficiency for pulsars and FRBs.

Conclusion: mRAID provides a computationally superior approach for RFI mitigation, particularly advantageous for large-scale radio surveys using multi-beam telescopes.

Abstract: With the installation of next-generation phased array feed (PAF) receivers on radio telescopes, there is an urgent need to develop effective and computationally efficient radio frequency interference (RFI) mitigation methods for large-scale surveys. Here we present a new RFI mitigation package, called mRAID (multi-beam RAdio frequency Interference Detector), which uses the eigenvalue decomposition algorithm to identify RFI in cross-correlation matrix (CCM) of data recorded by multiple beams. When applied to high time-resolution pulsar search data from the Five-hundred-meter Aperture Spherical Radio Telescope (FAST), mRAID demonstrates excellent performance in identifying RFI over short timescales, thereby enhancing the efficiency of pulsar and fast radio burst (FRB) searches. Since the computation of the CCM and the eigenvalue decomposition for each time sub-integration and frequency channel are independent, the process is fully parallelisable. As a result, mRAID offers a significant computational advantage over commonly used RFI detection methods.

</details>


### [14] [New methods to improve the decontamination of slitless spectra](https://arxiv.org/abs/2512.16324)
*Mostafa Bella,Shahram Hosseini,Thierry Contini,Hicham Saylani*

Main category: astro-ph.IM

TL;DR: The paper introduces four new methods for decontaminating spectra from slitless spectroscopy in missions like Euclid, using either a linear instantaneous model or a convolutive model that handles multiple light dispersion directions and noisy data effectively.


<details>
  <summary>Details</summary>
Motivation: Address the decontamination challenges in slitless spectroscopy data from space missions, which suffer from overlapping spectra and mixed signals across multiple dispersion directions.

Method: Two approaches are proposed: (1) the local instantaneous method using a spatial domain linear model, and (2) the local convolutive approach employing Fourier domain models for simultaneous decontamination and deconvolution. Both incorporate photometric data to resolve spectral mixtures.

Result: Tests with Euclid-like noisy data demonstrated the effectiveness of all four methods in accurately decontaminating spectra, validating their applicability for space mission data analysis.

Conclusion: The developed methods provide robust solutions for slitless spectroscopy decontamination, with the convolutive approach offering improved accuracy by handling complex mixtures through its model. These techniques enhance data quality for missions such as Euclid.

Abstract: This paper proposes four new methods to decontaminate spectra of stars and galaxies resulting from slitless spectroscopy used in many space missions such as Euclid. These methods are based on two distinct approaches and simultaneously take into account multiple dispersion directions of light. The first approach, called the local instantaneous approach, is based on an approximate linear instantaneous model. The second approach, called the local convolutive approach, is based on a more realistic convolutive model that allows simultaneous decontamination and deconvolution of spectra. For each approach, a mixing model was developed that links the observed data to the source spectra. This was done either in the spatial domain for the local instantaneous approach or in the Fourier domain for the local convolutive approach. Four methods were then developed to decontaminate these spectra from the mixtures, exploiting the direct images provided by photometers. Test results obtained using realistic, noisy, Euclid-like data confirmed the effectiveness of the proposed methods.

</details>


### [15] [Maximizing the sensitivity of ELT to habitable worlds with a space-based starshade](https://arxiv.org/abs/2512.16361)
*Markus Janson,Enric Palle,Thomas Henning,Sascha Quanz,Lars Buchhave,Alexis Brandeker*

Main category: astro-ph.IM

TL;DR: The combination of the Extremely Large Telescope (ELT) and a space-based starshade could enable the direct observation of Earth-like exoplanets around Sun-like stars, addressing key questions about habitability and life in the universe. Synergy between these instruments would open unprecedented scientific opportunities.


<details>
  <summary>Details</summary>
Motivation: To overcome the ELT's limitations in detecting Earth analogs in habitable zones due to extreme star-planet contrast ratios and angular separation. The desire to study habitability and life's prevalence drives the need for this hybrid approach.

Method: Proposing a collaboration between ESO and ESA to design a starshade compatible with the ELT. The starshade would suppress starlight, allowing the ELT's large aperture to detect faint exoplanets. Instrumentation on the ELT would be tailored for optimal synergy with the starshade.

Result: Potential to observe tens of Earth analogs and other planets, providing data on their atmospheres and conditions. This would advance understanding of planetary habitability and the distribution of life-supporting environments.

Conclusion: A coordinated ELT-starshade mission represents a transformative opportunity unmatched by other facilities, necessitating international collaboration to maximize scientific impact.

Abstract: The ELT will provide groundbreaking science across a wide range of areas, including small habitable-zone exoplanets; however, true Earth analogs in the habitable zones of Sun-like stars are generally beyond the reach even of the ELT, due to the extreme contrast ratio and small angular separation between the planet and star. Here, we note that the combination of ELT and a space-based starshade would provide the contrast needed to observe potentially tens of Earth analogs, as well as other planets. This would yield the scientific basis needed for addressing central scientific questions regarding the frequency and distribution of habitability and life in the Universe. The huge aperture of ELT, combined with a contrast otherwise only reachable in space, opens up scientific avenues that are unmatched by any other existing or foreseen facility. ESO could conceivably collaborate with ESA (and others) to facilitate a starshade mission suitable for synergy with the ELT, as well as to prepare the ELT instrumentation in order to maximize its potential for synergy with a starshade.

</details>


### [16] [Transformational astrophysics and exoplanet science with Habitable Worlds Observatory's High Resolution Imager](https://arxiv.org/abs/2512.16416)
*Vincent Van Eylen,Richard Massey,Saeeda Awan,Jo Bartlett,Louisa Bradley,Andrei Bubutanu,Kan Chen,Andrew Coates,Mark Cropper,Ross Dobson,Fabiola Antonietta Gerosa,Emery Grahill-Bland,Leah Grant,Daisuke Kawata,Tom Kennedy,Minjae Kim,Adriana Adelina Mihailescu,Jan-Peter Muller,Georgios Nicolaou,Mathew Page,Paola Pinilla,Louisa Preston,Ted Pyne,Hamish Reid,Santiago Velez Salazar,Jason L. Sanders,Giorgio Savini,Ralph Schoenrich,George Seabroke,Alan Smith,Philip J. Smith,Nicolas Tessore,Marina Ventikos,Esa Vilenius,Francesca Waines,Silvia Zane,James Betts,Sownak Bose,Cyril Borgsom,Shaun Cole,Jessica E. Doppel,Vincent Eke,Carlos Frenk,Leo W. H. Fung,Qiuhan He,Mathilde Jauzac,Owen Jessop,Zane Deon Lentz,Gavin Leroy,Simon Morris,Yuan Ren,Jurgen Schmoll,Ray Sharples,Fionagh Thomson,Maximilian von Wietersheim-Kramsta,Kai Wang,Stephane V. Werner,Subhajit Sarkar,Jacob Kegerreis,James Kirk,Subhanjoy Mohanty,John Southworth,John Philip Stott,Ashley King,James W. Nightingale,David Rosario,Paola Tiranti,Edward Gillen,Cynthia S. K. Ho,Christopher Watson,Andrzej Fludra,Chris Pearson,Yun-Hang Cho,Yu Tao,Joanna Barstow,James Bowen,Chris Castelli,Chiaki Crews,Angaraj Duara,Mark Fox-Powell,David Hall,Carole Haswell,Kit-Hung Mark Lee,Joan Requena,Anabel Romero,Jesper Skottfelt,Konstantin Stefanov,Olivia Jones,Sean McGee,Annelies Mortier,Graham P. Smith,Amalie Stokholm,Amaury Triaud,Becky Alexis-Martin,Malcolm Bremer,Katy L. Chubb,Joshua Ford,Ben Maughan,Daniel Valentine,Hannah Wakeford,Juan Paolo Lorenzo Gerardo Barrios,Chandan Bhat,Xander Byrne,Gregory Cooke,Natalie B. Hogg,Nikku Madhusudhan,Maximilian Sommer,Sandro Tacchella,Georgios N. Vassilakis,Nicholas Walton,Mark Wyatt,Manoj Joshi,Beth Biller,Mariangela Bonavita,Trent Dupuy,Aiza Kenzhebekova,Brian P. Murphy,Vincent Okoth,Cyrielle Opitom,Larissa Palethorpe,Paul Palmer,Mia Belle Parkinson,Ken Rice,Sarah Rugheimer,Colin Snodgrass,Ben J. Sutlieff,Souradeep Bhattacharya,Emma Curtis-Lake,Jan Forbrich,Darshan Kakkad,David J. Lagattuta,Brian Ongeri Momanyi Bichang'a,Peter Scicluna,Richard Booth,Martin Barstow,Sarah Casewell,Leigh Fletcher,Anushka Sharma,Christopher J. Conselice,Suzanne Aigrain,Jayne Birkby,Claire Guimond,Carly Howett,Mei Ting Mak,Richard Palin,Chris Pattison,Richard Robinson,Samantha Youles,Andrew Collier Cameron,Justin Read,David John Armstrong,David J. A. Brown,Mikkel N. Lund,Andrew Robertson,Pierre-Olivier Lagage,Lígia F. Coelho,Preethi R. Karpoor,Enric Palle,Leen Decin,Denis Defrère,Kaustubh Hakim,Swara Ravindranath,Jason Rhodes,Marc Postman,Iain Neill Reid,Fabien Malbet,Amirnezam Amiri,Marrick Braam,Qiuhan He,Haakon Dahle,Angharad Weeks*

Main category: astro-ph.IM

TL;DR: The Habitable Worlds Observatory (HWO), NASA's 2040s flagship telescope, aims to detect life on exoplanets and revolutionize astrophysics. The UK is positioned to lead the imaging camera's design and construction, offering significant industrial returns and enhanced global leadership in space science.


<details>
  <summary>Details</summary>
Motivation: The motivation behind HWO is to advance the search for extraterrestrial life and drive transformative discoveries in astrophysics. The UK's involvement would secure competitive advantages in space technology and public engagement through high-impact astronomical imagery.

Method: The paper likely discusses strategies for international collaboration, technical specifications for the imaging camera, and frameworks for maximizing economic and scientific returns through early UK participation in HWO development.

Result: Successful UK leadership in HWO's camera system could generate substantial investment returns for UK industry and establish the nation as a leader in space science, technology, and astrophysical research for decades.

Conclusion: Early UK involvement in HWO presents a strategic opportunity to contribute to groundbreaking scientific missions while driving domestic technological innovation and securing long-term international recognition in space exploration.

Abstract: Habitable Worlds Observatory (HWO) will be NASA's flagship space telescope of the 2040s, designed to search for life on other planets and to transform broad areas of astrophysics. NASA are seeking international partners, and the UK is well-placed to lead the design and construction of its imaging camera - which is likely to produce the mission's most visible public impact. Early participation in the mission would return investment to UK industry, and bring generational leadership for the UK in space science, space technology, and astrophysics.

</details>


### [17] [A direction-dependent framework for visibility plane mosaicing and primary beam correction](https://arxiv.org/abs/2512.16440)
*Keegan S. Trehaeven,Cyril Tasse,Oleg Smirnov,Tiziana Venturi*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: With the increasing sensitivity of modern radio interferometers, it has become important to image objects larger than the field of view while optimising sensitivity and image fidelity. We present a coherent visibility plane direction-dependent imaging, calibration and mosaicing framework. Our simulations and application to real MeerKAT data show that this joint deconvolution and primary beam correction approach, coupled with direction-dependent calibration, allows for deeper mosaics with greater fidelity and increased accuracy of recovered flux densities and spectral indices, especially beyond the half-power beam width. Our best-case mosaic produces precise flux values within a 6% uncertainty and spectral indices within 20\% throughout the imaged area, and is fully complete out to twice the radii and half the flux density than the image plane equivalent. The application to archival wideband MeerKAT 1283 MHz data produces the deepest high-resolution image of the Shapley Supercluster Core, with a sensitivity of 3.6 $μ$Jy/beam within the primary beam at a 7$^{\prime\prime}$ resolution, constituting a $\sim$ 50% increase in dynamic range over the image plane counterpart, and a fluxscale that is consistent within 10% across the entire field of view. The compute time for the direction-dependent visibility plane mosaic was comparable to the sum of the times needed to perform direction-dependent calibration on the individual pointings. Our results suggest that visibility plane mosaicing with its capability for deeper deconvolution could improve the efficiency of deep and wide surveys, particularly for on-the-fly mapping and studies of low surface brightness sources, and could form the basis of future calibration pipelines for SKA-scale instruments.

</details>


### [18] [Simulation-based inference with neural posterior estimation applied to X-ray spectral fitting - III Deriving exact posteriors with dimension reduction and importance sampling](https://arxiv.org/abs/2512.16709)
*Didier Barret,Simon Dupourqué*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Simulation-based inference (SBI) with neural posterior estimation (NPE) provides rapid X-ray spectral fitting in both Gaussian and Poisson regimes by learning approximate parameter posteriors from simulations. We investigate auto-encoders for compressing high-resolution X-ray spectra, motivated by newAthena X-ray Integral Field Unit (X-IFU), and use likelihood-based importance sampling to refine NPE outputs. Our auto-encoder maps spectra to a low-dimensional latent space and is trained with a custom loss equal to the Cash statistic (C-stat) between simulated and reconstructed spectra. A neural density estimator is then trained on the latent representations. Both models are trained in multiple rounds: at each round, new simulations are drawn from a truncated proposal concentrated around the observation, improving efficiency as the proposal contracts. After NPE convergence, we apply likelihood-based importance sampling to correct the learned posterior. To assess information retention, we train a diagnostic network that predicts the original spectral parameters from the latent space, and we also train a network to learn the likelihood directly to accelerate importance sampling. On X-IFU-like simulations, the auto-encoder and multi-round NPE outperforms PCA and hand-crafted spectral summaries in accuracy and robustness. After importance sampling, the resulting posteriors are statistically indistinguishable from those obtained with nested sampling. On a standard laptop, the full pipeline (simulation, compression, inference, correction) delivers 10x speedups. We further demonstrate the approach on XRISM/Resolve and on lower-resolution NICER and XMM-Newton EPIC-pn data, confirming applicability across instruments and resolutions. Overall, NPE on compressed spectra paired with likelihood-based importance sampling offers an exact yet efficient alternative for Bayesian X-ray spectral fitting.

</details>


### [19] [The WINTER Observatory: A One-Degree InGaAs Survey Camera to study the Transient Infrared Sky](https://arxiv.org/abs/2512.16753)
*Danielle Frostig,Nathan Lourie,Viraj Karambelkar,Mansi M. Kasliwal,Andrew Malonis,Robert A. Simcoe,Robert Stein,John W. Baker,Kevin Burdge,Rick Burruss,Curt Corcoran,Kishalay De,Gabor Furesz,Nicolae Ganciu,Kari Haworth,Carolyn M. Heffner,Erik Hinrichsen,Jill Juneau,Geoffrey Mo,Josiah Purdum,Sam Rose,Cruz Soto,Jeffry Zolkower*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Wide-field Infrared Transient Explorer (WINTER) is a new near-infrared time-domain survey instrument installed on a dedicated 1-meter robotic telescope at Palomar Observatory. The project takes advantage of the recent technology advances in time-domain astronomy, robotic telescopes, large-format sensors, and rapid data reduction and alert software for timely follow up of events. Since June of 2023, WINTER robotically surveys the sky each night to a median depth of J_AB = 18.5 mag, balancing a variety of science programs including searching for kilonovae from gravitational-wave alerts, blind surveys to study galactic and extragalactic transients and variables, and building up reference images of the near-infrared sky. The project also serves as a technology demonstration for new large-format Indium Gallium Arsenide (InGaAs) sensors for near-infrared photometry without cryogenic cooling. WINTER's custom camera combines six InGaAs sensors with a novel tiled fly's-eye optical design to cover a >1 degree-squared field of view with 1 arcsecond pixels in the Y-, J-, and shortened-H-band filters (0.9 - 1.7 micron). This paper presents the design, performance, and early on-sky science of the WINTER observatory.

</details>


### [20] [Strategies for Accurate Effective Point Spread Function (ePSF) Modelling on Undersampled Images](https://arxiv.org/abs/2512.16764)
*Emma Godden,Katherine M. Blundell*

Main category: astro-ph.IM

TL;DR: The paper demonstrates improvements to an existing ePSF modeling framework through specific modifications, enhancing accuracy in photometry and astrometry by addressing pixel-phase errors and optimizing parameters like oversampling, interpolation, and dithering. It applies these refined methods to real data from Global Jet Watch observatories.


<details>
  <summary>Details</summary>
Motivation: Accurate ePSF modeling is critical for high-precision photometry and astrometry in undersampled imaging, but existing methods may introduce pixel-phase errors affecting flux and position measurements. Improving this framework's accuracy can enhance reliability of stellar data analysis.

Method: The authors use synthetic ePSFs to generate simulated stellar images, systematically testing modifications to modeling parameters (oversampling, interpolation methods, gridpoint estimation, smoothing, star-sample distribution, dithering). They evaluate accuracy using these simulations and validate on real data from Global Jet Watch.

Result: Key factors affecting ePSF accuracy include oversampling rates, robust interpolation, optimized gridpoint estimation, and strategic dithering. The refined routine significantly reduces pixel-phase errors in flux and position measurements, validated both in simulations and real observations.

Conclusion: Tailoring ePSF modeling to instrument/detector characteristics and data nature is essential. The improved framework provides practical guidelines for optimizing ePSF construction, advancing reliable photometric and astrometric measurements in undersampled regimes.

Abstract: Accurate modelling of the effective point spread function (ePSF) is essential for high-precision photometry and astrometry, particularly in undersampled imaging regimes. In this work, we build on a well-established ePSF modelling framework and its commonly used open-source Python implementation and demonstrate that several simple but effective modifications to existing ePSF modelling routines can significantly improve model accuracy. We use synthetic ePSFs to generate simulated datasets of stellar images, allowing us to evaluate the accuracy of ePSF models and determine the scale of the pixel-phase errors in resulting flux and position measurements. We systematically investigate how specific modelling choices affect ePSF accuracy, and evaluate the influence of oversampling, interpolation, gridpoint estimation, smoothing, star-sample distribution, and dithering on photometric precision. We apply our refined ePSF modelling routine to images from the Global Jet Watch observatories, demonstrating its improved ability to recover an accurate ePSF for real astronomical images. Our findings highlight the importance of tailoring the modelling approach to the specific characteristics of the instrument and detector, as well as to the nature of the available imaging data used to construct the ePSF model. These results provide practical guidance for optimising ePSF construction, thereby improving the reliability of photometric and astrometric measurements.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [21] [Reconstruction of the dark matter density profile from cosmic positron anomaly data](https://arxiv.org/abs/2512.15741)
*K. M. Belotsky,F. V. Kostromin,M. L. Solovyov*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this work we continue our investigations of the possibility of explanation of the positron anomaly (PA) in cosmic rays with the help of annihilating or decaying dark matter (DM) component by varying its space distribution. In the contrast of our previous studies, where we first assumed some specific spatial distribution of DM component and looked at how it agrees with data, here we solve, in some sense, the inverse problem: we search for distribution, in a mathematical way, which satisfies observational data. A unique algorithm has been implemented which, using linear algebra and adaptive grid methods, adjusts distribution to the data. It allows telling in principle whether or not is possible to solve PA problem by variation of spatial distribution of DM sources. A positive result has been formally obtained. A class of solutions can be identified. Though the distributions obtained at the chosen injection spectra may seem slightly realistic, nonetheless it demonstrates a quite powerful possibility in explaining PA that could be realized in more realistic models.

</details>


### [22] [Self-confinement of relativistic pair beams in magnetized interstellar plasmas: the case of pulsar X-ray filaments](https://arxiv.org/abs/2512.15847)
*Luca Orusa,Lorenzo Sironi*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The observation of filamentary X-ray structures near bow-shock pulsar wind nebulae (PWNe) -- such as the Guitar, Lighthouse, and PSR J2030$+$4415 nebulae -- and of slow-diffusion regions around pulsars like Geminga, Monogem, and PSR J0622$+$3749, challenges the standard picture of cosmic-ray transport in the interstellar medium, implying a diffusion coefficient two orders of magnitude smaller than the Galactic average. The suppressed diffusion can be attributed to self-generated magnetic turbulence, driven -- via the non-resonant streaming instability -- by electron--positron pairs escaping the PWNe. This instability requires a net current, yet the beam of escaping pairs is expected to be charge-neutral. We show that a charge-neutral pair beam propagating through an electron--proton plasma can spontaneously generate a net current. Using fully kinetic two- and three-dimensional particle-in-cell simulations with realistic mass ratio, we find that beam electrons get focused into self-generated magnetic filaments produced by the nonlinear evolution of the Weibel instability, while beam positrons remain unconfined. The resulting net (positron) current drives the non-resonant streaming instability, further amplifying the magnetic field. This mechanism provides a pathway for the onset of charge asymmetries in initially charge-neutral pair beams and for the growth of magnetic fluctuations that efficiently scatter the beam particles, with implications for the formation of X-ray filaments and, more broadly, for particle self-confinement in TeV halos around PWNe.

</details>


### [23] [In-plane Black-hole Spin Measurements Suggest Most Gravitational-wave Mergers Form in Triples](https://arxiv.org/abs/2512.15873)
*Jakob Stegmann,Fabio Antonini,Aleksandra Olejak,Sylvia Biscoveanu,Vivien Raymond,Stefano Rinaldi,Beth Flanagan*

Main category: astro-ph.HE

TL;DR: The analysis of gravitational wave data from binary black hole mergers shows a significant preference for near-perpendicular spin-orbit tilt angles (∼cosθ ≈ 0), supporting isolated massive triple stellar evolution scenarios over traditional isolated-binary models.


<details>
  <summary>Details</summary>
Motivation: To determine the astrophysical origin of binary black holes through spin-orbit tilt angle distributions, addressing gaps in understanding formation channels.

Method: Hierarchical Bayesian inference applied to LIGO-Virgo-KAGRA's GWTC-4 data, using parametric models with Gaussian and isotropic components to model tilt-angle distributions.

Result: Data favor a dominant Gaussian component with ∼cosθ ≈0 (± near-perpendicular spins) mixed with minor isotropic contribution; aligned spin components are disfavored with Bayes factors 1-3 and constrained to ∼1%.

Conclusion: Near-perpendicular spin distributions challenge traditional isolated-binary formation (which predicts aligned spins) and align with triple-star evolution via Lidov-Kozai mechanism, suggesting new astrophysical insights.

Abstract: The spin-orbit tilt angles $θ_{1(2)}$ of merging stellar-mass black holes provide key insights into their astrophysical origin. The LIGO, Virgo, and KAGRA Collaborations (2025a, arXiv:2508.18083) report that the spin-orbit tilt distribution of mergers in the latest Gravitational-Wave Transient Catalog 4.0 exhibits a global peak at near-perpendicular directions $\cosθ_{1(2)}\approx0$. Here, we recover this feature using hierarchical Bayesian inference with parametric models that are tailored to enhance the diagnostic power about astrophysical formation channels. We find that the spin distribution of the low-mass bulk of the binary black hole merger population $(m_1\lesssim 44.3^{+8.7}_{-4.6}\,\rm M_\odot)$ can be well-modelled by a dominant Gaussian component that peaks at $\cosθ_{1(2)}\approx0$, possibly mixed with a subdominant isotropic component. Models that include a component with spins preferentially aligned with the orbit are disfavoured by current data (with Bayes factors $|Δ\ln\mathcal{B}|\approx1$ to $3$) and constrain its contribution to be small ($ξ\sim\mathcal{O}(1)\,\%$). If these findings are reinforced by more detections, they would challenge any major contribution from the traditional isolated-binary formation scenario yielding closely aligned spins. Instead, the dominant component with near-perpendicular spins qualitatively matches expectations from the evolution of isolated massive stellar triples in the galactic field, where the Lidov-Kozai effect naturally produces a unique overabundance of mergers with $\cosθ_{1(2)}\approx0$.

</details>


### [24] [2D or not 2D? Exploring 3D relativistic magnetic reconnection dynamics with highly accurate numerical simulations](https://arxiv.org/abs/2512.15954)
*Vittoria Berta,Matteo Bugli,Andrea Mignone,Giancarlo Mattia,Luca Del Zanna,Stefano Truzzi*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Fast reconnection in magnetically dominated plasmas is widely invoked in models of dissipation in pulsar winds, gamma-ray flares in the Crab nebula, and to explain the radio nanoshots of pulsars. When current sheets evolve reaching a critical inverse aspect ratio, scaling as $S^{-1/3}$ with the plasma Lundquist number, the so-called \textit{ideal} tearing instability sets in, with modes growing, independently of $S$, extremely rapidly on timescales of only a few light-crossing times of the sheet length. We present the first set of fully 3D simulations of current-sheet disruption triggered by the ideal tearing instability within the resistive relativistic MHD approximation, as appropriate in situations where the Alfvén velocity approaches the speed of light. We compare 3D setups with different initial conditions with their 2D counterparts, and we assess the impact of dimensionality and of the magnetic field topology on the onset, evolution, and efficiency of reconnection. In force-free configurations, 3D runs develop ideal tearing, secondary instabilities, and a thick, turbulent current layer, sustaining dissipation of magnetic energy longer than in 2D. In pressure-balanced current sheets with a null guide field, 2D reference runs show the familiar reconnection dynamics, whereas in 3D tearing dynamics is quenched after the linear phase, as pressure-driven modes growing on forming plasmoids outcompete plasmoid coalescence and suppress fast dissipation of magnetic energy. Taken together, these results suggest that the evolution and efficiency of reconnection depend sensitively on the local plasma conditions and current-sheet configuration, and can be properly captured only in fully 3D simulations.

</details>


### [25] [HEGS : Revisiting a decade of H.E.S.S. extragalactic observations](https://arxiv.org/abs/2512.16005)
*François Brun,David Sanchez,Andrew M. Taylor,Matteo Cerruti,Jean-Philippe Lenain*

Main category: astro-ph.HE

TL;DR: The H.E.S.S. experiment re-analyzed 2700 hours of extragalactic observations from 2004-2012 to create a catalog of 23 sources, covering 5.7% of the sky. This enabled studies of source variability, extragalactic gamma-ray background, and comparison with Fermi-LAT data, with high-level datasets publicly released.


<details>
  <summary>Details</summary>
Motivation: Re-examine and consolidate H.E.S.S. data from the first phase in a unified analysis framework to maximize scientific output and enable comprehensive astrophysical studies.

Method: Re-analyzed 2700 hours of H.E.S.S. data using a consistent framework. Cataloged 23 sources, produced sky maps, and conducted cross-mission comparisons with Fermi-LAT.

Result: Produced a catalog of 23 sources, analyzed source variability, contributed to understanding the extragalactic gamma-ray background, and facilitated comparisons with Fermi-LAT results. Released catalogs and maps for public use.

Conclusion: The re-analysis successfully enhanced data utilization, demonstrated the value of long-term observations, and provided foundational resources for future astrophysical research through shared datasets.

Abstract: During its first phase, from 2004 up to the end of 2012, the H.E.S.S. (High Energy Stereoscopic System) experiment observed the extragalactic skies for more than 2700 hours. These data have been re-analysed in a single consistent framework, leading to the derivation of a catalog of 23 sources. In total, about 5.7% of the sky was observed, allowing for several additional studies to be conducted: source variability, extragalactic gamma-ray background light, and comparison with the Fermi-LAT catalogues. In this contribution, we discuss these results and present the high-level data (catalogs, maps) released to the astrophysical community.

</details>


### [26] [Exploring the Galactic Plane: A Comparative Study of Fermi-LAT Sources and HESS's Non-Detection at TeV Energies](https://arxiv.org/abs/2512.16009)
*François Brun,Baptiste Le Nagat-Neher,Marianne Lemoine-Goumard,Marie-Hélène Grondin,Paul Fauverge*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The HESS Galactic Plane Survey (HGPS), published in 2018, presented a decade of very-high-energy (VHE) gamma-ray observations along the Galactic plane. This study was accompanied by the release of several maps in FITS format, offering a detailed view of the region. The flux upper-limits from these HGPS maps can be compared to the high-energy (HE) spectra of sources catalogued by the Fermi-LAT in the same region. For some sources, extrapolating the Fermi-LAT flux into the VHE range predicts flux values exceeding the upper-limits set by HESS. In this work, we present the results of this comparison and highlight the sources that are of particular interest for future VHE observations.

</details>


### [27] [Inferring the Intrinsic Energy Function of FRB 20220912A](https://arxiv.org/abs/2512.16122)
*Xiaohui Liu,Wei-Yang Wang,Weicong Jing,Xuelei Chen,Jinlin Han*

Main category: astro-ph.HE

TL;DR: The study analyzes selection effects on FRB energy distributions using FAST data, showing band-limited selection alone cannot create bimodal energy distributions, which instead may stem from intrinsic properties.


<details>
  <summary>Details</summary>
Motivation: To investigate whether observed bimodal energy distributions in FRB samples are due to selection biases or intrinsic properties of FRBs.

Method: Simulations of band-limited selection effects applied to FRB energy distributions, analyzed alongside observational data from FRB 20220912A observed by FAST.

Result: Unimodal intrinsic energy distributions don't produce observed bimodality via band selection alone; FRB 20220912A's energy shows no correlation with central frequency but links high frequency to narrower bandwidth/duration; intrinsic energy fits a log-normal + power-law model, indicating low-energy peak is observational artifact.

Conclusion: Bimodal energy distributions likely arise from intrinsic radiation mechanisms rather than observational biases. The low-energy peak is likely an artifact, while high-energy trends reflect true physical processes.

Abstract: The statistical analysis of fast radio burst (FRB) samples from repeaters may suffer from a band-limited selection effect, which can bias the observed distribution. We investigated the impact of this selection bias on the energy function through simulations and then applied our analysis to the particular case of FRB 20220912A. Our simulations show that, in the sample of bursts observed by the Five hundred meter Aperture Spherical Telescope (FAST), assuming a unimodal intrinsic energy distribution, the band selection effect alone is insufficient to produce a bimodal energy distribution; only the bimodal central frequency distribution can achieve this. The bursts' energy of FRB 20220912A that primarily fell within the observing band showed no significant correlation with the central frequency. In contrast, bursts with higher central frequency tend to exhibit narrower bandwidth and longer duration. The distribution of the intrinsic energy can be modeled as a log-normal distribution with a characteristic energy of $8.13 \times 10^{37}$ erg, and a power-law function with the index of $1.011 \pm 0.028$. In contrast to the initial energy function reported by \cite{2023ApJ...955..142Z}, the low-energy peak vanishes, and the high-energy decline becomes steeper, which implies the low-energy peak is an observational effect. The bimodality of the energy distribution seems to originate from the intrinsic radiation mechanism.

</details>


### [28] [Pulsar Science with the SKA Observatory](https://arxiv.org/abs/2512.16152)
*Bhal Chandra Joshi,Aris Karastergiou,Marta Burgay,The SKA pulsar science working group*

Main category: astro-ph.HE

TL;DR: The SKA Observatory's telescopes, SKA-Low and SKA-Mid, will revolutionize pulsar astronomy through their advanced capabilities, as detailed in this special issue's lead article and accompanying papers.


<details>
  <summary>Details</summary>
Motivation: To showcase how the SKA telescopes' unique features—large sensitivity, broad frequency range, and multi-beam observation capabilities—will transform pulsar research and highlight the contributions of the special issue's articles.

Method: The lead article provides an overview of the SKA telescopes' relevant features for pulsar studies and summarizes each accompanying paper, examining how different pulsar science use cases interrelate.

Result: The SKA telescopes are positioned to significantly advance pulsar astronomy by enabling comprehensive and flexible observations, supported by the in-depth analyses in the special issue.

Conclusion: The special issue demonstrates the profound impact of SKA's capabilities on pulsar science, emphasizing their role in future astronomical discoveries and interdisciplinary research.

Abstract: The large instantaneous sensitivity, a wide frequency coverage and flexible observation modes with large number of beams in the sky are the main features of the SKA observatory's two telescopes, the SKA-Low and the SKA-Mid, which are located on two different continents. Owing to these capabilities, the SKAO telescopes are going to be a game-changer for radio astronomy in general and pulsar astronomy in particular. The eleven articles in this special issue on pulsar science with the SKA Observatory describe its impact on different areas of pulsar science. In this lead article, a brief description of the two telescopes highlighting the relevant features for pulsar science is presented followed by an overview of each accompanying article, exploring the inter-relationship between different pulsar science use cases.

</details>


### [29] [A Square Kilometre Array Pulsar Census](https://arxiv.org/abs/2512.16153)
*E. F. Keane,V. Graber,L. Levin,C. M. Tan,O. A. Johnson,C. Ng,C. Pardo-Araujo,M. Ronchi,D. Vohl,M. Xue,The SKA Pulsar Science Working Group*

Main category: astro-ph.HE

TL;DR: The study outlines optimal strategies for an all-sky pulsar survey using the SKA, predicting the detection of thousands of pulsars and enabling advancements in neutron star physics and gravitational wave astronomy.


<details>
  <summary>Details</summary>
Motivation: The need for precise pulsar timing and astrometry with the SKA to address key questions in astrophysics requires first locating sufficient pulsars through an efficient survey.

Method: Two methods were used to project pulsar yields for various survey designs combining SKA1-Low and SKA1-Mid bands, considering factors like effective area, survey speed, and radio interference avoidance.

Result: Optimal strategies using both SKA1-Low (for high sky coverage) and SKA1-Mid (focused on the galactic plane) can detect ~10,800 pulsars. Upgraded hardware (AA4) increases yield by 20%, but broader Mid band coverage extends survey duration.

Conclusion: A well-planned SKA survey will provide a comprehensive pulsar census, enabling breakthroughs in understanding neutron star properties and key SKA science goals like dense matter physics and gravitational wave detection.

Abstract: Most of the pulsar science case with the Square Kilometre Array (SKA) depends on long-term precision pulsar timing of a large number of pulsars, as well as astrometric measurements of these using very long baseline interferometry (VLBI). But before we can time them, or VLBI them, we must first find them. Here, we describe the considerations and strategies one needs to account for when planning an all-sky blind pulsar survey using the SKA. Based on our understanding of the pulsar population, the performance of the now-under-construction SKA elements, and practical constraints such as evading radio frequency interference, we project pulsar survey yields using two complementary methods for a number of illustrative survey designs, combining SKA1-Low and SKA1-Mid Bands 1 and 2 in a variety of ways. A composite survey using both Mid and Low is optimal, with Mid Band 2 focused in the plane. We find that, given its much higher effective area and survey speed, the best strategy is to use SKA1-Low to cover as much sky as possible, ideally also overlapping with the areas covered by Mid. In our most realistic scenario, we find that an all-sky blind survey with Phase 1 of the SKA with the AA* array assembly will detect $\sim10,000$ slow pulsars and $\sim 800$ millisecond pulsars (MSPs) if SKA1-Mid covers the region within $5°$ of the plane, while higher latitudes will be covered with SKA1-Low. The yield with AA4 is $\sim 20\%$ higher. One could increase these numbers by increasing the range covered by SKA1-Mid Bands 1 and 2, at the cost of a considerably longer survey. The pulsar census will enable us to set new constraints on the uncertain physical properties of the entire neutron star population. This will be crucial for addressing major SKA science questions including the dense-matter equation of state, strong-field gravity tests, and gravitational wave astronomy.

</details>


### [30] [Pulsars in Globular Clusters With the SKAO](https://arxiv.org/abs/2512.16154)
*Manjari Bagchi,Federico Abbate,Vishnu Balakrishnan,Miquel Colom i Bernadich,Bhaswati Bhattacharyya,Arunima Dutta,Paulo C. C. Freire,Kriisa Halley,Jason W. T. Hessels,Sangeeta Kumari,Duncan R. Lorimer,Andrea Possenti,Rouhin Nag,Scott M. Ransom,Alessandro Ridolfi,Vivek Venkatraman Krishnan,Weiwei Zhu,The SKA Pulsar Science Working Group*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Because of their extreme stellar densities, globular clusters are highly efficient factories of X-ray binaries and radio pulsars: per unit of stellar mass, they contain about 1000 times more of these exotic objects. Thus far, 345 radio pulsars have been found in globular clusters. These can be used as precision probes of the structure, gas content, magnetic field, and dynamic history of their host clusters; some of them are also highly interesting in their own right because they probe exotic stellar evolution scenarios as well as the physics of dense matter, accretion, and gravity; one of them (PSR~J0514$-$4002E) might even be the first pulsar - black hole system known. Deep searches with SKA-MID and SKA-LOW will only require one to a few tied-array beams, and can be done during early commissioning of the telescope, before an all-sky pulsar survey using hundreds to thousands of tied-array beams is feasible. Even a conservative approach predicts new discoveries only with the core of SKA-MID AA*, and the full AA* and eventually AA4 is expected to increase the number of discoveries even more, leading to more than doubling the current known population. This offers a great opportunity for early SKAO pulsar science, even before all the collecting area is in place. On the other hand, a more optimistic prediction calls for a 4-5 times growth of the population, leading to a total of about 1700 pulsars to be detectable with SKA-MID AA4 configuration in all Galactic GCs visible by SKA telescopes. Thus, a dedicated search for pulsars in globular clusters will fully exploit the best possible natural laboratories to study many branches of physics and astrophysics, including properties of dense matter, stellar evolution, and the dynamical history of the Galactic globular cluster systems.

</details>


### [31] [Galactic Centre Pulsars with the SKAO](https://arxiv.org/abs/2512.16155)
*F. Abbate,A. Carleo,S. Chatterjee,J. Cordes,P. B. Demorest,G. Desvignes,R. P. Eatough,E. Hackmann,Hu Z.,M. Kramer,J. Lazio,K. J. Lee,K. Liu,I. Rammala-Zitha,S. M. Ransom,G. Saowanit,L. Shao,P. Torne,R. Wharton,J. Wongphechauxsorn,W. Zhu,The SKAO Pulsar Science Working Group*

Main category: astro-ph.HE

TL;DR: This paper discusses updated strategies and potential outcomes for detecting pulsars near Sagittarius A* using the upgraded SKAO design, building on previous Galactic Center searches which have found only seven pulsars despite an expected larger population.


<details>
  <summary>Details</summary>
Motivation: The detection of pulsars orbiting Sagittarius A* would allow the study of extreme relativistic effects and the magneto-ionic properties of the galactic nucleus, which are not observable in other systems.

Method: Analyzes recent updates since the last SKAO science book, proposes optimized observing strategies with the new SKAO design, and evaluates expected scientific results based on improved sensitivity and observational capabilities.

Result: A framework for effective SKA pulsar searches is outlined, emphasizing detection of a larger pulsar population near Sgr A* to test relativistic physics and probe galactic center environment.

Conclusion: The SKAO's enhanced capabilities will enable groundbreaking discoveries in pulsar astrophysics, refining our understanding of spacetime and galactic nuclei through precise pulsar timing.

Abstract: The detection of a pulsar closely orbiting our Galaxy's supermassive black hole - Sagittarius A* - is one of the ultimate prizes in pulsar astrophysics. The relativistic effects expected in such a system could far exceed those currently observable in compact binaries such as double neutron stars and pulsar white dwarfs. In addition, pulsars offer the opportunity to study the magneto-ionic properties of Earth's nearest galactic nucleus in unprecedented detail. For these reasons, and more, a multitude of pulsar searches of the Galactic Centre have been undertaken, with the outcome of just seven pulsar detections within a projected distance of 100 pc from Sagittarius A*. It is currently understood that a larger underlying population likely exists, but it is not until observations with the SKA have started that this population can be revealed. In this paper, we look at important updates since the publication of the last SKAO science book and offer a focused view of observing strategies and likely outcomes with the updated SKAO design.

</details>


### [32] [Understanding the Neutron Star Population with the SKAO telescopes](https://arxiv.org/abs/2512.16156)
*L. Levin,M. Bagchi,M. Burgay,A. T. Deller,V. Graber,A. Igoshev,M. Kramer,D. Lorimer,B. Posselt,T. Prabu,K. Rajwade,N. Rea,B. Stappers,T. M. Tauris,P. Weltevrede,The SKAO Pulsar Science Working Group*

Main category: astro-ph.HE

TL;DR: The SKAO telescopes will significantly expand the population of known neutron stars, enabling deeper insights into their evolution, classification, and role in testing gravitational theories.


<details>
  <summary>Details</summary>
Motivation: To enhance understanding of neutron star physics and uncover new phenomena by discovering more radio pulsars through SKAO's advanced capabilities.

Method: Utilizing SKAO's sensitivity, wide field of view, real-time beam searching, multi-frequency observations, and sub-arrays for pulsar surveys across all neutron star subgroups.

Result: Expected discoveries include new neutron star types, improved gravitational theory tests via pulsar binaries, better constraints on the nuclear equation of state, and clarity on pulsar evolution and magnetar connections.

Conclusion: SKAO will revolutionize neutron star research by increasing sample sizes, improving observational precision, and challenging existing theories with novel data.

Abstract: The known population of non-accreting neutron stars is ever growing and currently consists of more than 3500 sources. Pulsar surveys with the SKAO telescopes will greatly increase the known population, adding radio pulsars to every subgroup in the radio-loud neutron star family. These discoveries will not only add to the current understanding of neutron star physics by increasing the sample of sources that can be studied, but will undoubtedly also uncover previously unknown types of sources that will challenge our theories of a wide range of physical phenomena. A broad variety of scientific studies will be made possible by a significantly increased known population of neutron stars, unravelling questions such as: How do isolated pulsars evolve with time; What is the connection between magnetars, high B-field pulsars, and the newly discovered long-period pulsars; How is a pulsar's spin-down related to its radio emission; What is the nuclear equation of state? Increasing the known numbers of pulsars in binary or triple systems may enable both larger numbers and higher precision tests of gravitational theories and general relativity, as well as probing the neutron star mass distribution. The excellent sensitivity of the SKAO telescopes combined with the wide field of view, large numbers of simultaneous tied-array beams that will be searched in real time, wide range of observing frequencies, and the ability to form multiple sub-arrays will make the SKAO an excellent facility to undertake a wide range of neutron star research. In this paper, we give an overview of different types of neutron stars and discuss how the SKAO telescopes will aid in our understanding of the neutron star population.

</details>


### [33] [Understanding pulsar magnetospheres with the SKAO](https://arxiv.org/abs/2512.16157)
*L. S. Oswald,A. Basu,M. Chakraborty,B. C. Joshi,N. Lewandowska,K. Liu,M. E. Lower,A. Philippov,X. Song,P. Tarafdar,J. van Leeuwen,A. L. Watts,P. Weltevrede,G. Wright,J. Benacek,A. Beri,S. Cao,P. Esposito,F. Jankowski,J. C. Jiang,A. Karastergiou,K. J. Lee,N. Rea,D. Vohl,The SKA Pulsar Science Working Group*

Main category: astro-ph.HE

TL;DR: The paper discusses advancements in pulsar magnetosphere physics enabled by modern radio telescopes like the SKA precursors, highlights the SKA's potential to revolutionize the field through large-scale surveys and targeted observations, and outlines specific observational strategies using AA* and AA4 configurations to address pulsar radio emission physics.


<details>
  <summary>Details</summary>
Motivation: To leverage the SKA telescopes' capabilities—such as high sensitivity, wide field of view, and sub-arraying—to advance understanding of pulsar magnetosphere physics, building on progress from precursor instruments.

Method: Reviews past decade's advancements in pulsar magnetosphere studies driven by improved telescope technology. Details proposed SKA observation strategies (large-scale surveys and follow-up observations) and specific configurations (AA*, AA4) for future research.

Result: SKA observations will enable transformative insights into pulsar radio emission mechanisms by combining extensive monitoring with in-depth analysis of key targets, potentially resolving long-standing questions in the field.

Conclusion: The SKA's unique observational capabilities, particularly through its AA* and AA4 configurations, are critical for achieving breakthroughs in pulsar magnetosphere physics, setting the stage for solving fundamental emission physics problems in the near future.

Abstract: The SKA telescopes will bring unparalleled sensitivity across a broad radio band, a wide field of view across the Southern sky, and the capacity for sub-arraying, all of which make them the ideal instruments for studying the pulsar magnetosphere. This paper describes the advances that have been made in pulsar magnetosphere physics over the last decade, and details how these have been made possible through the advances of modern radio telescopes, particularly SKA precursors and pathfinders. It explains how the SKA telescopes would transform the field of pulsar magnetosphere physics through a combination of large-scale monitoring surveys and in-depth follow-up observations of unique sources and new discoveries. Finally, it describes how the specific observing opportunities available with the AA* and AA4 configurations will achieve the advances necessary to solve the problem of pulsar radio emission physics in the coming years.

</details>


### [34] [Exploring Galactic plasma with pulsars in the SKA era](https://arxiv.org/abs/2512.16158)
*C. Tiburzi,M. T. Lam,D. J. Reardon,N. K. Porayko,M. Mevius,S. Koch Ocker,S. C. Susarla,J. R. Dawson,A. Deller,G. M. Shaifullah,M. Walker,W. Jing,F. A. Iraci,N. D. R. Bhat,M. Geyer,L. Levin,M. Keith*

Main category: astro-ph.HE

TL;DR: This review paper discusses the use of pulsars to study the ionized media in the Milky Way, covering key plasma properties and their impact on pulsar research, while outlining future advancements with the SKA.


<details>
  <summary>Details</summary>
Motivation: Pulsars provide unique insights into the ionized interstellar medium, allowing studies of electron distributions in the ionosphere, Solar Wind, and Galaxy, as well as informing experiments like Pulsar Timing Arrays.

Method: Reviews existing pulsar-based plasma research methodologies including measurement of column density, turbulence, scattering measures, and intervening structures, while discussing considerations for effective plasma studies.

Result: Summarizes current understanding of interstellar plasma properties derived from pulsar observations and identifies areas needing improvement.

Conclusion: Highlights the potential of upcoming SKA facilities to enhance plasma research, emphasizing future directions for observational strategies and targeted studies.

Abstract: The ionised media that permeate the Milky Way have been active topics of research since the discovery of pulsars in 1967. In fact, pulsars allow one to study several aspects of said plasma, such as their column density, turbulence, scattering measures, and discrete, intervening structures between the neutron star and the observer, as well as aspects of the magnetic field throughout. Such sources of information allow us to characterise the electron distribution in the terrestrial ionosphere, the Solar Wind, and our Galaxy, as well as the impact on other experiments involving pulsars, such as Pulsar Timing Arrays. In this article, we review the state-of-the-art in plasma research using pulsars, the aspects that should be taken into consideration for optimal plasma studies, and we provide future perspectives on improvements enabled by the SKA.

</details>


### [35] [Understanding Pulsar Wind Nebulae with the SKA](https://arxiv.org/abs/2512.16160)
*Joseph D. Gelfand,C. -Y. Ng,B. Posselt,Mallory S. E. Roberts,Subir Bhattacharyya,Shi Dai,Rene Breton,Benjamin Stappers,Andrea Possenti,Jason Hessels,Yifan Sun,Moaz Abdelmaguid*

Main category: astro-ph.HE

TL;DR: This paper discusses how the Square Kilometer Array (SKA) will enhance understanding of pulsar wind nebulae (PWNe) and the ultra-relativistic particles within them by improving sensitivity and dynamic range in radio observations.


<details>
  <summary>Details</summary>
Motivation: PWNe studies are crucial for exploring neutron star magnetospheres and particle acceleration, but previous radio observations have limitations that the SKA's advancements aim to address.

Method: Analysis of the SKA's capabilities in studying the continuum and polarized radio emission of PWNe to map particle acceleration and propagation, and magnetosphere dynamics.

Result: SKA's superior sensitivity and dynamic range will enable detailed, high-resolution imaging of PWNe, revealing new insights into particle acceleration mechanisms and energy up to ~10^15 eV.

Conclusion: The SKA will revolutionize studies of PWNe, shedding light on the origins of the highest energy particles in the Milky Way by addressing current observational constraints.

Abstract: Produced by the interaction between the ``pulsar wind'' powered by the rotational energy of a neutron star and its surroundings, the study of pulsar wind nebulae (PWNe) provides vital insight into the physics of neutron star magnetospheres and ultra-relativistic outflows. Spatially-resolved studies of the continuum and polarized radio emission of these sources are vital for understanding the production of $e^\pm$ in the magnetospheres of neutron stars, the acceleration of these particles to $\gtrsim10^{15}~{\rm eV}$ energies, and the propagation of these particles within the PWN as well as the surrounding interstellar medium. The significant improvements in sensitivity, dynamic range, timing capabilities offered by the Square Kilometer Array have the potential to significantly improve our understanding of the origin of some of the highest energy particles produced in the Milky Way.

</details>


### [36] [Testing Gravity with Binary Pulsars in the SKA Era](https://arxiv.org/abs/2512.16161)
*V. Venkatraman Krishnan,L. Shao,V. Balakrishnan,M. Colom i Bernadich,A. Carelo,A. Corongiu,A. Deller,P. C. C. Freire,M. Geyer,E. Hackmann,H. Hu,Z. Hu,J. Kunz,M. Kramer,K. Liu,M. E. Lower,X. Miao,A. Possenti,D. Perrodin,D. S. Pillay,S. Ransom,I. Stairs,B. Stappers,The SKA Pulsar Science Working Group*

Main category: astro-ph.HE

TL;DR: The Square Kilometre Array (SKA) will enhance precision tests of gravitational theories using relativistic pulsar systems, enabling stronger constraints on general relativity and potential discovery of pulsar-black hole binaries to explore cosmic censorship and no-hair theorem.


<details>
  <summary>Details</summary>
Motivation: To leverage SKA's capabilities for improved timing precision and discovery of new pulsar systems to perform rigorous tests of gravity in strong-field regimes, beyond current capabilities.

Method: Improve timing precision of known binary/trinary pulsar systems with SKA; conduct Galactic census to find new relativistic systems (e.g., pulsar-black hole binaries); apply these systems to test strong equivalence principle, gravitational radiation, and other GR predictions.

Result: Expected results include unprecedented tests of GR's validity, potential detection of deviations from GR, and opportunities to validate cosmic censorship and no-hair theorem through newly discovered systems.

Conclusion: SKA's enhanced sensitivity and survey capabilities are crucial for advancing gravitational physics, making it indispensable for next-generation gravity tests in extreme astrophysical environments.

Abstract: Binary (and trinary) radio pulsars are natural laboratories in space for understanding gravity in the strong field regime, with many unique and precise tests carried out so far, including the most precise tests of the strong equivalence principle and of the radiative properties of gravity. The Square Kilometre Array (SKA) telescope, with its high sensitivity in the Southern Hemisphere, will vastly improve the timing precision of recycled pulsars, allowing for a deeper search of potential deviations from general relativity (GR) in currently known systems. A Galactic census of pulsars will, in addition, will yield the discovery of dozens of relativistic pulsar systems, including potentially pulsar -- black hole binaries, which can be used to test the cosmic censorship hypothesis and the ``no-hair'' theorem. Aspects of gravitation to be explored include tests of strong equivalence principles, gravitational dipole radiation, extra field components of gravitation, gravitomagnetism, and spacetime symmetries. In this chapter, we describe the kinds of gravity tests possible with binary pulsar and outline the features and abilities that SKA must possess to best contribute to this science.

</details>


### [37] [Probing neutron star interiors and the properties of cold ultra-dense matter with the SKAO](https://arxiv.org/abs/2512.16162)
*Avishek Basu,Vanessa Graber,Marcus E. Lower,Marco Antonelli,Danai Antonopoulou,Manjari Bagchi,Prasanta Char,Paulo C. C. Freire,Brynmor Haskell,Huanchen Hu,David I. Jones,Banibrata Mukhopadhyay,Micaela Oertel,Nanda Rea,Violetta Sagun,Benjamin Shaw,Jaikhomba Singha,Benjamin W. Stappers,Tinn Thongmeearkom,Anna L. Watts,Patrick Weltevrede,The SKA Pulsar Science Working Group*

Main category: astro-ph.HE

TL;DR: This paper discusses how SKA radio observations of neutron stars will advance understanding of ultra-dense matter physics, including superfluidity, by measuring neutron star properties and considering effects of dark matter and modified gravity, with synergies from X-ray and gravitational wave observatories.


<details>
  <summary>Details</summary>
Motivation: Neutron stars offer a unique environment to study ultra-dense matter under conditions unreachable on Earth. To reduce uncertainties in dense matter physics and superfluidity theories, the paper motivates the need for observational data from advanced instruments like the SKA.

Method: The paper reviews state-of-the-art dense matter physics and superfluidity, discusses methods to measure neutron star masses, moments of inertia, rotation frequencies, glitch behavior, and precession. It analyzes how SKA's capabilities (sensitivity, survey scale, sub-arraying) will constrain dense matter models. Also evaluates effects of dark matter and modified gravity on these constraints.

Result: SKA observations will provide new constraints on dense matter equations of state, superfluid properties, and test alternative gravity theories through neutron star measurements. Synergies with X-ray and GW observatories enhance observational power.

Conclusion: SKA's unique capabilities combined with multi-messenger astronomy will significantly improve our understanding of ultra-dense matter and associated physics, confirming or ruling out theoretical models through precise neutron star property measurements.

Abstract: Matter inside neutron stars is compressed to densities several times greater than nuclear saturation density, while maintaining low temperatures and large asymmetries between neutrons and protons. Neutron stars, therefore, provide a unique laboratory for testing physics in environments that cannot be recreated on Earth. To uncover the highly uncertain nature of cold, ultra-dense matter, discovering and monitoring pulsars is essential, and the SKA will play a crucial role in this endeavour. In this paper, we will present the current state-of-the-art in dense matter physics and dense matter superfluidity, and discuss recent advances in measuring global neutron star properties (masses, moments of inertia, and maximum rotation frequencies) as well as non-global observables (pulsar glitches and free precession). We will specifically highlight how radio observations of isolated neutron stars and those in binaries -- such as those performed with the SKA in the near future -- inform our understanding of ultra-dense physics and address in detail how SKAO's telescopes unprecedented sensitivity, large-scale survey and sub-arraying capabilities will enable novel dense matter constraints. We will also address the potential impact of dark matter and modified gravity models on these constraints and emphasise the role of synergies between the SKA and other facilities, specifically X-ray telescopes and next-generation gravitational wave observatories.

</details>


### [38] [The SKAO Pulsar Timing Array](https://arxiv.org/abs/2512.16163)
*Ryan M. Shannon,N. D. Ramesh Bhat,Aurelien Chalumeau,Siyuan Chen,H. Thankful Cromartie,A. Gopukumar,Kathrin Grunthal,Jeffrey S. Hazboun,Francesco Iraci,Bhal Chandra Joshi,Ryo Kato,Michael J. Keith,Kejia Lee,Kuo Liu,Hannah Middleton,Matthew T. Miles,Chiara M. F. Mingarelli,Aditya Parthasarathy,Daniel J. Reardon,Golam M. Shaifullah,Keitaro Takahashi,Caterina Tiburzi,Riccardo J. Truant,Xiao Xue,Andrew Zic,The SKAO Pulsar Science Working Group*

Main category: astro-ph.HE

TL;DR: The chapter advocates for the SKA PTA experiment's crucial role in detecting gravitational-wave backgrounds through enhanced sensitivity, emphasizing its ability to observe more millisecond pulsars with greater precision, mitigate astrophysical noise, and collaborate with other PTA projects to achieve a comprehensive view of the universe.


<details>
  <summary>Details</summary>
Motivation: To accelerate the confident detection of gravitational-wave signals and study their sources by leveraging the SKAO's superior sensitivity, enabling more precise observations of millisecond pulsars and improving detection capabilities beyond current PTAs.

Method: The SKAO PTA will utilize its increased sensitivity compared to existing southern hemisphere facilities to observe a larger number of millisecond pulsars. It will employ very long baseline interferometry to enhance sensitivity and employ advanced techniques to search for gravitational waves while addressing astrophysical noise.

Result: The SKAO PTA is positioned to detect and study gravitational-wave signals from astrophysical sources more effectively, providing complementary data to other 2030s-era facilities and improving our understanding of gravitational-wave emitting phenomena.

Conclusion: The SKAO PTA will be a transformative tool in gravitational-wave astronomy, offering a unique observational capacity that, when combined with other experiments, will advance multi-messenger astronomy and fundamental physics investigations in the coming decades.

Abstract: Pulsar timing arrays (PTAs) are ensembles of millisecond pulsars observed for years to decades. The primary goal of PTAs is to study gravitational-wave astronomy at nanohertz frequencies, with secondary goals of undertaking other fundamental tests of physics and astronomy. Recently, compelling evidence has emerged in established PTA experiments for the presence of a gravitational-wave background. To accelerate a confident detection of such a signal and then study gravitational-wave emitting sources, it is necessary to observe a larger number of millisecond pulsars to greater timing precision. The SKAO telescopes, which will be a factor of three to four greater in sensitivity compared to any other southern hemisphere facility, are poised to make such an impact. In this chapter, we motivate an SKAO pulsar timing array (SKAO PTA) experiment. We discuss the classes of gravitational waves present in PTA observations and how an SKAO PTA can detect and study them. We then describe the sources that can produce these signals. We discuss the astrophysical noise sources that must be mitigated to undertake the most sensitive searches. We then describe a realistic PTA experiment implemented with the SKA and place it in context alongside other PTA experiments likely ongoing in the 2030s. We describe the techniques necessary to search for gravitational waves in the SKAO PTA and motivate how very long baseline interferometry can improve the sensitivity of an SKAO PTA. The SKAO PTA will provide a view of the Universe complementary to those of the other large facilities of the 2030s.

</details>


### [39] [Fastest or Significant: A Systematic Framework for Validating Global Minimum Variability Timescale Measurements of Gamma-ray Bursts](https://arxiv.org/abs/2512.16204)
*S. Bala,P. Veres,A. Goldstein,R. Sonawane,R. Samanta,S. Iyyani*

Main category: astro-ph.HE

TL;DR: The paper presents a framework to validate Haar-based minimum variability timescale (MVT) measurements in GRB light curves, addressing ambiguities caused by noise and analysis choices. It introduces an empirical validation curve linking MVT reliability to signal-to-noise ratio, showing some published MVTs should be reclassified as upper limits.


<details>
  <summary>Details</summary>
Motivation: To resolve ambiguities in interpreting MVT due to noise and analysis biases, ensuring reliable physical inferences about GRB outflows and emission regions.

Method: Simulations of multi-component GRB light curves were used to quantitatively assess Haar-based MVT measurement robustness, analyzing how intrinsic timescales, SNR_MVT, and component complexity affect results.

Result: MVT often reflects the most statistically significant feature rather than the fastest timescale, requiring higher SNR_MVT for shorter timescales. An empirical MVT Validation Curve classifies measurements as robust or upper limits.

Conclusion: Standardizing MVT analysis is critical for accurate physical constraints. Caution is needed when using single MVT values from complex events, with some prior measurements requiring reclassification.

Abstract: The minimum variability timescale (MVT) is a key observable used to probe the central engines of Gamma-Ray Bursts (GRBs) by constraining the emission region size and the outflow Lorentz factor. However, its interpretation is often ambiguous: statistical noise and analysis choices can bias measurements, making it difficult to distinguish genuine source variability from artifacts. Here we perform a comprehensive suite of simulations to establish a quantitative framework for validating Haar-based MVT measurements. We show that in multi--component light curves, the MVT returns the most statistically significant structure in the interval, which is not necessarily the fastest intrinsic timescale, and can therefore converge to intermediate values. Reliability is found to depend jointly on the MVT value and its signal-to-noise ratio ($\mathrm{SNR}_{\mathrm{MVT}}$), with shorter intrinsic timescales requiring proportionally higher $\mathrm{SNR}_{\mathrm{MVT}}$ to be resolved.
  We use this relation to define an empirical MVT Validation Curve, and provide a practical workflow to classify measurements as robust detections or upper limits. Applying this procedure to a sample of Fermi-GBM bursts shows that several published MVT values are better interpreted as upper limits. These results provide a path toward standardizing MVT analyses and highlight the caution required when inferring physical constraints from a single MVT measurement in complex events.

</details>


### [40] [Astrophysical Implications of Eccentricity in Gravitational Waves from Neutron Star-Black Hole Binaries](https://arxiv.org/abs/2512.16289)
*Isobel Romero-Shaw,Jakob Stegmann,Gonzalo Morras,Andris Dorozsmai,Michael Zevin*

Main category: astro-ph.HE

TL;DR: The paper investigates the formation and detectability of eccentric neutron star-black hole (NSBH) mergers like GW200105, finding that eccentricities down to ~0.003-0.022 can be measured at 10 Hz. A field triple origin could explain a third of measured eccentric NSBHs.


<details>
  <summary>Details</summary>
Motivation: GW200105's potential eccentricity challenges standard isolated binary evolution models, which predict negligible eccentricity at detection. The study explores alternative formation pathways and detection thresholds.

Method: Compute minimum detectable eccentricity (e_min,10) for NSBHs across mass ranges and spin conditions. Simulate detection efficiency of quasi-circular templates for NSBHs from triples.

Result: e_min,10 is typically ~0.01 for NSBHs, but lowered to 0.003 for GW190814-like systems. Only 27% of field triple NSBHs are detected with current methods. Up to 1/3 of detected eccentric NSBHs could originate from triples.

Conclusion: Eccentric NSBH mergers require non-standard formation channels like triples. Improved detection methods and higher eccentricity fractions in observations could confirm field triple origins.

Abstract: The gravitational-wave signal from the neutron star-black hole (NSBH) merger GW200105 is consistent with this binary having significant orbital eccentricity close to merger. This raises the question of how an eccentric NSBH might form. Compact object binaries that form via isolated binary star evolution should radiate away any orbital eccentricity long before their gravitational-wave signal enters the sensitive frequency range of the LIGO-Virgo-KAGRA detector network. Meanwhile, dynamical environments -- which can be conducive to mergers on eccentric orbits -- produce very few NSBHs. We estimate the minimum measurable eccentricity of NSBHs at 10 Hz orbit-averaged gravitational-wave frequency, $e_{\mathrm{min},10}$, finding that for GW200105, GW200115, and GW230529-like systems, $e_{\mathrm{min},10}$ is O(0.01). For a GW190814-like unequal-mass binary with significant higher-order mode content, $e_{\mathrm{min},10}=0.003$; this is an order of magnitude lower than when higher-order modes are not present. For dominant-mode signals from eccentric binaries with $m_2=1.5$ M$_\odot$ and a range of total masses from $3\,{\rm M_\odot} \leq M \leq50\,\rm M_\odot$, we find $0.008\leq e_{\mathrm{min},10}\leq0.022$. The relationship between $M$ and $e_{\mathrm{min},10}$ is linear when the binaries are non-spinning. When the binaries are maximally spin-precessing, $e_{\mathrm{min},10}$ decreases as mass ratio becomes more unequal. We estimate the sensitivity of a quasi-circular templated search to a population of NSBHs from field triples, finding that we recover only 27% of our simulated population. Finally, we show that if ~1/3 of present NSBH detections are measurably eccentric, then all of them are consistent with an isolated field triple origin.

</details>


### [41] [Hydrodynamic Evolution and Detectability of Nova Remnants in the Galactic Center](https://arxiv.org/abs/2512.16316)
*Zhao Su,Zhiyuan Li*

Main category: astro-ph.HE

TL;DR: The paper investigates the detectability of nova remnants in the Galactic center using hydrodynamical simulations and multiwavelength emission analysis, finding varying detectability probabilities across X-ray, radio, and Paschen-α observations.


<details>
  <summary>Details</summary>
Motivation: To explore the existence and detectability of nova remnants in the GC's harsh environment, which is heavily obscured by extinction and has a low nova occurrence rate, providing insights into the GC's stellar population and ecosystem.

Method: The authors performed hydrodynamical simulations of nova remnants under GC conditions (hot, dense ISM), generated 79 models varying ejecta mass and velocity, calculated time-dependent multiwavelength emissions, and estimated detectability using existing observational data from Chandra, VLA, and HST. They also estimated detection probabilities by referencing the CV population in the nuclear star cluster.

Result: 6, 44, and 51 models showed detectability in X-ray, radio, and Paschen-α bands respectively, with peak luminosities of ~1e32, ~1e31, and ~1e36 erg/s. Detection windows range from weeks to centuries. The probabilities of detecting at least one remnant are 20%, 8%, and 18% in respective bands.

Conclusion: Nova remnants in the GC are potentially detectable, especially in X-rays, with future facilities like JWST, AXIS, and SKA enhancing detection prospects. This study underscores the value of multiwavelength observational campaigns for understanding GC stellar evolution and nova populations.

Abstract: Thousands of X-ray sources have been detected in the Galactic center (GC), most believed to be cataclysmic variables (CVs). As a potential probe of the old stellar population, in particular CVs, the existence and detectability of novae in the GC remain elusive, due to the prohibitive extinction toward the GC and their relatively low occurrence rate. Nova remnants evolving in the characteristic hot ($T\sim{10^{6}~\rm K}$) and dense ($n_e\sim{10~\rm cm^{-3}}$) interstellar medium in the GC may shed light on recent novae and provide useful insight on the GC ecosystem. In this work, we perform hydrodynamical simulations of putative nova remnants in the GC environment and calculate their time-dependent multiwavelength emission to estimate the detectability. Among 79 models sampling the nova parameter space (primarily ejecta mass and velocity), 6, 44, and 51 modelled nova remnants are detectable at their X-ray, radio, and Paschen-$α$ maximum, respectively, for existing {\it Chandra}, VLA, and HST observations of the GC. The predicted peak luminosities are $\sim10^{32}~\rm erg~s^{-1}$, $\sim10^{31}~\rm erg~s^{-1}$, and $\sim10^{36}~\rm erg~s^{-1}$ in these three bands and the detectable window ranges from weeks to notably hundred years. By specifying a CV population of the nuclear star cluster, we estimate the probability of detecting at least one remnant to be 20\%, 8\%, and 18\% in X-rays, radio, and Pa$α$. The nova remnant would be best resolved in the X-ray band. Our study highlights the potential for detecting nova remnants through further observations, leveraging JWST and the potentially forthcoming AXIS and SKA.

</details>


### [42] [Classification of the equation of state of neutron stars via sparse dictionary learning](https://arxiv.org/abs/2512.16441)
*Miquel Llorens-Monteagudo,Alejandro Torres-Forné,José A. Font*

Main category: astro-ph.HE

TL;DR: This paper uses a sparse dictionary learning framework (CLAWDIA) to classify neutron star equation of state models based on post-merger gravitational-wave signals from simulated BNS mergers, achieving high classification accuracy with third-generation detectors like ET and NEMO.


<details>
  <summary>Details</summary>
Motivation: To leverage post-merger gravitational-wave data from future detectors for EOS classification, addressing the challenge of extracting EOS information due to current detector limitations and high-frequency signal requirements.

Method: The CLAWDIA SDL framework is applied toCoRe database simulations of five EOS models. Signals are injected into ET and NEMO noise models. Classification focuses on the dominant post-merger frequency f₂, which carries EOS-dependent information.

Result: Achieved F₁ scores of 0.76 (ET) and 0.70 (NEMO) at SNR=5, improving with higher SNR. Successfully classified an unseen EOS and assessed detector biases, demonstrating robustness.

Conclusion: CLAWDIA enables effective EOS classification using post-merger signals, proving valuable for future detector data analysis to constrain neutron star matter properties.

Abstract: The post-merger phase of binary neutron star (BNS) mergers encodes valuable information about the equation of state (EOS) of supranuclear matter. Extracting this information from the analysis of the post-merger waveforms remains challenging due to the high-frequency limitations of current detectors. Future third-generation observatories, such as the Einstein Telescope (ET) and NEMO, will have the sensitivity required to resolve post-merger signals with high fidelity. In this work, we apply CLAWDIA, our recently developed sparse dictionary learning (SDL) framework, to classify different EOS models using only the post-merger gravitational-wave emission of simulated BNS mergers available in the CoRe database. Our dataset comprises five EOS models representative of a broad range of neutron star properties. The SDL framework is optimised under realistic detection conditions by injecting signals into simulated noise matching the sensitivity curves of ET and NEMO. Our results show that classification is primarily driven by the dominant post-merger frequency, $f_2$, which encodes EOS-dependent information. At a modest signal-to-noise ratio of 5, our method achieves $F_1$ scores of $0.76$ for ET and $0.70$ for NEMO, with performance improving for higher signal-to-noise ratios. The reliability and generalisation capabilities of the model are assessed with additional tests, including the classification of an EOS not included in the training dataset and the analysis of detector-specific biases.

</details>


### [43] [XMM-Newton multi-year campaign on NGC 55 ULX-1: Resolving the wind and its variability with RGS](https://arxiv.org/abs/2512.16522)
*C. Pinto,S. Caserta,F. Barra,Y. Xu,D. Barret,P. Kosec,N. La Palombara,A. Marino,F. Pintore,A. Riggio,T. P. Roberts,C. Salvaggio,L. Sidoli,R. Soria,D. J. Walton*

Main category: astro-ph.HE

TL;DR: The study confirms the presence of powerful winds in the ULX source NGC 55 ULX-1, linking wind properties to spectral variability and accretion processes through high-resolution X-ray spectroscopy.


<details>
  <summary>Details</summary>
Motivation: To understand ULX wind properties and their connection with the source's spectral and temporal behavior, crucial for modeling XRB evolution at high accretion rates.

Method: High-resolution XMM-Newton X-ray spectroscopy of NGC 55 ULX-1 across different epochs, optically-thin plasma modeling, and parameter space exploration to analyze emission/absorption lines.

Result: Confirmed classical XRB disc winds via photoionisation signatures, slow-cool emission and mildly relativistic absorption features. Wind variability correlates with continuum changes, indicating sensitivity to accretion dynamics.

Conclusion: ULX winds are powerful, radiatively-driven, and dynamically linked to accretion changes, offering insights into XRB evolution and ULX source nature via continuous spectral monitoring.

Abstract: Winds are an important ingredient in the evolution of X-ray binary (XRB) systems, particularly those at high accretion rates such as ultra-luminous X-ray sources (ULXs), because they may regulate the accretion of matter onto the compact object. We aim at understanding the properties of ULX winds and their link with the source spectral and temporal behavior. We performed high-resolution X-ray spectroscopy of the variable source NGC 55 ULX-1 to resolve emission and absorption lines as observed with XMM-Newton at different epochs. Optically-thin plasma models are used to characterise the wind. We confirmed and thoroughly strengthened previous evidence of outflows in NGC 55 ULX-1. The presence of radiative recombination signatures and the ratios between the fluxes of the emission lines favours photoionisation balance and low-to-moderate densities, which confirm that the lines originate from classical XRB disc winds. An in-depth parameter space exploration shows line emission from a slowly moving, cool, and variable plasma perhaps associated with a thermal wind. Mildly-relativistic Doppler shifts (about -0.15c) associated with the absorption lines confirm, at higher confidence, the presence of powerful, radiatively-driven, winds. The comparison between results obtained at different epochs revealed that the wind responds to the variability of the underlying continuum and these variations may be used to understand the actual accretion regime and the nature of the source.

</details>


### [44] [Pulsar B1237+25 at 111~MHz: average profile, mode switching, nullings, microstructure](https://arxiv.org/abs/2512.16526)
*M. V. Popov,T. V. Smirnova*

Main category: astro-ph.HE

TL;DR: This paper presents the first detection of a new central component in the pulsar B1237+25's average profile using 111 MHz observations. It explores emission mechanisms, radiation modes (O-mode/X-mode), and derives heights of radiation regions (80 km vs 370 km). Microstructure timescales (≤0.5 μs) suggest spark discharge interactions in the pulsar's magnetosphere, with constraints on plasma parameters.


<details>
  <summary>Details</summary>
Motivation: To investigate the structure and emission mechanisms of pulsar B1237+25, particularly focusing on new components detected in its average profile and the relationship between different radiation modes (O-mode/X-mode) in the context of pulsar magnetosphere physics.

Method: Analysis of 111 MHz observational data to identify emission components across QN, FN, and AB modes. Measured radiation component separation vs frequency dependence. Calculated radiation heights using timing parameters and plasma properties (e.g., γ-factor constraints via trailing edge analysis).

Result: Discovered a new central component visible in all emission modes. Identified O-mode (outer/inner cones) and X-mode (central components) radiation mode associations. Derived radiation heights of 80 km (X-mode) and 370 km (O-mode). Found microstructure timescales matching spark discharges and vacuum gap height constraints. Established power law exponent (-0.16) for component separation frequency dependence.

Conclusion: The pulsar's emission structure comprises distinct O-mode and X-mode components with different radiation heights, suggesting separate emission regions. The microstructure observations support a spark discharge model in the polar cap. The frequency-dependent component spacing implies common physical processes governing both cone structures, consistent with pulsar magnetospheric dynamics theories.

Abstract: The observations of B1237+25 at a frequency of 111 MHz were analyzed. For the first time in the normal radiation mode a new component in the central region in the average profile was detected. This component is manifested in all modes of pulsar emission: quiet-normal (QN), flare-normal (FN) and in the abnormal mode (AB). The subpulse drift is observed in the QN mode only in the first and last components of the average profile. The normal mode is interrupted by nullings and transitions into the abnormal AB mode. In the AB mode, the structure at the edge of the outer cone is destroyed, the distance between the inner and outer cones is almost doubled, and the distance between the inner cone and the central region is reduced.Analysis of our data has shown that the components of the outer and inner cones of the average profile are formed by an ordinary mode of radio emission (O-mode) and form a single cone radiation of the pulsar. The central components of the average profile (wide and narrow) are formed by an extraordinary mode (X-mode). Estimates of the height of the radiation output from the central region (X-mode) and the cone radiation (O-mode) are obtained: 80~km and 370~km, respectively. A microstructure with a time scale of $τ_μ\le0.5$~$μs$ has been detected. This time scale corresponds well to the time of the development of a spark discharge in the polar cap. For this value $τ_μ$, the height of the vacuum gap should be $h_p\le750$~cm. Based on the steepness of the individual pulse's trailing edge at the longitude of the first component, a limit was obtained on the value of the $γ$ factor of the relativistic secondary plasma: $γ\ge$260. The dependence of the distance between the components of the outer and inner cone of radiation on the frequency is the same and corresponds to a power law with an exponent of -0.16.

</details>


### [45] [Double shell structure in supernova 2024ggi](https://arxiv.org/abs/2512.16554)
*Kobi Shiran,Noam Soker*

Main category: astro-ph.HE

TL;DR: The paper presents a two-shell model for core-collapse supernova (CCSN) ejecta that explains the evolution of the photospheric radius in SN 2024ggi, showing a transition from concave to convex behavior. This structure aligns with the jittering jets explosion mechanism (JJEM) and provides evidence against the neutrino-driven mechanism.


<details>
  <summary>Details</summary>
Motivation: To explain the observed transition in the photospheric radius (Rph(t)) behavior of SN 2024ggi and support the JJEM as a primary CCSN mechanism, given discrepancies with single-shell models and compatibility with jet-induced ejecta structures seen in other remnants.

Method: A toy model with two shells—an outer spherical (S-shell) and inner elongated (E-shell)—was constructed to simulate the photospheric evolution. The model tracks how the photosphere transitions from the outer shell to the inner elongated shell, affecting Rph(t) curvature.

Result: The model reproduces the observed concave-to-convex transition in Rph(t). The elongated inner shell's contribution explains the increased photospheric growth rate later, consistent with SN 2024ggi and previous studies like SN 2023ixf, supporting the JJEM over neutrino-driven mechanisms.

Conclusion: The findings strengthen the case that the JJEM, involving multiple jet pairs, is the dominant mechanism for CCSNe explosions, as the observed ejecta structures align better with jet-induced asymmetries than traditional models.

Abstract: We built a simple toy model of a core-collapse supernova (CCSN) ejecta composed of two shells, an outer low-mass spherical shell and an inner elongated massive shell, and show that it can reproduce the evolution of the photospheric radius of SN 2024ggi, Rph(t). During the first week, the larger spherical shell, the S-shell, forms the photosphere. As the shell expands and becomes increasingly transparent, the photosphere moves inward along the mass coordinate, although it grows in size. When the photosphere reaches the long axis of the elongated inner shell, the E-shell begins to contribute to the photosphere, ultimately comprising the entire photosphere. The simple toy model explains the transition of Rph(t) from being concave (decreasing slope) to convex (increasing slope). A single-shell model predicts only concave behavior. The structure of a spherical shell with an inner elongated shell is motivated by the morphologies of several CCSN remnants whose structures have been attributed to multiple pairs of jets in the framework of the jittering jets explosion mechanism (JJEM). The deduced multiple-shell ejecta of SN 2024ggi in this study, and of SN 2023ixf in an earlier study, as well as studies of the polarization of SN 2024ggi, are better compatible with the JJEM than with the neutrino-driven mechanism. Our study supports the growing evidence that the JJEM is the primary explosion mechanism of CCSNe.

</details>


### [46] [A finite temperature framework for quark matter with color-superconducting phases](https://arxiv.org/abs/2512.16720)
*Hosein Gholami,Marco Hofmann,Débora Mroczek,Jacquelyn Noronha-Hostler*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Current observations of neutron stars and measurements of gravitational waves only provide constraints on the zero temperature ($T=0$) equation of state (EoS) of dense matter. The detection of the post-merger gravitational-wave signal from a binary neutron star merger would additionally provide access to finite-temperature properties of the EoS which contain more information about the composition and the interactions of dense matter than the cold EoS alone. In particular deconfined quark matter may be probed by its characteristic finite temperature effects. This is especially the case for color-superconducting phases, in which the quasiparticle contribution to the thermal pressure is exponentially suppressed at low temperatures. Here we develop a new finite $T$ framework to model the thermal EoS for dense quark matter based on the cold quark matter EoS which is useful for numerical relativity simulations. We test the validity of the framework against a three-flavor NJL mean-field calculation, both with and without diquark pairing. We find that even for the complicated phase diagram of the NJL model including multiple different phases the framework is accurate to the few percent level for temperatures up to $T\sim 50\,$MeV.

</details>


### [47] [Prompt Searches for Very-High-Energy γ-Ray Counterparts to IceCube Astrophysical Neutrino Alerts](https://arxiv.org/abs/2512.16562)
*J. Abhir,A. Biland,K. Brand,T. Bretz,D. Dorner,L. Eisenberger,D. Elsaesser,P. Günther,S. Hasan,D. Hildebrand,K. Mannheim,M. Linhoff,F. Pfeifle,W. Rhode,B. Schleicher,V. Sliusar,M. Vorbrugg,R. Walter,F. Aharonian,F. Ait Benkhali,J. Aschersleben,H. Ashkar,M. Backes,V. Barbosa Martins,R. Batzofin,Y. Becherini,D. Berge,M. Böttcher,C. Boisson,J. Bolmont,J. Borowska,R. Brose,A. Brown,F. Brun,B. Bruno,S. Casanova,J. Celic,M. Cerruti,A. Chen,M. Chernyakova,J. Chibueze,O. Chibueze,B. Cornejo,G. Cotter,G. Cozzolongo,J. Damascene Mbarubucyeye,J. de Assis Scarpin,A. Delgado Giles,A. Djannati-Ataï,J. Djuvsland,A. Dmytriiev,K. Egberts,K. Egg,S. Einecke,J. -P. Ernenwein,C. Escañ,K. Feijen,M. Filipovic,G. Fontaine,S. Funk,S. Gabici,J. F. Glicenstein,P. Goswami,G. Grolleron,B. Heß,J. A. Hinton,M. Holler,M. Jamrozy,F. Jankowsky,I. Jung-Richardt,E. Kasai,K. Katarzyń,H. Katjaita,D. Kerszberg,R. Khatoon,B. Khélifi,W. Kluź,Nu. Komin,R. Konno,K. Kosack,D. Kostunin,G. Kukec Mezek,R. G. Lang,A. Lemière,M. Lemoine-Goumard,J. -P. Lenain,A. Luashvili,J. Mackey,V. Marandon,G. Martí-Devesa,R. Marx,M. Mayer,A. Mehta,A. Mitchell,R. Moderski,M. O. Moghadam,L. Mohrmann,E. Moulin,M. de Naurois,J. Niemiec,E. de Ona Wilhelmi,S. Panny,M. Panter,R. D. Parsons,U. Pensec,P. Pichard,G. Pühlhofer,M. Punch,A. Quirrenbach,M. Regeard,O. Reimer,H. Ren,F. Rieger,G. Rowell,B. Rudak,K. Sabri,V. Sahakian,H. Salzmann,M. Sasaki,J. Schäfer,F. Schüssler,H. M. Schutte,M. Senniappan,J. N. S. Shapopi,A. Sharma,H. Sol,S. Spencer,Ł.,R. Steenkamp,S. Steinmassl,C. Steppa,T. Takahashi,T. Tanaka,A. M. Taylor,M. Tsirou,C. van Eldik,M. Vecchi,C. Venter,J. Vink,T. Wach,S. J. Wagner,A. Wierzcholska,M. Zacharias,A. A. Zdziarski,A. Zech,N. Żywucka,S. Abe,J. Abhir,A. Abhishek,A. Aguasca-Cabot,I. Agudo,T. Aniello,S. Ansoldi,L. A. Antonelli,A. Arbet Engels,C. Arcaro,M. Artero,K. Asano,A. Babić,C. Bakshi,U. Barres de Almeida,J. A. Barrio,L. Barrios-Jiménez,I. Batković,J. Baxter,J. Becerra González,W. Bednarek,E. Bernardini,J. Bernete,A. Berti,J. Besenrieder,C. Bigongiari,A. Biland,O. Blanch,H. Bökenkamp,G. Bonnoli,Ž,E. Bronzini,I. Burelli,A. Campoy-Ordaz,A. Carosi,R. Carosi,M. Carretero-Castrillo,A. J. Castro-Tirado,D. Cerasole,G. Ceribella,Y. Chai,A. Chilingarian,A. Cifuentes,J. L. Contreras,J. Cortina,S. Covino,G. D'Amico,P. Da Vela,F. Dazzi,A. De Angelis,B. De Lotto,M. Delfino,C. Delgado Mendez,F. Di Pierro,R. Di Tria,L. Di Venere,A. Dinesh,D. Dominis Prester,A. Donini,D. Dorner,M. Doro,L. Eisenberger,D. Elsaesser,J. Escudero,L. Fariña,A. Fattorini,L. Foffano,L. Font,S. Fröse,Y. Fukazawa,S. Gasparyan,M. Gaug,J. G. Giesbrecht Paiva,N. Giglietto,F. Giordano,P. Gliwny,N. Godinović,T. Gradetzke,R. Grau,D. Green,J. G. Green,P. Günther,D. Hadasch,A. Hahn,T. Hassan,L. Heckmann,D. Hrupec,R. Imazawa,D. Israyelyan,I. Jiménez Martínez,J. Jiménez Quiles,J. Jormanainen,S. Kankkunen,T. Kayanoki,D. Kerszberg,J. Konrad,P. M. Kouch,H. Kubo,J. Kushida,M. Láinez,A. Lamastra,E. Lindfors,S. Lombardi,F. Longo,R. López-Coto,M. López-Moya,A. López-Oramas,S. Loporchio,L. Lulić,E. Lyard,P. Majumdar,M. Makariev,M. Mallamaci,G. Maneva,M. Manganaro,S. Mangano,S. Marchesi,M. Mariotti,M. Martínez,P. Maruš,A. Mas-Aguilar,D. Mazin,S. Menchiari,J. Méndez Gallego,D. Miceli,J. M. Miranda,R. Mirzoyan,M. Molero González,E. Molina,H. A. Mondal,A. Moralejo,T. Nakamori,C. Nanci,V. Neustroev,M. Nievas Rosillo,C. Nigro,L. Nikolić,K. Nilsson,K. Nishijima,K. Noda,S. Nozaki,A. Okumura,J. Otero-Santos,S. Paiano,D. Paneque,J. M. Paredes,M. Peresano,M. Persic,M. Pihet,F. Podobnik,P. G. Prada Moroni,E. Prandini,M. Ribó,J. Rico,T. Saito,S. Sakurai,K. Satalecka,F. G. Saturni,K. Schmitz,F. Schmuckermaier,J. L. Schubert,A. Sciaccaluga,G. Silvestri,J. Sitarek,V. Sliusar,D. Sobczynska,A. Stamerra,J. Striš,D. Strom,M. Strzys,Y. Suda,H. Tajima,M. Takahashi,R. Takeishi,P. Temnikov,K. Terauchi,T. Terzić,A. Tutone,S. Ubach,J. van Scherpenberg,M. Vazquez Acosta,S. Ventura,G. Verna,I. Viale,A. Vigliano,C. F. Vigorito,E. Visentin,V. Vitale,I. Vovk,R. Walter,F. Wersig,M. Will,T. Yamamoto,P. K. H. Yeung,S. Yoo,A. Acharyya,A. Archer,P. Bangale,J. T. Bartkoske,W. Benbow,J. H. Buckley,Y. Chen,J. L. Christiansen,A. J. Chromey,M. Errando,S. Feldman,Q. Feng,S. Filbert,L. Fortson,A. Furniss,W. Hanlon,O. Hervet,C. E. Hinrichs,J. Holder,Z. Hughes,T. B. Humensky,W. Jin,M. N. Johnson,P. Kaaret,M. Kertzman,M. Kherlakian,D. Kieda,T. K. Kleiner,N. Korzoun,M. J. Lang,M. Lundy,G. Maier,M. J. Millard,J. Millis,P. Moriarty,R. Mukherjee,W. Ning,R. A. Ong,A. Pandey,M. Pohl,J. Quinn,P. L. Rabinowitz,K. Ragan,P. T. Reynolds,D. Ribeiro,E. Roache,I. Sadeh,A. C. Sadun,L. Saha,M. Santander,G. H. Sembroski,R. Shang,D. Tak,A. K. Talluri,J. V. Tucci,J. Valverde,V. V. Vassiliev,D. A. Williams,S. L. Wong,S. Buson,R. Abbasi,M. Ackermann,J. Adams,S. K. Agarwalla,J. A. Aguilar,M. Ahlers,J. M. Alameddine,S. Ali,N. M. Amin,K. Andeen,C. Argü,Y. Ashida,S. Athanasiadou,S. N. Axani,R. Babu,X. Bai,J. Baines-Holmes,A. Balagopal V.,S. W. Barwick,S. Bash,V. Basu,R. Bay,J. J. Beatty,J. Becker Tjus,P. Behrens,J. Beise,C. Bellenghi,B. Benkel,S. BenZvi,D. Berley,E. Bernardini,D. Z. Besson,E. Blaufuss,L. Bloom,S. Blot,I. Bodo,F. Bontempo,J. Y. Book Motzkin,C. Boscolo Meneguolo,S. Bö,O. Botner,J. Bö,J. Braun,B. Brinson,Z. Brisson-Tsavoussis,R. T. Burley,D. Butterfield,M. A. Campana,K. Carloni,J. Carpio,S. Chattopadhyay,N. Chau,Z. Chen,D. Chirkin,S. Choi,B. A. Clark,A. Coleman,P. Coleman,G. H. Collin,D. A. Coloma Borja,A. Connolly,J. M. Conrad,D. F. Cowen,C. De Clercq,J. J. DeLaunay,D. Delgado,T. Delmeulle,S. Deng,P. Desiati,K. D. de Vries,G. de Wasseige,T. DeYoung,J. C. Dí,S. DiKerby,T. Ding,M. Dittmer,A. Domi,L. Draper,L. Dueser,D. Durnford,K. Dutta,M. A. DuVernois,T. Ehrhardt,L. Eidenschink,A. Eimer,P. Eller,E. Ellinger,D. Elsä,R. Engel,H. Erpenbeck,W. Esmail,S. Eulig,J. Evans,P. A. Evenson,K. L. Fan,K. Fang,K. Farrag,A. R. Fazely,A. Fedynitch,N. Feigl,C. Finley,L. Fischer,D. Fox,A. Franckowiak,S. Fukami,P. Fü,J. Gallagher,E. Ganster,A. Garcia,M. Garcia,G. Garg,E. Genton,L. Gerhardt,A. Ghadimi,C. Glaser,T. Glü,J. G. Gonzalez,S. Goswami,A. Granados,D. Grant,S. J. Gray,S. Griffin,S. Griswold,K. M. Groth,D. Guevel,C. Gü,P. Gutjahr,C. Ha,C. Haack,A. Hallgren,L. Halve,F. Halzen,L. Hamacher,M. Ha Minh,M. Handt,K. Hanson,J. Hardin,A. A. Harnisch,P. Hatch,A. Haungs,J. Hä,K. Helbing,J. Hellrung,B. Henke,L. Hennig,F. Henningsen,L. Heuermann,R. Hewett,N. Heyer,S. Hickford,A. Hidvegi,C. Hill,G. C. Hill,R. Hmaid,K. D. Hoffman,D. Hooper,S. Hori,K. Hoshina,M. Hostert,W. Hou,M. Hrywniak,T. Huber,K. Hultqvist,K. Hymon,A. Ishihara,W. Iwakiri,M. Jacquart,S. Jain,O. Janik,M. Jansson,M. Jeong,M. Jin,N. Kamp,D. Kang,W. Kang,X. Kang,A. Kappes,L. Kardum,T. Karg,M. Karl,A. Karle,A. Katil,M. Kauer,J. L. Kelley,M. Khanal,A. Khatee Zathul,A. Kheirandish,H. Kimku,J. Kiryluk,C. Klein,S. R. Klein,Y. Kobayashi,A. Kochocki,R. Koirala,H. Kolanoski,T. Kontrimas,L. Kö,C. Kopper,D. J. Koskinen,P. Koundal,M. Kowalski,T. Kozynets,A. Kravka,N. Krieger,J. Krishnamoorthi,T. Krishnan,K. Kruiswijk,E. Krupczak,A. Kumar,E. Kun,N. Kurahashi,N. Lad,C. Lagunas Gualda,L. Lallement Arnaud,M. Lamoureux,M. J. Larson,F. Lauber,J. P. Lazar,K. Leonard DeHolton,A. Leszczyń,J. Liao,C. Lin,Y. T. Liu,M. Liubarska,C. Love,L. Lu,F. Lucarelli,W. Luszczak,Y. Lyu,M. Macdonald,J. Madsen,E. Magnus,Y. Makino,E. Manao,S. Mancina,A. Mand,I. C. Mariş,S. Marka,Z. Marka,L. Marten,I. Martinez-Soler,R. Maruyama,J. Mauro,F. Mayhew,F. McNally,J. V. Mead,K. Meagher,S. Mechbal,A. Medina,M. Meier,Y. Merckx,L. Merten,J. Mitchell,L. Molchany,S. Mondal,T. Montaruli,R. W. Moore,Y. Morii,A. Mosbrugger,M. Moulai,D. Mousadi,E. Moyaux,T. Mukherjee,R. Naab,M. Nakos,U. Naumann,J. Necker,L. Neste,M. Neumann,H. Niederhausen,M. U. Nisa,K. Noda,A. Noell,A. Novikov,A. Obertacke,V. O'Dell,A. Olivas,R. Orsoe,J. Osborn,E. O'Sullivan,V. Palusova,H. Pandya,A. Parenti,N. Park,V. Parrish,E. N. Paudel,L. Paul,C. Pé,T. Pernice,T. C. Petersen,J. Peterson,M. Plum,A. Ponté,V. Poojyam,Y. Popovych,M. Prado Rodriguez,B. Pries,R. Procter-Murphy,G. T. Przybylski,L. Pyras,C. Raab,J. Rack-Helleis,N. Rad,M. Ravn,K. Rawlins,Z. Rechav,A. Rehman,I. Reistroffer,E. Resconi,S. Reusch,C. D. Rho,W. Rhode,L. Ricca,B. Riedel,A. Rifaie,E. J. Roberts,M. Rongen,A. Rosted,C. Rott,T. Ruhe,L. Ruohan,D. Ryckbosch,J. Saffer,D. Salazar-Gallegos,P. Sampathkumar,A. Sandrock,G. Sanger-Johnson,M. Santander,S. Sarkar,J. Savelberg,M. Scarnera,P. Schaile,M. Schaufel,H. Schieler,S. Schindler,L. Schlickmann,B. Schlü,F. Schlü,N. Schmeisser,T. Schmidt,F. G. Schrö,L. Schumacher,S. Schwirn,S. Sclafani,D. Seckel,L. Seen,M. Seikh,S. Seunarine,P. A. Sevle Myhr,R. Shah,S. Shefali,N. Shimizu,B. Skrzypek,R. Snihur,J. Soedingrekso,A. Sø,D. Soldin,P. Soldin,G. Sommani,C. Spannfellner,G. M. Spiczak,C. Spiering,J. Stachurska,M. Stamatikos,T. Stanev,T. Stezelberger,T. Stü,T. Stuttard,G. W. Sullivan,I. Taboada,S. Ter-Antonyan,A. Terliuk,A. Thakuri,M. Thiesmeyer,W. G. Thompson,J. Thwaites,S. Tilav,K. Tollefson,S. Toscano,D. Tosi,A. Trettin,A. K. Upadhyay,K. Upshaw,A. Vaidyanathan,N. Valtonen-Mattila,J. Valverde,J. Vandenbroucke,T. Van Eeden,N. van Eijndhoven,L. Van Rootselaar,J. van Santen,J. Vara,F. Varsi,M. Venugopal,M. Vereecken,S. Vergara Carrasco,S. Verpoest,D. Veske,A. Vijai,J. Villarreal,C. Walck,A. Wang,E. H. S. Warrick,C. Weaver,P. Weigel,A. Weindl,J. Weldert,A. Y. Wen,C. Wendt,J. Werthebach,M. Weyrauch,N. Whitehorn,C. H. Wiebusch,D. R. Williams,L. Witthaus,M. Wolf,G. Wrede,X. W. Xu,J. P. Yanez,Y. Yao,E. Yildizci,S. Yoshida,R. Young,F. Yu,S. Yu,T. Yuan,A. Zander Jurowitzki,A. Zegarelli,S. Zhang,Z. Zhang,P. Zhelnin,P. Zilberman,F. D'Ammando*

Main category: astro-ph.HE

TL;DR: The paper analyzes follow-up observations from imaging atmospheric Cherenkov telescopes (IACTs) to search for gamma-ray counterparts to high-energy neutrinos from 2017-2021. No significant associations were found between neutrinos and gamma-ray sources, improving upper limits on VHE gamma-ray flux.


<details>
  <summary>Details</summary>
Motivation: To advance the search for cosmic high-energy neutrino sources via multi-messenger astronomy. Motivated by the successful TXS 0506+056/IceCube-170922A detection, this study aims to find similar neutrino-gamma-ray correlations.

Method: The IACTs (FACT, H.E.S.S., MAGIC, VERITAS) conducted targeted observations of neutrino alert locations and nearby gamma-ray sources after IceCube neutrino clusters. Data from 2017-2021 was analyzed for temporal/spectral correlations and flux limits.

Result: No confirmed gamma-ray counterparts detected for observed neutrino events. Published individual and joint upper limits on VHE gamma-ray fluxes for targeted sources, contributing to the constraints on neutrino emission models.

Conclusion: Despite extensive searches, no clear multi-messenger connections found. Highlights need for improved detection sensitivity and persistent multi-messenger observations to identify rare or transient neutrino sources.

Abstract: The search for sources of high-energy astrophysical neutrinos can be significantly advanced through a multi-messenger approach, which seeks to detect the gamma rays that accompany neutrinos as they are produced at their sources. Multi-messenger observations have so far provided the first evidence for a neutrino source, illustrated by the joint detection of the flaring blazar TXS 0506+056 in highenergy (HE, E > 1 GeV) and very-high-energy (VHE, E > 100 GeV) gamma rays in coincidence with the high-energy neutrino IceCube-170922A, identified by IceCube. Imaging atmospheric Cherenkov telescopes (IACTs), namely FACT, H.E.S.S., MAGIC, and VERITAS, continue to conduct extensive neutrino target-of-opportunity follow-up programs. These programs have two components: followup observations of single astrophysical neutrino candidate events (such as IceCube-170922A), and observation of known gamma-ray sources after the identification of a cluster of neutrino events by IceCube. Here we present a comprehensive analysis of follow-up observations of high-energy neutrino events observed by the four IACTs between September 2017 (after the IceCube-170922A event) and January 2021. Our study found no associations between gamma-ray sources and the observed neutrino events. We provide a detailed overview of each neutrino event and its potential counterparts. Furthermore, a joint analysis of all IACT data is included, yielding combined upper limits on the VHE gamma-ray flux.

</details>


### [48] [A Tidal Disruption Event from an Intermediate-mass Black Hole Revealed by Comprehensive Multi-wavelength Observations](https://arxiv.org/abs/2512.16568)
*Jialai Wang,Mengqiu Huang,Yongquan Xue,Ning Jiang,Shifeng Huang,Yibo Wang,Jiazheng Zhu,Shifu Zhu,Lixin Dai,Chichuan Jin,Bin Luo,Xinwen Shu,Mouyuan Sun,Tinggui Wang,Fan Zou*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Tidal disruption events (TDEs) occur when a star crosses the tidal radius of a black hole (BH) and is ripped apart, providing a novel and powerful way to probe dormant BHs over a wide mass range. In this study, we present our late-time observations and comprehensive multi-wavelength analyses of an extraordinary TDE at the center of a dwarf galaxy, which exhibited successive flares in the optical, X-ray, and radio bands. Notably, we discovered an unexpected high-state X-ray plateau phase following the peak until the present time. Along with its reported prolonged rise lasting at least 550 days, these unique characteristics are consistent with the scenario of a TDE caused by an intermediate-mass black hole (IMBH) with a mass of approximately $(1-6) \times 10^5$ solar masses. Furthermore, scaling relations derived from the host-galaxy properties indicated a similar BH mass in concert. This discovery highlights the invaluable role of TDEs in the search for elusive IMBHs.

</details>


### [49] [Cygnus X-3: A variable petaelectronvolt gamma-ray source](https://arxiv.org/abs/2512.16638)
*LHAASO Collaboration*

Main category: astro-ph.HE

TL;DR: The discovery of variable γ-rays up to PeV energies from Cygnus X-3 using LHAASO, suggesting proton acceleration in relativistic jets of X-ray binaries.


<details>
  <summary>Details</summary>
Motivation: To explore the origin and production mechanisms of ultra-high energy gamma-rays in binary systems.

Method: Detection of γ-rays using LHAASO with high statistical significance, analysis of spectral energy distribution accounting for cosmic microwave background absorption, and evaluation of month-scale variability and orbital modulation.

Result: Observed PeV γ-rays with significant signal, spectral rise toward 1 PeV, month-scale variability, and possible orbital modulation linked to the binary system's jet.

Conclusion: PeV γ-rays likely originate from photomeson processes in Cygnus X-3's relativistic jet, requiring proton acceleration to tens of PeV energies.

Abstract: We report the discovery of variable $γ$-rays up to petaelectronvolt from Cygnus X-3, an iconic X-ray binary.The $γ$-ray signal was detected with a statistical significance of approximately 10 $σ$ by the Large High Altitude Air Shower Observatory (LHAASO).Its intrinsic spectral energy distribution (SED), extending from 0.06 to 3.7 PeV, shows a pronounced rise toward 1 PeV after accounting for absorption by the cosmic microwave background radiation.The detected month-scale variability,together with a 3.2$σ$ evidence for orbital modulation, suggests that the PeV $γ$-rays originate within, or in close proximity to, the binary system itself.The observed energy spectrum and temporal modulation can be naturally explained by $γ$-ray production through photomeson processes in the innermost region of the relativistic jet, where protons need to be accelerated to tens of PeV energies.

</details>


### [50] [Einstein Probe Discovery of an X-ray Flare from K-type Star PM J23221-0301](https://arxiv.org/abs/2512.16679)
*Guoying Zhao,WeiKang Zheng,Rong-Feng Shen,Qingcang Shui,Dongyue Li,Chang Zhou,Tianci Zheng,Weimin Yuan,Chong Ge,Junfeng Wang,Alexei V. Filippenko,Thomas G. Brink,Jordan Forman,Mayra Gutierrez,Isabelle Jones,Ravjit Kaur,Naunet Leonhardes-Barboza,Petra Mengistu,Avi Patel,Andrew Skemer,Anavi Uppal,Nicole Wolff,Michele N. Woodland*

Main category: astro-ph.HE

TL;DR: The Einstein Probe detected an X-ray transient from a nearby K-type star, showing a strong flare with characteristic FRED light curve and energy release consistent with magnetic reconnection models, highlighting the probe's ability to study stellar activity.


<details>
  <summary>Details</summary>
Motivation: To understand the impact of stellar flares on planetary atmospheres and stellar magnetic activity, the study investigates a newly detected X-ray transient from a K-type star.

Method: The Einstein Probe detected the transient, followed by X-ray observations confirming flux enhancement and optical spectroscopy revealing variable H-alpha emission. Analysis included light curve fitting and energy correlation with magnetic-reconnection models.

Result: Observed a FRED light curve with specific timescales, peak luminosity 1.3×10^31 erg/s, and total energy 9.1×10^34 erg, aligning with magnetic-reconnection-driven flare correlations.

Conclusion: The detection demonstrates the Einstein Probe's efficacy in studying stellar magnetic activity through transient observations, providing insights into stellar flare effects on exoplanetary environments.

Abstract: Stellar flares are an intense stellar activity that can significantly impact the atmospheric composition of the surrounding planets and even the possible existence of life. During such events, the radiative energy of the star is primarily concentrated in the optical and X-ray bands, with the X-ray flux potentially increasing by tens or even hundreds of times. Einstein Probe (EP) detected a new X-ray transient EP J2322.1-0301 on 27 September 2024. Its spatial localization shows a high positional coincidence with the nearby high proper motion K-type star PM J23221-0301. Follow-up X-ray observations confirmed the flux enhancement of the source, while optical spectroscopic monitoring revealed time-variable features, particularly the disappearance of the H-alpha emission line. This X-ray flare is consistent with a characteristic fast-rise-exponential-decay (FRED) light curve, with a rise timescale of 1.4 ks, a decay timescale of 5.7 ks, and a total duration of about 7.1 ks. The peak luminosity in the 0.5-4.0 keV energy band reached about 1.3 x 10^31 erg s^-1, with a total energy release of about 9.1 x 10^34 erg, consistent with the empirical energy correlations observed in magnetic-reconnection-driven stellar flares, as inferred from the multitemperature plasma structure and H-alpha-X-ray energy correlation. This discovery underscores EP's capability in understanding stellar magnetic activity via observing stellar transients.

</details>


### [51] [Discovery of two new millisecond pulsars towards the Galactic bulge](https://arxiv.org/abs/2512.16699)
*J. Berteaud,F. Calore,M. Clavel,S. Dai,J. S. Deneva,S. Hyman,F. K. Schinzel,A. Ridolfi,S. M. Ransom,F. Abbate,C. J. Clark,M. Kramer,T. Thongmeearkom,B. W. Stappers,E. D. Barr,R. P. Breton*

Main category: astro-ph.HE

TL;DR: The paper reports the discovery of two new millisecond pulsars in the Galactic bulge using deep radio observations, doubling the number of such pulsars within 2 degrees of the Galactic center. These findings could help explain the Galactic Center Excess of gamma rays.


<details>
  <summary>Details</summary>
Motivation: To detect millisecond pulsars associated with the Galactic Center Excess by conducting deep radio pulsation searches towards X-ray candidate sources in the inner Galaxy.

Method: Deep radio observations and follow-up campaigns using telescopes like MeerKAT, Murriyang, and Green Bank towards 9 X-ray candidates identified by Chandra and Fermi. The study employs an innovative candidate selection method.

Result: Two new millisecond pulsars (including a black widow candidate) were detected: PSRs J1740-2805 and J1740-28. This doubles the known MSP population within the innermost 2 degrees of the Galactic center.

Conclusion: The discoveries support the hypothesis that a large population of faint millisecond pulsars in the Galactic bulge could explain the gamma-ray excess. Further observations are needed to confirm this and understand their contribution to the excess.

Abstract: The mysterious Galactic Center Excess of gamma rays could be explained by a large population of millisecond pulsars hiding in the Galactic bulge, too faint to be detected as individual high-energy point sources by the Fermi Large Area Telescope, as well as too fast and too dispersed to be detected in shallow radio pulsation surveys. Motivated by an innovative candidate selection method, we aim at detecting millisecond pulsars associated with the Galactic Center Excess by carrying deep radio pulsation searches towards promising candidates detected in the inner Galaxy, in X rays by Chandra, and in radio or gamma rays by the Very Large Array or Fermi. We conducted deep radio observation and follow-up campaigns with MeerKAT, the Murriyang and the Green Bank telescopes towards 9 X-ray candidate sources. We here report the detection of two new millisecond pulsars, including a black widow candidate, towards the Galactic bulge: PSRs J1740-2805 and J1740-28. These discoveries double the number of MSPs discovered within the innermost 2 degree from the Galactic center.

</details>


### [52] [Multiwavelength identification of millisecond pulsar candidates in the Galactic bulge](https://arxiv.org/abs/2512.16712)
*J. Berteaud,F. Calore,M. Clavel,J. Marvil,S. Hyman,F. K. Schinzel,M. Kerr*

Main category: astro-ph.HE

TL;DR: The paper identifies over a thousand X-ray sources as potential millisecond pulsar candidates in the Galactic bulge by analyzing their multiwavelength counterparts, with five showing radio signals in preliminary data.


<details>
  <summary>Details</summary>
Motivation: To address the discrepancy between the Fermi GeV excess suggesting bulge millisecond pulsars and the lack of radio detections, the study aims to find candidates using X-ray and multiwavelength data.

Method: Analyzing Chandra X-ray sources: excluding those with UV/optical/strong IR counterparts (indicative of non-pulsar sources) and selecting those with radio or faint IR counterparts. Cross-matching with unpublished VLA radio data.

Result: Identified ~1,000 X-ray sources as candidates, five of which show radio signals. Follow-up searches are ongoing.

Conclusion: Multiwavelength筛选 provides a robust method for pinpointing bulge millisecond pulsar candidates, offering targets for future radio observations to confirm their existence and explain the Fermi GeV excess.

Abstract: The existence of a population of millisecond pulsars in the Galactic bulge is supported, along with other evidence, by the Fermi GeV excess, an anomalous γ-ray emission detected almost 15 years ago in the direction of the Galactic center. However, radio surveys searching for pulsations have not yet revealed bulge millisecond pulsars. Identifying promising bulge millisecond pulsar candidates is key to motivating pointed radio pulsation searches. Candidates are often selected among steep-spectrum or polarized radio sources, but multiwavelength information can also be exploited: The aim of this work is to pinpoint strong candidates among the yet unidentified X-ray sources. We investigated the multiwavelength counterparts of sources detected by the Chandra X-ray observatory that have spectral properties expected for millisecond pulsars in the Galactic bulge. We considered that ultraviolet, optical, and strong infrared counterparts indicate that an X-ray source is not a bulge pulsar, while a radio or a faint infrared counterpart makes it a promising candidate. We identify a large population of more than a thousand X-ray sources without optical, ultraviolet, or strong infrared counterparts. Among them, five are seen for the first time in unpublished radio imaging data from the Very Large Array. We provide the list of promising candidates, for most of which follow-up pulsation searches are ongoing.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [53] [GRHayL: a modern, infrastructure-agnostic, extensible library for GRMHD simulations](https://arxiv.org/abs/2512.15846)
*Samuel Cupp,Leonardo R. Werneck,Terrence Pierre Jacques,Samuel Tootle,Zachariah B. Etienne*

Main category: gr-qc

TL;DR: GRHayL is a modular GRMHD library designed to facilitate multi-messenger astrophysics research by providing portable, reusable algorithms across diverse HPC platforms, enabling efficient code development and validation.


<details>
  <summary>Details</summary>
Motivation: The need to accurately interpret signals from neutron stars and black holes using GRMHD simulations is critical, but existing codes are infrastructure-specific, making verification and reuse difficult. This hindrance motivated the development of a通用, modular solution.

Method: GRHayL refactors the IllinoisGRMHD code into reusable pointwise/stencil kernels. It offers conservative-to-primitive recovery, reconstruction, flux/source operators, equations of state, and neutrino leakage routines through an interface compatible with frameworks like Einstein Toolkit and BlackHoles@Home.

Result: Successful portable implementation in two frameworks with minimal duplication. Validation via unit tests, Riemann problem comparisons, Tolman-Oppenheimer-Volkoff evolutions, and binary neutron-star merger simulations showed performance matching or exceeding legacy codes.

Conclusion: GRHayL enables rapid development, cross-code validation, and easier integration of new physics/compute architectures, addressing scalability/portability challenges in relativistic astrophysics simulations.

Abstract: Interpreting multi-messenger signals from neutron stars and black holes requires reliable general-relativistic magnetohydrodynamics (GRMHD) simulations across rapidly evolving high-performance-computing platforms, yet key algorithms are routinely rewritten within infrastructure-specific numerical-relativity codes, hindering verification and reuse. We present the General Relativistic Hydrodynamics Library (GRHayL), a modular, infrastructure-agnostic GR(M)HD library providing conservative-to-primitive recovery, reconstruction, flux/source and induction operators, equations of state, and neutrino leakage through an intuitive interface. GRHayL refactors and extends the mature IllinoisGRMHD code into reusable pointwise and stencil-wise kernels, enabling rapid development and cross-code validation in diverse frameworks, while easing adoption of new microphysics and future accelerators. We implement the same kernels in the Einstein Toolkit (Carpet and CarpetX) and BlackHoles@Home, demonstrating portability with minimal duplication. Validation combines continuous-integration unit tests with cross-infrastructure comparisons of analytic GRMHD Riemann problems, dynamical Tolman-Oppenheimer-Volkoff evolutions, and binary neutron-star mergers, showing comparable or improved behavior over legacy IllinoisGRMHD and established Einstein Toolkit codes.

</details>


### [54] [Particle Production by Time-Varying Dark Energy and the End of Cosmic Expansion](https://arxiv.org/abs/2512.15860)
*Nicolas Patino,Paul J. Steinhardt*

Main category: gr-qc

TL;DR: The paper explores how time-varying dark energy from a quintessence scalar field, with energy converted to particles, affects cosmic expansion dynamics. Thermal friction from particle production complicates distinguishing between different dark energy models, increases accelerated expansion duration, and delays the transition from expansion to contraction. Detection might be viable through thermal dark radiation signatures.


<details>
  <summary>Details</summary>
Motivation: To investigate the effects of particle production and thermal friction on quintessence-driven dark energy, aiming to clarify ambiguities in distinguishing between different cosmological models (steep vs flat potentials, cosmological constant) and to identify observational signatures for detecting transitions in cosmic expansion phases.

Method: The study analyzes scalar field evolution under energy conversion to particles, modeling thermal friction's impact on the field's acceleration and equation of state. It examines scenarios where the potential transitions from positive to negative, altering expansion dynamics, and evaluates detectability via thermal radiation backgrounds.

Result: Thermal friction prolongs accelerated expansion, obscures model distinctions, and delays contraction onset. However, particle production generates detectable thermal dark radiation (e.g., neutrinos) surpassing photon energy density, offering a potential observational signature.

Conclusion: While thermal effects complicate direct detection of quintessence models, alternative detection methods via thermal radiation remnants are promising. Future observations of such radiation could distinguish between dark energy scenarios and confirm cosmic expansion phase transitions.

Abstract: We consider various possible consequences of time-varying dark energy due to a quintessence scalar field whose energy density is partially converted to particles as the field evolves down its potential. This particle production acts as a source of thermal friction on the field that can make it difficult to distinguish whether dark energy is due to a radiating field rolling down a steep potential, a purely self-interacting field moving down a flatter potential, or a cosmological constant. By reducing the acceleration of the scalar field, thermal friction increases the amount of accelerated expansion and can cause a sizable bump in the quintessence equation of state. We take special interest in the case where a steep potential rapidly changes from positive to negative as the field evolves, resulting in the end of cosmic expansion and the beginning of contraction. Even in this case, we find that thermal friction lengthens the period of accelerated expansion and consequently delays the end of cosmic expansion, making it challenging to detect the impending transition to contraction using conventional cosmological tests. However, particle production can also provide alternative avenues for detection by generating a background of thermal dark radiation, partly comprised of neutrinos or other particles, whose energy density exceeds the remnant photon energy density.

</details>


### [55] [Modeling the frequency-domain ringdown amplitude of comparable-mass mergers with greybody factors](https://arxiv.org/abs/2512.15877)
*Romeo Felice Rosato,Sophia Yi,Emanuele Berti,Paolo Pani*

Main category: gr-qc

TL;DR: The paper presents a four-parameter model based on greybody factors that accurately predicts the ringdown signal after a binary black hole merger using SXS catalog waveforms, achieving high precision and laying groundwork for new tests of black hole physics.


<details>
  <summary>Details</summary>
Motivation: To improve the accuracy of post-merger ringdown signal modeling compared to existing models, which have higher mismatches, and to enable new consistency checks for black hole spectroscopy.

Method: Developed a four-parameter greybody factor model, tested it across a large set of comparable-mass, aligned-spin numerical relativity waveforms from the SXS catalog, and analytically fit model parameters to progenitor masses and spins.

Result: Achieved mismatches of ~1e-5, which is two orders of magnitude better than previous models, identified optimal initial frequencies for the model application, and provided analytical parameter fits.

Conclusion: The model enables precise ringdown tests, complementing traditional methods and supporting future gravitational-wave astronomy studies for verifying black hole properties.

Abstract: It was recently shown that, in a binary coalescence, the greybody factor of the remnant black hole modulates the post-merger ringdown signal. In this work, we demonstrate that a simple four-parameter model based on the greybody factor accurately reproduces the frequency-domain amplitude of a large set of comparable-mass, aligned-spin numerical relativity waveforms from the SXS catalog, achieving mismatches of order ${\cal O}(10^{-5})$ and improving existing models by roughly two orders of magnitude. We also identify the optimal initial frequency for applying the model in the frequency domain and provide analytical fits of the model parameters in terms of the progenitor masses and aligned spins. Our results pave the way for new consistency tests of the ringdown phase, complementary to traditional black hole spectroscopy.

</details>


### [56] [Excitation of scalar quasi-normal modes from boson clouds](https://arxiv.org/abs/2512.15878)
*Enrico Cannizzaro,Marco Palleschi,Laura Sberna,Richard Brito,Stephen Green*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Massive scalar fields on black hole backgrounds generally admit two families of modes: quasi-bound states (QBS) and quasinormal modes (QNM). We demonstrate the orthogonality between the two mode families with respect to a relativistic product. We also find that, although the two families appear on different Riemann sheets of the Green's function of massive scalar perturbations, they can be brought to a single sheet with an appropriate redefinition of the frequency variable. In this variable, it is more natural to see how both mode families can be excited by initial data, and to approximate the Green's function with saddle points. Finally, we investigate the QNM emission from boson clouds - the latter effectively consisting of a single QBS - driven by the tidal perturbation of a second compact object. We show that while the resonant emission of QNMs is generally suppressed, QNM transitions may be more prominent when the interaction with the perturber is non-resonant, such as in the dynamical capture of unbound objects, and when the perturber transits close to the light ring.

</details>


### [57] [Effective metric for binaries in framework of EOB theory to fifth PM order](https://arxiv.org/abs/2512.16098)
*Jiliang Jing,Weike Deng,Sheng Long*

Main category: gr-qc

TL;DR: The paper constructs an effective metric in the EOB theory for binary systems up to the fifth post-Minkowskian order, enabling a self-consistent theory for advanced gravitational wave detectors.


<details>
  <summary>Details</summary>
Motivation: To satisfy the precision requirements of third-generation gravitational wave detectors, which necessitate fifth-order PM accuracy, the EOB theory must be extended to higher PM orders through a unified effective metric approach.

Method: Develop a type D effective metric that allows derivation of decoupled, variable-separable equations for the null tetrad components of the perturbed Weyl tensor, facilitating fifth PM-order Hamiltonian, radiation reaction, and waveform calculations.

Result: Constructed EOB effective metric up to 5PM order with type D properties, enabling the formulation of decoupled equations essential for self-consistent binary system dynamics.

Conclusion: Successfully established foundational elements for a fifth-order EOB theory, advancing gravitational wave modeling for next-gen detectors through consistent PM-derived components.

Abstract: To establish a self-consistent effective one-body (EOB) theory that describes the dynamical evolution of binary systems based on the post-Minkowskian (PM) approximation, where the Hamiltonian, radiation reaction force, and waveforms are derived from an effective metric, the primary objective is to obtain the effective metric. Given that third generation gravitational wave detectors require at least fifth-order PM accuracy, in this paper we constructed an effective metric in the EOB theory of binaries up to fifth PM order. The effective metric is of type D, allowing for the derivation of decoupled and variable-separable equations for the null tetrad component of the gravitational perturbed Weyl tensor. This presents a basis for us to establish a self-consistent EOB theory up to 5PM order.

</details>


### [58] [Adiabatic Anisotropic Gravitational Collapse in Painlevé-Gullstrand Coordinates: A Geometric Analysis](https://arxiv.org/abs/2512.16104)
*G. Abellán,N. Bolívar,A. Alexandrova,I. Vasilev*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a detailed geometric analysis of adiabatic, anisotropic gravitational collapse formulated in a single Painlevé-Gullstrand coordinate system that covers both the interior and exterior, thereby eliminating cross-chart matching artifacts. Building on the Oppenheimer-Snyder framework with a phenomenologically motivated energy-density profile, we enforce the Israel junction conditions and obtain closed-form surface evolution. Within this unified chart we derive exact solutions for the complete collapse process, characterize the causal structure, and track horizon formation and evolution. In particular, we identify and analyse a double apparent-horizon phase inside the matter and show that the event horizon stabilizes at the Schwarzschild radius. We further obtain critical parameter relations that govern the dynamics, including a threshold linking initial compactness to immediate horizon formation. The model is geometrically self-consistent within Einstein's equations but exhibits violations of the standard point-wise energy conditions, highlighting known limitations of idealized anisotropic matter models and delineating the boundary where classical descriptions become inadequate. Together, these results provide geometric insights, compact analytic benchmarks and a didactic, coordinate-uniform perspective on collapse and horizon dynamics.

</details>


### [59] [Gravitational Effects of Sources Inspired by ideal Electromagnetic Fields in Spherical Painlevé-Gullstrand Coordinates](https://arxiv.org/abs/2512.16109)
*G. Abellán,N. Bolívar,I. Vasilev*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We construct and analyze a class of static spherically symmetric spacetimes in general relativity sourced exclusively by classical electrostatic configurations. Using a spherically symmetric Painlevé-Gullstrand-like metric with unit lapse and a radial shift function, we develop piecewise-defined solutions where the interior geometry is flat and the exterior is supported by several sources inspired by electromagnetic distributions. These include point-charge-like fields, Yukawa-screened electric fields, dielectric layers, and Hulthén-type field. The Einstein equations naturally impose a relation between the energy density and radial pressure, while the tangential pressure is derived from the metric. We systematically evaluate the classical energy conditions in each model and study the appearance of singular behavior using Israel junction conditions. This framework offers an analytically tractable setting to explore the gravitational effects of physically simple, well-understood sources without resorting to exotic matter.

</details>


### [60] [Unified dynamical system formulations for $f(R,φ,X)$ gravity with applications to nonminimal derivative coupling and $R^2$-Higgs inflation](https://arxiv.org/abs/2512.16176)
*Saikat Chakraborty,Sergio E. Jorás,Alberto Saa*

Main category: gr-qc

TL;DR: The paper presents two dynamical system approaches for analyzing $f(R,φ,X)$ gravity theories, applying them to a Non-Minimal Derivative Coupling (NMDC) model and a mixed $R^2$-Higgs inflation model. The first method partially succeeds with NMDC but struggles with fixed points, while the second method effectively handles the mixed inflation model, capturing expected submanifolds and dynamics.


<details>
  <summary>Details</summary>
Motivation: To explore viable dynamical system formulations for complex $f(R,φ,X)$ theories, ensuring accurate analysis of their phase spaces and fixed point structures, particularly in models combining different inflationary mechanisms.

Method: Two dynamical system formulations were applied: the first to a NMDC model without potential, identifying invariant submanifolds but failing to resolve non-hyperbolic fixed points; the second to a mixed $R^2$-Higgs model, successfully recovering individual phase spaces (R² and Higgs inflation) and correct invariant structures.

Result: The first formulation showed dynamics independent of NMDC coupling strength but couldn't fully analyze fixed points. The second method effectively modeled the mixed inflation scenario, providing phase portraits and validating expected behaviors under special cases.

Conclusion: While the first approach has limitations with non-hyperbolic fixed points, the second dynamical system formulation is robust for analyzing combined gravity models, confirming its utility for studying complex inflationary dynamics in $f(R,φ,X)$ theories.

Abstract: Two different dynamical system formulations are presented for the generic $f(R,φ,X)$ family of gravity theories. As illustrative examples, the first and the second formulation is applied to study the phase space of a toy model of the Non-Minimal Derivative Coupling (NMDC) without a potential, and the mixed $R^2$-Higgs inflation model, respectively. The first dynamical system formulation applied to the toy NMDC model, although able to identify several invariant submanifolds, fails to fully investigate the fixed point structure, as all the fixed points turn out to be non-hyperbolic. We, however, discover an interesting feature that the qualitative dynamics are independent of the coupling strength between the Ricci scalar and the scalar field derivative. The second dynamical system formulation applied to the mixed $R^2$-Higgs inflation model performs much better, being able to correctly reduce to the individual phase spaces of the $R^2$ and Higgs inflation separately in special cases, as well as correctly delivering the expected invariant submanifolds and fixed points. For the mixed $R^2$-Higgs case, illustrative phase portraits are provided for a somewhat better understanding of the dynamics.

</details>


### [61] [Back-action from inertial and non-inertial Unruh-DeWitt detectors revisited in covariant perturbation theory](https://arxiv.org/abs/2512.16217)
*Adam S. Wilkinson,Leo J. A. Parry,Jorma Louko,William G. Unruh*

Main category: gr-qc

TL;DR: The study examines the back-action of a pointlike detector on a quantum scalar field, focusing on stress-energy tensor expectations. It demonstrates that detector interactions split into deterministic and fluctuating components, with explicit calculations for inertial and accelerated detectors in Minkowski spacetime. Notably, accelerated detectors exhibit negative energy density regions near the Rindler horizon and far future.


<details>
  <summary>Details</summary>
Motivation: To understand the influence of particle detection on quantum fields without requiring measurement outcomes, ensuring localised interaction analysis using covariant methods instead of non-local decompositions.

Method: Utilizes second-order perturbation theory in curved spacetime QFT to compute the field's two-point function for a Gaussian Hadamard state. Analyzes a two-level Unruh-DeWitt detector, calculating renormalised stress-energy for both inertial and accelerated trajectories in Minkowski space.

Result: For accelerated detectors, negative energy density regions appear near the Rindler horizon and far future. Energy flux exchanges match detector transitions via Unruh effect. Inertial detectors only show outward energy flux from de-excitations.

Conclusion: The split of detector effects into deterministic and fluctuating parts holds under back-action. Acceleration produces unique negative energy regions, validating the robustness of covariant QFT methods for detector-field interactions without relying on particle counting.

Abstract: We investigate the back-action from a spatially pointlike particle detector on a quantum scalar field, as characterised by the expectation value of the field's stress-energy tensor, without conditioning on a measurement of the detector. First, assuming the field to be initially in a zero-mean Gaussian Hadamard state in a globally hyperbolic spacetime, we evaluate the field's two-point function in second-order perturbation theory by techniques of covariant curved spacetime quantum field theory, which allow a full control of the time and space localisation of the interaction, and do not rely on field mode decompositions or non-local particle countings. The detector's two-point function splits into a deterministic and a fluctuating part, and we show that this split is maintained in the back-action.
  We then specialise to a two-level Unruh-DeWitt detector, prepared in an energy eigenstate, for which the back-action is fully fluctuating. We compute the renormalised stress-energy tensor for a massless scalar field in $(3+1)$-dimensional Minkowski spacetime for a general detector trajectory, using the manifestly causal two-point function. We present explicit analytic and numerical results for an inertial detector and a uniformly linearly accelerated detector, switched on in the asymptotic past. The energy flux into and out of the accelerated detector accounts exactly for the energy gained and lost by the detector in its transitions due to the Unruh effect. The same holds for the outward flux associated with de-excitations of the inertial detector, which has a vanishing excitation rate and no inward flux. A novelty with the accelerated detector is two regions of negative energy density when the detector is initially prepared in its ground state, one near the Rindler horizon that bounds the causal future of the trajectory, the other in the far future of the trajectory.

</details>


### [62] [Gravitational wave interactions with a viscous fluid: Core collapse supernova, binary neutron star merger, and accretion around a black hole merger](https://arxiv.org/abs/2512.16253)
*Nigel T. Bishop,Vishnu Kakkat,Monos Naidoo*

Main category: gr-qc

TL;DR: The study extends previous analyses of gravitational wave (GW) interactions with viscous fluids to general static, spherically symmetric spacetimes, showing significantly enhanced damping and heating effects in certain astrophysical scenarios like core-collapse supernovae and binary neutron star mergers, potentially leading to complete signal damping and gamma-ray bursts.


<details>
  <summary>Details</summary>
Motivation: To address limitations of prior studies confined to Minkowski backgrounds and explore how non-vacuum spacetimes amplify GW-matter interactions, which could have observable astrophysical consequences.

Method: Extended perturbation analysis on general static, spherically symmetric spacetimes, derived expressions for GW damping and fluid heating, and applied computational models to specific astrophysical scenarios.

Result: Damping and heating effects increase compared to Minkowski cases, sometimes by orders of magnitude, with potential for complete GW signal suppression and gamma-ray burst generation.

Conclusion: GW-matter interactions in curved spacetimes are far more significant than previously thought, suggesting revisions to astrophysical models and possible observational signatures like gamma-ray bursts.

Abstract: The interaction of gravitational waves (GWs) with matter is normally treated as being insignificant. However, recent work has shown that the interaction with a viscous fluid may be astrophysically important when the distance between the matter and GW source is somewhat smaller than the GW wavelength. Previous work has mainly considered perturbations on a Minkowski background, and here these results are extended to the case that the background is a general, non-vacuum, static, spherically symmetric spacetime. Expressions are obtained for GW damping and the consequent heating of the fluid, and implemented in computer code. The results are applied to astrophysical scenarios: Core collapse supernovae, the post-merger signal from a binary neutron star merger, and matter accreting at a binary black hole merger. It is found that, compared to the Minkowski case, the damping and heating effects increase, in some cases by several orders of magnitude. It is possible for a GW signal to be completely damped, and for the heating to be such that a gamma-ray burst occurs.

</details>


### [63] [Phantom Menace in general Palatini $f(R,φ)$ theories](https://arxiv.org/abs/2512.16256)
*Rahul Thakur*

Main category: gr-qc

TL;DR: This paper explores unified $f(R,φ)$ gravity models using the Palatini formalism to explain both cosmic inflation and late-time acceleration. By analyzing fixed points and stability, it identifies conditions where the theory matches observations but suggests a transient phantom phase before settling into a stable future dominated by potential energy.


<details>
  <summary>Details</summary>
Motivation: To unify the early inflationary epoch and late-time cosmic acceleration within a single $f(R,φ)$ gravity framework while ensuring consistency in weak gravity regimes and across cosmic eras.

Method: The authors use the Palatini formalism to analyze $f(R,φ)$ theories, assume the curvature part behaves like Starobinsky gravity, and study dynamical stability in the Einstein frame. They identify fixed points and constrain the model using DESI, Cosmic Chronometers, and SNeIa data.

Result: Two stable fixed points are found: one corresponding to a transient phantom-driven acceleration today and another indicating a future transition to a stable potential-dominated expansion. Observational data tighten constraints near the present epoch.

Conclusion: While the model successfully unifies inflation and late acceleration, the current phantom phase may be temporary, suggesting a future evolution toward a stable regime dominated by scalar field potential energy. Further observational tests are needed to validate the time scales of these transitions.

Abstract: We study general $f(R,φ)$ theories in Palatini formalism and attempt to constrain the behavior of ones that could support both inflationary and late-time expansion era in a unified model. In particular, we find conditions for which the theories remain consistent in weak gravity regimes as well as cosmic expansion eras in both early and late universe. Assuming that the curvature part of the $f(R,φ)$ behaves as Starobinsky gravity, we assess post-inflation dynamical stability of the theory in Einstein frame and proceed to isolate two distinct fixed points that provide a stable late-time accelerating universe. Comparison with DESI, Cosmic Chronometers, and SNeIa datasets adds more stringent constraints to the behavior of the theory near the present epoch, giving us one stable fixed point where expansion is driven by a phantom scalar field. However, time scales of the two fixed points suggest that this fixed point may be transient and may eventually evolve toward a stable expansion stage driven potential domination in the distant future of the universe.

</details>


### [64] [First-time assessment of glitch-induced bias and uncertainty in inference of extreme mass ratio inspirals](https://arxiv.org/abs/2512.16322)
*Amin Boumerdassi,Matthew C. Edwards,Avi Vajpeyi,Ollie Burke*

Main category: gr-qc

TL;DR: The study evaluates the effect of glitches on parameter estimation for EMRIs in LISA, finding that moderate glitch mitigation suffices to keep biases below 1σ, except for weakly mitigated cases with high-SNR glitches which approach 1σ bias. EMRIs are more robust than massive black hole binaries to glitches.


<details>
  <summary>Details</summary>
Motivation: Assess the previously unquantified impact of glitches on long-lived EMRI signals in LISA, contrasting with known effects on short-duration sources like massive black hole binaries.

Method: Fisher-matrix-based analysis of simulated LISA data with injected EMRIs and glitch streams (shapelet-based from LISA Pathfinder catalog). Verified accuracy with MCMC. Tested two mitigation scenarios (moderately vs weakly mitigated).

Result: Moderate mitigation (glitches up to SNR 90) caused <0.6σ biases. Weak mitigation (glitches up to 400 SNR) approached ~1σ bias. EMRIs show greater glitch robustness compared to short-duration sources.

Conclusion: Some glitch modeling/mitigation is essential for unbiased EMRI analyses, but EMRIs tolerate higher glitch levels than other sources before significant bias occurs.

Abstract: This work investigates the impact of streams of transient, non-Gaussian noise artifacts or "glitches" on the parameter estimation of extreme mass ratio inspirals (EMRI) in the Laser Interferometer Space Antenna (LISA). Glitches cause biased and less precise inference for short-duration signals such as massive black hole binaries, but their effect on long-lived sources such as EMRIs has not been quantified. Using simulated LISA observations containing injected EMRIs and streams of shapelet-based glitches drawn from the LISA Pathfinder catalog, we estimate the glitch-induced parameter biases and uncertainties through a Fisher-matrix-based analysis whose accuracy we verify with Markov-Chain Monte Carlo. We find that moderately mitigated glitch streams i.e. ones containing only glitches of up to moderate SNRs ($ρ\lesssim 90$) induce negligible to minor biases $[\sim0.04σ,\sim0.6σ]$ in the inferred EMRI parameters. In contrast, weakly mitigated glitch streams containing higher-SNR events ($ρ\lesssim 400$) can produce biases nearing $1σ$. These results demonstrate that, when compared to inference of other sources such as massive black hole binaries, EMRI inference is notably more robust to glitches. We stress that at least some amount of glitch modeling and mitigation remains essential for unbiased EMRI analyses in the LISA era.

</details>


### [65] [Modified light-cylinder and centrifugal acceleration in Schwarzschild geometry](https://arxiv.org/abs/2512.16337)
*Nikoloz Kurtskhalia,Nikoloz Maltsev,Zaza N. Osmanov*

Main category: gr-qc

TL;DR: The paper investigates how electron motion near a primordial sub-stellar mass black hole differs from flat spacetime models by incorporating gravity into the analysis, leading to a non-cylindrical modified light cylinder (MLC) and determining the maximum energies limited by radiation processes.


<details>
  <summary>Details</summary>
Motivation: To correct deficiencies in earlier flat spacetime models that ignored gravitational effects, providing a more accurate framework for understanding electron dynamics and energy limits near black holes.

Method: Dynamical analysis of electron motion in the Schwarzschild metric, incorporating general relativistic effects to derive the modified light cylinder (MLC) and assess energy loss mechanisms like inverse Compton scattering, curvature radiation, and synchrotron radiation.

Result: The MLC's geometry deviates from a cylinder due to gravitational effects, and maximum attainable electron energies are significantly lower than previous estimates when radiation limits are properly accounted for.

Conclusion: Gravitational considerations are crucial for accurate predictions of electron acceleration and radiation processes near primordial black holes, necessitating revisions to existing light cylinder models and energy estimation methodologies.

Abstract: We examine the motion of an electron constrained to follow a magnetic field line near a primordial sub-stellar mass black hole. Earlier studies treated the problem in flat (Minkowski) spacetime, yielding qualitatively correct results and introducing a light cylinder (LC), a hypothetical surface where the linear velocity of rotation equals the speed of light. However, this picture changes significantly when gravity is included. By analyzing the electron's dynamics in the Schwarzschild metric, we obtain a modified light cylinder (MLC) whose geometry no longer resembles a cylinder. We then determine the maximum energies attainable by the electrons under the limiting effects of inverse Compton scattering, curvature radiation, and synchrotron radiation.

</details>


### [66] [GWTC-4.0: Searches for Gravitational-Wave Lensing Signatures](https://arxiv.org/abs/2512.16347)
*The LIGO Scientific Collaboration,The Virgo Collaboration,The KAGRA Collaboration*

Main category: gr-qc

TL;DR: The paper presents results from gravitational-wave lensing searches during the first part of the fourth LIGO-Virgo-KAGRA observing run (O4a), using three methods: phase shift analysis at saddle points, frequency-consistent candidate pairs, and sub-threshold counterparts. No conclusive evidence of strongly lensed events was found, allowing constraints on lensed event rates and binary black hole merger rates. An outlier event, GW231123_135430, shows potential but requires further study due to waveform uncertainties.


<details>
  <summary>Details</summary>
Motivation: To detect gravitational lensing effects on observed gravitational waves, constrain the rate of lensed events, and infer the merger rate density of high-redshift binary black holes.

Method: Three search strategies: (1) detecting phase shifts in images from saddle points, (2) identifying candidate pairs with matching frequency evolution, and (3) finding sub-threshold counterparts to detected signals. Additionally, lensing distortions were analyzed using a point-mass model.

Result: No statistically significant strongly lensed events were found. One outlier event (GW231123_135430) was noted but remains inconclusive due to waveform uncertainties. These results help constrain detectable lensed event rates and binary black hole merger densities.

Conclusion: While no confirmed lensed gravitational waves were detected, the analysis provides valuable constraints on astrophysical parameters. Further observational data and population studies are needed to confirm the lensing nature of GW231123_135430 and refine rate estimates.

Abstract: Gravitational waves can be gravitationally lensed by massive objects along their path. Depending on the lens mass and the lens-source geometry, this can lead to the observation of a single distorted signal or multiple repeated events with the same frequency evolution. We present the results for gravitational-wave lensing searches on the data from the first part of the fourth LIGO-Virgo-KAGRA observing run (O4a). We search for strongly lensed events in the newly acquired data by (1) searching for an overall phase shift present in an image formed at a saddle point of the lens potential, (2) looking for pairs of detected candidates with consistent frequency evolution, and (3) identifying sub-threshold counterpart candidates to the detected signals. Beyond strong lensing, we also look for lensing-induced distortions in all detected signals using an isolated point-mass model. We do not find evidence for strongly lensed gravitational-wave signals and use this result to constrain the rate of detectable strongly lensed events and the merger rate density of binary black holes at high redshift. In the search for single distorted lensed signals, we find one outlier: GW231123_135430, for which we report more detailed investigations. While this event is interesting, the associated waveform uncertainties make its interpretation complicated, and future observations of the populations of binary black holes and of gravitational lenses will help determine the probability that this event could be lensed.

</details>


### [67] [Pseudospectrum and black hole total transmission mode (in)stability](https://arxiv.org/abs/2512.16372)
*Yu-Sen Zhou,Ming-Fei Ji,Liang-Bi Wu,Li-Ming Cao*

Main category: gr-qc

TL;DR: The study investigates spectral stability of total transmission modes (TTMs) in d-dimensional Tangherlini black holes using pseudospectra and condition numbers, finding generic instability except for purely imaginary TTMs (s=2) and a higher-dimensional threshold (d≥8) for genuinely complex TTMs.


<details>
  <summary>Details</summary>
Motivation: To explore the spectral stability of TTMs following the discovery that virtual absorption can suppress reflections by exciting these modes. The work aims to understand the sensitivity of TTMs to perturbations analogous to quasinormal modes.

Method: Recast the TTM problem into a generalized eigenvalue problem using Eddington-Finkelstein coordinates. Analyzed pseudospectra and condition numbers for varying dimensions and overtone numbers. Compared stability properties between purely imaginary TTMs and complex overtones.

Result: TTMs are generally spectrally unstable, with higher overtones more sensitive. Purely imaginary TTMs (spin s=2) show enhanced stability with nearly concentric pseudospectra and smaller condition numbers. Genuine complex TTMs exist only in d≥8 dimensions, revising prior d≥10 thresholds.

Conclusion: TTMs exhibit instability except in specific cases (purely imaginary modes for s=2), with higher-dimensional dependencies. This bridges TTM stability to quasinormal mode behavior, clarifying dimensionality constraints for complex TTM existence.

Abstract: Total transmission modes (TTMs) are modes with complex frequencies that propagate across a black hole spacetime without reflection. Recently, it is found that suitably tailored time-dependent scattering can excite these complex modes and suppress the reflected signal for the entire duration of the process, a phenomenon referred to as virtual absorption. Motivated by this, we present the study of the spectrum stability of TTMs using pseudospectrum and condition numbers. We focus on perturbations of $d$-dimensional Tangherlini black holes and recast the TTM problem as a generalized eigenvalue problem by utilizing the Eddington-Finkelstein coordinates. The results show that TTMs are generically spectrally unstable, with sensitivity increasing for higher overtones, in close analogy with quasinormal modes. A notable exception is a purely imaginary TTM whose pseudospectrum's contours are nearly concentric and whose condition number is orders of magnitude smaller than that of the overtones, indicating enhanced spectral stability. Additionally, we confirm that purely imaginary TTMs occur only for spin $s=2$, whereas genuinely complex TTM families appear only in sufficiently high dimensions, $d \geqslant 8$, extending earlier claims that placed the onset at $d \geqslant 10$.

</details>


### [68] [Implementing F (T ) Gravity in Boltzmann Codes: A Framework for Power Spectrum Computation](https://arxiv.org/abs/2512.16404)
*Robert Rugg,Shambel Akalu,Amare Abebe*

Main category: gr-qc

TL;DR: The paper examines the nonlinearity in the power-law F(T) gravity model and addresses limitations of the CLASS solver by applying a second-order Taylor expansion to handle nonlinear equations, assuming a small parameter n (≤0.05) to maintain ΛCDM consistency.


<details>
  <summary>Details</summary>
Motivation: The motivation is to overcome the inability of the Boltzmann solver CLASS to handle nonlinear models in F(T) gravity and validate the model's consistency with ΛCDM using observational data.

Method: A second-order Taylor expansion is applied to the nonlinear field equations under the assumption that the deviation parameter n remains small (≤0.05), allowing computation within CLASS.

Result: Supernova data supports the validity of the Taylor expansion approach, with negligible truncation errors for n ≤0.05, enabling accurate power spectrum calculations.

Conclusion: The method successfully circumvents CLASS's limitations for small n values, maintaining ΛCDM's key properties while allowing F(T) gravity analysis.

Abstract: This work investigates the nonlinearity of the power-law model of F(T) gravity, highlighting the inability of the Boltzmann solver CLASS to handle nonlinear models. As a workaround, a second-order Taylor expansion is applied to the nonlinear field equations, under the assumption that the extra degree of freedom n, which quantifies deviations from the currently favored cosmological model (ΛCDM), remains sufficiently small to preserve the key properties of the ΛCDM model. The validity of the Taylor expansion is supported by supernova data indicating n \leq 0.05, for which the power spectrum can be accurately computed within CLASS with a negligible truncation error.

</details>


### [69] [Cosmology with non-linear barotropic Israel-Stewart fluid with causal relaxation time](https://arxiv.org/abs/2512.16502)
*Vishnu A Pai,Titus K Mathew*

Main category: gr-qc

TL;DR: The paper introduces an extended expression for the relaxation time of a barotropic Israel-Stewart fluid using non-linear causality constraints, enabling a simpler non-linear viscous pressure-energy density relationship. This leads to new analytical solutions in Friedmann universes and supports a transient slow-roll inflation phase followed by a smooth transition to radiation dominance, unlike standard models.


<details>
  <summary>Details</summary>
Motivation: To address limitations in standard causal viscous cosmology, particularly the challenge of achieving a transient inflationary phase and smooth transition to radiation-dominated eras, while ensuring physically acceptable fluid behavior.

Method: Derivation of extended relaxation time formula under non-linear causality; analytical solutions in spatially flat Friedmann models; dynamical systems analysis of the Einstein-Israel-Stewart system; numerical simulations of EIS equations.

Result: New analytical solutions in linear/non-linear regimes reproduce generalized polytropic equations of state; numerical solutions show a transient slow-roll expansion and natural exit to radiation dominance; derived constraints ensure valid fluid evolution.

Conclusion: The proposed framework provides a viable alternative to standard inflationary models by naturally incorporating causal viscosity effects that support observational inflationary dynamics without ad hoc assumptions.

Abstract: We derive an extended expression for the relaxation time of a barotropic Israel-Stewart (IS) fluid using the non-linear causality constraint, and propose a new formulation for modeling causal viscous dissipation in barotropic fluids. With this generalized relaxation time, the non-linear IS equation simplifies to a first-order non-linear expression connecting bulk viscous pressure and energy density, which remains valid in any homogeneous and isotropic spacetime. In the case of spatially flat Friedmann universe, adopting this extended relation in the generalized non-linear IS theory, provides new class of analytical solutions in both, the linear, and the non-linear regimes. We also find that, the resulting effective equation of state in the linear regime naturally reproduces the generalized polytropic form which is often introduced phenomenologically in literature. Resulting dynamical implications are investigated and the constraints necessary for ensuring an acceptable evolutionary behavior for the fluid are determined. A detailed dynamical system analysis of the coupled Einstein-Israel-Stewart (EIS) system is also performed. Finally, we solve the coupled EIS equations numerically, and show that the model can support a transient Hubble slow-roll expansion phase with a smooth exit to a radiation-dominated universe, which is challenging to obtain in standard inflationary models.

</details>


### [70] [A Universal Geometric Framework for Black Hole Phase Transitions: From Multivaluedness to Classification](https://arxiv.org/abs/2512.16629)
*Shi-Hao Zhang,Zi-Yuan Li,Jing-Fei Zhang,Xin Zhang*

Main category: gr-qc

TL;DR: The paper unifies understanding of synchronized multivalued behavior during black hole phase transitions using a geometric framework involving real analysis and covering space theory.


<details>
  <summary>Details</summary>
Motivation: Address the poorly understood fundamental origin of multivaluedness in thermodynamic/dynamical quantities during black hole first-order phase transitions.

Method: Constructed a unified geometric framework combining real analysis and covering space theory. Analyzed temperature function T(r_+) and its critical points to explain parameter space folding.

Result: Proved multivaluedness comes from two non-degenerate critical points forming a three-sheeted covering structure. Proposed phase transition criterion based on T(r_+) curves and introduced classification scheme A1, A2, B.

Conclusion: Established a foundational geometric perspective linking black hole thermodynamics, dynamics, and spacetime structure during phase transitions, providing a diagnostic tool through multivaluedness analysis.

Abstract: Recent studies have revealed synchronized multivalued behavior in thermodynamic, dynamical, and geometric quantities during the black hole first-order phase transition, which enables a diagnosis from different perspectives, yet its fundamental origin has remained poorly understood. By constructing a unified geometric framework integrating real analysis and covering space theory, we reveal the universal mathematical mechanism behind this phenomenon. We prove that this multivaluedness originates from two non-degenerate critical points in the temperature function $T(r_+)$, where $r_+$ is the horizon radius, which fold the parameter space into a three-sheeted covering structure. As a direct application, we propose that a black hole undergoes a first-order phase transition if and only if its $T(r_+)$ curve has two extrema. Accordingly, we establish a classification scheme, denoted $A1$, $A2$, and $B$ for black holes. This scheme offers a complementary perspective to classifications based on global topological invariants. Our work provides a theoretical foundation for diagnosing phase transitions via multivaluedness and establishes a unified geometric perspective on black hole thermodynamics, chaotic dynamics, and spacetime structure during first-order phase transitions.

</details>


### [71] [Field Quantisations in Schwarzschild Spacetime: Theory versus Low-Energy Experiments](https://arxiv.org/abs/2512.16667)
*Viacheslav A. Emelyanov*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Non-relativistic quantum particles in the Earth's gravitational field are successfully described by the Schrödinger equation with Newton's gravitational potential. Particularly, quantum mechanics is in agreement with such experiments as free fall and quantum interference induced by gravity. However, quantum mechanics is a low-energy approximation to quantum field theory. The latter is successful by the description of high-energy experiments. Gravity is embedded in quantum field theory through the general-covariance principle. This framework is known in the literature as quantum field theory in curved spacetime, where the concept of a quantum particle is, though, ambiguous. In this article, we study in this framework how a Hawking particle moves in the far-horizon region of Schwarzschild spacetime by computing its propagator. We find this propagator differs from that which follows from the path-integral formalism -- the formalism which adequately describes both free fall and quantum interference induced by gravity.

</details>


### [72] [Exponential plateaus and inflation in metric-affine gravity](https://arxiv.org/abs/2512.16815)
*Antonio Racioppi*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose a new mechanism for inflationary model building in the framework of metric-affine gravity. Such a mechanism involves an inflaton non-minimally coupled with the Holst invariant. If the non-minimal coupling function has a zero point and it is very steep at that same point, then the canonically normalized inflaton potential always features an exponential plateau, regardless of the shape of the original inflaton potential. The inflationary predictions in such a region are equivalent to the ones of Starobinsky inflation.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [73] [Cosmological Neutron Stars Produce Diffuse Axion X-Ray Signatures](https://arxiv.org/abs/2512.15849)
*Orion Ning,Kailash Raman,Benjamin R. Safdi*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Axion-like particles can be abundantly produced through scattering processes in the cores of neutron stars (NSs). If they are ultralight ($m_a \lesssim 10^{-4}$ eV), then they can efficiently convert to detectable photons in the external NS magnetospheres, and if they are heavy ($m_a \gtrsim 1$ eV), then they can decay into photons before reaching Earth. In this work, we search for the resulting X-ray signatures from both of these channels summing over the $\textit{cosmological}$ NS population. We compare the predicted axion-induced X-ray signal to the cosmic X-ray background today as measured by a number of instruments such as NuSTAR, HEAO, Swift, and INTEGRAL. We model the axion-induced signal using NS cooling simulations and magnetic field evolution models. We find no evidence for axions and derive strong constraints for both ultralight and heavy axion scenarios, covering new parameter space for the axion-photon and axion-nucleon couplings. Our results rule out the axion-explanation of the Magnificent Seven X-ray excess from nearby isolated NSs.

</details>


### [74] [Reusable theory representations for colliders: a demonstrator SMEFT foundation model](https://arxiv.org/abs/2512.15862)
*Supratim Das Bakshi,T. J. Hobbs,Brandon Kriesten*

Main category: hep-ph

TL;DR: The paper introduces a foundation model using contrastive learning to analyze collider physics data, specifically Drell-Yan processes in the SMEFT framework. It creates a low-dimensional latent space for Wilson coefficients, enabling geometric interpretation of physics effects and facilitating downstream tasks like classification and anomaly detection. The model is a first step toward unified New-Physics search tools at colliders.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenge of efficiently exploring high-dimensional parameter spaces in SMEFT for collider physics. Traditional methods struggle with analyzing vast Wilson coefficient configurations, so a structured, data-driven approach is needed to uncover meaningful relationships between parameters and observables.

Method: The method involves generating a dataset of Drell-Yan cross sections using simulated SMEFT parameters (Wilson coefficients). A contrastive learning network is trained on this data to create a compact latent space where physical deformations have geometric meaning. Key aspects include supervised contrastive loss, Monte Carlo replicas with uncertainties, and analysis of latent space structures.

Result: Key results are: (i) Latent dimensions capture distinct SMEFT effects like four-fermion interactions and vertex corrections; (ii) Wilson coefficient families form clusters with similar phenomenology; (iii) The representation successfully supports tasks like classification and anomaly detection. Limitations include use of leading-order SMEFT and simplified uncertainties.

Conclusion: The conclusion states this work establishes a foundational framework for physics-informed machine learning in New-Physics searches. It emphasizes potential for extension to multi-process analyses and higher-order corrections, while highlighting current limitations as pathways for future improvement.

Abstract: We develop a demonstrator foundation model for collider-scale explorations of the Standard Model Effective Field Theory (SMEFT), constructed from contrastive representations of theoretically simulated neutral-current Drell-Yan cross sections. Using a controlled sampling of the Warsaw-basis dimension-6 Wilson-coefficient space at $O(Λ^{-2})$, we generate a corpus of high-resolution differential distributions in $m_{\ell\ell}$ and $p_{T}$, augmented by physics-motivated Monte Carlo replicas with correlated uncertainties. A minimally parameterized encoder network is trained with a supervised contrastive loss to produce a low-dimensional latent manifold on which SMEFT-induced deformations of the Drell-Yan spectrum acquire a well-defined geometric structure. We analyze the resulting embedding and demonstrate that (i) latent directions correlate with characteristic SMEFT shape distortions, including energy-growing four-fermion contributions and electroweak vertex corrections; (ii) clusters in the embedding correspond to families of Wilson-coefficient configurations with similar phenomenological impact; and (iii) the learned representation supports downstream tasks such as classification with uncertainty quantification, anomaly detection, and nearest-neighbor retrieval. While restricted to leading-order SMEFT and simplified uncertainty modeling, this study provides the first step toward a reusable, physics-aligned foundational representation for the theory of New-Physics searches at high-energy colliders. We outline extensions towards a complete global analyses, including multi-process training corpora, higher-order corrections, and multi-objective pretraining.

</details>


### [75] [Kination and the Inert Doublet Model](https://arxiv.org/abs/2512.15864)
*Geneviève Bélanger,Nicolás Bernal,Andreas Goudelis,Alexander Pukhov*

Main category: hep-ph

TL;DR: The paper investigates the allowed mass range for dark matter in the inert doublet model under non-standard cosmological conditions with a stiff equation of state (w > 1/3), resolving previous underabundance issues for 120-500 GeV masses and aligning with experimental constraints.


<details>
  <summary>Details</summary>
Motivation: To address the underabundance problem of dark matter in the inert doublet model for 120-500 GeV masses caused by efficient annihilation during standard cosmology freeze-out.

Method: Examines dark matter freeze-out dynamics in cosmologies with a stiff equation of state (e.g., kination), altering thermal history assumptions to reduce annihilation efficiency.

Result: Shows that a stiff equation of state extends the allowed dark matter mass range to include 120-500 GeV previously excluded under standard cosmology.

Conclusion: The modified scenario successfully accommodates dark matter masses up to 500 GeV while satisfying experimental constraints, offering a testable model for future detection experiments.

Abstract: The inert doublet model is a two-Higgs-doublet extension of the standard model that provides a minimal and versatile framework for frozen-out dark matter. Assuming standard cosmology, if the dark matter mass ranges between approximately 120 GeV and 500 GeV then it turns out to be underabundant, as gauge interactions render its annihilation too efficient. In this work, we show that this mass window becomes allowed in cosmological scenarios where dark matter freeze-out occurs during a period with a stiff equation of state, $w > 1/3$, such as kination. This predictive setup satisfies all current experimental constraints while remaining within the reach of upcoming detection efforts.

</details>


### [76] [Weak Charge Form Factor Determination at the Electron-Ion Collider](https://arxiv.org/abs/2512.15865)
*Hooman Davoudiasl,Hongkai Liu,Sonny Mantry,Ethan T. Neil*

Main category: hep-ph

TL;DR: The paper explores the Electron-Ion Collider (EIC)'s potential to determine the weak charge form factor (F_W(Q²)) across a continuous range of momentum transfers, complementing fixed-target experiments which provide data at single Q² values but with higher precision. The EIC can provide broad Q² coverage for various nuclei, improving neutron density distribution constraints.


<details>
  <summary>Details</summary>
Motivation: Current fixed-target experiments (e.g., CREX, PREX-1,2) only measure F_W(Q²) at single Q² values, limiting the ability to map neutron density distributions. The EIC can offer continuous Q² coverage, enhancing understanding of nuclear structure, neutron stars, and beyond-Standard-Model physics.

Method: The analysis evaluates EIC's capability to measure F_W(Q²) over 0≲Q²≲0.1 GeV² with integrated luminosities >200/A fb⁻¹. It compares EIC's broad Q² range to fixed-target precision and discusses how combining data can reduce model degeneracies in neutron density modeling.

Result: The EIC could complement fixed-target experiments by providing data across multiple Q² values for various nuclei. At sufficient luminosities, EIC data can significantly improve constraints on neutron density distributions, filling gaps in current knowledge.

Conclusion: The EIC's wide Q² coverage, despite lower precision than fixed-target setups, will provide critical complementary data, lifting theoretical model degeneracies and advancing studies of neutron distributions, nuclear structure, and related fields.

Abstract: Determining the weak charge form factor, $F_W(Q^2)$, of nuclei over a continuous range of momentum transfers, $0\lesssim Q^2 \lesssim 0.1$ GeV$^2$, is essential for mapping out the distribution of neutrons in nuclei. The neutron density distribution has significant implications for a broad range of areas, including studies of nuclear structure, neutron stars, and physics beyond the Standard Model. Currently, our knowledge of $F_W(Q^2)$ comes primarily from fixed target experiments that measure the parity-violating longitudinal electron spin asymmetry in coherent elastic electron-ion scattering. Fixed target experiments, such as CREX and PREX-1,2, have provided high-precision weak charge form factor extractions for the $^{48}{\rm Ca}$ and $^{208}{\rm Pb}$ nuclei, respectively. However, a major limitation of fixed target experiments is that they each provide data only at a single value of $Q^2$. With the proposed Electron-Ion Collider (EIC) on the horizon, we explore its potential to impact the determination of the weak charge form factor. While it cannot compete with the precision of fixed target experiments, it can provide data over a wide and continuous range of $Q^2$ values, and for a wide variety of nuclei. We show that for integrated luminosities of $\mathcal{L} > $ 200/$A$ fb$^{-1}$, where $A$ denotes the nucleus atomic weight, the EIC can be complementary to fixed target experiments, and can significantly impact constraints from CREX and PREX-1,2 by lifting degeneracies in theoretical models of the neutron density distribution.

</details>


### [77] [Renormalization of general Effective Field Theories: Renormalization of fermionic operators](https://arxiv.org/abs/2512.15866)
*Renato M. Fonseca,Pablo Olgoso,José Santiago*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Renormalization group equations play a central role in effective field theories, both maintaining perturbative control and allowing one to determine the correct low-energy phenomenology. In this work, we complete the one-loop renormalization of the recently developed general effective field theory up to mass dimension six by providing the beta functions for physical fermionic operators. Together with Ref. [1], our results allow one to renormalize any effective theory up to dimension six at one loop using only a group-theoretical calculation.

</details>


### [78] [HEPTAPOD: Orchestrating High Energy Physics Workflows Towards Autonomous Agency](https://arxiv.org/abs/2512.15867)
*Tony Menzo,Alexander Roman,Sergei Gleyzer,Konstantin Matchev,George T. Fleming,Stefan Höche,Stephen Mrenna,Prasanth Shyamsundar*

Main category: hep-ph

TL;DR: HEPTAPOD is a framework enabling LLMs to execute complex HEP workflows through tool orchestration and structured operations.


<details>
  <summary>Details</summary>
Motivation: To leverage modern LLM capabilities for coordinated multi-step tasks in HEP pipelines, previously limited to text generation.

Method: HEPTAPOD interfaces LLMs with domain-specific tools using schema validation and run-card configurations to manage simulation workflows and analyses.

Result: Demonstrated a BSM Monte Carlo validation pipeline integrating model generation, simulation, and analysis in a reproducible workflow.

Conclusion: Provides a transparent, auditable system for human-LLM-infrastructure interaction, advancing agency-based computational research in HEP.

Abstract: Many workflows in high-energy-physics (HEP) stand to benefit from recent advances in transformer-based large language models (LLMs). While early applications of LLMs focused on text generation and code completion, modern LLMs now support orchestrated agency: the coordinated execution of complex, multi-step tasks through tool use, structured context, and iterative reasoning. We introduce the HEP Toolkit for Agentic Planning, Orchestration, and Deployment (HEPTAPOD), an orchestration framework designed to bring this emerging paradigm to HEP pipelines. The framework enables LLMs to interface with domain-specific tools, construct and manage simulation workflows, and assist in common utility and data analysis tasks through schema-validated operations and run-card-driven configuration. To demonstrate these capabilities, we consider a representative Beyond the Standard Model (BSM) Monte Carlo validation pipeline that spans model generation, event simulation, and downstream analysis within a unified, reproducible workflow. HEPTAPOD provides a structured and auditable layer between human researchers, LLMs, and computational infrastructure, establishing a foundation for transparent, human-in-the-loop systems.

</details>


### [79] [Fifty shades of grayness: parameterizations of spectral distortions and applications in cosmology](https://arxiv.org/abs/2512.15893)
*Gabriela Barenboim,Julien Froustey,Cyril Pitrou,Héctor Sanchis*

Main category: hep-ph

TL;DR: The paper proposes a new polynomial-based method to parameterize distortions in thermal spectra, offering computational advantages over existing methods and enabling model-independent constraints on nonstandard distortions of cosmological relics like neutrinos and photons.


<details>
  <summary>Details</summary>
Motivation: To develop a computationally efficient parameterization of thermal spectrum distortions that can capture a wide range of deviations from Fermi-Dirac/Bose-Einstein distributions, improving upon Stebbins' temperature distribution approach.

Method: The authors extend Stebbins' method by using number density distributions and introduce a polynomial-modulated thermal spectrum approach, where distortion parameters are coefficients of an orthonormal polynomial basis decomposition.

Result: The new method successfully describes standard cosmological background distortions and provides constraints on nonstandard distortions without assuming specific physical models.

Conclusion: The polynomial-based parameterization is favored for its computational efficiency and versatility in analyzing both known and novel thermal spectrum distortions in cosmological contexts.

Abstract: Thermal distribution functions can only be of the Fermi-Dirac or Bose-Einstein types, whereas distorted spectra encompass any possible deviations from these shapes. It is fruitful to devise parameterizations of these distortions with only a few parameters which depend on the physical system considered. A method proposed by Stebbins consists in describing a distorted spectrum as a sum of thermalized spectra with a distribution of temperatures, the moments of which are the parameters of interest. After revisiting and extending this approach by working at the level of the number density distribution instead of the standard spectrum, we build another method which consists in describing the distorted spectrum by a polynomial modulating a reference thermalized spectrum. The distortion parameters are then the coefficients of a decomposition on a suitable orthonormal polynomial basis. We advocate that the latter is computationally easier and allows to describe a wide range of distortions. With this formalism, we efficiently describe the standard distortions of the cosmological backgrounds of neutrinos and photons, and we obtain model-independent constraints on nonstandard distortions of these cosmological relics.

</details>


### [80] [Energy-Energy Correlators in $e^+e^-$ and Deep Inelastic Scattering](https://arxiv.org/abs/2512.15896)
*Yuxun Guo,Werner Vogelsang,Feng Yuan,Wenbin Zhao*

Main category: hep-ph

TL;DR: The paper analyzes energy-energy correlators in $e^+e^-$ annihilation and DIS, exploring nonperturbative physics through EEC jet functions, one-loop calculations, factorization, and a matching scheme to describe experimental data and simulations.


<details>
  <summary>Details</summary>
Motivation: To understand nonperturbative aspects of EECs by studying their infrared behavior, factorization, and universality, and to enable accurate descriptions of experimental data across different kinematic regions.

Method: Introduced EEC jet functions; performed one-loop calculations for small-angle and angle-integrated EECs; demonstrated factorization/universality; proposed a matching scheme combining scaling behaviors for different jet energy regimes; compared results with NLO corrections and PYTHIA simulations.

Result: Successful description of high-energy $e^+e^-$ annihilation data and PYTHIA simulations using the proposed method; presented predictions for DIS processes applicable to future electron-ion collider experiments.

Conclusion: The developed framework effectively captures nonperturbative contributions and provides a reliable tool for analyzing EECs in both $e^+e^-$ and DIS processes, with validated applicability and predictive capabilities for future colliders.

Abstract: We study energy-energy correlators (EECs) in $e^+e^-$ annihilation and deep inelastic lepton-hadron scattering (DIS), focusing on aspects of nonperturbative physics in these observables. We introduce the EEC jet functions and investigate the infrared (IR) behavior of both small-angle EECs and angle-integrated EECs by performing explicit one-loop calculations. The factorization and universality of the EECs in these processes are demonstrated. A matching scheme is proposed to smoothly connect kinematic regions where different scaling behaviors with jet energy are observed. In combination with the next-to-leading order correction, this matching provides a good description of the EEC data and PYTHIA simulations in high-energy $e^+e^-$ annihilation. Predictions for DIS processes for future electron-ion collider kinematics are also presented.

</details>


### [81] [Deconstructive Composite Dark Matter Detection](https://arxiv.org/abs/2512.16043)
*Yilda Boukhtouchen,Joseph Bramante,Christopher Cappiello,Melissa Diamond*

Main category: hep-ph

TL;DR: The paper explores detecting composite dark matter that disintegrates into cascades when passing through Earth, focusing on how scattering events and detector signatures can reveal such phenomena.


<details>
  <summary>Details</summary>
Motivation: To identify observable signatures of composite dark matter via its disintegration cascades during Earth passage, addressing gaps in understanding TeV-scale weakly-interacting dark matter's behavior.

Method: Analyzes trajectories and cascade profiles of dissociated dark matter constituents, simulating their scattering paths and energy transfers through Earth's medium. Examines detector可观测到的signatures like non-collinear scatters, timing separations, and multi-lab coincidences.

Result: Dissociation-induced scattering cascades are common in TeV-scale composite dark matter. Specific signatures include non-collinear multiple scatters in detectors, timing differences inmultiscatter events, and parameter-dependent coincidences between labs.

Conclusion: Underground detectors can distinguish composite dark matter via these cascades, providing new avenues to probe particle dark matter models through unique Earth-scattering phenomena.

Abstract: We investigate the detection of composite dark matter that disassembles into a cascade while crossing the Earth. This occurs for loosely bound composite dark matter, where the binding energy per constituent is small, such that scattering with Standard Model nuclei typically imparts enough energy to dissociate a constituent from its composite. Trajectories and cascade profiles are found for dissociated constituents that are further diverted by scattering through the Earth. Such scattering cascades are a common feature of TeV-scale weakly-interacting dark matter loosely bound in composites. We identify underground detector signatures of constituent cascades that depend on composite characteristics; these signatures include non-collinear multiple scatters in detectors, parameter-dependent timing separation of multiscatter events, and regions of parameter space where a dark matter cascade would leave a coincident signature in different underground laboratories.

</details>


### [82] [Investigation of Nuclear Modification Factor from RHIC to LHC energies using Boltzmann Transport equation in conjunction with q-Weibull distribution](https://arxiv.org/abs/2512.16078)
*Rohit Gupta*

Main category: hep-ph

TL;DR: A theoretical model based on the Boltzmann Transport equation with q-Weibull distribution accurately predicts nuclear modification factors of charged hadrons and identified particles across RHIC to LHC energies, showing mass-dependent parameter trends.


<details>
  <summary>Details</summary>
Motivation: To advance understanding of hot dense nuclear matter in heavy-ion collisions by developing a theoretical framework that aligns with experimental data from multiple colliders.

Method: Used the Boltzmann Transport equation in relaxation time approximation with q-Weibull distribution as final-state distribution. Analyzed nuclear modification factor data from 7.7 GeV (RHIC) to 5.44 TeV (LHC) collisions.

Result: Model reproduces experimental data with good χ²/NDF agreement. Identified linear mass dependence in some model parameters.

Conclusion: The q-Weibull distribution-based model effectively describes particle production dynamics in heavy-ion collisions, providing insights into mass-dependent interactions in hot dense matter.

Abstract: The study of nuclear modification factor is crucial in advancing our knowledge of the hot and dense nuclear matter created during high energy heavy-ion collision. In this direction, we have developed a theoretical model for the nuclear modification factor using the Boltzmann Transport equation in relaxation time approximation with the q-Weibull distribution as the final state distribution and studied the experimental data of nuclear modification factor of charged hadrons as well as identified particles at various energies ranging from 7.7 GeV measured at RHIC upto the maximum value of 5.44 TeV studied in LHC. We observed a good agreement between the model and the experimental data as can be quantified using the $χ^2$/NDF values. We have also studied the mass dependence of different fit parameters that appears in the theoretical model and observe a linear mass dependence of some parameters.

</details>


### [83] [Visible and Invisible Pseudoscalar Meson Decays from Anomaly Sum Rules](https://arxiv.org/abs/2512.16100)
*Xurong Chen,Sergey Khlebtsov,Armen Oganesian,Oleg Teryaev*

Main category: hep-ph

TL;DR: The paper analyzes pseudoscalar meson decays into photons and neutrino-antineutrino pairs using dispersive Anomaly Sum Rules. It highlights the nontrivial structure of B(q²) around 1 GeV², indicating a possible pseudoscalar glueball at 1.5-2 GeV. Pion and eta decay branching ratios show significant enhancements, with eta being orders of magnitude higher. The results are relevant for future experiments at HHaS/HIAF.


<details>
  <summary>Details</summary>
Motivation: To explore the role of the gluon form factor B(q²) in pseudoscalar meson decays and its implications for glueball existence, as well as to refine decay predictions with mixing effects for experimental validation at HHaS/HIAF.

Method: The dispersive method based on Anomaly Sum Rules was employed, incorporating the non-perturbative gluon form factor B(q²) in the singlet channel. Analysis of meson transition form factors provided constraints on B(q²) dependence on q².

Result: B(q²) exhibits a nontrivial structure at 1 GeV², suggesting a 1.5-2 GeV glueball. Pion branching ratio increases by 3x with mixing effects, while eta's increases by several orders of magnitude. Decay mass dependence matches QCD-based meson form factors.

Conclusion: The study confirms compatibility with prior results when neglecting mixing but emphasizes significant enhancements due to mixing. Highlights the role of B(q²) and glueball potential in decay dynamics, advocating for HHaS/HIAF experiments to test these predictions.

Abstract: The decays of pseudoscalar mesons to real and virtual photons as well as neutrino-antineutrino pairs are considered in the framework of the dispersive method based on Anomaly Sum Rules. The contribution of singlet channel involving the new non-perturbative gluon form factor of virtual photon $B(q^2)$ is systematically taken into account. The detailed analysis of its dependence on photon virtuality $q^2$ relying on the available data for meson transition fomfactors is performed. It is shown that B has quite a nontrivial structure at $q^2 \sim 1 GeV^2$ which may be a signal of the existence of pseudoscalar glueball with a mass about 1.5-2 GeV. The calculation of the decay to $ν\bar ν$ pairs leads to the compatibility with the result of Arnellos, Marciano and Parsa of 1982, when pion decay is considered neglecting the mixing effects. The account for these effects results, however, in the enhancement of pion branching ratio by a factor of 3, while that for eta decay is larger by several orders of magnitude. It is stressed, that dependence on the pair invariant mass is entirely defined by QCD and coincides with that of the meson transition form factor. The role of obtained results for the physics at HHaS detector at HIAF is discussed.

</details>


### [84] [Fatjet Signatures of Quintuplet Fermions at the LHC](https://arxiv.org/abs/2512.16180)
*Sourabh Dube,Nilanjana Kumar,Shriyansh Ranjan*

Main category: hep-ph

TL;DR: The paper examines a simplified Standard Model extension with a neutral fermion quintuplet and scalar quadruplet to generate neutrino masses via tree and loop mechanisms, focusing on LHC collider signatures and detection strategies using boosted W/Z boson fatjets.


<details>
  <summary>Details</summary>
Motivation: To explore a minimal BSM scenario explaining neutrino masses while predicting distinctive LHC signatures, particularly involving doubly charged fermions with high production cross sections.

Method: Simulated pair production analysis of 700-1200 GeV quintuplet fermions, with boosted W/Z decays into fatjets. Applied jet substructure/kinematic techniques to separate signals from SM backgrounds in multilepton-multifatjet channels.

Result: Both 2-lepton-2-fatjet and 3-lepton-1-fatjet channels achieved >5σ significance even with 50% background uncertainty at 3000 fb⁻¹ luminosity.

Conclusion: The model provides a testable scenario at the LHC with current/delivered luminosity, demonstrating viability of detection through optimized analysis channels.

Abstract: This paper explores a simplified extension of the standard model featuring a neutral fermion quintuplet and a scalar quadruplet, which together generate neutrino masses through tree and loop level mechanisms. The quintuplet fermions decay into standard model gauge bosons via the scalars, producing unique collider signatures at the LHC characterized by multilepton and multijet final states. The study focuses on the pair production of quintuplet fermions in the 700-1200 GeV mass range, where their decays produce highly boosted W and Z bosons identifiable as fatjets. Emphasis is placed on the production and decay of doubly charged fermions due to their higher cross section. Advanced jet substructure and kinematic techniques are applied to enhance sensitivity by reducing standard model backgrounds. A detailed analysis of signal significance is performed in the two lepton, two fatjet and three lepton, one fatjet channels for different masses of the fermion and the scalars, optimizing selection cuts to maximize signal efficiency over standard model backgrounds. The study found that both channels exhibit excellent performance, with significance exceeding $5σ$ under realistic conditions including a 50\% background uncertainty at integrated luminosity up to 3000 fb$^{-1}$.

</details>


### [85] [Fermion reheating with a quartic inflaton potential](https://arxiv.org/abs/2512.16203)
*Nabeen Bhusal,M. Ernesto Chávez M.,Marcos A. G. Garcia,Adriana G. Menkara,Mathias Pierre*

Main category: hep-ph

TL;DR: The paper examines reheating in a quartic inflaton model, focusing on fermion pair decays via Yukawa interactions. It finds that for Yukawa couplings y ≳ 10^-8, effects like parametric resonance and Pauli blocking must be considered, with reheating before fragmentation requiring y ≳ 0.2.


<details>
  <summary>Details</summary>
Motivation: To ensure the universe reheats sufficiently before nucleosynthesis, the study addresses how quartic inflaton models handle particle production and inflaton fragmentation risks under various Yukawa coupling strengths.

Method: Combines non-perturbative (Heisenberg/Bogoliubov) and perturbative (Boltzmann) methods to analyze inflaton decay into fermions, accounting for self-interaction-induced parametric resonance and quantum statistical effects.

Result: Threshold couplings y ≳ 10^-8 are needed to account for resonance and blocking effects; reheating must occur before fragmentation at y ≳ 0.2 to avoid cosmological inconsistencies.

Conclusion: Yukawa coupling strength critically determines successful reheating timing. Values below ~0.2 risk post-nucleosynthesis fragmentation, constraining viable quartic inflaton models.

Abstract: Any viable inflationary model must account for reheating of the universe prior to the onset of primordial nucleosynthesis. In this work, we study the reheating mechanism for an inflaton field with a quartic minimum, assuming that the main particle production channel corresponds to the decay into a pair of spin 1/2 fermions via Yukawa-like interactions. On top of its decays, the self-interaction of the inflaton sources the resonant growth of inflaton inhomogeneities, leading to its eventual fragmentation, unless reheating is completed in a shorter timescale. By means of a combination of non-perturbative (Heisenberg/Bogoliubov) and perturbative (Boltzmann) methods, we find that for Yukawa couplings $y\gtrsim 10^{-8}$ parametric resonance, kinematic blocking, and Pauli suppression effects cannot be ignored to estimate the fermion energy density during reheating. Reheating prior to nucleosynthesis requires couplings above this threshold, and in particular, reheating occurring before fragmentation is only possible for $y\gtrsim 0.2$.

</details>


### [86] [Long-lived particle production through the PRISM](https://arxiv.org/abs/2512.16222)
*Kevin J. Kelly,Mudit Rai*

Main category: hep-ph

TL;DR: The paper analyzes the ability of DUNE near detectors to distinguish between different sub-GeV long-lived particles and their production mechanisms using their excellent energy resolution and off-axis detector positioning (DUNE-PRISM).


<details>
  <summary>Details</summary>
Motivation: To address the challenge of distinguishing between theoretically similar long-lived particles with overlapping signatures in accelerator-based neutrino experiments like DUNE.

Method: Explores the capabilities of DUNE near detectors, focusing on energy resolution and off-axis detector placement (DUNE-PRISM) to differentiate particle classes and production mechanisms.

Result: Demonstrates that combining high energy resolution with off-axis detector movement significantly enhances the discrimination between different long-lived particle models.

Conclusion: DUNE's configuration, particularly DUNE-PRISM, provides a powerful tool for distinguishing between sub-GeV long-lived particles, advancing model discrimination in particle physics.

Abstract: Accelerator-based neutrino experiments offer a competitive environment to search for long-lived particles with sub-GeV masses. Yet, many theoretical models involving such particles predict very similar phenomenology and nearly identical final-state signatures. In view of this, we study the capabilities of upcoming experiments -- specifically the DUNE near detectors -- to distinguish between different classes of long-lived particles and the mechanisms by which they are produces. We expound how the experiment's excellent energy resolution, combined with the possibility to move the detector off-axis (the DUNE-PRISM concept), work in tandem to improve the discrimination power.

</details>


### [87] [Neutrino Propagation in Quantum Field Theory at Short and Long Baselines](https://arxiv.org/abs/2512.16281)
*Vadim A. Naumov,Dmitry S. Shkirmanov*

Main category: hep-ph

TL;DR: The paper explores neutrino oscillations using quantum field theory with wave packets, showing that wave packet effects modify the neutrino propagator and lead to deviations from the inverse-square law, potentially explaining reactor antineutrino anomalies.


<details>
  <summary>Details</summary>
Motivation: To address discrepancies like the reactor antineutrino anomaly and understand the asymptotic behavior of neutrino propagation on different baselines by considering wave packet effects in a quantum field approach.

Method: Uses a quantum field theory framework where neutrinos are propagators and external states are covariant wave packets. Derives asymptotic series for the propagator on short and long baselines, calculating corrections to the inverse-square law.

Result: Leading-order corrections from wave packet effects reduce the neutrino-induced event rate, violating the classical inverse-square law. These effects could partially explain the reactor antineutrino anomaly.

Conclusion: Wave packet considerations in quantum field theory provide a viable framework to reinterpret neutrino oscillation phenomena, offering potential explanations for observed anomalies without invoking new physics.

Abstract: In a quantum field approach to neutrino oscillations, the neutrino is treated as a propagator, while the external initial and final particle states are described by covariant wave packets. For the asymptotic behavior on short and long macroscopic baselines, the wave packet modified neutrino propagator is expressed through asymptotic series in powers of dimensionless Lorentz and rotation invariant variables. In both regimes, leading-order corrections violate the classical inverse-square law and lead to a decrease in the neutrino-induced event rate. The possibility that the so-called reactor antineutrino anomaly can, at least partially, be explained within this approach is discussed.

</details>


### [88] [Entropy of Schwinger pair production in time-dependent Sauter pulse electric field](https://arxiv.org/abs/2512.16328)
*Zhi-Hang Yao,Hong-Hao Fan,Lie-Juan Li,Hai-Bo Sang,Bai-Song Xie*

Main category: hep-ph

TL;DR: The paper examines three types of entropy (entanglement entropy S_E, thermal distribution entropy S_Th, and S_Th,CP with chemical potential correction) in electron-positron pair production under time-dependent Sauter pulse electric fields. It finds varying relationships between entropies depending on pulse duration and momentum considerations, showing S_E predominates in short pulses while S_Th dominates in long pulses. The chemical potential causes non-monotonic behavior in per-particle entropies, and asymptotic saturation differences in full momentum scenarios using Unruh temperature.


<details>
  <summary>Details</summary>
Motivation: To understand how different entropy measures relate in quantum field theory processes, specifically pair production in time-dependent fields, by exploring their dependencies on pulse duration, momentum treatments, and thermal/chemical potential effects.

Method: The study analyzes pair production in time-dependent Sauter pulse fields, considering both longitudinal and full momentum cases. Three entropy measures are computed: S_E (entanglement), S_Th (thermal), and S_Th,CP (thermal with chemical potential). Calculations involve comparing entropy behaviors across short vs long pulses, introducing Unruh temperature for full momentum entropy assessment.

Result: Key findings include inverse entropy dominance between short (S_E higher) and long (S_Th higher) pulses. Chemical potential induces non-monotonic behavior in per-particle entropies (S_Th,CP/N and S_E/N) for short pulses. In full momentum analysis using Unruh temperature, both S_Th,U and S_E asymptote to constants but S_Th,U has a higher saturation value.

Conclusion: Different entropy measures exhibit complex interdependencies in quantum pair production processes. Pulse duration and thermal/chemical potential factors significantly alter entropy relationships, suggesting entropy measures can serve as indicators of system dynamics and thermalization in time-dependent field scenarios.

Abstract: We investigate entropy of electron-positron pair production in time-dependent Sauter pulse electric field. Both cases of pair longitudinal momentum only and full momentum consideration are examined. We further examine three types of entropy, one is the usual entanglement entropy $S_{\text{E}}$, the other two extensions are thermal distribution entropy $S_{\text{Th}}$, and that with the chemical potential correction, $S_{\text{Th,CP}}$. For short pulse, $S_{\text{E}}$ is higher than $S_{\text{Th}}$ and vice versa for long pulse. The chemical potential causes the single-particle average thermal distribution entropy $\frac{S_{\text{Th,CP}}}{N}$ to exhibit non-monotonic behavior, similar to the single-particle average entanglement entropy $\frac{S_{\text{E}}}{N}$ in the short-pulse range. In the full momentum case, we calculate the thermal distribution entropy $S_{\text{Th, U}}$ via introducing the Unruh temperature as the local effective temperature. We find that both $S_{\text{Th, U}}$ and $S_{\text{E}}$ saturate asymptotically to the constant while the former has a larger asymptotic value. The results presented in this study reveals that the different entropies have some delicate relationships among them.

</details>


### [89] [Generalized CP from non-invertible selection rules](https://arxiv.org/abs/2512.16376)
*Tatsuo Kobayashi,Hajime Otsuka*

Main category: hep-ph

TL;DR: The paper explores a framework where fields are labeled by conjugacy classes of a finite group to define CP-invariant systems with parity, leading to generalized CP transformations and spontaneous CP violation possibilities.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of traditional field labeling by irreducible representations and to explore non-invertible fusion rules in constructing CP-symmetric systems with flavor symmetries.

Method: Using fusion algebras based on conjugacy classes instead of irreps, incorporating Z2 symmetry for charge conjugation, and combining group-based flavor symmetries with CP to derive generalized transformations.

Result: Demonstrated spontaneous CP violation in the framework and its implications for Yukawa textures, showing how non-invertible selection rules with CP symmetry lead to consistent CP-invariant systems.

Conclusion: The approach provides a novel structure for understanding CP violation and flavor symmetries through non-invertible fusion algebras, offering new avenues for model building in particle physics.

Abstract: We study a framework in which fields are labeled by basis elements of a fusion algebra with non-invertible fusion rules. In particular, we consider the case where fields are labeled by conjugacy classes of a finite group rather than its irreducible representations. When the fusion rules possess a $\mathbb{Z}_2$ symmetry identified with charge conjugation, a CP-invariant system can be consistently defined together with parity transformation. Furthermore, it is found that combining group-based flavor symmetries underlying non-invertible selection rules with CP symmetry naturally leads to a generalized CP transformation. We also demonstrate the possibility of spontaneous CP violation in this framework and discuss its implications for Yukawa textures.

</details>


### [90] [Compactified 2HDM under the Non-SUSY AdS instability conjecture](https://arxiv.org/abs/2512.16389)
*M. A. Rbah,S. Saoud,R. Sammani,E. H. Saidi,R. Ahl Laamara*

Main category: hep-ph

TL;DR: The study explores how extra dimensions affect the Higgs sector's behavior through compactification of a Two-Higgs-Doublet Model on a circular extra dimension, deriving an effective potential that stabilizes the vacuum and imposes a lower bound on heavy Higgs masses (~680 GeV) using quantum gravity conditions.


<details>
  <summary>Details</summary>
Motivation: To understand the impact of extra-dimensional dynamics on Higgs physics and derive constraints on the heavy Higgs sector via Swampland-inspired conjectures. Specifically, ensuring a stable vacuum and non-supersymmetric AdS consistency requirements.

Method: Compactify 2HDM coupled to 4D gravity on an S¹ circle, compute the 3D effective action incorporating tree-level 2HDM terms, one-loop Coleman-Weinberg corrections from Kaluza-Klein modes, and radion contributions from Goldberger-Wise mechanism.

Result: The radion potential achieves a stable minimum with near-zero vacuum energy for m_h=125 GeV. Applying the AdS instability conjecture yields a model-independent bound(M_H ≥ 680 GeV) to prevent an unstable AdS3 vacuum.

Conclusion: Swampland conjectures provide testable predictions for extended Higgs sectors, emphasizing their role in constraining particle physics models via quantum gravity considerations.

Abstract: We investigate how extra-dimensional dynamics influence the Higgs sector phenomenology by compactifying a Two-Higgs-Doublet Model (2HDM) coupled to 4D gravity on a circle $S^{1}$. The resulting effective potential includes tree-level 2HDM interactions, one-loop Coleman-Weinberg corrections from the Kaluza-Klein towers, and a radion contribution inspired by the Goldberger-Wise mechanism. We derive the full 3D effective action and show that, for the observed Higgs mass $m_{h}=125$ GeV, the radion potential admits a stable minimum, near-zero vacuum energy. By imposing the non-supersymmetric AdS instability conjecture as a quantum gravity consistency requirement, we obtain a model independent bound on the heavy Higgs sector, finding that the additional scalar states must satisfy $M_{H}\gtrsim 680$ GeV to avoid an unstable AdS$_{3}$ vacuum. Our results demonstrate how Swampland inspired constraints can yield sharp, phenomenologically testable predictions for extended Higgs sectors.

</details>


### [91] [CHIC: Caley-Hamilton, Invariants and Constants for Neutrino Oscillation Probabilities and Gradients](https://arxiv.org/abs/2512.16427)
*Pablo Fernández-Menéndez*

Main category: hep-ph

TL;DR: The paper presents an analytical method using the Caley-Hamilton theorem to compute neutrino oscillation probabilities and their derivatives efficiently, implemented in CHIC software, and introduces oscillograds for data analysis visualization.


<details>
  <summary>Details</summary>
Motivation: To avoid Hamiltonian diagonalization and improve computational efficiency for neutrino oscillation studies, while enabling gradient-based analysis tools.

Method: Application of the Caley-Hamilton theorem to derive analytical solutions for three-flavor neutrino propagation, using precomputed matrix invariants to separate energy and baseline dependencies.

Result: Development of CHIC software with fast computation capabilities, demonstration of probability gradients' utility in data analysis, and introduction of oscillograds visualization.

Conclusion: The proposed method offers a computationally efficient alternative to traditional approaches, enhances parameter sensitivity analysis, and provides new visualization tools for neutrino mixing studies.

Abstract: We use the Caley-Hamilton theorem to derive analytical solutions for the three-flavor neutrino propagation amplitude in a constant-density medium and their derivatives with respect to the mixing parameters. This approach avoids the diagonalization of the Hamiltonian and exploits precomputed matrix invariants to separate the dependence of oscillation probabilities on neutrino energy and propagation baseline. The results are implemented in the CHIC software, which provides simple, fast and efficient computation of oscillation probabilities and their derivatives. Finally, we demonstrate the value of probability gradients for neutrino data analyses and introduce a complementary visualization, the oscillograds, to probe underlying features of neutrino mixing.

</details>


### [92] [Learning holographic QCD with unflavoured meson spectra](https://arxiv.org/abs/2512.16450)
*Mathew Thomas Arun,Ritik Pal*

Main category: hep-ph

TL;DR: The paper presents a neural network framework to predict holographic QCD parameters using meson mass spectra, achieving accurate predictions for pion mass and spectra through learned potentials and dilaton profiles.


<details>
  <summary>Details</summary>
Motivation: To develop a data-driven approach for constructing holographic QCD models that accurately predict background geometries and scalar potentials without relying solely on theoretical assumptions.

Method: A neural network trained on unflavored meson mass spectra to solve discretized Schrödinger-like equations in a 5D deconstructed spacetime. The model learns confining potentials, dilaton profiles satisfying the null energy condition, and scalar field parameters (k₁ ~ -8, k₂ ~17).

Result: Predicts IR dilaton behavior intermediate between linear/quadratic forms, accurately computes pion mass/spectrum, and provides validated Python tools for further research.

Conclusion: Machine learning successfully bridges holographic QCD theory with experimental data, offering a novel paradigm for gauge-gravity duality studies with practical computational tools.

Abstract: We develop a neural network framework to predict the five-dimensional background geometry, dilaton potential, and chiral symmetry breaking scalar potential of holographic QCD from unflavored meson mass spectra. The model was trained in a discretized form of the Schrödinger-like equation, which resembles a linear moose in ``deconstructed" 5 dimensions with Dirichlet boundary conditions, in contrast to the AdS/DL with ``emergent" space-time. Using the $ρ$, $a_1$, $a_2$, and $f_0$ unflavored mesons and their excitations as training data, the model learns confining effective potentials and computes a dilaton profile that satisfies the null energy condition. The network predicts the IR behavior of dilaton to be in-between linear and quadratic forms. Moreover, the symmetry-breaking bulk potential of the scalar field, $V(X)= k_1 X^3+k_2 X^4$, was computed, and the parameters $k_1$ and $k_2$ predicted to be $\sim - \ 8$ and $\sim 17$ respectively. The deep-learned parameters, metric, and the dilaton profile were then used to predict the pion mass and its spectrum with good accuracy. A Python code, along with the trained models, is provided to facilitate further studies

</details>


### [93] [Coherence from Randomness: Sub-keV Dark Matter Scattering off Random, Heterogeneous Materials](https://arxiv.org/abs/2512.16451)
*Zhi-Han Liu,Shigeki Matsumoto,Jie Sheng,Chuan-Yang Xing*

Main category: hep-ph

TL;DR: Proposes a novel mechanism for detecting sub-keV dark matter using quadratic couplings to SM particles and heterogeneous material interactions, deriving new constraints from MICROSCOPE data.


<details>
  <summary>Details</summary>
Motivation: Address the challenge of detecting sub-keV dark matter by exploiting coherent scattering effects in heterogeneous materials to enhance signal visibility.

Method: Analyzes dark matter scattering in materials with density fluctuations, calculates enhanced coherent response leading to measurable accelerations, applies this to MICROSCOPE mission data.

Result: Derives constraints probing cross sections as low as ~4e-38 cm², extending into new parameter space for sub-keV dark matter.

Conclusion: Demonstrates the viability of using existing missions like MICROSCOPE to explore previously inaccessible dark matter parameters through novel scattering mechanisms.

Abstract: The sub-keV mass range has long posed a challenge for the direct detection of dark matter via elastic scattering. In this Letter, we propose a new mechanism in which dark matter, assumed to be quadratically coupled to SM particles, scatters from random heterogeneous materials with intrinsic density fluctuations, yielding an enhanced coherent response. This effect can substantially increase the total scattering rate and induce measurable accelerations of the target. Using this idea, we derive new constraints from the MICROSCOPE mission that extend into previously unexplored parameter space for sub-keV dark matter, probing cross sections down to $\sim 4\times10^{-38}\,\mathrm{cm^2}$.

</details>


### [94] [Unveiling Light-Quark Yukawa Flavor Structure via Dihadron Fragmentation at Lepton Colliders](https://arxiv.org/abs/2512.16492)
*Qing-Hong Cao,Xin-Kai Wen,Bin Yan,Shutao Zhang*

Main category: hep-ph

TL;DR: The paper proposes a method to probe light-quark Yukawa couplings using transverse spin dependent azimuthal modulations in dihadron fragmentation at lepton colliders, offering linear sensitivity and distinguishing up/down-quark contributions.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of directly measuring small light-quark Yukawa couplings amidst strong QCD backgrounds by developing a novel observables approach.

Method: Analyzing transverse spin-dependent azimuthal correlations in $e^-e^+	o q\bar{q}Z$ processes with dihadron fragmentation, leveraging interference between Higgs-mediated and SM amplitudes for linear $y_q$ sensitivity. Combines channels with identified hadrons (π±, K±, p/p̄) to separate up/down Yukawa contributions.

Result: Demonstrates ability to constrain Yukawa couplings at O(10^-4) precision, showing fragmentation dynamics can effectively probe Higgs flavor structure complementarily.

Conclusion: This framework establishes a new avenue for probing Yukawa couplings via fragmentation observables, offering improved sensitivity over quadratic-scale methods and distinguishing quark flavor contributions.

Abstract: Directly probing light-quark Yukawa couplings and their flavor structure remains a major challenge due to their smallness and overwhelming QCD backgrounds. In this Letter, we propose a theoretical framework to access these couplings at lepton colliders through transverse spin dependent azimuthal modulations in dihadron fragmentation. These modulations arise from the interference between Higgs mediated and Standard Model amplitudes in $e^-e^+\to q\bar{q}Z$, producing angular structures that are linearly sensitive to the Yukawa couplings $y_q$, in contrast to conventional observables that scale as $y_q^2$. By combining channels with an identified accompanying single hadron, $h^\prime=π^\pm,K^\pm$, and $p/\bar{p}$, this approach cleanly disentangles the up- and down-quark Yukawa contributions, yielding typical limits at the $\mathcal{O}(10^{-4})$ level and establishing fragmentation dynamics as a novel and complementary probe of the Higgs flavor structure.

</details>


### [95] [The Nontrivial Vacuum Structure of an Extended $t\bar{t}$ BEH (Higgs) Bound State](https://arxiv.org/abs/2512.16527)
*Christopher T. Hill*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In a recent reformulation of top-quark condensation for the Brout-Englert-Higgs boson, we introduced an extended internal wave-function, $φ(r)$. We show how this leads to a manifestly Lorentz invariant formalism, where the absence of ``relative time'' is a gauge invariance of the bilocal field theory. This dictates a novel and nontrivial Lorentz invariant vacuum structure for the BEH boson, the relativistic generalization of a condensed matter state such as a BCS or Bose-Einstein condensate.

</details>


### [96] [Chiral magnetic effect amplified baryogenesis at first-order phase transitions](https://arxiv.org/abs/2512.16537)
*Hui Liu,Ligong Bian*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this study, we show that, in the background of the primordial magnetic field, the CME effect can significantly amplify the chiral chemical potential sourced by the CP violation near the bubble walls during the first-order electroweak phase transition. This effect can lift the generated baryon asymmetry by several orders, and make it possible to explain the baryon asymmetry of the Universe with a CPV in the fermion sector far beyond the limitation of the electron dipole moment.

</details>


### [97] [Supercooling exit from charge supersaturation](https://arxiv.org/abs/2512.16601)
*Pietro Baratella*

Main category: hep-ph

TL;DR: This paper proposes that in scalar field systems with quasi scale-invariant potentials and a metastable vacuum at φ=0, the system can avoid eternal supercooling by utilizing a non-zero chemical potential for a conserved charge Q. When a species decouples from the plasma, the chemical potential's destabilizing effect may overcome thermal stabilization, leading to φ condensation and transition to the true vacuum.


<details>
  <summary>Details</summary>
Motivation: The motivation is to resolve the problem of eternal supercooling in scalar field systems, where the transition to the true vacuum via bubble nucleation is too slow. The authors aim to explore mechanisms to ensure the phase transition occurs before the universe becomes trapped indefinitely in the metastable state.

Method: The analysis involves studying the interplay between thermal effects (stabilizing) and chemical potential effects (destabilizing) on the scalar field φ. The key idea is that when a charged species decouples from the plasma, the balance shifts towards the chemical potential, inducing φ condensation and phase transition.

Result: The paper demonstrates that the presence of a non-zero chemical potential for the conserved charge Q, coupled with decoupling processes, can effectively destabilize the metastable vacuum, enabling the system to escape eternal supercooling and transition to the true vacuum through φ condensation.

Conclusion: The conclusion supports the proposed mechanism as a viable solution to avoid eternal supercooling in such systems, highlighting the critical role of chemical potential and decoupling processes in driving necessary phase transitions in early universe scenarios.

Abstract: Systems that feature a scalar field $φ$ with a quasi scale invariant potential, metastable at $φ=0$, can remain trapped, during cosmic evolution, in the `wrong' vacuum because the process of bubble nucleation to the true vacuum is inefficient. If $φ$ carries a conserved charge $Q$, the presence in the system of a non-zero chemical potential for $Q$ offers the possibility of escaping eternal supercooling: when a species decouples from the plasma the balance among the stabilising effect of temperature and the destabilising effect of chemical potential can change in favour of the latter, so that $φ$ condenses and triggers the transition to the stable phase.

</details>


### [98] [Condensation of slow $γ$-quanta in strong magnetic fields](https://arxiv.org/abs/2512.16628)
*Leah Folkerts,Reinhold Egger,Carsten Müller,Selym Villalba-Chávez*

Main category: hep-ph

TL;DR: The paper explores how strong magnetic fields affect blackbody radiation through vacuum polarization, leading to anisotropic Planck radiation with a resonance competing with the Wien peak, and proposes a new light state that could coexist with dense matter in neutron stars, impacting their structure and stability.


<details>
  <summary>Details</summary>
Motivation: Investigate the effects of strong magnetic fields (above QED scales) on blackbody radiation via vacuum polarization tensor singularities, understanding novel radiation states in extreme environments like neutron stars.

Method: Analytical analysis of the vacuum polarization tensor's root singularity near pair creation threshold, derivation of modified Planck radiation law incorporating vacuum birefringence and anisotropy, theoretical modeling of thermal spectrum resonances and phase behavior under extreme conditions.

Result: Anisotropic thermal radiation with resonance competing against Wien maximum, discovery of a light many-body condensate state in high-temperature phases, potential coexistence of this state with nuclear/quark matter in neutron star cores.

Conclusion: These quantum effects significantly alter radiation properties in strong fields, suggesting revisions to neutron star models for accurate predictions of compactness and stability under extreme astrophysical conditions.

Abstract: The implications of the root singularity of the vacuum polarization tensor near the first pair creation threshold on blackbody radiation are investigated for magnetic fields above the characteristic scale of quantum electrodynamics. We show that the vacuum birefringence in such a strong background leads to an anisotropic behavior of the Planck radiation law. The thermal spectrum is characterized by a resonance that competes with the Wien maximum, causing a crossover in the low $γ$-spectrum of the heat radiation. A light state resembling a many-body condensate with slow motion is linked to the high-temperature phase. This novel state of radiation may coexist with nuclear or quark matter in a neutron star's core, increasing its compactness and influencing its stability.

</details>


### [99] [Probing Excited $q\bar{q}$ Mesons via QCD Sum Rules](https://arxiv.org/abs/2512.16637)
*Shuang-Hong Li,Wei-Yang Lai,Hong-Ying Jin*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a systematic study of the masses of light excited $q\bar{q}$ mesons using QCD sum rules at next-to-leading order (NLO). To probe excited states, we construct several interpolating currents involving covariant derivatives. The calculation is carried out up to dimension-8 condensates, including NLO perturbative and $m\langle\bar{q}q\rangle$ corrections. Employing Gaussian sum rules, we obtain several $J^P=2^\pm$ nonets with masses agreeing well with experiments. Several $J=0,1$ states compatible with experiments are also obtained using both Gaussian and Laplace sum rules. In particular, the $J^P=2^+$ current couples to two distinct $J^P=2^+$ resonances. This work demonstrates the efficacy of operators with covariant derivatives for studying excited hadrons.

</details>


### [100] [The Physics of Herwig 7](https://arxiv.org/abs/2512.16645)
*J. Bellm,G. Bewick,S. Ferrario Ravasio,S. Gieseke,D. Grellscheid,S. Kiebacher,P. Kirchgaeßer,F. Loshaj,M. R. Masouminia,G. Nail,A. Papaefstathiou,S. Plätzer,M. Rauch,P. Reimitz,C. Reuschle,P. Richardson,D. Samitz,P. Sarmah,P. Schichtel,M. H. Seymour,A. Siódmok,D. Stafford,C. B. Strange,S. Sule,S. Webster,J. Whitehead*

Main category: hep-ph

TL;DR: Herwig 7 is a modern event generator for high-energy physics simulations, integrating advanced QCD and EW calculations, flexible matrix element methods, and improved parton showering/hadronization models to provide accurate predictions for collider experiments.


<details>
  <summary>Details</summary>
Motivation: To create a flexible, systematically improvable framework that unifies state-of-the-art perturbative QCD/EW calculations with non-perturbative models, addressing limitations in previous event generators by enabling precise simulations across a wide range of Standard Model processes and beyond.

Method: Uses automated Matchbox framework for generating hard scattering processes with tree-level/NLO matrix elements, supports subtraction schemes, multichannel phase-space sampling, and POWHEG/MCATNLO matching. Implements dual showering approaches (angular-ordered and dipole showers), YFS formalism for QED/EW radiation, and advanced cluster hadronization with colour reconnection models. Includes multi-partonic scattering models combining soft/semi-hard interactions.

Result: Provides precise predictions for SM processes through consistent multijet merging at LO/NLO, accurate treatment of QCD/EW effects, and comprehensive non-perturbative physics modeling. Enables effective beyond Standard Model phenomenology studies.

Conclusion: Herwig 7 offers a versatile, modular platform for analyzing data from current/future colliders by blending systematic theoretical improvements with practical simulation tools, supporting both precision Standard Model studies and new physics exploration.

Abstract: We present the physics foundations and recent developments of Herwig 7, the modern successor of the original HERWIG and Herwig++ series. Herwig 7 provides a flexible and systematically improvable framework for the simulation of high-energy lepton and hadron collisions, with particular emphasis on QCD and EW effects. Hard scattering processes are generated within the automated Matchbox framework, which integrates external amplitude providers, supports tree-level, next-to-leading-order (NLO) and loop-induced matrix elements, and implements subtraction schemes, multi-channel phase-space sampling, dynamic scale choices and both POWHEG- and MC@NLO-type matching algorithms. Consistent multijet merging at LO and NLO is provided, enabling precise predictions across a wide range of SM processes. Parton radiation is simulated using two complementary showers: an angular-ordered shower incorporating QCD coherence and the heavy-quark dead-cone effect, and a dipole shower optimised for NLO matching and multijet merging. Higher-order corrections are included through matrix-element corrections and dedicated reweighting techniques, while QED and EW radiation are treated using a YFS formalism and EW showering algorithms. The modelling of non-perturbative physics employs an advanced cluster hadronization framework with improved cluster formation, fission and decay, as well as colour reconnection models, heavy-quark effects and interfaces to alternative hadronization schemes. An extended eikonal multiple-partonic-scattering model, incorporating semi-hard and soft components together with diffractive interactions, enables realistic descriptions of minimum-bias and underlying-event data. Herwig 7 thus represents a versatile event generator, providing a coherent, modular and extensible platform for Standard Model and beyond-the-Standard-Model collider phenomenology at current and future facilities.

</details>


### [101] [Scalar damping in cosmological phase transitions](https://arxiv.org/abs/2512.16663)
*Andreas Ekstedt,Thomas Konstandin,Jorinde van de Vis*

Main category: hep-ph

TL;DR: The paper calculates scalar damping rates during cosmological phase transitions using kinetic theory, focusing on top quarks and weak gauge bosons. It finds convergence of bosonic contributions depends on soft mode treatment and that the phenomenological friction term used in simulations is marginally valid for Standard Model particles. It also tests the hypothesis that runaway wall pressure bounds local friction, showing that next-to-leading order terms are negative, supporting the hypothesis within the valid regime.


<details>
  <summary>Details</summary>
Motivation: To accurately model cosmological phase transitions, it is crucial to understand scalar damping terms and validate approximations used in hydrodynamical simulations. The study addresses gaps in treating soft modes and evaluates the validity of existing friction term approximations.

Method: The authors use kinetic theory to calculate scalar damping rates from top quarks and weak gauge bosons. They analyze convergence conditions for bosonic contributions under different treatments of soft modes. They also test the hypothesis about runaway wall pressure bounds by calculating next-to-leading order terms in velocity and mass.

Result: The bosonic contributions converge only with proper soft mode treatment. The phenomenological friction term is marginally valid for Standard Model particles. Negative next-to-leading order terms confirm that local damping cannot exceed runaway bubble pressure within the valid regime.

Conclusion: The study validates the use of phenomenological friction terms with caution for Standard Model scenarios and confirms the runaway pressure as an upper bound for local damping, emphasizing the importance of soft mode handling in such calculations.

Abstract: We outline how to calculate the scalar damping term during a cosmological phase transition from kinetic theory. We determine the scalar damping rate from top quarks and weak gauge bosons in a Standard Model-like theory. We find that the convergence of the bosonic contributions hinges on how the soft modes are treated. We discuss the validity of the phenomenological friction term employed in hydrodynamical simulations. We find that for a Standard Model particle content, this approximation is (marginally) justified.
  We also test the hypothesis that the pressure from a runaway wall acts as an upper bound on the pressure from the local friction term. We find that next-to-leading order contributions in terms of velocity and mass are negative and that in the regime of validity, the local damping term indeed cannot surpass the pressure from runaway bubbles.

</details>


### [102] [Enhanced di-Higgs production from TeV-scale heavy neutral leptons at future lepton colliders](https://arxiv.org/abs/2512.16734)
*Jonathan Kriewald,Emanuelle Pinsard,Ana M. Teixeira*

Main category: hep-ph

TL;DR: The paper examines how heavy neutral leptons from a low-scale Inverse Seesaw model enhance di-Higgs production (ℓ⁺ℓ⁻→hh) at future lepton colliders, showing up to 60x cross-section increases and potential for probing seesaw scenarios via cross-section bounds.


<details>
  <summary>Details</summary>
Motivation: Investigate the impact of TeV-scale heavy neutral leptons on di-Higgs production and explore complementary probes of low-scale seesaw mechanisms beyond traditional electroweak precision tests.

Method: Studied di-Higgs production within an Inverse Seesaw framework, analyzing cross-section modifications through theoretical calculations and considering constraints from electroweak precision observables.

Result: TeV-scale heavy neutral leptons can enhance the di-Higgs production cross-section by up to 60 times, with collider measurements potentially offering complementary constraints on seesaw models.

Conclusion: Future high-energy lepton colliders' di-Higgs cross-section data could provide unique insights into TeV-scale seesaw mechanisms beyond current electroweak bounds, emphasizing the role of heavy neutral leptons.

Abstract: Within the context of heavy neutral lepton extensions of the Standard Model, we consider the rare di-Higgs production mode $\ell^+\ell^-\to hh$ at future high-energy lepton colliders. As a concrete example, we study the impact of a low-scale Inverse Seesaw realisation on the prospects for di-Higgs production. Our results show that the presence of TeV-scale heavy neutral leptons can enhance the cross-section by up to factor 60. We further comment on the interplay with electroweak precision observables, showing that bounds on the di-Higgs production cross-section at future high-energy lepton colliders could serve as complementary probes of low-scale seesaw scenarios.

</details>


### [103] [On Non-Minimal Couplings to Gravity and Axion Isocurvature Bounds](https://arxiv.org/abs/2512.16754)
*Claire Rigouzzo,Sebastian Zell*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: For axions present during inflation, it has been shown that a non-minimal coupling $ξ_σ$ of the inflaton to gravity worsens isocurvature bounds, while a non-minimal coupling $ξ_ρ$ of the radial Peccei-Quinn field can alleviate them. We analyze the simultaneous presence of both couplings and determine when one effect dominates the other, in both the metric and Palatini formulations of gravity. The two tendencies interpolate smoothly, but introducing a non-minimal inflaton coupling reduces the viable interval of $ξ_ρ$ in which isocurvature bounds can be alleviated while avoiding backreaction on the inflationary dynamics. We illustrate our findings in Palatini Higgs inflation and Starobinsky inflation.

</details>


### [104] [Delayed Scaling of Multi-Type Cosmic F- and D-strings in VOS Models](https://arxiv.org/abs/2512.16821)
*Kazuto Nakamura,Masaki Yamada*

Main category: hep-ph

TL;DR: The paper examines the application of the velocity-dependent one-scale (VOS) model to cosmic F-strings and two D-strings in Spin(4N) gauge theory, analyzing scaling string density and reconnection probabilities. It identifies a potential suppression in high-frequency gravitational-wave signals detectable by future observatories.


<details>
  <summary>Details</summary>
Motivation: To understand the dynamics of cosmic strings in gauge theories and their gravitational-wave signatures, particularly focusing on how reconnection probabilities influence scaling behavior and observational prospects.

Method: Analytical calculations of string density scaling with reconnection probabilities, numerical validation, and determination of the timescale for reaching the scaling regime in Spin(4N) gauge theory with F- and D-strings.

Result: Found that high reconnection probabilities delay the scaling regime onset, causing prolonged non-scaling phases and suppression of high-frequency gravitational-wave signals, which could be detectable with future instruments.

Conclusion: The study highlights the significance of reconnection dynamics in cosmic string models, suggesting that observational tests of these models require accounting for timescale delays and potential signal suppression at high frequencies.

Abstract: We investigate the velocity-dependent one-scale (VOS) model to the case of one cosmic F-string and two D-strings as color flux tubes in pure Spin($4N$) gauge theory. We analytically calculate the scaling string density as a function of the reconnection probabilities, and confirm our results with numerical calculations. We also determine the timescale at which the string density reaches the scaling regime, and find that for certain values of the reconnection probability, the scaling time can become extremely large, by many orders of magnitude. This leads to a characteristic suppression signature of the gravitational-wave signal at high frequencies, which may become observable in the frequency range of future interferometric gravitational-wave observations.

</details>


### [105] [Consistent Excesses in the LHC Electroweak SUSY Searches: GUT-based Singlino/Higgsino Interpretation in the NMSSM](https://arxiv.org/abs/2512.16783)
*Emanuele Bagnaschi,Manimala Chakraborti,Sven Heinemeyer,Ipsita Saha*

Main category: hep-ph

TL;DR: This paper explores a supersymmetric model within the NMSSM framework to explain observed excesses in LHC data through specific particle mass relations and dark matter assumptions, complying with existing experimental constraints.


<details>
  <summary>Details</summary>
Motivation: To explain persistent excesses in LHC's 'golden channel' searches for supersymmetry using a singlino-dominated neutralino as dark matter and GUT-related gaugino masses.

Method: Interpreting 2/3 soft-lepton plus missing energy excesses via NMSSM with singlino DM, higgsino-like next neutralinos/charged sleptons, and GUT-scale gaugino mass relations (M1 ∼ M2/2 ∼ M3/6), predicting gluino masses above 3 TeV.

Result: The model successfully accounts for the excesses while satisfying LHC SUSY/Higgs limits, DM relic density, and direct detection bounds. It is first to explain the data using GUT-parameter SUSY models.

Conclusion: NMSSM with specified particle masses and DM candidate offers a consistent explanation for observed anomalies, providing a viable SUSY model within BSM physics.

Abstract: The search for supersymmetric models remains one of the main items on the BSM search program at the LHC, with EW SUSY partners still allowed with masses as low as a few hundred GeV. Over the last years, searches for the "golden channel", $pp \to \tildeχ^0_2 \tildeχ^{\pm}_1 \to \tildeχ^0_1 Z^{(*)} \tildeχ^0_1 W^{\pm (*)}$ show consistent excesses between ATLAS and CMS in the 2~soft-lepton and 3~soft-lepton plus missing-$E_T$ searches, assuming $m_{\tildeχ^0_2} \approx m_{\tildeχ^{\pm}_1} \gtrsim 200$ GeV and $Δm_{21} := m_{\tildeχ^0_2} - m_{\tildeχ^0_1} \approx 20$ GeV. We interpret these excesses in the framework of the Next-to-Minimal Supersymmetric Standard Model. We assume a singlino dominated lightest neutralino as a Dark Matter (DM) candidate. The second and third lightest neutralinos are higgsino like, with the higgsino mixing parameter $μ$ being smaller than the soft SUSY-breaking bino and wino masses, $M_1$ and $M_2$. We furthermore assume the approximate GUT relations $M_1 \sim M_2/2 \sim M_3/6$, with the implication for our scenario of a gluino mass $m_{\tilde{g}} \sim M_3 \gtrsim 3$ TeV. Scalar masses are assumed to heavy and do not play a role in our analysis. We find that this scenario is in agreement with all relevant experimental constraints, comprising the LHC searches for SUSY particles and additional Higgs bosons, the LHC Higgs-boson rate measurements, the DM direct detection limits and the upper limit on the DM relic density. We demonstrate that this scenario gives an excellent description of the observed excesses in the search for 2~and 3~soft-leptons plus \ETmiss, with $m_{\tildeχ^0_2} \sim m_{\tildeχ^0_3} \sim m_{\tildeχ^{\pm}_1}$ and $Δm_{21} \sim 20$ GeV. This constitutes the first explanation of the soft-lepton excesses in a model with GUT relations among the soft SUSY-breaking parameters.

</details>


### [106] [Next-to-Leading Order corrections to the Next-to-Eikonal DIS structure functions](https://arxiv.org/abs/2512.16788)
*Tolga Altinoluk,Guillaume Beuf,Jules Favrel,Michael Fucilla*

Main category: hep-ph

TL;DR: The paper presents next-to-leading order (NLO) corrections for next-to-eikonal quark background contributions in DIS structure functions, showing finite longitudinal and divergent transverse contributions.


<details>
  <summary>Details</summary>
Motivation: The motivation is to accurately compute NLO NEik corrections, which are essential for precise predictions in deep inelastic scattering (DIS) experiments, particularly addressing divergences that arise in transverse structure functions.

Method: The method involves calculating NLO corrections from both quark and gluon background fields, analyzing rapidity and UV divergences, and extracting finite terms. Specifically, t-channel quark exchanges are considered as the leading NEik contributions.

Result: The results indicate finite NLO corrections for the longitudinal structure function, while transverse contributions have rapidity and UV divergences. The divergences are systematically analyzed and finite components are isolated.

Conclusion: The study establishes a framework for handling NEik NLO corrections in DIS, crucial for reducing theoretical uncertainties in experimental analyses. The separation of divergences provides a pathway for future renormalization and factorization procedures.

Abstract: We compute next-to-leading order (NLO) corrections to next-to-eikonal (NEik) quark background contributions to DIS structure functions. Among NEik corrections, $t$-channel quark exchanges provide the lowest order contributions in $α_s$, and can be represented as insertions of the quark background field of the target. At NLO, we compute NEik corrections induced by both quark and gluon background fields, and suppressed by an explicit factor of $α_s$. We show that the NLO corrections to the NEik longitudinal structure function are finite, while those to the NEik transverse structure function exhibit rapidity and UV divergences. These divergences are analyzed, and the finite contributions are extracted.

</details>


### [107] [Impact of Supercooling on Direct Searches for Dark Matter and Gravitational Wave Backgrounds](https://arxiv.org/abs/2512.16809)
*Davide Racco,Alfredo Stanzione*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: An interesting feature of a cosmological phase transition can be a stage of exponential expansion (supercooling). The modified expansion history and the entropy injection at reheating, can affect the final energy fraction of dark matter. In this paper, we revisit the calculation of the freeze-out and freeze-in dynamics, showing additional effects on top of the standard dilution factor if the dark matter production is completed during the supercooling stage. We show for the first time how these effects can be particularly interesting for direct detection, as the parameter space for WIMP-like candidates shifts from excluded to allowed regions, and freeze-in candidates get closer to experimental reach. A phenomenological motivation to consider supercooling is the associated gravitational wave background. The implications of a finite-duration reheating stage, when the equation of state is close to matter-domination, are a peculiar low-frequency spectrum, and its shift to lower frequencies. These effects are a complementary test of the dynamics that we study for dark matter production, and remarkably can link direct detection of dark matter and gravitational wave astronomy.

</details>


### [108] [ggxy: NLO QCD corrections to loop induced gg initiated processes](https://arxiv.org/abs/2512.16835)
*Daniel Stremmer*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present the program package ggxy, which in its first version can be used to calculate partonic and hadronic cross sections to Higgs boson pair production at NLO QCD and it offers a direct interface to POWHEG-BOX. The 2-loop virtual amplitudes are implemented using analytical approximations in different kinematic regions, while all other parts of the calculation are exact. This implementation allows to freely modify all input parameter, such as the three Higgs coupling, the masses of the top quark and the Higgs boson, and the top-quark mass renormalization scheme.

</details>


### [109] [Multiple Axions in Laboratory Experiments](https://arxiv.org/abs/2512.16837)
*Arturo de Giorgi,Joerg Jaeckel,Sebastian Monath,Volodymyr Takhistov*

Main category: hep-ph

TL;DR: The paper explores the effects of multiple axion species on photon-axion oscillations and their implications for experimental searches like light-shining-through-a-wall experiments, helioscopes, and haloscopes, showing that multiple axions can both enhance and suppress signals through coherence and interference.


<details>
  <summary>Details</summary>
Motivation: To address the assumption in many searches that only a single axion species exists, and to analyze how multiple axions affect experimental signatures and parameter determinations.

Method: Develops general formulas for axion-photon oscillations in multi-axion scenarios, examines coherence and interference effects, and evaluates how experimental setups can detect multiple axion contributions.

Result: Multiple axions can qualitatively alter observational signatures, leading to both enhanced and suppressed signals compared to single-axion cases. Experimental parameter variations and targeted searches can identify axion multiplicity and infer their properties.

Conclusion: Axion multiplicity significantly impacts experimental signals, necessitating updated search strategies to account for interference effects to accurately determine axion properties and avoid misinterpretation of results.

Abstract: Axions and axion-like particles generically appear in extensions of the Standard Model. While many searches assume only a single axion species, there may exist a whole spectrum of multiple such fields. We develop general formulas for axion-photon oscillations in the presence of multiple axions and analyze the implications for experimental searches, including light-shining-through-a-wall experiments, helioscopes and haloscopes. We demonstrate that axion multiplicity can qualitatively alter observational signatures, particularly through coherence and interference effects. Multiple axions can not only enhance signals compared to single axion scenarios, but also suppress them. We show that variations of experimental parameters and searches allow identifying contributions of multiple axions and obtaining information about their properties.

</details>


### [110] [Exploring nuclear modification using one-point energy correlator at the electron-ion collider](https://arxiv.org/abs/2512.16847)
*Yu Fu,Zhong-Bo Kang,Jani Penttala,Yiyu Zhou*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study the one-point energy correlator (OPEC) at both the back-to-back and collinear limits in electron-proton and electron-nucleus collisions. We provide the factorization formalism for the two types of OPEC and present phenomenological predictions in the kinematic region relevant for the future Electron-Ion Collider. Focusing on cold nuclear matter effects in electron-nucleus scattering, we demonstrate that the OPEC serves as a powerful probe of the transverse momentum dependent (TMD) physics and in characterizing the medium-induced transverse momentum broadening in cold nuclear matter.

</details>


### [111] [Gravity-assisted neutrino masses](https://arxiv.org/abs/2512.16862)
*Stefan Antusch,Salvador Centelles Chuliá,Miguel Levy*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Gravity is generally expected to violate global symmetries, including lepton number. However, neutrino masses from the Planck-suppressed Weinberg operator are typically too small to account for oscillation data. We propose a new model-building approach to low-scale neutrino mass generation, in which an intermediate spontaneous symmetry-breaking scale generates masses and mixings in the heavy neutral lepton (HNL) sector, while leaving an unbroken residual symmetry $G_{\mathrm{res}}$ that forbids light-neutrino masses. The observed light-neutrino masses then arise because gravity breaks $G_{\mathrm{res}}$ via Planck-suppressed operators, inducing the small lepton-number violation required in low-scale seesaw constructions. The HNLs form pseudo-Dirac pairs, with masses potentially within reach of future colliders and complementary tests in precision searches such as charged lepton flavour violation (cLFV). As an illustration, we present a representative realisation of this class of models and show that, for $\mathcal{O}(1)$ operator coefficients, it predicts a region in the ($M_R$, $Θ^2$)-plane that can be testable via displaced-vertex searches at the High-Luminosity (HL) LHC and the FCC-ee.

</details>


### [112] [Solving the Dirac equation on a GPU for strong-field processes in multidimensional background fields](https://arxiv.org/abs/2512.16889)
*Greger Torgrimsson*

Main category: hep-ph

TL;DR: This paper solves the Dirac equation on GPUs using JAX for faster computation, enabling 2+1/3+1D background fields and calculating Schwinger/nonlinear Breit-Wheeler pair production probabilities compared to worldline-instanton approximations.


<details>
  <summary>Details</summary>
Motivation: To achieve significant speedup over CPU-based solutions and enable consideration of higher-dimensional background electromagnetic fields for quantum pair production studies.

Method: GPU acceleration with JAX library; scattered-wave-function approach for probability calculations; comparison with worldline-instanton approximations.

Result: Successful implementation showing orders-of-magnitude speed improvement, accurate computation of pair production probabilities in higher-dimensional fields.

Conclusion: GPU-based JAX implementation effectively handles Dirac equation solutions under complex electromagnetic backgrounds, providing a powerful tool for investigating quantum pair production phenomena.

Abstract: In this paper, we show how to solve the Dirac equation, $(iγ^μ[\partial_μ+ieA_μ(t,{\bf x})]-m)ψ=0$, on a GPU. This is orders of magnitude faster than solving it on CPU and allows us to consider background fields, $A_μ(t,{\bf x})$, that depend on $2+1$ or even $3+1$ coordinates. Our approach is conveniently implemented using the computational library JAX. We show how to obtain the probabilities of Schwinger and nonlinear Breit-Wheeler pair production from these solutions using a scattered-wave-function approach and compare the results with the worldline-instanton approximations.

</details>


### [113] [Anomalous Dimension of a General Effective Gauge Theory II: Fermionic Sector](https://arxiv.org/abs/2512.16890)
*Jason Aebischer,Luigi C. Bresciani,Nudzeim Selimovic*

Main category: hep-ph

TL;DR: The paper derives the complete set of one-loop anomalous dimensions for general Effective Field Theories (EFTs) using on-shell methods, completing the computation of leading order RGEs for gauge EFTs with scalar and fermion fields. It accounts for renormalization effects at order 1/Λ² and includes operator mixing across dimensions for arbitrary gauge groups.


<details>
  <summary>Details</summary>
Motivation: To provide a comprehensive framework for calculating Renormalization Group Equations (RGEs) in EFTs, ensuring consistent treatment of renormalization effects up to 1/Λ² order and incorporating both renormalizable and non-renormalizable couplings. This completes previous work focused on the bosonic sector by including fermions and scalar fields.

Method: On-shell methods are employed to compute one-loop anomalous dimensions for general EFTs. The approach systematically handles operator mixing across different mass dimensions and works for arbitrary gauge groups, ensuring the RGEs are valid in a general EFT context.

Result: A complete template of leading order RGEs for arbitrary gauge EFTs including scalar and fermion fields. These equations account for renormalization at 1/Λ² order, cover both renormalizable and non-renormalizable couplings, and allow for operator mixing between operators of different dimensions.

Conclusion: The derived RGEs offer a universal tool for studying renormalization effects in EFTs with any gauge group, enabling precise predictions and constraints on physics beyond the Standard Model at the order 1/Λ². This work paves the way for systematic EFT analyses in particle physics models with composite Higgs scenarios or ultraviolet completions.

Abstract: The complete set of one-loop anomalous dimensions for general Effective Field Theories (EFTs) is derived using on-shell methods. Combined with previous findings for the bosonic sector, the obtained results conclude the computation of the complete set of leading order Renormalization Group Equations (RGEs) in arbitrary gauge EFTs containing scalar and fermion fields. Renormalization effects are consistently taken into account at the order $1/Λ^2$ in the new physics scale $Λ$ for all renormalizable and non-renormalizable couplings. The obtained template RGEs include operator mixing across different dimensions and are valid for arbitrary gauge groups.

</details>


### [114] [Probing scalar and pseudoscalar new physics using rare kaon decays](https://arxiv.org/abs/2512.16903)
*G. D'Ambrosio,A. M. Iyer,F. Mahmoudi,S. Neshatpour*

Main category: hep-ph

TL;DR: The paper examines rare Kaon decays, particularly focusing on scalar and pseudoscalar operators in $K\to π\ell^+\ell^-$ and $K\to \ell^+\ell^-$ decays, emphasizing their potential to probe new physics through complementary decay channels and experiments.


<details>
  <summary>Details</summary>
Motivation: Rare kaon decays offer a sensitive probe for beyond Standard Model physics, as they are less affected by hadronic uncertainties and can reveal deviations from Standard Model predictions.

Method: Analyzes the role of different decay modes like $K^+\to π^+\ell^+\ell^-$ (especially muon forward-backward asymmetry for scalar effects), constraints from $K_L\to μ^+μ^-$, and future prospects for $K_S\to μ^+μ^-$ and $K_L\to π^0 \ell^+\ell^-$. Explores interplay between NA62, LHCb upgrade, and KOTO-II experiments.

Result: Highlights the complementary strengths of charged and neutral Kaon decay modes in constraining new physics scenarios. Specific emphasis on the muon forward-backward asymmetry as a clean scalar probe and the stringent limits from $K_L\to μ^+μ^-$.

Conclusion: Future measurements, particularly from upgraded experiments, will enhance sensitivity to new physics through these decay channels, reinforcing the need for coordinated experimental efforts.

Abstract: Rare kaon decays provide sensitive tests of new physics. In this work, we focus on scalar and pseudoscalar operators, analysing the $K\to π\ell^+\ell^-$ and $K\to \ell^+\ell^-$ decays. We highlight the complementary role of different modes: $K^+\toπ^+\ell^+\ell^-$, in particular the forward-backward asymmetry in the muon channel as a clean probe of scalar effects, the stringent constraints from $K_L\to μ^+μ^-$, and the discovery potential of future measurements of $K_S\to μ^+μ^-$ and $K_L\to π^0 \ell^+\ell^-$. The interplay between charged and neutral modes underscores the complementarity of NA62, the LHCb upgrade, and KOTO-II.

</details>
