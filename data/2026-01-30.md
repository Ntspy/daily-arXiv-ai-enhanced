<div id=toc></div>

# Table of Contents

- [astro-ph.HE](#astro-ph.HE) [Total: 15]
- [hep-ph](#hep-ph) [Total: 21]
- [gr-qc](#gr-qc) [Total: 25]
- [astro-ph.IM](#astro-ph.IM) [Total: 4]


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [1] [Constraining high-energy neutrinos from tidal disruption events with IceCube high-energy starting events](https://arxiv.org/abs/2601.20934)
*Mainak Mukhopadhyay,Patrick Wusinich,Kohta Murase*

Main category: astro-ph.HE

TL;DR: The paper investigates whether tidal disruption events (TDEs) correlate with high-energy neutrinos using IceCube data but finds no significant correlation, constraining parameters like jet fraction and cosmic ray energy.


<details>
  <summary>Details</summary>
Motivation: To test the hypothesis that TDEs are sources of high-energy neutrinos and to constrain their associated astrophysical parameters using neutrino observations.

Method: The authors used IceCube's 12.5-year HESE dataset to perform a maximum likelihood analysis, examining spatial and temporal correlations with 89 TDEs.

Result: No significant correlation was found between HESE events and TDEs, supporting the background-only hypothesis. Constraints were placed on $f_{\rm jet}$ and $\mathcal{E}_{\rm CR}$, e.g., $\mathcal{E}_{\rm CR} \lesssim 3×10^{53}$ erg for high jet fractions.

Conclusion: Current data limit TDEs' role in producing detectable neutrinos, but future electromagnetic and neutrino observations could further refine parameters and constraints.

Abstract: Tidal disruption events (TDEs) have been proposed as candidate sources of high-energy neutrinos. Successful and choked jets, as well as the accretion disk, corona, wind, and outflow regions in a TDE have been examined and shown to produce TeV - PeV neutrinos. In this work, we use the IceCube 12.5 year high energy starting events (HESE) dataset and perform a maximum likelihood analysis to investigate the spatial and temporal correlations between HESE dataset and a selected sample of 89 TDEs. Our results indicate that the currently observed data do not show any significant correlation and hence is consistent with the background only hypothesis. Using this result, we place constraints on the fraction of TDEs harboring intrinsic jets ($f_{\rm jet}$) and the corresponding isotropic-equivalent cosmic ray (CR) energy ($\mathcal{E}_{\rm CR}$). We note that even with limited statistics, we can constrain the parameter space as $\mathcal{E}_{\rm CR} \lesssim 3 \times 10^{53}$ erg for $f_{\rm jet} \gtrsim 0.6$ at more than 90% C.L. Finally, we discuss the theoretical implications of our results and the limits on the all-sky diffuse neutrino flux from TDEs. With more observational data in the electromagnetic band for TDEs and neutrino observations from IceCube and KM3NeT, our analysis can be used to place stringent constraints on physical parameters associated with TDEs.

</details>


### [2] [Turbulent Dynamo Action in Binary Neutron Star Mergers](https://arxiv.org/abs/2601.20953)
*Eduardo M. Gutiérrez,David Radice,Jacob Fields,James M. Stone*

Main category: astro-ph.HE

TL;DR: The study explores magnetic field generation in binary neutron star mergers, finding rapid small-scale field growth through turbulent dynamo action and coherent large-scale fields at high resolutions, which could influence post-merger electromagnetic and gravitational-wave signals.


<details>
  <summary>Details</summary>
Motivation: To investigate how initially weak magnetic fields evolve during binary neutron star mergers and determine the strength and coherence of resulting fields, which affect observable multimessenger signatures.

Method: Performed general-relativistic, dynamical spacetime magnetohydrodynamic simulations starting with pulsar-like magnetic fields, focusing on resolution effects on field amplification and structure.

Result: Rapid small-scale magnetic field amplification via turbulence was observed. At high resolutions, coherent large-scale magnetic structures emerged post-merger, suggesting ordered fields.

Conclusion: Strong, ordered magnetic fields may form immediately after neutron star mergers, impacting remnant evolution and observational signals like electromagnetic emissions and gravitational waves.

Abstract: Binary neutron star mergers are expected to generate intense magnetic fields that power relativistic and non-relativistic outflows and shape their multimessenger signatures. These fields likely arise from the turbulent amplification of initially weak magnetic fields during the merger, particularly via the Kelvin-Helmholtz instability at the collisional interface between the stars. While previous studies have shown efficient amplification to magnetar-level strengths, the degree of large-scale coherence of the resulting field remains uncertain. We present general-relativistic, dynamical spacetime, magnetohydrodynamic simulations following the evolution of initially weak, pulsar-like magnetic fields in a binary neutron star merger. We find rapid magnetic field growth at small scales with clear signatures of small-scale turbulent dynamo action. At the highest resolutions, we additionally observe the emergence of coherent magnetic structures on larger scales. Our results imply that strong, ordered magnetic fields may be present immediately after merger, with important implications for the subsequent evolution of the remnant and its observable electromagnetic and gravitational-wave signals.

</details>


### [3] [Early results in the search for extreme coronal line emitters with the Dark Energy Spectroscopic Instrument](https://arxiv.org/abs/2601.20964)
*Peter Clark,Joseph Callow,Or Graur,Alexei V. Filippenko,Thomas G. Brink,WeiKang Zheng,Jessica Aguilar,Steven Ahlen,Segev BenZvi,Davide Bianchi,David Brooks,Todd Claybaugh,Andrei Cuceu,Axel de la Macorra,Arjun Dey,Peter Doel,Jaime E. Forero-Romero,Enrique Gaztañaga,Satya Gontcho A Gontcho,Gaston Gutierrez,Victoria Fawcett,Mustapha Ishak,Jorge Jimenez,Dick Joyce,Stephanie Juneau,Theodore Kisner,Anthony Kremin,Martin Landriau,Laurent Le Guillou,Marc Manera,Aaron Meisner,Ramon Miquel,John Moustakas,Seshadri Nadathur,Will J. Percival,Francisco Prada,Ignasi Pérez-Ràfols,Graziano Rossi,Eusebio Sanchez,David Schlegel,Michael Schubnell,Joseph Harry Silber,David Sprayberry,Gregory Tarlé,Benjamin A. Weaver,Rongpu Zhou,Hu Zou*

Main category: astro-ph.HE

TL;DR: The study uses DESI's Early Data Release to identify three TDE-linked ECLEs and over 200 AGN contaminants, establishing a TDE rate consistent with prior research.


<details>
  <summary>Details</summary>
Motivation: To discover new TDE events via ECLEs and assess their astrophysical contaminants using DESI's data, aiding in understanding transient phenomena in galaxies.

Method: Analyzed DESI EDR spectra to detect ECLEs linked to TDEs, distinguishing them from AGN contaminants by spectral features. Developed custom Python code for the search.

Result: Found three TDE-linked ECLEs and >200 AGNs showing coronal lines. Estimated TDE rate R_G = 5e-6 per galaxy per year at z~0.2. Results align with previous studies.

Conclusion: DESI is effective for discovering TDE-linked ECLEs. AGNs significantly contaminate TDE searches, requiring improved filtering methods. The code developed aids future transient studies.

Abstract: Here we present the results of our search through the Early Data Release (EDR) of the Dark Energy Spectroscopic Instrument (DESI) for extreme coronal line emitters (ECLEs) - a rare classification of galaxies displaying strong, high-ionization iron coronal emission lines within their spectra. With the requirement of a strong X-ray continuum to generate the coronal emission, ECLEs have been linked to both active galactic nuclei (AGNs) and tidal disruption events (TDEs). We focus our search on identifying TDE-linked ECLEs. We identify three such objects within the EDR sample, highlighting DESI's effectiveness for discovering new nuclear transients, and determine a galaxy-normalized TDE-linked ECLE rate of $R_\mathrm{G}=5~^{+5}_{-3}\times10^{-6}~\mathrm{galaxy}^{-1}~\mathrm{yr}^{-1}$ at a median redshift of z = 0.2 - broadly consistent with previous works. Additionally, we also identify more than 200 AGNs displaying coronal emission lines, which serve as the primary astrophysical contaminants in searches for TDE-related events. We also include an outline of the custom python code developed for this search.

</details>


### [4] [Proposal to Search for the CP Violating Electromagnetic Vacuum Angle at the Event Horizon Telescope](https://arxiv.org/abs/2601.20965)
*Willy Fischler,Tom Banks*

Main category: astro-ph.HE

TL;DR: The paper investigates whether CP-violating effects, specifically the Fischler-Kundu Hall current, can be detected in EHT observations of SgrA* and M87*. It proposes methods to distinguish the signal from plasma-induced effects but concludes current data is insufficient.


<details>
  <summary>Details</summary>
Motivation: To explore observable signatures of quantum gravitational effects (CP-violating coupling) in black hole observations and differentiate them from astrophysical plasma influences.

Method: Analyzes the potential for extracting a non-zero CP-violating observable ${\cal C}$ from EHT data, proposes time-averaging techniques during polarization flips and compares polarization patterns between SgrA* and M87* to isolate universal topological signals.

Result: Identifies challenges like plasma masking the signal and polarization flips in M87*, but suggests methodology for future analysis. Current data lacks resolution for confirmation.

Conclusion: While promising, current observational data cannot yet confirm or rule out the FK effect. Improved data and refined analysis techniques are needed to distinguish quantum gravitational signals from plasma effects.

Abstract: We examine the possibility that evidence for a non-zero value of the CP violating $ \frac{e^2 }{32π^2}θ_{EM} \int d^4 x {\vec E}\cdot {\vec B}$ coupling might be extracted from Event Horizon Telescope observations of the black holes SgA* and M87*. The Fischler-Kundu\cite{FK} effect predicts a universal Hall current in the relaxation of charge falling onto the black hole horizon. We argue that this leads to a non-zero value of a certain CP-violating observable ${\cal C}$, defined below. The effect can be masked by parity violating plasma currents. In particular, evidence for polarization flips \cite{flip} in the signals from M87* indicate strong plasma effects in the data. We suggest that time averaging the data over periods including the flip might leave over a residual that would be an indicator of the FK signal. In addition, similarities in the polarization patterns between the two very different black holes, and a part of the signal that is uniform in frequency, might enable us to distinguish the universal topological signal from source and frequency dependent plasma effects. Current data does not appear to be sufficient to perform such a test.

</details>


### [5] [Towards precision astrometry of scattered images of compact radio sources: scintillometry theory and prospects](https://arxiv.org/abs/2601.21041)
*Dylan L. Jow,Delon Shen*

Main category: astro-ph.HE

TL;DR: The paper presents a new theoretical framework for FRB scintillometry, enabling astrometric reconstructions of lensing geometries and revealing insights into the circumgalactic medium.


<details>
  <summary>Details</summary>
Motivation: To advance FRB scintillometry to match pulsar scintillometry's capabilities, resolve scattering geometry degeneracies, and explore tiny-scale structures in the CGM.

Method: Introduces the concept of the instantaneous spatial wavefield as a unifying observable, linking it to dynamic spectra, and proposes methods to break degeneracies in multi-screen models and measure dispersion measure gradients.

Result: Frameworks enable full astrometric reconstructions of FRB sources and scattering screens, address key observational challenges, and open pathways to study CGM physics on ~100 AU scales.

Conclusion: FRB scintillometry, through this framework, offers transformative potential for probing extragalactic ionized media and refining FRB emission models, though observational challenges remain.

Abstract: Compact radio sources such as pulsars and FRBs undergo scintillation in the interstellar medium (ISM) when scattered images interfere at the observer. ``Scintillometry'' refers to the range of techniques to extract astrometric information -- such as the angular positions of the images and distances to the scattering screen and source -- from scintillation observations. Pulsar scintillometry has proven to be a powerful technique, revealing rich and unexpected scattering phenomenology in the ISM and also shedding light on the emission physics of pulsars. FRB scintillometry stands to be a similarly powerful probe of FRB emission, as well as structure on tiny scales in ionized media beyond our galaxy, such as the circumgalactic medium (CGM). However, nascent FRB scintillation studies are far from the sophisticated lensing geometry reconstructions that have been performed for scintillating pulsars. In this paper, we introduce a novel theoretical framework for scintillometry, demonstrating that the full astrometric content of scintillation observations is contained within a single underlying observable: the instantaneous spatial wavefield. We relate the instantaneous spatial wavefield to more familiar concepts from the pulsar scintillometry literature, such as the dynamic spectrum. Using this framework, we discuss prospects and limitations for FRB scintillometry, towards the goal of full astrometric reconstructions of FRB lensing geometries. We show how key degeneracies in two-screen scattering measurements can be ameliorated. In addition, we discuss the possibility of inferring dispersion measure gradients across scintillation screens, which may shed light on the highly unconstrained physics of the cool CGM phase on tiny ($\sim 100\,{\rm au}$) scales.

</details>


### [6] [NOCTURNE. I. The radio spectrum of narrow-line Seyfert 1 galaxies](https://arxiv.org/abs/2601.21099)
*M. Berton,E. Järvelä,S. Chen,L. Crepaldi,I. Varglund,M. Coloma Puga,A. Jimenez-Gallardo,A. Lähteenmäki,S. Panda,C. Piscitelli,A. Tortosa*

Main category: astro-ph.HE

TL;DR: The study investigates radio emission in narrow-line Seyfert 1 galaxies (NLS1s) using the JVLA, finding their radio spectra are dominated by optically thin emission from low-power outflows or star formation, with minimal relativistic jet contributions except in rare cases.


<details>
  <summary>Details</summary>
Motivation: To explore the origin of radio emission in NLS1s, especially the role of new extreme radio variability observed at frequencies above 10 GHz, which hints at exotic mechanisms beyond traditional models.

Method: Observed 50 NLS1s with the JVLA, with 20 re-observed for variability checks. Analyzed spectral shapes and identified new jetted candidates.

Result: 24 sources undetected; most others showed steep power-law spectra. No significant variability detected in re-observed targets. Two new jetted NLS1s found, including a high-frequency peaker indicative of young jets.

Conclusion: Radio emission in NLS1s is primarily from optically thin regimes (low-power outflows or star formation), with jets making minor contributions except in rare cases. Further multiwavelength studies are needed for full understanding.

Abstract: The origin of the radio emission in active galactic nuclei (AGN) is still debated. Multiple physical mechanisms can contribute to the spectrum at these frequencies, including relativistic jets, the jet base, outflows, star formation, and synchrotron emission from the hot corona. Recently, new extreme radio variability has been observed in the class of low-mass/high-Eddington AGN known as narrow-line Seyfert 1 (NLS1) galaxies, suggesting that another, more exotic mechanism may also play a role, especially at frequencies above 10 GHz. To investigate this relatively unexplored area of the radio spectrum, we observed a sample of 50 NLS1s with the Karl G. Jansky Very Large Array (JVLA), and 20 of them were observed twice. In this sample, 24 sources were not detected, while the others are typically characterized by a steep spectrum that can be modeled with a power law. We also identified two new candidate jetted NLS1s, including a high-frequency peaker, which is an extremely young relativistic jet. We found no significant variability in the sources observed twice. We conclude that the radio spectrum of NLS1s is typically dominated by optically thin emission, likely from low-power outflows, or by circumnuclear star formation, with a limited contribution from relativistic jets. Further studies at different spatial scales and at other wavelengths are necessary to fully constrain the origin of the radio emission in this class of active galaxies.

</details>


### [7] [Data-Driven Generation of Neutron Star Equations of State Using Variational Autoencoders](https://arxiv.org/abs/2601.21231)
*Alex Ross,Tianqi Zhao,Sanjay Reddy*

Main category: astro-ph.HE

TL;DR: The paper proposes a structured variational autoencoder (VAE) to reconstruct and generate neutron star equations of state (EOS) with high fidelity, incorporating supervised NS observables and latent variables for unresolved features.


<details>
  <summary>Details</summary>
Motivation: To create a flexible model for generating causal and stable neutron star EOSs that satisfy astronomical constraints and enable Bayesian inference using multimessenger data like gravitational waves and pulsar observations.

Method: A structured VAE framework with an encoder-decoder architecture mapping EOS data to a latent space. The latent space includes two supervised observables (M_max, R_1.4) and one latent variable for crust-core transition features.

Result: The VAE achieves mean absolute percentage errors of ~0.15% for M_max and R_1.4 when reconstructing Skyrme EOSs, demonstrating high-fidelity EOS generation.

Conclusion: The method effectively reconstructs EOS models with minimal latent variables and provides a tool for Bayesian inference using multimessenger data, advancing neutron star research.

Abstract: We develop a machine learning model based on a structured variational autoencoder (VAE) framework to reconstruct and generate neutron star (NS) equations of state (EOS). The VAE consists of an encoder network that maps high-dimensional EOS data into a lower-dimensional latent space and a decoder network that reconstructs the full EOS from the latent representation. The latent space includes supervised NS observables derived from the training EOS data, as well as latent random variables corresponding to additional unspecified EOS features learned automatically. Sampling the latent space enables the generation of new, causal, and stable EOS models that satisfy astronomical constraints on the supervised NS observables, while allowing Bayesian inference of the EOS incorporating additional multimessenger data, including gravitational waves from LIGO/Virgo and mass and radius measurements of pulsars. Based on a VAE trained on a Skyrme EOS dataset, we find that a latent space with two supervised NS observables, the maximum mass $(M_{\max})$ and the canonical radius $(R_{1.4})$, together with one latent random variable controlling the EOS near the crust--core transition, can already reconstruct Skyrme EOSs with high fidelity, achieving mean absolute percentage errors of approximately $(0.15\%)$ for $(M_{\max})$ and $(R_{1.4})$ derived from the decoder-reconstructed EOS.

</details>


### [8] [TeV Gamma-Rays from the Low-Luminosity Active Galactic Nucleus NGC 4278: Implications for the Diffuse Neutrino Background](https://arxiv.org/abs/2601.21411)
*Chengchao Yuan,Ruo-Yu Liu*

Main category: astro-ph.HE

TL;DR: The study examines the TeV emission from NGC 4278, a galaxy with a low-luminosity active galactic nucleus (LLAGN). It evaluates leptonic jet and lepto-hadronic wind scenarios, finding both can explain multiwavelength data. The state transitions between quiet and active modes may involve increased accretion and jet/wind expansion. Future observations in MeV and VHE γ-rays could distinguish between the models. The lepto-wind model accounts for the PeV neutrino background when considering corrected LLAGN density.


<details>
  <summary>Details</summary>
Motivation: To understand the origin of TeV emission from NGC 4278 observed by LHAASO, particularly distinguishing between relativistic jet and sub-relativistic wind mechanisms. Also, to assess how state transitions occur and their impact on neutrino emission and astrophysical backgrounds.

Method: Modeled multiwavelength (X-ray, GeV, TeV) spectra using single-zone leptonic and lepto-hadronic emission models across TeV-low (quiescent) and TeV-high (active) states. Compared model parameters to observed data to evaluate jet vs. wind scenarios. Calculated neutrino flux predictions and LLAGN density implications.

Result: Both scenarios fit the observed spectral energy distributions. Enhanced accretion rates and jet/wind expansion explain state transitions. Lepto-hadronic wind models require specific LLAGN density (10^-5 Mpc^-3) to explain PeV neutrino background, though current neutrino detectors can't observe predicted flux. Future MeV/VHE observations are needed to discriminate between models.

Conclusion: The TeV emission mechanism remains uncertain, but the study provides a framework linking LLAGN activity states and neutrino backgrounds. It emphasizes the need for upcoming MeV and very-high-energy γ-ray observations to validate models, and highlights the potential role of LLAGNs in contributing to cosmic neutrino signals when considering their active duty cycles.

Abstract: This work investigates the origin of the TeV emission detected by the Large High Altitude Air Shower Observatory (LHAASO) from NGC 4278, a galaxy hosting a low-luminosity active galactic nucleus (LLAGN). Considering two plausible scenarios, AGN jets and winds, we model the X-ray, GeV, and TeV emission during both TeV-low (quasi-quiet) and TeV-high (active) states. The spectral energy distributions can be explained either by single-zone leptonic emission from moderately relativistic jets or by lepto-hadronic emission from sub-relativistic winds. The best-fit parameters suggest that the transition from the quasi-quiet to the active state may be driven jointly by an enhanced accretion rate and the expansion of jets or winds. We further show that future MeV and very-high-energy $γ$-ray observations can discriminate between the {leptonic and lepto-hadronic scenarios}. Although the neutrino flux from NGC~1068 predicted by the wind model is too low to be detected with current neutrino observatories, a lepto-hadronic wind scenario can account for the PeV diffuse neutrino background when adopting a local LLAGN density corrected for the TeV duty cycle, $n_{\rm L,0}(ΔT_{\rm TeV}/T) \sim 10^{-5}~\rm Mpc^{-3}$, as inferred from the LHAASO detection.

</details>


### [9] [Compton hump reverberation lag in the bright Seyfert 1 galaxy IC 4329A with NuSTAR](https://arxiv.org/abs/2601.21537)
*Samuzal Barua,Hengxiao Guo,Minfeng Gu,Wenwen Zuo*

Main category: astro-ph.HE

TL;DR: The paper presents the first detection of relativistic reverberation in the Compton hump of the Seyfert galaxy IC 4329A using NuSTAR data, providing independent measurements of the black hole mass and coronal height. The observed lags at different frequencies confirm the presence of the reflection hump and align with prior findings.


<details>
  <summary>Details</summary>
Motivation: To extend reverberation measurements to the Compton hump (above 10 keV) and constrain black hole mass and coronal height using relativistic lag modeling, building on previous studies that only reached up to 10 keV.

Method: Analyzed a long NuSTAR observation of IC 4329A, measuring lags in the 20-30 keV band at varying frequencies. Combined relativistic reverberation modeling of lag-energy spectra with reflection spectroscopy on time-averaged flux data. Improved spectral resolution through data binning adjustments.

Result: Detected a lag time of ~1825 s at low frequencies, decreasing to ~195 s at higher frequencies. Derived M_BH=1.37e8 solar masses and coronal height h=2.45 R_g. Coronal temperature constrained to ~50 keV, consistent with past results. This is the fifth source showing Compton hump reverberation.

Conclusion: Reverberation mapping in the Compton hump validates the relativistic reflection scenario and offers independent black hole mass measurements. Results support the need for higher-frequency observations to better constrain coronal geometry and confirm the stability of mass estimates across methods. Future work should expand this technique to more sources.

Abstract: Recent reverberation delay measurements have moved beyond the 10 keV X-ray range, providing evidence for the Compton hump (a.k.a. reflection hump) in the lag spectra. We report the relativistic reverberation of the reflection hump in the bright Seyfert\,1 galaxy IC\,4329A based on a long {\it NuSTAR} observation. We find a delayed response of the 20--30 keV X-ray band, with a lag time of $\sim1825$ s at frequencies $0.5-1.5 \times 10^{-4}$ Hz. The lag amplitude drops to $\sim195$ s as the frequencies increase to $(1.5-10)\times10^{-4}$ Hz. Including IC\,4329A, so far five sources have been explored for reflection hump reverberation. We perform reverberation modelling of the 3--50 keV lag-energy spectra using the general relativistic transfer function code, which provides independent timing-based measurements of the black hole mass $M_{\rm BH}=1.37_{-0.36}^{+0.33}\times10^8~M_{\odot}$ and the coronal height $h=2.45_{-2.36}^{+1.92}~R_{\rm g}$ (with uncertainties at 90\% confidence). Within the uncertainties, the measured mass is found to be consistent with the previous finding. Furthermore, we undertake reflection spectroscopy to account for the hump feature and the associated relativistic effect using the time-averaged flux spectrum. Further sampling of the {\it NuSTAR} data (with a bin width of 0.2/0.4 keV below and above 10 keV) that reshapes the spectral resolution allows us to constrain the coronal temperature at $50.26_{-4.03}^{+5.58}$ keV -- consistent with the previous result from the combined {\it Suzaku} and {\it NuSTAR} data.

</details>


### [10] [Investigating the emission signatures of pulsar halo candidate HESS J1813-126](https://arxiv.org/abs/2601.21689)
*Agnibha De Sarkar*

Main category: astro-ph.HE

TL;DR: The paper examines whether HESS J1813-126, associated with the pulsar PSR J1813-1246, can be explained as a pulsar halo using synchro-curvature radiation and particle transport models. Results show the SED matches multiple models, but future observations will distinguish between them.


<details>
  <summary>Details</summary>
Motivation: To determine if HESS J1813-126 is a pulsar halo powered by PSR J1813-1246 and to identify particle transport mechanisms via observational diagnostics.

Method: Applied synchro-curvature radiation to model pulsar SEDs. Simulated electron-positron transport using time-dependent diffusion-loss equations. Compared IC emission predictions with multi-observatory data. Analyzed surface brightness profiles and aperture-dependent emission for model comparison.

Result: SC model successfully explains pulsar's emission. HESS J1813-126's SED aligns with multiple halo models. SBPs and emission predictions vary by model, offering testable signatures for next-gen telescopes.

Conclusion: HESS J1813-126 likely a pulsar halo, but transport model distinctions require future observations. The analysis strengthens the pulsar-halo connection and provides diagnostics for upcoming instruments.

Abstract: Extended gamma-ray sources surrounding middle-aged pulsars, primarily observed at teraelectronvolt energies, have been interpreted as pulsar halos, where relativistic $e^\pm$ diffuse into the interstellar medium and produce inverse-Compton (IC) emission. HESS J1813-126, associated with the energetic, radio-quiet gamma-ray pulsar PSR J1813-1246, has been suggested as a candidate pulsar halo, though its nature remains uncertain. We interpreted the high-energy emission of PSR J1813-1246 using the synchro-curvature (SC) radiation model and tested whether the gamma-ray spectral energy distribution (SED) of HESS J1813-126 can be explained as a pulsar halo powered by PSR J1813-1246. We explain the X-ray and gamma-ray SEDs of the pulsar using the SC framework. We further computed the transport and losses of $e^\pm$ injected by the pulsar through time-dependent diffusion-loss equations, exploring various common pulsar halo transport models. The resulting IC emission was compared with \textit{Fermi}-LAT, H.E.S.S., HAWC, and LHAASO data. We present predictions for the surface brightness profiles (SBPs) and the aperture-dependent emission for the different transport models, providing key diagnostics for assessing the observability of HESS J1813-126 with current and future instruments. The SC framework successfully reproduces the emission of PSR J1813-1246. The SED of HESS J1813-126 can be consistently reproduced within different pulsar halo frameworks, albeit with distinct predictions across different transport models. The corresponding SBP predictions and aperture-dependent emission offer testable signatures for future imaging atmospheric Cherenkov telescopes, which will be crucial for discriminating between the transport models. We further examined the link between the pulsar central engine and its extended halo by comparing the pair multiplicities in the magnetospheric and halo regions.

</details>


### [11] [Pulse-resolved Classification and Characteristics of Long-duration GRBs with \emph{Swift}-BAT Data.I. Precursors versus Main Bursts](https://arxiv.org/abs/2601.21693)
*Liang Li,Yu Wang,Jin-Jun Geng,Yong-Feng Huang,Rong-Gen Cai*

Main category: astro-ph.HE

TL;DR: The study analyzes 22 long-duration GRBs with precursors, finding differences in variability timescales and lags between precursors and main bursts, suggesting distinct dissipation mechanisms but a single collapsar origin.


<details>
  <summary>Details</summary>
Motivation: To investigate the origin of GRB precursors and their relation to main bursts by comparing their temporal and spectral properties.

Method: Systematic comparison of duration, spectral hardness, minimum variability timescale (MVT), and spectral lag between precursors and main bursts in 22 Swift-observed GRBs.

Result: Precursors have longer MVTs (3-10x) and near-zero lags, while main bursts show variable MVTs and positive lags. Both align with Type II GRBs but suggest different dissipation conditions.

Conclusion: Precursors likely arise from cocoon shock breakout or early outflows, while main bursts follow a standard collapsar model; no dual-progenitor evidence found.

Abstract: We present a systematic pulse-by-pulse analysis of 22 long-duration GRBs observed by \emph{Swift}, each exhibiting a well-separated precursor before the main burst. We compare duration, spectral hardness ratio, minimum variability timescale (MVT), and spectral lag between these components. Both precursors and main bursts have durations and hardness broadly consistent with Type II GRBs. However, precursors show longer MVTs (by factors of 3-10) and diverse lags with near-zero median values, while main bursts display variable MVTs and positive lags. These differences suggest precursors may originate from distinct dissipation conditions, possibly due to cocoon shock breakout or early magnetically dominated outflows. Despite temporal differences, both episodes are consistent with a single collapsar origin, providing no evidence for dual-progenitor events. Our findings support pulse-resolved classification and show that precursors offer critical insights into jet formation and pre-burst activity.

</details>


### [12] [Late-time X-ray afterglows of GRBs: Implications for particle acceleration at relativistic shocks](https://arxiv.org/abs/2601.21827)
*Zhi-Qiu Huang,Om Sharan Salafia,Lara Nava,Annalisa Celotti,Giancarlo Ghirlanda*

Main category: astro-ph.HE

TL;DR: The study challenges PIC simulation predictions about electron acceleration in GRB afterglows by analyzing X-ray data from six GRBs, finding no spectral cutoffs and suggesting PIC models may underestimate maximum electron energies.


<details>
  <summary>Details</summary>
Motivation: To verify PIC simulation predictions about the maximum synchrotron photon energy in GRB afterglows at late times and assess their consistency with observational data.

Method: Analyzing X-ray spectra (from Swift/XRT) of six GRBs beyond 1e7 seconds, applying a model considering shock opening angle effects to compare with PIC simulation results.

Result: No clear spectral cutoffs observed, which conflicts with PIC predictions unless extreme afterglow parameters are assumed that are inconsistent with typical modeling values.

Conclusion: PIC simulations likely underestimate electron acceleration efficiency, indicating a need to revise acceleration mechanisms for relativistic shocks in GRB afterglows.

Abstract: Particle-in-cell (PIC) numerical simulations are currently among the most advanced tools to investigate particle acceleration at relativistic shocks. Still, they come with limitations imposed by finite computing power, whose impact is not straightforward to evaluate a priori. Observational features are hence required as verification. energy electrons accelerated at external shocks, provides a testbed for such predictions. Current numerical studies suggest that in GRB afterglows the maximum synchrotron photon energy, which corresponds to the limit of electron acceleration, may fall within the $\sim$ 0.1--10 keV X-ray energy band at late times, $t\gtrsim 10^6 - 10^7$ s. To test this prediction, we analyzed the X-ray spectra of six GRBs with \emph{Swift}/XRT detections beyond $10^7$ s: our analysis reveals no clear evidence of a spectral cutoff. Using a model that accounts for the effect of the finite opening angle of the shock on the observed maximum synchrotron photon energy, we show that these observations are incompatible with PIC simulation predictions, unless one or more physical afterglow parameters attain values at odds with those typically inferred from afterglow modeling (small radiative efficiency, low ambient density, large equipartition fraction $ε_{\rm B}$ of the magnetic field). These findings challenge existing numerical simulation results and imply a more efficient acceleration of electrons to high-energies than seen in PIC simulations, with important implications for our understanding of particle acceleration in relativistic shocks.

</details>


### [13] [Extreme-Value Distribution Analysis of the Second CHIME/FRB Catalog: Assessing the Rarity of the One-off FRB 20250316A](https://arxiv.org/abs/2601.21870)
*Wen-Long Zhang,Jun-Jie Wei*

Main category: astro-ph.HE

TL;DR: The study analyzes the extreme brightness of FRB 20250316A using a statistical framework, finding it to be a rare outlier with a 600-year return period for peak flux. The findings suggest challenges in characterizing FRB luminosity tails and hint at possible unique sub-populations.


<details>
  <summary>Details</summary>
Motivation: To quantify the rarity of FRB 20250316A within known FRBs and explore the tail behavior of the FRB luminosity function given limited data.

Method: Applied the Generalized Extreme Value (GEV) distribution to CHIME/FRB catalog data using Bayesian fitting on peak flux and fluence block maxima.

Result: FRB 20250316A has a ~600-year return period for peak flux (Fréchet type) and ~50-year for fluence. Removing outliers shifts fluence to a Weibull-type distribution with a finite upper bound exceeded by the FRB.

Conclusion: FRB 20250316A is an exceptional event ('FRB BOAT'), indicating rare luminous FRBs may probe extreme luminosity limits or distinct sub-populations.

Abstract: We present a statistical analysis of the extreme brightness of the fast radio burst FRB 20250316A, a luminous, apparently non-repeating event detected by CHIME/FRB. Employing a model-agnostic framework based on the Generalized Extreme Value (GEV) distribution applied to the second CHIME/FRB catalog, we quantify its rarity within the current population. Bayesian fitting of GEV models to block maxima of peak flux and fluence data reveals FRB 20250316A to be a profound statistical outlier. For the peak flux, the analysis yields a return period of $\sim$ 600 years ($1σ$ credible level), with the underlying distribution being of the heavy-tailed, unbounded Fréchet type ($ξ> 0$). The fluence analysis indicates greater complexity: while the full sample suggests a Fréchet-type distribution with a $\sim50$-year return period in $1σ$ credible level, the removal of three other notable outliers points toward a light-tailed Weibull-type distribution ($ξ< 0$) with a finite upper bound far exceeded by FRB 20250316A. This dichotomy highlights the challenge in characterizing the tail of the FRB luminosity function with limited data. Although less extreme in recurrence time than the ``Brightest Of All Time'' gamma-ray burst GRB 221009A, FRB 20250316A constitutes a similarly exceptional event (a potential FRB ``BOAT'') within the short observational history of wide-field radio surveys. Our results underscore the existence of rare, highly luminous events that may probe the upper limits or distinct sub-populations of the FRB luminosity distribution.

</details>


### [14] [Spectroscopic Variability of the Broad H$β$ Emission Line in Sloan Digital Sky Survey Quasars](https://arxiv.org/abs/2601.21974)
*Collin M. Dabbieri,Jessie C. Runnoe,Michael Eracleous,Mary E. Kaldor,Mary Ogborn,Niana N. Mohammed*

Main category: astro-ph.HE

TL;DR: The paper presents a catalog of variability properties for the broad Hβ emission in quasars using SDSS DR16 data, including measurements like luminosity, FWHM, and velocity changes, with uncertainty estimation and analysis of non-normal distributions dependent on observational intervals.


<details>
  <summary>Details</summary>
Motivation: To systematically analyze broad Hβ variability in quasars for better understanding their physical properties like black hole mass and accretion processes, addressing measurement uncertainties and the impact of observational subsamples.

Method: Spectral decomposition of SDSS quasar spectra (z<0.8), measuring Hβ properties (luminosity, FWHM, etc.), calculating Δv_rad between observations, using forward-modeling for uncertainty estimation, and statistical analysis of distributions.

Result: Catalog of Hβ variability parameters, non-normal Δv_rad distribution linked to observation intervals, and revised uncertainty estimation method for spectral decompositions, noting the influence of the Reverberation Mapping subsample.

Conclusion: The catalog provides critical data for studying quasar dynamics and black hole physics. Non-normally distributed velocity changes and sample biases highlight the need for improved observational strategies and uncertainty models.

Abstract: We present a catalog of broad H$β$ variability properties for all spectra of quasars with $z<0.8$ and at least two observations included in the Sloan Digital Sky Survey (SDSS) Data Release 16 quasar catalog. For each spectrum, we perform a spectral decomposition to isolate the broad H$β$ emission. We measure the luminosity, FWHM, equivalent width, centroid, and Pearson skewness coefficient of broad H$β$ and provide derived physical properties such as the single-epoch black hole mass and the bolometric luminosity. For each pair of spectra in the sample, we calculate the change in radial velocity of the centroid of broad H$β$ emission ($Δv_{rad}$) as well as other derived properties related to broad H$β$ shape variability. We use forward-modeling methods to estimate the uncertainty in our measurements and discuss an improved method for estimating the uncertainty in $Δv_{rad}$ in the case where a spectral decomposition is used to isolate the broad H$β$ emission. We find that $Δv_{rad}$ is not normally distributed and that the shape of the distribution depends on the interval between observations. We discuss the effect of the predominance of the Reverberation Mapping subsample in the sample of pairs of spectra in SDSS.

</details>


### [15] [Constraining Black Hole Parameters from Shadow and Inner-Shadow Morphology Considering Effects from Thick Disk Accretion Flows](https://arxiv.org/abs/2601.21995)
*Julien A. Kearns,Dominic O. Chang,Daniel C. M. Palumbo,Shane W. Davis*

Main category: astro-ph.HE

TL;DR: The study examines how emission geometry influences the ability to determine black hole parameters using shadow and inner-shadow observations from Reissner-Nordström black holes, considering thick/thin accretion disks. It shows that while mass, charge, observer inclination, and emission co-latitude can be constrained with known inclination, the accuracy depends on assuming correct emission geometry. Applications to M87* and Sgr A* with future observatories like BHEX and NgEHT are analyzed.


<details>
  <summary>Details</summary>
Motivation: To understand how emission geometry impacts parameter estimation for Reissner-Nordström black holes and assess observational constraints for future telescopes like BHEX and NgEHT.

Method: The study investigates shadow and inner-shadow imaging from thick/thin accretion disks around Reissner-Nordström black holes, simulating observations to evaluate parameter constraints under varying geometries and known inclinations.

Result: Confirm previous findings that shadow and inner-shadow radii can constrain parameters with known inclination, but this requires correct emission geometry assumptions. Demonstrates parameter estimation effectiveness for M87* and Sgr A*-like systems with future observatories.

Conclusion: Accurate black hole parameter constraints require precise knowledge of both observer inclination and emission geometry. Future observatories like BHEX and NgEHT can improve these constraints but must account for emission geometry uncertainties.

Abstract: We study the effects of emission geometry on the capability to constrain black hole parameters from measurements of the shadow and inner-shadow of a Reissner-Nordström black hole. We investigate the capability to constrain mass, charge, observer inclination, and emission co-latitude from images of black hole accretion flows that would arise from thick and thin accretion disks. We confirm previous studies that have shown that independent radii measurements of the shadow and inner-shadow can constrain black hole parameters if the viewing inclination is known, but find that it is only possible if the true emission geometry is also assumed. We study the constraining capabilities of the shadow and inner-shadow observations of M87* and Sgr A* like systems within the context of the BHEX and NgEHT future observatories.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [16] [Photon angular momentum near Planck scale](https://arxiv.org/abs/2601.20899)
*Kenil Solanki,Gaurav Bhandari,S. D. Pathak,Vikash Kumar Ojha*

Main category: hep-ph

TL;DR: The paper examines angular momentum in gauge fields under Lorentz covariant RGUP with minimal length effects. It derives energy-momentum tensors and angular momentum currents using Noether's theorem, showing conservation laws hold despite Planck-scale corrections. Results include modified Poynting vectors that reduce to Maxwell's when the RGUP parameter is zero.


<details>
  <summary>Details</summary>
Motivation: Investigate how Planck-scale minimal length effects (via RGUP) influence gauge field angular momentum structure while preserving fundamental conservation laws. Tests the robustness of Noether's theorem-derived currents and tensors in high-energy regimes.

Method: Apply Noether's theorem to RGUP-modified higher-derivative gauge field Lagrangians. Calculate canonical and Belinfante energy-momentum tensors, and derive spin/orbital angular momentum currents. Analyze conservation laws and compare RGUP corrections to classical Maxwell limits.

Result: RGUP corrections add higher-order terms to angular momentum density and Poynting vector, yet standard conservation laws remain valid. When RGUP parameter is zero, classical Maxwell results are recovered. This indicates conservation laws persist even with quantum gravity-inspired modifications.

Conclusion: RGUP-induced minimal length effects modify angular momentum properties without violating conservation laws, suggesting such high-energy corrections are compatible with established relativistic frameworks. Results validate Noether's theorem applicability in modified gravitational scenarios.

Abstract: We study the angular momentum structure of the gauge field in Lorentz covariant relativistic generalized uncertainty principle (RGUP) framework incorporating Planck scale minimal length effects. Using Noether's theorem for higher derivative RGUP-modified gauge field Lagrangian, we obtain the canonical and symmetric (Belinfante) energy-momentum tensors and the corresponding gauge spin and orbital angular momentum currents. We show that the canonical and Belinfante-Rosenfeld angular-momentum tensors continue to satisfy the standard conservation law in the presence of Planck-scale corrections. %These results support the stability of fundamental conservation laws under high-energy modifications. The RGUP corrections introduce higher-order contributions to the angular momentum density and momentum flow, yielding a modified Poynting vector, with the Maxwell limit recovered for vanishing RGUP parameter.

</details>


### [17] [High precision heavy-boson-jet substructure with energy correlators](https://arxiv.org/abs/2601.20923)
*Jack Holguin,Ian Moult,Aditya Pathak,Massimiliano Procura,Siddharth Sule*

Main category: hep-ph

TL;DR: The paper studies energy correlators in heavy boson jets, showing a mass-induced peak arises from Sudakov resummation and provides precise predictions at N³LL' accuracy, validated with simulations and OPAL data.


<details>
  <summary>Details</summary>
Motivation: To investigate multi-scale jet substructure features using energy correlators, focusing on heavy boson jets where the boson mass introduces a distinct scale.

Method: The authors analyze the energy-correlator spectra of heavy boson jets by boosting measurements from $e^+e^-$ collisions at the $Z$ pole, leveraging Sudakov factorization in the back-to-back limit.

Result: The peak in the correlator is shown to stem from Sudakov resummation rather than Breit-Wigner effects, with predictions matching Herwig/Pythia simulations. Boosted-$Z$ spectra can be constructed using OPAL data.

Conclusion: Energy correlators enable precision measurements akin to lepton colliders in hadronic LHC jets, offering a versatile probe across varied transverse momentum scales.

Abstract: Energy-correlator-based jet substructure has gained significant attention in recent years. One of the notable applications has been the study of multi-scale jets, where distinct physical scales manifest as features localised in different angular regions of the correlator. In this article, we present the first high-precision study of energy correlators on the simplest multi-scale jets: heavy boson jets. In such systems, the boson mass $M$ introduces an additional scale, generating a sharp peak at angles $\sim M/p_T^{\rm jet}$. We show that this feature can be computed directly by boosting the EEC spectrum measured in $e^+e^- \rightarrow {\rm hadrons}$ at the $Z$ pole. We identify that the peak arises from boosting the well-studied Sudakov factorisation governing the back-to-back limit of the two-point correlator. As a result, the feature is controlled by Sudakov resummation, not a Breit-Wigner-like structure in the $Z$ decay, and is therefore calculable with exceptional precision. We provide predictions at N$^3$LL$'$ accuracy for both $pp$ $Z$-tagged jets and $e^+e^-$ di-$Z$ production, and compare them to Herwig and Pythia simulations, finding close agreement. We also demonstrate that the boosted-$Z$ spectrum can be constructed directly by boosting OPAL measurements at the $Z$ pole. In this light, energy-correlator jet substructure on the hadronic decays of heavy bosons at the LHC provide access to clean, lepton-collider-like measurements across a wide range of effective centre-of-mass energies set by the boson jet transverse momentum.

</details>


### [18] [Precision Jet Substructure of Boosted Boson Decays with Energy Correlators](https://arxiv.org/abs/2601.20933)
*Anjie Gao,Kyle Lee,Xiaoyuan Zhang*

Main category: hep-ph

TL;DR: The paper initiates a precision study of boosted jet substructure using energy correlators applied to hadronic Higgs decays, demonstrating distinct angular signatures and resolving infrared scales, which could enhance electroweak precision studies and new physics searches.


<details>
  <summary>Details</summary>
Motivation: To explore precision analysis of boosted Higgs decays and unveil infrared-scale phenomena like the dead-cone effect, potentially improving electroweak studies and new physics detection.

Method: Use of energy correlators to analyze jet substructure in boosted Higgs decays, focusing on angular distributions and Lorentz boost effects on decay patterns.

Result: Observed a characteristic angular peak at θ≈arccos(1−2/γ²) for boost factor γ, and resolution of infrared scales such as the dead-cone effect and confinement transition.

Conclusion: Precision analytic studies of boosted jet substructure could advance electroweak precision measurements and provide new avenues for discovering beyond-Standard-Model physics.

Abstract: We initiate the precision study of boosted jet substructure using energy correlators, applying this framework to hadronic Higgs decays. We demonstrate that the two-body decay of the Higgs manifests as a distinct angular peak at $θ\sim \arccos(1-2/γ^2)$ for Lorentz boost factor $γ$. We show that infrared scales, such as the dead-cone effect and confinement transition, are also resolved within the boosted distribution. Precision analytic studies of boosted jet substructure may enable precision electroweak studies and open new avenues for new physics searches.

</details>


### [19] [Probing Bose-enhanced Inflaton Decay with Gravitational Waves](https://arxiv.org/abs/2601.20939)
*Nicolás Bernal,Quan-feng Wu,Xun-Jie Xu,Yong Xu*

Main category: hep-ph

TL;DR: The study explores how a transient bosonic condensate formed from inflaton decay products enhances inflaton decay efficiency and boosts gravitational-wave production, potentially creating an observable low-frequency stochastic background.


<details>
  <summary>Details</summary>
Motivation: To understand how transient condensates and Bose enhancement impact reheating dynamics beyond standard perturbative models and their implications for detectable gravitational-wave signals.

Method: Analyzing cosmic reheating dynamics with a focus on the formation of a transient bosonic condensate and its effect on inflaton decay processes and graviton production.

Result: Bose enhancement from the condensate significantly amplifies inflaton decay efficiency and gravitational-wave production, producing a detectable stochastic gravitational-wave background even at low frequencies.

Conclusion: The presence of a transient bosonic condensate leads to new reheating dynamics that can generate observable gravitational-wave signals, offering a novel observational test for early universe models.

Abstract: We investigate cosmic reheating dynamics in the presence of a transient condensate formed by bosonic decay products of the inflaton. We show that the emergence of such a condensate and the corresponding Bose enhancement can dramatically increase the efficiency of inflaton decay, giving rise to qualitatively new reheating dynamics beyond the standard perturbative picture. As a consequence, graviton production from inflaton decay processes is significantly amplified by Bose enhancement effects, leading to a stochastic gravitational-wave background with a potentially observable amplitude, even in the low-frequency regime.

</details>


### [20] [Catalog of electroweak scalar manifolds](https://arxiv.org/abs/2601.20940)
*Juan Carlos Criado*

Main category: hep-ph

TL;DR: The paper classifies electroweak symmetry realizations with minimal fields (three Goldstone bosons and a Higgs), highlighting that local Higgs structure doesn't determine global properties like scalar manifold topology or fixed points. It shows diverse global scenarios even with the same local vacuum data.


<details>
  <summary>Details</summary>
Motivation: To address the gap in understanding how local Higgs sector properties relate to global topological features, as current experiments only provide local data leading to ambiguous global interpretations. The aim is to establish a classification under minimal field assumptions.

Method: Mathematical analysis of possible topologies and symmetry fixed points in scalar manifolds containing three Goldstones and a Higgs. Derivation of conditions for distinct global structures compatible with given local vacuum properties.

Result: Complete classification of electroweak symmetry realizations with minimal fields, revealing multiple possible global configurations (different manifold topologies, 0-2 fixed points) even when local vacuum structures are the same.

Conclusion: Experimental focus on local Higgs data is insufficient to uniquely determine global properties. Future studies should consider these global ambiguities when interpreting electroweak symmetry realizations and exploring phenomenological implications.

Abstract: The local structure of the Higgs sector around the vacuum does not uniquely determine its global properties. Most of the current experimental data provides only local information, which allows for a rich variety of global features, including several distinct topologies of the scalar manifold, and the existence of zero, one, or two fixed points of the symmetry transformations. Here, I provide, under general conditions, a complete classification of realizations of the electroweak symmetry with minimal field content -- the three would-be Goldstone bosons and the Higgs -- and outline some of their physical consequences.

</details>


### [21] [MadAgents](https://arxiv.org/abs/2601.21015)
*Tilman Plehn,Daniel Schiller,Nikita Schmal*

Main category: hep-ph

TL;DR: This paper introduces MadAgents, a set of agents designed to streamline the use of MadGraph for LHC research by providing accessible installation, hands-on training, user support, and automated simulation capabilities, including autonomous campaigns initiated from paper PDFs.


<details>
  <summary>Details</summary>
Motivation: To make state-of-the-art particle physics simulations more accessible to both new and advanced users, accelerating LHC research through automation and user-friendly tools.

Method: MadAgents interact with users via agentic installation, learning-by-doing training, and user support, automate event generation, and execute autonomous simulation campaigns starting from paper PDFs.

Result: Demonstrated effective user assistance for diverse simulation tasks and successful autonomous simulation campaigns triggered by PDF inputs.

Conclusion: MadAgents enhance accessibility and efficiency in particle physics simulations, promoting faster LHC research and broader participation through automation and user-centric design.

Abstract: We uncover an effective and communicative set of agents working with MadGraph. Agentic installation, learning-by-doing training, and user support provide easy access to state-of-the-art simulations and accelerate LHC research. We show in detail how MadAgents interact with inexperienced and advanced users, support a range of simulation tasks, and analyze results. In a second step, we illustrate how MadAgents automatize event generation and run an autonomous simulation campaign, starting from a pdf file of a paper.

</details>


### [22] [Constraining dimension-6 SMEFT with higher-order predictions for $p p \to t W$](https://arxiv.org/abs/2601.21040)
*Nikolaos Kidonakis,Kaan Şimşek*

Main category: hep-ph

TL;DR: This paper analyzes single-top production in association with a W boson at the LHC to probe dimension-6 SMEFT operators affecting top-quark dipole interactions. Using Run II and Run III data, they evaluate uncertainties and find effective scale ranges of up to ~2 TeV in nonmarginalized fits, and 0.5-1.5 TeV in marginalized fits.


<details>
  <summary>Details</summary>
Motivation: To investigate dimension-6 SMEFT contributions to top-quark weak and chromomagnetic dipole interactions via single-top + W production, leveraging LHC data at multiple perturbative orders to constrain beyond-Standard Model physics.

Method: Doubly differential top-quark distributions in transverse momentum and rapidity are used for SMEFT fits (linear and quadratic) at LO, NLO, and approximate NNLO QCD. Uncertainty components are analyzed across bins and orders.

Result: Nonmarginalized fits probe up to 2 TeV effective scales. Marginalized fits show lower scales (0.5 TeV for linear, 1.5 TeV for quadratic), indicating reduced sensitivity when uncertainties are considered.

Conclusion: The study highlights the process's sensitivity to SMEFT operators and quantifies how perturbative uncertainties affect scale reach. Results emphasize the importance of Run III data for future precision SMEFT constraints.

Abstract: We study single-top production in association with a $W$ boson at the LHC as a probe of dimension-6 Standard Model Effective Field Theory (SMEFT) at leading order, next-to-leading order, and approximate next-to-next-to-leading order accuracy in QCD. The process is sensitive to operators that modify the top-quark weak and chromomagnetic dipole interactions, and we perform three-parameter linear and quadratic SMEFT fits using doubly differential top-quark distributions in transverse momentum and rapidity for the Run II and Run III configurations at the LHC. We provide a detailed account of the uncertainties and quantify the impact of the different uncertainty components across bins and perturbative orders. We find that effective scales up to 2 TeV can be probed in nonmarginalized fits, while in marginalized fits the corresponding scales are around 0.5 and 1.5 TeV for linear and quadratic fits, respectively.

</details>


### [23] [Medium separation scheme effects on the magnetized and cold two-flavor superconducting quark matter](https://arxiv.org/abs/2601.21042)
*Francisco X. Azeredo,Dyana C. Duarte,Ricardo L. S. Farias*

Main category: hep-ph

TL;DR: This paper investigates how the Medium Separation Scheme (MSS) affects two-flavor color superconducting (2SC) dense quark matter in strong magnetic fields. It compares different regularization methods and finds that combining MSS with Magnetic Field Independent Regularization (MFIR) removes artificial oscillations in the diquark condensate and ensures correct high-density behavior. The MSS also keeps magnetization positive, unlike traditional methods.


<details>
  <summary>Details</summary>
Motivation: To address discrepancies in previous studies where unphysical oscillations were misidentified as de Haas–van Alphen effects and to ensure proper separation of medium and vacuum contributions in models of dense quark matter under magnetic fields.

Method: The study uses the Nambu–Jona-Lasinio model to compare regularization approaches: MFIR combined with MSS versus traditional smooth form factors. It analyzes the diquark condensate and magnetization under varying magnetic fields and densities.

Result: The MFIR-MSS approach eliminates spurious oscillations in the condensate, correctly predicts high-density behavior, and yields a consistently positive magnetization. Traditional methods show unphysical oscillations and negative magnetization regions.

Conclusion: Proper separation of medium and vacuum effects via MSS is critical for accurate modeling of quark matter in magnetic fields. The combined MFIR-MSS scheme provides reliable results, avoiding misinterpretations of physical phenomena.

Abstract: We analyze the impact of the Medium Separation Scheme (MSS) on two-flavor color superconducting (2SC) dense quark matter under the influence of a constant external magnetic field. The effects of the proper treatment of the model divergences are examined through a comparison of different approaches, including the combined implementation of the Magnetic Field Independent Regularization (MFIR) and the MSS, as well as the standard use of smooth form factors. Our findings for the Nambu--Jona-Lasinio model emphasize the critical role of properly separating medium effects from vacuum contributions in the model. The combined MFIR-MSS scheme suppresses spurious unphysical oscillations, often misinterpreted in the literature as de Haas--van Alphen oscillations, and ensures the correct high-density behavior of the diquark condensate. Furthermore, within the MSS framework, the magnetization remains positive across the explored parameter space, in sharp contrast with the behavior obtained in the traditional approach.

</details>


### [24] [Nucleon axial-vector form factor and radius from radiatively-corrected antineutrino scattering data](https://arxiv.org/abs/2601.21155)
*Oleksandr Tomalak,Aaron S. Meyer,Clarence Wret,Tejin Cai,Richard J. Hill,Kevin S. McFarland*

Main category: hep-ph

TL;DR: The paper addresses the importance of the nucleon axial-vector form factor ($G_A$) in neutrino interactions and other processes, emphasizing the need for accurate theoretical predictions and radiative corrections to reconcile lattice QCD calculations with experimental data from MINERvA.


<details>
  <summary>Details</summary>
Motivation: The scarcity of experimental data on $G_A$'s momentum dependence motivates the use of new experimental probes and lattice QCD calculations. Accurate extraction of $G_A$ and its radius requires applying radiative corrections to compare theory and experiments.

Method: The authors apply radiative corrections to extract $G_A$ and the axial-vector radius from MINERvA antineutrino-hydrogen data. They compare these corrections' impact with other experimental uncertainties and discuss lattice QCD results against measurements.

Result: The study highlights the necessity of radiative corrections in reducing uncertainties and facilitates comparison between lattice QCD predictions and experiments like MINERvA. It underscores the role of $G_A$ in improving neutrino interaction models.

Conclusion: Accurate determination of $G_A$ via radiative corrections and lattice QCD is crucial for future neutrino experiments. The analysis provides a framework to assess theoretical predictions against data, guiding improvements in understanding nucleon electroweak interactions.

Abstract: The nucleon axial-vector form factor, $G_A$, is critical to determine the electroweak interactions of leptons with nucleons. Important examples of processes influenced by $G_A$ are elastic (anti)neutrino-nucleon scattering and muon capture by the proton. Sparse experimental data results in a large uncertainty on the momentum dependence of $G_A$ and has motivated the consideration of new experimental probes and first-principles lattice quantum chromodynamics (QCD) evaluations. The comparison of new and precise theoretical predictions for $G_A$ with future experimental data necessitates the application of radiative corrections to experimentally-observable processes. We apply these corrections in the extraction of $G_A$ and the associated axial-vector radius from the recent MINERvA antineutrino-hydrogen data, compare the effects from radiative corrections to other uncertainties in neutrino scattering experiments, and discuss the comparison of lattice QCD evaluations to experimental measurements.

</details>


### [25] [Earth-Density Effects in LBL Experiments: A Comprehensive Review of Theory, Observations, and Future Directions](https://arxiv.org/abs/2601.21256)
*Tia Pandit,Bipin Singh Koranga*

Main category: hep-ph

TL;DR: The paper highlights that spatial variations in Earth's density significantly impact neutrino oscillation probabilities, particularly for muon to electron appearance channels crucial for CP violation studies. Mismodeling density profiles can introduce degeneracies, degrading CP phase sensitivity and inference. It argues for using spatially resolved density profiles instead of path-averaged approximations in future experiments.


<details>
  <summary>Details</summary>
Motivation: To address the shortcomings of path-averaged density approximations in neutrino oscillation experiments, which fail to capture energy-dependent density effects and may obscure CP violation signals, thereby necessitating improved modeling for next-generation precision measurements.

Method: The authors analyze three-flavor neutrino oscillations in realistic Earth density models, comparing results with path-averaged approximations. They identify energy-dependent probability structures and degeneracies caused by density mismodeling.

Result: Realistic density variations introduce additional energy-dependent oscillation structures. Mismodeling densities creates degeneracies that reduce CP phase sensitivity and bias results. Single-parameter marginalization is insufficient for future experiments.

Conclusion: Future long-baseline experiments must incorporate spatially resolved Earth density profiles to maintain CP violation sensitivity and avoid biased parameter inferences, ensuring accuracy in next-generation neutrino measurements.

Abstract: Earth matter density uncertainties play a non trivial role in three flavor neutrino oscillations in matter, particularly for the muon to electron appearance channel that underpins CP violation measurements in long baseline experiments. We demonstrate that when realistic spatial variations of the Earths density are taken into account, the oscillation probabilities acquire additional, energy dependent structures that cannot be captured by path-averaged density approximations. We show that mismodeling of the matter density profile can introduce degeneracies that obscure genuine leptonic CP violating effects, thereby degrading parameter sensitivity and biasing the inference of the CP phase. Identifying energy regions in which CP sensitivity remains robust against matter density uncertainties is therefore essential. These considerations indicate that marginalization over a single effective density parameter is insufficient for next generation precision measurements and motivate the incorporation of spatially resolved Earth density profiles in the analysis frameworks of future long-baseline neutrino oscillation experiments.

</details>


### [26] [Measurements of $H\rightarrow W^+W^-$ in the Fully Leptonic Decay Mode at the FCC-ee](https://arxiv.org/abs/2601.21327)
*Kael Kemp,Aman Desai,Paul Jackson*

Main category: hep-ph

TL;DR: The paper evaluates the precision of measuring the cross-section σ(e⁺e⁻→ZH) multiplied by the branching ratio Br(H→WW) in the fully leptonic decay mode at the FCC-ee collider for two center-of-mass energies (240 GeV and 365 GeV) and corresponding luminosities, achieving relative uncertainties of 2.9% and 6.8%, respectively.


<details>
  <summary>Details</summary>
Motivation: To assess the feasibility and accuracy of measuring Higgs boson production via the ZH process in the WW decay channel at the proposed Future Circular Collider-electron positron (FCC-ee) collider. This helps validate the Standard Model and search for potential new physics beyond it.

Method: Simulated analysis of FCC-ee data at 240 GeV (10.8 ab⁻¹ luminosity) and 365 GeV (3.12 ab⁻¹ luminosity) center-of-mass energies. Event generation, detector simulation, selection criteria, and statistical evaluation were performed to derive the cross-section times branching ratio with quantified uncertainties.

Result: Relative uncertainties of 2.9% and 6.8% were obtained for the σ×Br measurements at 240 GeV and 365 GeV, respectively, demonstrating the FCC-ee's capability for high-precision Higgs studies.

Conclusion: The FCC-ee offers significant improvement in measuring H→WW production in ZH associated production compared to previous colliders, supporting its role in precision Standard Model tests and probing beyond-Standard-Model physics.

Abstract: The expected precision on measuring the $σ(e^+ e^- \rightarrow ZH) \times Br(H\rightarrow W^+W^-)$ in the fully leptonic decay mode at the Future Circular Collider (FCC) is presented. We consider two FCC-ee scenarios: $\sqrt{s} =240$ GeV centre-of-mass energy with a luminosity of 10.8$\rm{~ab}^{-1}$ and $\sqrt{s} =365$ GeV centre-of-mass energy with a luminosity of 3.12$\rm{~ab}^{-1}$. Our results indicate that a relative uncertainty of 2.9\% and 6.8\% can be achieved on measurements of $σ(e^+ e^- \rightarrow ZH) \times Br(H\rightarrow W^+W^-)$ in the fully leptonic decay mode at $\sqrt{s} =240$ GeV and $\sqrt{s} =365$ GeV, respectively.

</details>


### [27] [Scaling Properties of Two-Particle-Two-Hole Responses in Asymmetric Nuclei for Neutrino Scattering within the Relativistic Mean-Field Framework](https://arxiv.org/abs/2601.21373)
*V. L. Martinez-Consentino,J. E. Amaro,J. Segovia*

Main category: hep-ph

TL;DR: The paper analyzes nuclear dependence of meson-exchange currents in lepton-nucleus scattering using a relativistic mean-field model, calculates nuclear responses for 17 nuclei, proposes a scaling method with phase space and nuclear parameters, showing accuracy under 10% and utility for neutrino event generators.


<details>
  <summary>Details</summary>
Motivation: To systematically study meson-exchange current contributions and provide a scalable framework for accurate nuclear response predictions across diverse nuclei.

Method: Microscopic calculations using a relativistic mean-field framework with distinct proton/neutron Fermi momenta; proposed scaling based on two-particle phase space and nuclear parameters; benchmarked against electron-scattering data.

Result: Accurate nuclear response descriptions (sub-10% deviations) across 17 nuclei; validated by electron-scattering data; scalable parametrization for neutrino event generators.

Conclusion: The proposed scaling method effectively captures nuclear dependencies, enabling broader applicability in particle physics simulations.

Abstract: We perform a systematic analysis of the nuclear dependence of two-particle-two-hole meson-exchange current contributions to inclusive lepton-nucleus scattering within the relativistic mean-field framework. We present microscopic calculations of nuclear responses for a set of 17 nuclei, ranging from helium to uranium, using a model with different Fermi momenta for protons and neutrons. We propose a novel scaling prescription based on the two-particle phase space and key nuclear parameters. The resulting description is accurate over a wide range of nuclear targets, with typical deviations below 10\%, and allows for a separate treatment of the different emission channels. In addition, a consistent benchmark against electron-scattering data is provided. The parametrization presented provides a practical framework for extending the responses to different nuclear targets in neutrino event generators.

</details>


### [28] [Lepton sourced baryon asymmetry in the fourth generation model](https://arxiv.org/abs/2601.21374)
*Hsiang-nan Li*

Main category: hep-ph

TL;DR: This paper proposes that the observed baryon asymmetry of the universe can be explained within an extended Standard Model with a fourth sequential generation of fermions (SM4). Using dimension-6 effective operators involving fourth generation quarks' CP violation sources from the 4x4 CKM matrix, it calculates the baryon-to-entropy ratio (η_B ~10⁻¹⁰) matching observational data.


<details>
  <summary>Details</summary>
Motivation: To address the origin of the universe's baryon asymmetry without requiring physics beyond the Standard Model, by exploring an SM4 framework with fourth generation fermions that naturally incorporates CP violation.

Method: Constructs dimension-6 operators from SM4 quark contributions, determines CKM matrix elements (V_ib') using previous analyses of heavy quark decays and meson mixing, then applies these into electroweak baryogenesis formalism to compute η_B.

Result: Achieves a baryon-to-entropy ratio η_B ~10⁻¹⁰ consistent with cosmological observations through the proposed SM4 mechanism with fourth generation fermions.

Conclusion: The SM4 model with sequential fourth generation fermions provides a viable Standard Model extension that can account for the observed baryon asymmetry through electroweak-scale CP violation mechanisms inherent in its extended CKM matrix configuration.

Abstract: We demonstrate that the observed baryon asymmetry in the Universe can be accommodated in the extended Standard Model with sequential fourth generation fermions (SM4). We first construct the dimension-6 effective operators of the type $-i(Φ^\daggerΦ)\bar F_LΦf_R$ induced by fourth generation quarks, which carry the $CP$ violation (CPV) source from the $4\times 4$ Cabibbo-Kobayashi-Maskawa (CKM) matrix, $Φ$ ($F_L$, $f_R$) being a Higgs double (left-handed fermion doublet, right-handed fermion singlet). The required inputs of the fourth generation fermion masses were derived in our previous dispersive analyses on heavy quark decays and neutral meson mixing. The similar framework allows the determination of the $4\times 4$ CKM matrix elements $V_{ib'}$, $i=u$, $c$ and $t$, such that the strength of the CPV source can be evaluated unambiguously. The dimension-6 operators associated with fourth generation leptons, as implemented into the formalism for the electroweak baryogenesis in the literature, lead to the baryon-over-entropy ratio $η_B\approx 10^{-10}$.

</details>


### [29] [Chiral-odd generalized parton distributions of spin-1/2 baryons](https://arxiv.org/abs/2601.21415)
*Navpreet Kaur,Monika Randhawa,Harleen Dahiya*

Main category: hep-ph

TL;DR: The paper investigates the tomographical structure of baryons using nonforward matrix elements of lightlike correlation functions with a tensor current, focusing on chiral-odd distributions at leading twist. Calculations using a diquark spectator model with light-front formalism, considering zero skewness, reveal differences in nucleons and hyperons due to quark flavor variations.


<details>
  <summary>Details</summary>
Motivation: To explore the internal structure of baryons (nucleons and hyperons) by analyzing chiral-odd distributions through nonforward matrix elements of tensor current correlation functions, highlighting the impact of quark flavor differences.

Method: The study employs a diquark spectator model within the light-front formalism to compute four chiral-odd distributions at leading twist. The analysis assumes purely transverse momentum transfer (zero skewness) to simplify the calculations.

Result: Predictions are made for nucleons and light hyperons, showing distinct distributions stemming from their differing quark compositions, which can guide future experimental investigations into baryonic structures.

Conclusion: The approach successfully distinguishes baryonic structures based on quark flavors, emphasizing the importance of chiral-odd functions and model-based calculations for understanding baryon tomography.

Abstract: We present the tomographical structure of baryons by studying the nonforward matrix elements of lightlike correlation functions of the tensor current. At the leading twist, with the tensor current, four chiral-odd distributions are in count. We calculate these distributions in a diquark spectator model with light-front formalism by considering purely transverse momentum transfer, i.e., zero skewness. Predictions for the nucleons and light hyperons are studied, emphasizing the difference arising from their different quark flavors.

</details>


### [30] [Gravitational form factors of baryons in a spectator diquark model](https://arxiv.org/abs/2601.21430)
*Navpreet Kaur,Harleen Dahiya*

Main category: hep-ph

TL;DR: The paper investigates the gravitational form factors of baryons using the diquark spectator model, focusing on strange and non-strange baryons by analyzing quark-diquark systems and their relation to generalized parton distributions through quantum chromodynamics.


<details>
  <summary>Details</summary>
Motivation: To explore the indirect measurement of the energy-momentum tensor (EMT) via electromagnetic interactions in QCD, as direct graviton scattering is infeasible.

Method: Parameterizing matrix elements of the local EMT operator with gravitational form factors linked to generalized parton distributions, employing the diquark spectator model to examine quark-diquark systems in baryons.

Result: Analyzes the behavior of each quark flavor in strange and non-strange baryons through feasible quark-diquark pairs, providing insights into their gravitational form factors.

Conclusion: Demonstrates that the diquark spectator model offers a viable framework for understanding baryon EMT properties indirectly through QCD electromagnetic interactions.

Abstract: Energy momentum tensor (EMT) expresses the interaction between the gravitation and the matter fields, in which the scattering off the graviton is a natural but infeasible probe. However, the EMT can be accessed indirectly through electromagnetic interactions in quantum chromodynamics. The matrix elements of the local EMT operator are parameterized by gravitational form factors, which are subsequently related to the generalized parton distributions. Within the diquark spectator model, we investigate the gravitational form factors of baryons. We consider all the feasible pairs of quark-diquark systems to understand the behavior of each constituent quark flavor of strange and non-strange baryons.

</details>


### [31] [The $Ω(2380)$ as a partner of the $Ω(2012)$](https://arxiv.org/abs/2601.21536)
*Yi-Yao Li,Albert Feijoo,Eulogio Oset*

Main category: hep-ph

TL;DR: The paper analyzes the Omega(2380) resonance, identifying it as a dynamically generated state from interactions involving mesons and hyperons, similar to Omega(2012). It aligns with experimental data on mass, width, and decay channels, and suggests future experimental tests.


<details>
  <summary>Details</summary>
Motivation: To determine the nature of the Omega(2380) resonance and confirm its dynamical generation through specific meson-hyperon interactions, following the success of similar analyses for Omega(2012).

Method: The study uses coupled-channel unitary models to explore interactions between ar{K}^*Ξ^*, ωΩ, and φΩ, calculating resonance properties and comparing with experimental data.

Result: The Omega(2380) properties match experimental observations, confirming its origin from the proposed interactions. Partial decay widths into specific channels are consistent with data.

Conclusion: The Omega(2380) is validated as a dynamically generated resonance. Further experimental measurements on proposed observables are encouraged to deepen understanding.

Abstract: We present a study of the $Ω(2380)$ resonance and show that it is consistent with a dynamically generated state arising from the $\bar{K}^*Ξ^*$, $ωΩ$, and $φΩ$ interactions. In this picture, the $Ω(2380)$ is analogous to the $Ω(2012)$, which is generated from the $\bar{K}Ξ^*$ and $ηΩ$ channels. The resulting mass, total width, and partial decay widths into the $\bar{K}Ξ^*$ and $\bar{K}^*Ξ$ channels are compatible with the available experimental data. We also discuss possible experimental observables that could provide further insight into the nature of this state.

</details>


### [32] [Understanding the 1P- and 2S-wave nucleon resonances within the extended Lee-Friedrichs Model](https://arxiv.org/abs/2601.21697)
*Yu-Hui Zhou,Hui-Hua Zhong,Zhi-Yong Zhou,Xian-Hui Zhong*

Main category: hep-ph

TL;DR: The paper proposes an extended Lee-Friedrichs model to analyze low-lying 1P- and 2S-wave nucleon resonances, resolving the Roper resonance's level inversion via coupled-channel dynamics with meson-baryon continua. It explains the Roper's lower mass as a dressed bare 2S state and accurately reproduces 1P-wave resonance properties.


<details>
  <summary>Details</summary>
Motivation: Address the long-standing issue of the Roper resonance's (N(1440)) level inversion, where its mass is lower than expected for a 2S state, and provide a unified description of both 1P- and 2S-wave nucleon resonances through coupled-channel effects.

Method: Using an extended Lee-Friedrichs framework with coupled-channel dynamics between bare quark-model states and πN, πΔ, and ηN continua. Parameters are calibrated to match known 1P-wave spectra and widths.

Result: The model shifts the bare 2S pole to the Roper's mass, explaining its level inversion. Roper shows significant meson-baryon component, and all five 1P-wave resonance properties are accurately reproduced.

Conclusion: Coupled-channel effects are critical in determining nucleon resonance spectra. The Roper arises from a dressed bare 2S state, emphasizing interplay between quark degrees of freedom and meson-baryon interactions.

Abstract: We present a unified desciption of the low-lying $1P$- and $2S$-wave nucleon resonance within the framework of an extended Lee-Friedrichs scheme. By incorporating the coupled-channel dynamics between bare quark-model states and the $πN$, $πΔ$ and $ηN$ meson-baryon continua, we examine the mass shifts and structural properties of these excited states. We demonstrate that when the model parameters are calibrated to match the $1P$-wave spectrum and their widths, the pole associated with the bare $2S$ state is naturally shifted downward to the mass region of physical Roper resonance--$N(1440)$, thereby offering a dynamical explanation for the long-standing level-inversion problem. An approximate analysis of compositeness and elementariness reveals that the Roper resonance contains a significant meson-baryon continuum states, consistent with the picture of a bare core heavily dressed by meson-baryon cloud. Simultaneously, the pole positions and properties of five $1P$-wave resonances--$N(1535)$, $N(1650)$, $N(1520)$, $N(1700)$ and $N(1675)$ are successfully reproduced. Our results highlight the essential role of coupled-channel effects in shaping the nucleon spectrum and provide a consistent microscopic insight into the interplay between internal quark degrees of freedom and external hadronic fields.

</details>


### [33] [From LUXE to Future Colliders: Probing Strong-Field QED and Beyond](https://arxiv.org/abs/2601.21891)
*Ivo Schulthess*

Main category: hep-ph

TL;DR: The abstract discusses using ultra-intense laser-electron beam collisions at the LUXE/DESY experiment to study strong-field quantum electrodynamics phenomena like vacuum pair production, with future potential extensions to higher-energy scales and applications in new physics searches via high-energy photon beam-dumps.


<details>
  <summary>Details</summary>
Motivation: To explore non-perturbative QED effects such as vacuum pair production in intense electromagnetic fields, and investigate opportunities for future experiments to probe higher energy/intensity regimes and search for new physics phenomena.

Method: Colliding ultra-high intensity lasers with 16.5 GeV electron beams at the European XFEL's LUXE facility to study strong-field QED processes. Proposed future methods involve advanced accelerators like linear colliders for higher scale studies. High-energy photons from these interactions are proposed for use in beam-dump experiments to detect new particles.

Result: Primary expected results include observation/measurement of electron-positron pair creation rates in strong fields, characterization of high-energy photon production, and establishment of foundational data for future new physics searches.

Conclusion: LUXE represents a pioneering experimental platform for QED vacuum studies, demonstrating feasibility of using current facilities while laying groundwork for next-generation experiments capable of accessing unprecedented intensity/energy regimes to uncover new physics beyond Standard Model predictions.

Abstract: Strong-field quantum electrodynamics offers a unique window into non-perturbative phenomena such as vacuum pair production, in which electron--positron pairs are created from the vacuum in the presence of intense electromagnetic fields. The LUXE experiment at DESY is designed to probe this regime using collisions between a high-intensity laser and the 16.5 GeV electron beam of the European XFEL. Future accelerator infrastructures, such as linear colliders, could extend these studies to even higher intensity and energy scales. Additionally, high-energy photons produced in such interactions can be used in beam-dump experiments to search for new physics.

</details>


### [34] [$f$-Mode oscillations and the gravitational response of compact stars with analytic equations of state](https://arxiv.org/abs/2601.21911)
*Kilar Zhang,Alessandro Parisi,C. Vásquez Flores,Chian-Shu Chen*

Main category: hep-ph

TL;DR: The paper uses analytical models to study neutron stars and dark stars, focusing on their masses, radii, tidal deformabilities, and f-mode oscillations. The method can apply to any analytical equations of state and uses multi-messenger observations to constrain model parameters.


<details>
  <summary>Details</summary>
Motivation: To explore global observable properties of compact stars and constrain theoretical models using observational data from multi-messenger astronomy.

Method: Application of analytical models to calculate neutron star and dark star properties including mass, radius, tidal deformability, and f-mode oscillations. The method is demonstrated with two typical models but is applicable to any analytical equation of state.

Result: The methodology provides a framework for comparing theoretical compact star properties with observational data, enabling parameter constraints in the models through multi-messenger observations.

Conclusion: The approach effectively links theoretical equations of state with observational evidence, offering a tool for refining models of dense matter in compact stars.

Abstract: We apply analytical models to study the property of neutron stars and dark stars. With the aim of exploring the global observable properties of those compact stars, we investigate the total masses and radii, the tidal deformabilities and especially the fundamental (f -) mode oscillations. While we choose two typical models in this work, this method applies to any analytical equations of state. By comparing with the multi-messenger observations, one can constrain the corresponding parameters in those models.

</details>


### [35] [Discovery prospects of a singly-charged scalar at $μ$TRISTAN](https://arxiv.org/abs/2601.22000)
*Joseph George,Nobuchika Okada,Dibyashree Sengupta,Sudhir K. Vempati*

Main category: hep-ph

TL;DR: This study explores the production of a singly-charged scalar particle (Δ⁺) alongside a W⁺ boson in the µTRISTAN muon collider at 2 TeV. The research leverages the Type-II seesaw model, which explains neutrino masses and enables lepton flavor violation (LFV). It proposes using LFV processes to detect Δ⁺ without Standard Model backgrounds and suggests that lepton flavor distributions in final states could distinguish between neutrino mass hierarchies (Normal vs. Inverted).


<details>
  <summary>Details</summary>
Motivation: The motivation is to investigate the production mechanisms of the singly-charged scalar in the context of the Type-II seesaw model, which not only explains neutrino masses but also allows for LFV processes absent in the Standard Model. The absence of SM background in LFV makes it an ideal probe for new physics at µTRISTAN.

Method: The method involves analyzing the associated production of Δ⁺ and W⁺ boson in the µTRISTAN collider at 2 TeV. The analysis focuses on LFV processes to identify Δ⁺ signals. Additionally, the distribution of lepton flavors in the final state is proposed as a method to determine the neutrino mass hierarchy (Normal vs. Inverted).

Result: The study demonstrates the viability of using LFV processes at µTRISTAN to probe the Type-II seesaw model without Standard Model background interference. It also establishes a potential method to infer neutrino mass hierarchy through lepton flavor distributions in experimental data.

Conclusion: The conclusion underscores the effectiveness of LFV processes in detecting singly-charged scalars at µTRISTAN and highlights the significance of lepton flavor distributions for distinguishing neutrino mass hierarchies, offering a roadmap for future collider experiments in particle physics.

Abstract: In this article, we study the associated production of a singly-charged ($Δ^+$) scalar along with a $W^+$ boson in the newly proposed $μ^+μ^+$ collider (also known as $μ$TRISTAN) at $\sqrt{s} = 2~$ TeV. Such a singly-charged scalar is naturally accommodated in an extremely well-motivated neutrino mass model, namely, the Type-II seesaw model. This model, beside providing a viable explanation of neutrino mass generation, also allows for lepton flavor violating (LFV) processes. Since LFV processes are not allowed in the Standard Model (SM), we focus on the discovery prospect of the singly-charged scalar in the Type-II seesaw model at $μ$TRISTAN through a LFV process, owing to the advantage of this process being free of any SM background. Additionally, this article also proposes a method to indicate if the underlying theory follows a Normal or an Inverted hierarchy depending on the distribution of lepton flavors in the final state.

</details>


### [36] [All-order prescription for facet regions in massless wide-angle scattering](https://arxiv.org/abs/2601.22144)
*Yao Ma*

Main category: hep-ph

TL;DR: The paper addresses the systematic determination of regions in the Expansion-by-Regions technique for multiscale Feynman integrals, particularly in massless wide-angle scattering, using graph theory and convex geometry to uncover the algebraic structure of momentum modes in Minkowski space.


<details>
  <summary>Details</summary>
Motivation: To resolve a long-standing question in asymptotic expansions of Feynman integrals by providing a systematic method for identifying regions, especially in multiscale processes where existing Euclidean-space methods are insufficient for Minkowski-space complexity.

Method: Develop an all-order momentum-space prescription for facet regions via a novel analytical approach combining graph theory and convex geometry. This extends the subgraph-based Euclidean methods to handle the complexities of Minkowski space and hierarchies of momentum modes like collinear, soft, etc.

Result: Identified that facet regions generally dominate asymptotic expansions and may exhaust contributions in most cases. Derived the algebraic structure of momentum modes for the first time, providing a foundational framework for region determination in Minkowski space.

Conclusion: The introduced method systematically selects dominant regions using graph theory and convex geometry, offering a significant advancement in handling multiscale Feynman integrals in realistic high-energy physics scenarios.

Abstract: We take a step toward answering a long-standing question in the asymptotic expansion of Feynman integrals: how to systematically determine the regions in the Expansion-by-Regions technique for multiscale processes? Focusing on generic massless wide-angle scattering, we provide an all-order momentum-space prescription for facet regions, which generally dominate -- and in most cases exhaust -- the contributions in a given asymptotic expansion. This extends the Euclidean-space picture, where regions correspond to specific subgraphs, to the complexities of Minkowski space. Our results are derived from a novel analytical approach combining graph theory and convex geometry; as a key byproduct, we uncover for the first time the algebraic structure underlying momentum modes (collinear, soft, and their hierarchies).

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [37] [Cosmological Expansion from Machian Phase Normalization by Horizon Constraints](https://arxiv.org/abs/2601.20889)
*Maurice H. P. M. van Putten*

Main category: gr-qc

TL;DR: The paper proposes a Machian phase normalization approach for cosmological expansion, where the conformal factor is a global gauge variable fixed by causal horizon boundary conditions. This framework explains ΛCDM behavior, phantom regimes without new degrees of freedom, and late-time cosmological tensions by linking thermal equilibrium at cosmological turning points to the horizon Clausius relation.


<details>
  <summary>Details</summary>
Motivation: To address the conformal-factor problem in cosmology and clarify the conceptual basis of ΛCDM. The authors seek to explain the observed cosmological dynamics without introducing new degrees of freedom while resolving tensions like the Hubble constant discrepancy.

Method: The authors use gravitational path integrals with Machian phase normalization, governed by causal horizon boundary conditions. They fix the cosmological conformal factor via the Hamiltonian constraint, treating it as a global gauge variable. Thermal equilibrium principles at cosmological turning points are applied to derive the equilibrium phase density (Λ=R/6), which exacts the horizon Clausius relation. Non-adiabatic evolution is parameterized by a single variance parameter.

Result: The framework naturally accounts for effective wCDM behavior, including phantom regimes, and provides an origin for late-time tensions through unstable de Sitter states. It resolves the conformal-factor problem by removing the propagating degree of freedom associated with Λ.

Conclusion: The cosmological dynamics are fundamentally governed by global horizon constraints rather than local fields. This approach redefines the role of Λ as an emergent integrating factor from thermal equilibrium conditions, offering a unified explanation for observed cosmic acceleration and its associated tensions without new physics.

Abstract: We argue that cosmological expansion is governed by Machian phase normalization of the gravitational path integral, fixed by causal horizon boundary conditions rather than by local dynamics. In this formulation, the cosmological conformal factor is not a propagating degree of freedom but a global gauge variable fixed by the Hamiltonian constraint, rendering the conventional conformal-factor problem inapplicable. Thermal equilibrium at cosmological turning points uniquely fixes the equilibrium phase density ($Λ=R/6$) as the integrating factor that renders the horizon Clausius relation exact. Controlled departures from equilibrium are encoded by a single variance parameter governing non-adiabatic background evolution. The resulting framework clarifies the conceptual status of $Λ$CDM, explains the emergence of effective $w$CDM behavior--including phantom regimes without new degrees of freedom--and provides a natural origin for late-time cosmological tensions, arising from global constraints that preclude a stable de Sitter state.

</details>


### [38] [Generalized ModMax and the Early Universe](https://arxiv.org/abs/2601.20908)
*M. Sabido,V. Sierra*

Main category: gr-qc

TL;DR: The paper presents a cosmological model based on Generalized ModMax nonlinear electrodynamics that avoids the initial universe singularity and supports an inflationary epoch matching observed values of N, n_s, and r.


<details>
  <summary>Details</summary>
Motivation: To eliminate the initial singularity problem in cosmology and provide a model that naturally incorporates a viable inflationary phase consistent with observational data.

Method: The authors analyze a cosmological model driven by Generalized ModMax nonlinear electrodynamics, tuning parameters to remove the singularity and achieve inflationary parameters (N, n_s, r) aligning with current observations.

Result: The model successfully avoids the initial singularity and produces an inflationary epoch with parameter values matching observational constraints, demonstrating viability of Generalized ModMax for non-singular cosmology.

Conclusion: Generalized ModMax nonlinear electrodynamics provides a framework to construct a universe without initial singularity while supporting inflation compatible with observations.

Abstract: In this work, we study a cosmological model driven by Generalized ModMax nonlinear electrodynamics. We find that, with an appropriate choice of the theory's parameters, the universe's initial singularity can be avoided. Moreover, we also find that this model has an inflationary epoch that is consistent with the current values for $N$, $n_s$ and $r$. Therefore, using Generalized ModMax, we can construct a non singular Universe with an inflationary epoch.

</details>


### [39] [Lyapunov Exponents and Phase Transitions in Four-Dimensional AdS Black Holes with a Nonlinear Electrodynamics Source](https://arxiv.org/abs/2601.20919)
*Ramón Bécar,P. A. González,Felipe Moncada,Yerko Vásquez*

Main category: gr-qc

TL;DR: The paper examines how dynamical instability relates to thermodynamic phase transitions in specific 4D AdS black holes with a nonlinear electromagnetic field. It finds that the Lyapunov exponent reflects phase coexistence and critical behavior, aligning with thermodynamic indicators like critical charge and spinodal temperatures.


<details>
  <summary>Details</summary>
Motivation: To explore the connection between dynamical chaos (via Lyapunov exponents) and thermodynamic phase transitions in black holes, specifically identifying how these dynamical measures correlate with established thermodynamic critical points.

Method: The study uses the canonical ensemble to analyze Einstein gravity with a nonlinear power-law electromagnetic field (p=3/4). Numerical methods likely computed phase diagrams, Lyapunov exponents for massless/massive probes, and critical exponents, comparing them to thermodynamic quantities like heat capacity and spinodal temperatures.

Result: Key findings include the multivalued Lyapunov exponent in coexistence regions, its discontinuity at transition temperatures vanishing at Q_c, universal scaling with critical exponent 1/2 near criticality, and alignment of spinodal points with Lyapunov singularities.

Conclusion: The Lyapapunov exponent serves as a unified dynamical probe that captures both first-order phase transitions and second-order critical behavior, linking quantum chaos dynamics to thermodynamic phase structure in black holes.

Abstract: We investigate the relationship between dynamical instability and thermodynamic phase transitions in four-dimensional Anti--de Sitter black holes in Einstein gravity coupled to a nonlinear power-law electromagnetic field with exponent $p = 3/4$. In the canonical ensemble, we identify a critical electric charge $Q_c$ separating a regime exhibiting a first-order small/large black-hole (SBH/LBH) phase transition from a regime with a single thermodynamically stable phase. For both massless and massive probes, the thermal profile of the Lyapunov exponent $λ(T)$ becomes multivalued in the SBH/LBH coexistence region and exhibits a finite discontinuity at the transition temperature. This jump vanishes continuously as $Q \to Q_c$, signaling the termination of the first-order transition at a second-order critical point. Near criticality, the Lyapunov discontinuity obeys a universal mean-field scaling law with critical exponent $1/2$. For massless probes, we further analyze the critical impact parameter $b_c$, which displays the same multivalued structure and critical behavior as the Lyapunov exponent. We also demonstrate that the spinodal temperatures, defined by the extrema of the $T(r_h)$ curve where the heat capacity at fixed charge diverges, coincide with singular features in the Lyapunov exponent. Our results identify the Lyapunov exponent as a unified dynamical probe capable of capturing both first-order phase coexistence and second-order critical behavior in black-hole thermodynamics.

</details>


### [40] [Violation of the third law of black hole mechanics in vacuum gravity](https://arxiv.org/abs/2601.20955)
*John R. V. Crump,Maxime Gadioux,Harvey S. Reall,Jorge E. Santos*

Main category: gr-qc

TL;DR: The paper demonstrates numerically that a 5D Schwarzschild black hole can evolve into an extremal rotating black hole in finite time, violating the third law of black hole mechanics. It also shows this outcome possible from vacuum initial data without a pre-existing black hole.


<details>
  <summary>Details</summary>
Motivation: To test the validity of the third law of black hole mechanics in vacuum gravity and show its violation independently of matter models.

Method: Numerical simulations in five-dimensional vacuum gravity to model black hole evolution scenarios.

Result: Successful demonstration of finite-time formation of extremal rotating black holes both from Schwarzschild black holes and vacuum initial data without prior black holes.

Conclusion: The third law of black hole mechanics is invalidated in 5D vacuum gravity, indicating its dependence on spacetime dimensions and invalidity beyond certain conditions.

Abstract: We demonstrate numerically the existence of solutions of five-dimensional vacuum gravity describing the formation, in finite time, of an extremal rotating black hole from a pre-existing Schwarzschild black hole. This is the first example of a violation of the third law of black hole mechanics in vacuum gravity and demonstrates that the third law is false independently of any matter model. We also demonstrate the existence of solutions describing the formation, in finite time, of an extremal rotating black hole from vacuum initial data that does not contain a black hole.

</details>


### [41] [The Spherical-Rindler framework: From compact Minkowski regions to black-Hole and cosmological Solutions](https://arxiv.org/abs/2601.20971)
*Edgar Alejandro León*

Main category: gr-qc

TL;DR: The paper introduces cyclic coordinates and Spherical Rindler metrics, offering new insights into accelerated frames and spacetime curvature through compact region analysis and applications to black holes and cosmology.


<details>
  <summary>Details</summary>
Motivation: To expand the understanding of flat spacetime by extending Rindler coordinates to compact regions and spherical geometries, inspired by near-horizon Schwarzschild coordinates.

Method: Development of cyclic coordinates as part of an infinite family of transformations, derivation of Spherical Rindler metrics, and application to black hole and cosmological solutions.

Result: Successful derivation of black hole and cosmological metrics from Spherical Rindler coordinates, revealing novel geometric relationships between acceleration and global curvature.

Conclusion: The findings establish Spherical Rindler frameworks as valuable tools for exploring spacetime curvature effects in both local accelerated frames and cosmological contexts.

Abstract: In this article we first develop novel Rindler-type representations of flat spacetime by demonstrating that the standard hyperbolic transformation is a member of an infinite family of coordinate mappings. We specifically introduce cyclic coordinates, which, in contrast to the conventional Rindler wedge, delineate a compact region of Minkowski spacetime. By extending this framework, and motivated by near horizon coordinates in Schwarzschild metric, we propose a class of Spherical Rindler metrics. We demonstrate the utility of this approach by deriving and analyzing a black hole solution and a cosmological metric, both emerging naturally from a Spherical Rindler origin. Our results highlight unique geometric properties of these solutions, providing new insights into the relationship between accelerated frames and global spacetime curvature.

</details>


### [42] [Rethinking Resonance Detectability during Binary Neutron Star Inspiral: Accurate Mismatch Computations for Low-lying Dynamical Tides](https://arxiv.org/abs/2601.21086)
*Alberto Revilla Peña,Ruxandra Bondarescu,Andrew P. Lundgren,Jordi Miralda-Escudé*

Main category: gr-qc

TL;DR: The paper investigates how tidal resonance in binary neutron star or neutron star-black hole mergers affects gravitational wave signals, focusing on time advances and phase changes. It uses both analytical and numerical methods to assess detectability with current and future detectors, finding that time advances of ~1 ms and energy flux of a few percent are detectable, challenging previous assumptions of phase shifts.


<details>
  <summary>Details</summary>
Motivation: To address discrepancies in previous models that only considered phase shifts or cycle differences from tidal resonances, the study aims to accurately quantify the detectability of tidal effects via time advances in gravitational wave signals.

Method: The authors employ a quasi-analytical approach using moment integrals and an optimized numerical match function to compute mismatches in gravitational wave signals caused by tidal resonances during binary mergers.

Result: The study finds that tidal resonance primarily causes a time advance (up to ~1 ms) rather than phase shifts, and that the single-frequency approximation overestimates detectability. Detectability requires an energy flux ~a few percent of the gravitational wave emission for advanced detectors like LVK.

Conclusion: Previous models' reliance on phase shifts or cycle counts underestimates the true nature of tidal resonance effects. Accurate detection of tidal resonances requires accounting for time advances, and the single-frequency method overestimates detectability, necessitating improved models for future detector analyses.

Abstract: We compute deviations from observed gravitational wave signals, where the amplitude of the signal is unchanged. As an example, we consider the detectability of low lying dynamical tides in binary neutron star or neutron star black hole mergers. Tidal forces can excite oscillatory modes of one or both of the stars in the binary when the orbital frequency of the binary system sweeps through the resonant mode frequency dissipating energy into the vibrational mode. The orbital energy loss to the vibrational mode extracts energy from the orbital motion, advancing the time to merger. The inspiral then continues with an excess phase and a time advance. Both will cause a mismatch when fitting to a system that has not gone through the resonance. To resolve this effect, we compute the mismatch for current and planned detectors using both a quasi-analytical approach that relies on the computation of moment integrals and an optimized version of the standard numerical match function. We conclude that detectability can occur for time advances of the order of 1 ms with advanced LVK detectors for an excess energy-flux that is a few percent of the gravitational wave emission. Our results contrast with previous work, which model this effect solely as a phase shift of the waveform or by using the difference in the number of cycles induced by the resonant behavior. We show that tidal resonance effects primarily cause a time advance of the merger, rather than a phase difference, and that the single-frequency approximation commonly used in the literature significantly overestimates the detectability of this effect.

</details>


### [43] [On the quantum nature of strong gravity](https://arxiv.org/abs/2601.21145)
*Felipe Sobrero,Luca Abrahão,Thiago Guerreiro*

Main category: gr-qc

TL;DR: The study analyzes a thought experiment where gravitational waves from an extended quadrupolar object are used to detect Newtonian tidal fields, showing that quantum fluctuations in these waves prevent superluminal signaling. This implies quantization of gravitational radiation is necessary to maintain consistency between the Newtonian limit of general relativity and quantum mechanics, even with strong gravity sources like rotating black holes.


<details>
  <summary>Details</summary>
Motivation: The motivation is to extend a previous analysis by Belenchia et al., which showed quantum effects prevent superluminal communication in certain setups. The focus here is on gravitational waves as detectors for Newtonian fields and to explore implications for quantum gravity.

Method: Reformulating the original gedankenexperiment using gravitational waves from an extended quadrupolar object (like rotating black holes under the strong equivalence principle). Analyzing quantum fluctuations in these waves to determine their impact on signaling.

Result: Quantum fluctuations in gravitational waves prevent violations of causality or quantum mechanics. This requires gravitational radiation quantization for consistency between Newtonian gravity's general relativity limit and quantum principles.

Conclusion: The necessity of quantizing gravitational waves is demonstrated even in strong gravity regimes, as classical treatment would otherwise allow inconsistencies with quantum mechanics in the Newtonian limit.

Abstract: Belenchia et al. [Phys. Rev. D 98, 126009 (2018)] have analyzed a gedankenexperiment where two observers, Alice and Bob, attempt to communicate via superluminal signals using a superposition of massive particles dressed by Newtonian fields and a test particle as field detector. Quantum fluctuations in the particle motion and in the field prevent signaling or violations of quantum mechanics in this setup. We reformulate this thought experiment by considering gravitational waves emitted by an extended quadrupolar object as a detector for Newtonian tidal fields. We find that quantum fluctuations in the gravitational waves prevent signaling. In the Newtonian limit, rotating black holes behave as extended quadrupolar objects, as consequence of the strong equivalence principle. It follows that consistency of the Newtonian limit of general relativity with quantum mechanics requires the quantization of gravitational radiation, even when the waves originate in strong gravity sources.

</details>


### [44] [Exact analytic rotating black-hole solutions with primary hair](https://arxiv.org/abs/2601.21163)
*Pedro G. S. Fernandes*

Main category: gr-qc

TL;DR: The paper presents new exact, analytic, asymptotically flat rotating black-hole solutions within Generalized Proca theories, demonstrating primary hair and non-circularity, contrasting with Kerr black holes.


<details>
  <summary>Details</summary>
Motivation: To expand the limited set of known rotating black-hole solutions by exploring Generalized Proca theories, which allow features absent in General Relativity's Kerr solutions.

Method: Employing a Kerr-Schild ansatz to derive solutions in a class of Generalized Proca theories, leading to black holes with primary hair and non-circular event horizons.

Result: Discovered multiple solutions showing departure from Kerr's symmetry, with measurable differences in orbits and spacetime structure due to primary hair.

Conclusion: Generalized Proca theories support novel black hole configurations, offering testable alternatives to General Relativity predictions and insights into beyond-standard-model physics.

Abstract: Exact, analytic, asymptotically flat rotating black-hole solutions are exceedingly rare, with only a handful of examples known. Using a Kerr-Schild ansatz, we derive a multitude of exact, analytic, asymptotically flat rotating black-hole solutions within a broad class of Generalized Proca theories. These black holes differ significantly from Kerr black holes, as they possess primary hair and are non-circular, thus breaking a symmetry that vacuum black holes exhibit in General Relativity.

</details>


### [45] [Is Phantom Divide Crossing in General Relativity Completely Impossible? Shortcomings and Possible Solutions](https://arxiv.org/abs/2601.21356)
*Shin'ichi Nojiri,S. D. Odintsov,V. K. Oikonomou*

Main category: gr-qc

TL;DR: The paper explores whether general relativity-based field theories can account for a phantom-to-quintessence transition in dark energy scenarios. It concludes that canonical scalar field theories cannot achieve this, but k-essence theories might, though with challenges, while modified gravity offers a more natural solution.


<details>
  <summary>Details</summary>
Motivation: To address the insufficiency of general relativity in describing large-scale宇宙 phenomena and investigate feasible dark energy models that allow a transition between phantom and quintessence phases, crucial for late Universe dynamics.

Method: Analyzed the capability of various field theories (canonical scalar fields, ghost condensate/k-essence) to enable such transitions, identified instabilities and requirements for ghost elimination in k-essence, compared these with modified gravity approaches.

Result: Canonical scalar fields cannot support the transition, k-essence theories can but require fine-tuning and ghost elimination. Modified gravity naturally allows the transition without these issues.

Conclusion: Modified gravity provides a more viable framework for realizing the phantom-to-quintessence transition in dark energy models compared to scalar-tensor theories, which face significant theoretical challenges.

Abstract: General relativity has its successes at the local astrophysical level, however, it seems to be insufficient in describing the Universe at large scales. In this work we investigate how the most general field theories in the context of general relativity can accomodate a phantom-to-quintessence transition which may be essential element of realistic Dark Energy scenarios in the late Universe. As we demonstrate in a very detailed manner, this is impossible for a canonical and minimally coupled single scalar field theory, but it may be possible for ghost condensate theories like $k$-essence theories. We point out how the ghost instabilities may be eliminated, and we analyze the quantitative features of a $k$-essence theory that may realize a phantom-to-quintessence transition in the late Universe. We also qualitatively compare the difficulties and fine-tunings required for $k$-essence theories to realize a phantom-to-quintessence transition, and how such a transition is naturally realized in modified gravity, without unnecessary fine-tunings and ghost eliminations.

</details>


### [46] [$\mathcal{R}^2$-corrected Tachyon Scalar Field Inflation, the ACT Data, and Phantom Transition](https://arxiv.org/abs/2601.21364)
*S. D. Odintsov,V. K. Oikonomou*

Main category: gr-qc

TL;DR: The study explores a scalar-tensor theory combining a tachyonic scalar field with R² corrections and a rescaled Einstein-Hilbert term. It demonstrates that phantom divide line transitions are possible, with the equation of state crossing from phantom to non-phantom regimes during inflation. The model aligns with ACT data only if inflationary gravity is stronger than standard Einstein-Hilbert gravity, leaving post-inflationary processes unaffected.


<details>
  <summary>Details</summary>
Motivation: To investigate whether a modified scalar-tensor framework allows crossing the phantom divide line and compatibility with observational data (ACT) by incorporating R² corrections and rescaled gravity terms.

Method: Analyzes an inverse square power-law model from tachyon inflation, deriving field equations dependent only on the scalar field. This framework differs from single scalar field theories as it inherently allows phantom divide crossing.

Result: Phantom divide line transition occurs during inflation, starting with a phantom equation of state (w < -1) and ending at w = -1/3. Compatibility with ACT data requires an enhanced gravitational strength (G/λ) during inflation. The modification does not affect post-inflation processes like Big Bang Nucleosynthesis.

Conclusion: The model successfully enables phantom divide line transitions in modified gravity, offering a novel mechanism in f(R,φ) theories. Its compatibility with ACT data under specific conditions highlights its viability as an inflationary model.

Abstract: Phantom divide line transitions are not possible in the context of single scalar field scalar-tensor theories. In this article we study a combined framework of a tachyonic minimally coupled single scalar field theory in the presence of an $\mathcal{R}^2$ correction term and with a rescaled Einstein-Hilbert term of the form $\sim λ\frac{\mathcal{R}}{16πG}$. Such terms can be part of an $f(\mathcal{R})$ gravity which in the large curvature regime yields such correction terms effectively. Alternatively, such terms can simply be quantum corrections to the scalar field action. We aim to answer two questions, firstly if this framework can lead to phantom divide line transitions and secondly whether the resulting model can be compatible with the ACT data. The model we studied is an inverse square power-law model, well known from tachyon inflation models. As we show, the field equations can be cast in terms of the scalar field solely, however the resulting theory is distinct from a single scalar field theory, because the phantom divide line is crossed during inflation. Thus initially the tachyonic nature of the scalar field generates a phantom equation of state parameter, and during inflation the phantom divide line is crossed, with the effective equation of state parameter at the end of inflation being $w=-1/3$ which corresponds to the non-accelerating state of the Universe. The model is proved to be compatible with the ACT data, only when the gravity during inflation is stronger than Einstein-Hilbert gravity, with the effective gravitational constant during inflation being $\frac{G}λ$. The effective theory is valid only during inflation, thus Big-Bang nucleosynthesis is not affected by the rescaling of the Einstein-Hilbert gravity. The feature of a phantom crossing in $f(\mathcal{R},φ)$ frameworks is new in the literature.

</details>


### [47] [Analytic Solution for the Motion of Spinning Particles in Plane Gravitational Wave Spacetime](https://arxiv.org/abs/2601.21438)
*Ke Wang*

Main category: gr-qc

TL;DR: The paper derives an analytic solution for the motion of a spinning body interacting with a plane gravitational wave using Mathisson-Papapetrou-Dixon equations, revealing spin-induced deviations through conserved quantities and parallel-transported tetrad methods.


<details>
  <summary>Details</summary>
Motivation: To understand how spinning objects deviate from geodesic paths due to spin-gravity wave interactions, providing a framework for analyzing spin effects in gravitational memory and future detectors.

Method: Combining parallel-transported tetrad with Killing symmetries to solve Mathisson-Papapetrou-Dixon equations at linear spin order, deriving six conserved quantities that determine momentum, spin evolution, and worldline.

Result: Closed-form expressions for transverse and longitudinal motions as single integrals of retarded time, enabling model-independent calculations of spin-curvature effects.

Conclusion: The solution provides a versatile tool for studying spin-dependent phenomena in gravitational memory, Penrose-limit geometries, and space-based detector analyses.

Abstract: The interaction between spin and gravitational waves causes spinning bodies to deviate from their geodesics. In this work, we obtain the complete analytic solution of the Mathisson--Papapetrou--Dixon equations at linear order in the spin for a general plane gravitational wave with arbitrary polarization profiles. Our approach combines a parallel-transported tetrad with the translational Killing symmetries of plane wave spacetimes, yielding six conserved quantities that fully determine the momentum, spin evolution, and worldline. The resulting transverse and longitudinal motions are expressed in closed form as single integrals of the retarded time, providing a unified and model-independent framework for computing spin--curvature-induced deviations for realistic or theoretical gravitational-wave signals. This analytic solution offers a versatile tool for studying spin-dependent effects in gravitational memory, Penrose-limit geometries, and future high-precision space-based detectors.

</details>


### [48] [Primordial black holes and Scalar-Induced Gravitational Waves formed by inflation potential with non-trivial characteristics](https://arxiv.org/abs/2601.21538)
*Ruifeng Zheng,Yanqing Xu*

Main category: gr-qc

TL;DR: This paper explores how local coupling modifications of the Starobinsky and KKLT potentials using a linear Lorentzian-type coupling can generate primordial black holes (PBHs) through disrupted slow-roll inflation, with both positive and negative couplings enabling significant PBH formation, and also examines the resulting scalar-induced gravitational waves (SIGWs).


<details>
  <summary>Details</summary>
Motivation: To investigate mechanisms for PBH formation via modified density perturbations and understand SIGW production in such models.

Method: Analyzes local coupling properties of Starobinsky and KKLT potentials with linear Lorentzian-type coupling, simulating disruption of slow-roll conditions to assess PBH abundance and SIGW generation.

Result: Both positive and negative couplings produce sufficient density perturbations for PBH formation; the model also predicts detectable SIGWs with specific frequency and amplitude signatures.

Conclusion: Local coupling modifications offer a viable pathway for PBH production in inflationary models, with observable SIGW signatures potentially confirming these mechanisms.

Abstract: The formation of primordial black holes (PBHs) generally requires large density perturbations, which is widely supported by researchers. This paper studies the local coupling properties of the Starobinsky potential and KKLT potential by introducing a linear Lorentzian-type coupling, which locally breaks the slow roll conditions. We found that both positive and negative coupling can form a considerable abundance of PBH. Additionally, we also studied the scalar-induced gravitational waves (SIGWs) generated by this model.

</details>


### [49] [Leveraging rapid parameter estimates for efficient gravitational-wave Bayesian inference via posterior repartitioning](https://arxiv.org/abs/2601.21630)
*Metha Prathaban,Charlie Hoy,Michael J. Williams*

Main category: gr-qc

TL;DR: The paper introduces a method combining the simple-pe algorithm with posterior repartitioning to accelerate Bayesian inference for gravitational wave astronomy, ensuring statistical rigor and maintaining prior independence from data. It shows up to 2.2x speedup for SNRs below 150 and scalability with SNR.


<details>
  <summary>Details</summary>
Motivation: To address the computational expense of Bayesian analyses in gravitational wave astronomy by leveraging rapid low-latency results without biasing the final inference.

Method: The method integrates the fast simple-pe algorithm's constraints with posterior repartitioning, a nested sampling acceleration technique, ensuring the prior remains independent of data. This guides the sampler efficiently to high-probability parameter regions for SNR >20.

Result: Validation via injection study confirms unbiased, robust results with speedups up to 2.2x for binaries with SNR <150. The performance improves with higher SNR, making it effective for current and future observatories.

Conclusion: The approach provides a statistically valid way to accelerate analysis, reducing computational costs, especially for high-SNR events, thus enhancing the feasibility of handling data from advanced gravitational-wave detectors.

Abstract: Gravitational wave astronomy typically relies on rigorous, computationally expensive Bayesian analyses. Several methods have been developed to perform rapid Bayesian inference, but they are not yet used to inform our full analyses. We present a novel approach for doing this whilst ensuring that the Bayesian prior remains independent of the data, providing a statistically rigorous way to leverage low-latency information to accelerate the final inference. By combining the fast constraints from the simple-pe algorithm with the nested sampling acceleration technique of posterior repartitioning, we demonstrate that our method can guide the nested sampler towards the most probable regions of parameter space more efficiently for signal-to-noise ratios (SNR) greater than 20, while mathematically guaranteeing that the final inference is identical to that of a standard, uninformed analysis. We validate the method through an injection study, demonstrating that it produces statistically robust and unbiased results, whilst providing speedups of up to $2.2\times$ for binaries with SNRs $< 150$. Importantly, we show that the performance gain provided by our method scales with SNR, establishing it as a powerful technique to mitigate the cost of analysing signals from current and future gravitational-wave observatories.

</details>


### [50] [Elementary blocks of Loop Quantum Gravity](https://arxiv.org/abs/2601.21644)
*Mehdi Assanioussi,Etera R. Livine*

Main category: gr-qc

TL;DR: The paper studies Hamiltonian dynamics on a 'candy graph' in Loop Quantum Gravity (LQG), deriving non-linear differential equations for area variables and finding both oscillatory and divergent solutions, providing a framework for future LQG dynamics research.


<details>
  <summary>Details</summary>
Motivation: To explore the dynamics of LQG by simplifying complex spin network states into smaller, manageable blocks (candy graphs) to understand curvature and boundary dynamics before scaling up.

Method: Analyzing classical dynamics of a candy graph (two linked nodes with open edges) using LQG Hamiltonian ansatz, leading to cubic Schrödinger-like equations for area variables. Derived analytical solutions.

Result: Identified two types of solutions: oscillatory (bounded) modes and divergent modes similar to bouncing cosmological trajectories. Established a template for studying more complex spin network architectures.

Conclusion: The candy graph provides a foundational model for understanding LQG dynamics. Future work will extend quantum analysis and apply this framework to larger spin network structures.

Abstract: We embark on the vast program of integrating the dynamics of Loop Quantum Gravity (LQG). Adopting the strategy of decomposing spin network states into small blocks of (quantum) geometry which can later be glued back together, we focus on the more modest objective of studying the Hamiltonian dynamics on the {\it candy graph}, that is two nodes linked together by an arbitrary number of edges and also having open edges. This elementary setting allows both for curvature to develop around the bulk loops and both non-trivial boundary data and dynamics on the open edges. We study this system at the classical level and leave the detailed of its quantum regime for future investigation. Working on a single loop with two external legs, we show how the LQG Hamiltonian ansatz reduces to a pair of non-linear differential equations, similar to the cubic Schrödinger equation, on the areas carried by the bulk links. We provide analytical solutions to this evolution equation, identifying oscillatory modes (bounded modes) and divergent modes (similar to bouncing cosmological trajectories). This provides an explicit template for future investigations of LQG dynamics on more sophisticated spin network architecture built as arrays of candy graphs.

</details>


### [51] [Beyond Kasner Epochs: Ordered Oscillations and Spike Dynamics Inside Black Holes with Higher-Derivative Corrections](https://arxiv.org/abs/2601.21658)
*Mei-Ning Duan,Li Li,Yu-Xuan Li,Fu-Guo Yang*

Main category: gr-qc

TL;DR: Incorporating higher-curvature and quantum gravitational corrections with a scalar field reveals three new dynamical phases near spacelike singularities, altering the classical Kasner paradigm and showing structured behavior in black hole interiors.


<details>
  <summary>Details</summary>
Motivation: To investigate how higher-curvature terms and quantum gravity effects modify the traditional Kasner epoch dynamics near spacelike singularities, which had been the dominant framework.

Method: Integrated higher-curvature corrections and a minimally coupled scalar field into the spacetime dynamics analysis to identify modified Kasner eons, persistent oscillations, and growing-amplitude spike dynamics.

Result: Three distinct phases were discovered where classical Kasner behavior only persists under strict conditions; oscillatory regimes show unprecedented order beyond Einstein's theory.

Conclusion: The findings expand our understanding of gravitational nonlinearity in extreme environments like black hole interiors, showing richer dynamics than previously thought under modified gravity scenarios.

Abstract: Building upon the long-standing paradigm that dynamics near a spacelike singularity are governed by a sequence of Kasner epochs, we demonstrate that this picture is fundamentally altered when higher-curvature or quantum gravitational corrections are included. By incorporating such terms alongside a minimally coupled scalar field, we discover three distinct dynamical phases near the singularity: modified Kasner eons, persistent periodic oscillations, and oscillatory spike dynamics with growing amplitude. In particular, the Kasner-like geometry persisting only in highly constrained situations. The latter two regimes represent a clean departure from classical Kasner phenomenology, revealing a richer and more ordered landscape of behaviors in the deep interior of black holes beyond Einstein gravity. This work establishes a comprehensive approach for understanding the gravitational nonlinearity in the most extreme gravitational environment.

</details>


### [52] [Optimal cross-correlation technique to search for strongly lensed gravitational waves](https://arxiv.org/abs/2601.22138)
*Anirban Kopty,Sanjit Mitra,Anupreeta More*

Main category: gr-qc

TL;DR: OCCAM is a new method to detect strongly lensed gravitational wave event pairs efficiently, with high accuracy and low computational cost, using strain data from multiple detectors and sky localization info.


<details>
  <summary>Details</summary>
Motivation: Current methods are computationally expensive or require prior source parameter knowledge, necessitating a faster, less resource-intensive approach to identify lensed pairs as GW events increase.

Method: OCCAM employs optimal cross-correlation analysis of CBC strain data from one or more detectors, using a mildly model-dependent approach to reduce search space for lensed pairs.

Result: Achieved 97% (80%) detection rate at 13% (7%) false positive rate with single LIGO detector at design sensitivity, assuming SNR≥10. Network detectors and sky localization further reduce false positives.

Conclusion: OCCAM enables efficient, quick detection of lensed GW pairs among thousands of events, including sub-threshold candidates, enhancing viability of finding rare lensing events.

Abstract: As the number of detected gravitational wave (GW) events increases with the improved sensitivity of the observatories, detecting strongly lensed pairs of events is becoming a real possibility. Identifying such lensed pairs, however, remains challenging due to the computational cost and/or the reliance on prior knowledge of source parameters in existing methods. This study investigates a novel approach, Optimal Cross-Correlation Analysis for Multiplets (OCCAM), applied to strain data from one or more detectors for Compact Binary Coalescence (CBC) events identified by GW searches, using an optimal, mildly model-dependent, low computation cost approach to identify strongly lensed candidates. This technique efficiently narrows the search space, allowing for more sensitive, but (much) higher latency, algorithms to refine the results further. We demonstrate that our method performs significantly better than other computationally inexpensive methods. In particular, we achieve 97 percent (80 percent) lensed event detection at a pairwise false positive probability of approximately 13 percent (7 percent) for a single detector with LIGO design sensitivity, assuming an SNR greater than or equal to 10 astrophysically motivated lensed and unlensed populations. Thus, this method, using a network of detectors and in conjunction with sky-localisation information, can enormously reduce the false positive probability, making it highly viable to efficiently and quickly search for lensing pairs among thousands of events, including the sub-threshold candidates.

</details>


### [53] [Perturbative analysis of singularity-free cosmological solutions in unimodular Kaluza-Klein theory](https://arxiv.org/abs/2601.21661)
*J. C. Fabris,S. Faller,R. Kerner*

Main category: gr-qc

TL;DR: The paper explores a modified Kaluza-Klein theory with unimodularity, linking the 5D metric constraint to 4D cosmology. It derives singularity-free solutions and analyzes their stability through perturbations.


<details>
  <summary>Details</summary>
Motivation: To investigate how unimodularity in 5D Kaluza-Klein theory introduces a cosmological term and Brans-Dicke scalar field in 4D, and to examine the stability of singularity-free cosmological solutions.

Method: Constructs the unimodular Kaluza-Klein theory projection onto 4D spacetime, derives cosmological solutions with scalar fields and matter sources, then performs perturbative analysis for stability assessment.

Result: Establishes equivalence between unimodular 5D metric (det g_{AB}=1) and 4D cosmologicalconstant/Brans-Dicke scalar. Successfully constructs singularity-free solutions and demonstrates their stability under small perturbations.

Conclusion: Unimodular Kaluza-Klein framework provides a coherence mechanism linking higher-dimensional geometry to 4D cosmological phenomena, with stable solutions supporting its viability as an alternative gravity model.

Abstract: The unimodular version of the Kaluza-Klein theory is briefly recalled, and its projection on the $4$-dimensional spacetime is constructed. Imposing unimodularity condition on the $5$-dimensional Kaluza-Klein metric, det$g_{AB}=1$ is equivalent with introducing cosmological term in Einstein's equations in $4$ dimensions, and with scalar field of the Brans-Dicke type. Singularity-free cosmological solutions with scalar field and with matter sources are constructed, and their basic properties analyzed, along the results obtained in previous publications. In the present paper, attention is focussed on the perturbative analysis of cosmological solutions, providing a clue concerning their stability against small fluctuations.

</details>


### [54] [The reason peculiar velocities grow faster in general relativity than in Newtonian gravity](https://arxiv.org/abs/2601.21741)
*Erick Pastén,Christos Tsagas*

Main category: gr-qc

TL;DR: This paper investigates the discrepancy between Newtonian and relativistic predictions of galaxy peculiar velocities, showing that relativistic effects significantly enhance velocity growth, potentially resolving the tension with observed bulk flows.


<details>
  <summary>Details</summary>
Motivation: To address the issue of large-scale peculiar motions exceeding ΛCDM expectations and reconcile observations with theory by exploring relativistic corrections.

Method: Directly comparing Newtonian, quasi-Newtonian, and fully relativistic models; incorporating relativistic peculiar flux contributions into Newtonian frameworks via modified Poisson equations.

Result: Relativistic treatments yield faster peculiar velocity growth (v ∝ t^{2/3}) compared to Newtonian predictions (v ∝ t^{1/3}), explaining observed bulk flows. A unified framework shows how relativistic results can emerge from modified Newtonian equations.

Conclusion: Relativistic effects from peculiar flux kinetic energy significantly impact large-scale velocity fields, challenging Newtonian-based ΛCDM assumptions and offering a pathway to resolve observational discrepancies.

Abstract: An increasing number of surveys has been reporting large-scale peculiar motions with sizes and speeds in excess of those allowed by the concordance cosmological model. These are the so called bulk flows, the presence of which has come to be treated as a problem for the $Λ$CDM paradigm. However, the limits of the $Λ$CDM model are based on Newtonian studies, which predict the mediocre $v\propto t^{1/3}$ growth-rate for the peculiar-velocity field ($v$). Recently, a few fully relativistic treatments have appeared in the literature, arguing for a much stronger velocity growth that could explain the reported fast and deep bulk flows. What separates the Newtonian from the relativistic studies is the gravitational input of the peculiar flux, namely of the kinetic energy triggered by the moving matter. The latter has no direct gravitational contribution in Newtonian theory, but it does so in general relativity. This drastically changes the driving agent of the peculiar-velocity field and boosts its linear growth. The aim of this work is to directly compare the two treatments, as well as identify and discuss the reasons for their different results. In the process, we also demonstrate how one could recover the relativistic growth-rate from a Newtonian setup by selectively including certain (typically ignored) source-free terms into the Poisson equation. This way, we provide a unified covariant comparison of the Newtonian, the quasi-Newtonian and the fully relativistic studies.

</details>


### [55] [Scattering laws for interfaces in self-gravitating matter flows](https://arxiv.org/abs/2601.21773)
*Bruno Le Floch,Philippe G. LeFloch*

Main category: gr-qc

TL;DR: This paper explores the evolution of self-gravitating matter fields undergoing phase transitions by integrating phase transition dynamics with bouncing cosmology concepts. It introduces scattering maps on two hypersurfaces (gravitational singularity and fluid-discontinuity) to formulate a local evolution problem for the Einstein-Euler system. The study establishes universal relations and model-dependent parameters under physical constraints to ensure a unique macroscopic description of fluid-gravity dynamics.


<details>
  <summary>Details</summary>
Motivation: The motivation is to bridge phase transition dynamics and bouncing cosmology, addressing the need for a complete macroscopic description of spacetime evolution across singularities and discontinuities. The authors aim to ensure uniqueness in solutions to the Einstein-Euler equations by supplementing them with scattering relations derived from microscopic physics.

Method: The method involves analyzing causal structures (light cone and acoustic cone) around two hypersurfaces and formulating scattering maps to handle interfaces in the Einstein-Euler system. The framework extends Veneziano's singularity scattering map for quiescent singularities, focusing on junction prescriptions compatible with Einstein and Euler equations under constraints like covariance and causality.

Result: The results include a rigid set of universal relations and model-dependent parameters derived under physically motivated requirements (covariance, causality, constraint compatibility, ultra-locality). This provides a classification of admissible scattering relations that macroscopically describe fluid-Einstein dynamics across phase transitions.

Conclusion: The conclusion is that a consistent macroscopic description of self-gravitating fluids undergoing phase transitions requires specific scattering relations complying with both field equations and physical principles. This framework offers a pathway to connect microscopic physics with macroscopic cosmological dynamics through well-defined junction conditions.

Abstract: We consider the evolution of self-gravitating matter fields that may undergo phase transitions, and we connect ideas from phase transition dynamics with concepts from bouncing cosmology. Our framework introduces scattering maps prescribed on two classes of hypersurfaces: a gravitational singularity hypersurface and a fluid-discontinuity hypersurface. By analyzing the causal structures induced by the light cone and the acoustic cone, we formulate a local evolution problem for the Einstein-Euler system in the presence of such interfaces. We explain how suitable scattering relations must supplement the field equations in order to ensure uniqueness and thus yield a complete macroscopic description of the evolution. This viewpoint builds on a theory developed in collaboration with G. Veneziano for quiescent (velocity-dominated) singularities in solutions of the Einstein equations coupled to a scalar field, where the passage across the singular hypersurface is encoded by a singularity scattering map. The guiding question is to identify junction prescriptions that are compatible with the Einstein and Euler equations, in particular with the propagation of constraints. The outcome is a rigid set of universal relations, together with a family of model-dependent parameters. Under physically motivated requirements (general covariance, causality, constraint compatibility, and ultra-locality), we aim to classify admissible scattering relations arising from microscopic physics and characterizing, at the macroscopic level, the dynamics of a fluid coupled to Einstein gravity.

</details>


### [56] [Action integrals for quantum BTZ black holes](https://arxiv.org/abs/2601.21779)
*Yuanfan Cao,Andrew Svesko*

Main category: gr-qc

TL;DR: The paper explores the thermodynamics of three-dimensional charged and rotating quantum black holes in various spacetimes using holographic methods and gravitational partition functions, deriving their thermal entropy as the generalized entropy.


<details>
  <summary>Details</summary>
Motivation: To construct and study quantum black holes that incorporate quantum matter backreaction effects, which are notoriously difficult to analyze, especially regarding their horizon thermodynamics.

Method: The authors use the tree-level gravitational partition function and holographic techniques focusing on quantum BTZ black holes dual to accelerating black holes in anti-de Sitter space. They regulate the Euclidean geometry with a second ETW brane at infinity and compute the on-shell action in the grand canonical ensemble.

Result: They derived the thermodynamics for quantum BTZ black holes, showing thermal entropy equals generalized entropy. They also extend this to de Sitter and Minkowski spaces using ETW branes, providing a first-principles derivation for these systems.

Conclusion: This work offers a foundational approach to computing generalized entropy in three-dimensional quantum black holes, advancing our understanding of quantum gravity effects in black hole thermodynamics through holography.

Abstract: Black holes exactly incorporating quantum matter backreaction effects, namely, quantum black holes, are notoriously difficult to construct, let alone study their horizon thermodynamics. Here, we derive the thermodynamics of three-dimensional charged and rotating quantum black holes via the tree-level gravitational partition function. Specifically, we primarily focus on holographic quantum BTZ black holes, dual to $(3+1)$-dimensional accelerating black holes in anti-de Sitter space that localize on Karch-Randall end-of-the-world (ETW) branes. To derive their horizon thermodynamics, we regulate the bulk Euclidean geometry by adding a second ETW brane at asymptotic spatial infinity. We compute the on-shell action of the complexified accelerating black hole in the grand canonical ensemble and derive the quantum BTZ black hole thermodynamics, where the thermal entropy is equal to the generalized entropy. This provides a first principles derivation of the generalized entropy of three-dimensional quantum black holes. Further, we construct charged and rotating quantum black holes in three-dimensional de Sitter and Minkowski space using Randall-Sundrum ETW branes, and compute their horizon thermodynamics.

</details>


### [57] [Melvin-Zipoy-Voorhees Spacetime and Circular Orbits](https://arxiv.org/abs/2601.21793)
*Haryanto M. Siahaan*

Main category: gr-qc

TL;DR: This paper presents a magnetized generalization of the Zipoy-Voorhees spacetime using the magnetic Harrison transformation, showing how magnetic fields affect the spacetime structure and orbits of charged particles.


<details>
  <summary>Details</summary>
Motivation: To understand how static, magnetized spacetimes with quadrupolar deformations influence particle dynamics and gravitational properties.

Method: Applied the magnetic Harrison transformation to a static seed spacetime with parameter $k$, deriving the Melvin-Zipoy-Voorhees metric and analyzing its Petrov type and geodesic equations.

Result: Found the spacetime is Petrov type I, the ISCO moves inward due to a Lorentz shift in angular momentum, while the photon ring radius increases slightly with magnetization.

Conclusion: Magnetic fields significantly alter orbital mechanics and spacetime properties, demonstrating the importance of considering electromagnetic effects in relativistic astrophysics.

Abstract: We construct an exact magnetized generalization of the Zipoy-Voorhees spacetime by applying the magnetic Harrison transformation to a static seed with quadrupolar deformation parameter $k$. The resulting Melvin-Zipoy-Voorhees metric is a solution to the Einstein-Maxwell equations that interpolates between the unmagnetized Zipoy-Voorhees geometry and the Melvin magnetic universe. We analyze the algebraic structure, finding the spacetime to be generically of Petrov type I, and investigate the equatorial dynamics of charged test particles and photons. Our analysis reveals that the external magnetic field $b$ induces a ``Lorentz shift'' in the effective angular momentum, suppressing the potential barrier and causing the Innermost Stable Circular Orbit (ISCO) to migrate inward. In contrast, the radius of the photon ring shifts slightly outward with increasing magnetization.

</details>


### [58] [Compact Stars Sourced by Perfect Fluid Dark Matter Halos](https://arxiv.org/abs/2601.21848)
*Yuan Yue,Yong-Qiang Wang*

Main category: gr-qc

TL;DR: The study investigates dark matter halos modeled as isotropic perfect fluids using Einasto and Dehnen profiles, resulting in non-singular, horizonless compact star solutions that are stable under perturbations.


<details>
  <summary>Details</summary>
Motivation: To explore whether dark matter halos, when treated as isotropic perfect fluids, can support compact objects like black holes or stars without requiring anisotropic assumptions.

Method: Numerically solved Einstein's equations using galactic dark matter profiles (Einasto and Dehnen) as mass-energy sources, then analyzed stability against axial perturbations and checked energy conditions.

Result: Non-singular, horizonless compact star solutions were found which remain stable against axial perturbations and satisfy the dominant energy condition.

Conclusion: Dark matter halos modeled as isotropic perfect fluids can form stable compact objects without event horizons, offering an alternative model to black holes in galactic centers.

Abstract: Recent studies have shown that dark matter halos can support regular black holes or compact stars by assuming an anisotropic energy-momentum tensor. In this paper, we extend the analysis to the dark matter halo as an isotropic perfect fluid. By employing galactic dark matter profiles-specifically the Einasto and Dehnen models-as the mass-energy density source, we numerically solve the Einstein field equations and find a class of non-singular, horizonless compact star solutions. Moreover, these configurations remain stable against axial perturbations while satisfying the dominant energy condition.

</details>


### [59] [Numerical simulations of primordial black hole formation via delayed first-order phase transitions](https://arxiv.org/abs/2601.21878)
*Zhuan Ning,Xiang-Xi Zeng,Rong-Gen Cai,Shao-Jiang Wang*

Main category: gr-qc

TL;DR: The paper uses numerical simulations to study primordial black hole formation during phase transitions, identifying three outcomes based on dynamic criteria involving timescale ratios and density contrasts.


<details>
  <summary>Details</summary>
Motivation: To understand the dynamics of superhorizon false-vacuum-domain collapse and determine precise criteria for primordial black hole formation during delayed first-order phase transitions.

Method: Performed fully nonlinear, spherically symmetric numerical simulations with adaptive mesh refinement to resolve bubble wall dynamics, evaluating $t_	ext{H}/t_	ext{V}$ and $δ(t_	ext{H})$ as formation criteria.

Result: Found that $t_	ext{H}/t_	ext{V}$ is a more robust predictor for distinguishing three outcomes: type B (supercritical), type A (subcritical) PBHs, and dispersal, with specific threshold ranges. Density contrast $δ(t_	ext{H})$ is less universal due to wall structure dependencies.

Conclusion: Provides new quantitative thresholds for PBH formation in phase transition scenarios, enhancing predictions of PBH abundance from delayed FOPTs.

Abstract: We perform fully nonlinear, spherically symmetric numerical simulations of superhorizon false-vacuum-domain (FVD) collapse in a coupled gravity-scalar-fluid system to study primordial black hole (PBH) formation during delayed first-order phase transitions (FOPTs). Using adaptive mesh refinement to resolve the bubble wall, we identify three dynamical outcomes: type B (supercritical) PBHs with an interior baby universe and a bifurcating trapping horizon, type A (subcritical) PBHs with an apparent horizon formed by direct wall collapse, and dispersal with no PBH formation. To separate these three cases, we evaluate two commonly used PBH-formation criteria: the time scale ratio $t_\mathrm{H}/t_\mathrm{V}$ (horizon crossing time versus vacuum-energy domination time) and the local density contrast $δ(t_\mathrm{H})$ at horizon crossing. For the parameter space explored, we find that $t_\mathrm{H}/t_\mathrm{V}$ is a more robust predictor of outcome: type B PBHs form when $t_\mathrm{H}/t_\mathrm{V} \gtrsim 1$ (critical range $\sim 1.1 - 1.6$ in our survey), type A PBHs arise when $t_\mathrm{H}/t_\mathrm{V}$ is below this threshold but remains above a lower bound (typical range $\sim 0.35 - 0.7$), and no-PBH dispersal occurs when $t_\mathrm{H}/t_\mathrm{V}$ falls below this lower bound. When a clear thin-wall FVD boundary exists, $δ(t_\mathrm{H})$ can correspondingly distinguish different outcomes (roughly $δ_c(t_\mathrm{H}) \sim 1 - 1.7$ for type B and $δ_c(t_\mathrm{H}) \sim 0.35 - 0.5$ for type A), but is highly sensitive to wall structure and model details and thus less universal. These results offer new insights into the dynamics of FVD collapse, quantify practical PBH-formation thresholds, and pave the way for precise predictions of PBH abundance from delayed FOPTs.

</details>


### [60] [Stückelberg inspired approach for avoiding singular Hamiltonians in Lorentz violating models of antisymmetric tensor field](https://arxiv.org/abs/2601.22007)
*Sandeep Aashish,Md Saif*

Main category: gr-qc

TL;DR: The paper resolves the singular Hamiltonian issue in spontaneous Lorentz violation models by using an auxiliary vector field inspired by the Stückelberg mechanism, making these theories viable for cosmological studies.


<details>
  <summary>Details</summary>
Motivation: Spontaneous Lorentz violation models using antisymmetric tensor fields suffer from singular Hamiltonians on the vacuum manifold, causing pathologies that hinder their application in cosmology. The goal is to address these issues to make the theories usable.

Method: The authors introduce an auxiliary vector field via the Stückelberg mechanism to restore gauge symmetry in the Lagrangian. They perform a Dirac-Bergmann constraint analysis, resulting in a constraint matrix dependent on gradients and the conjugate momentum of the Stückelberg field, which avoids singularity.

Result: The constraint matrix remains non-singular on the vacuum manifold, resolving the previous pathologies. This makes the modified models suitable for cosmological investigations.

Conclusion: The use of the Stückelberg-inspired auxiliary vector field successfully removes the singular Hamiltonian problem, thereby restoring the viability of these theories for cosmological applications.

Abstract: Spontaneous Lorentz violation models of antisymmetric tensor field are known to possess singular Hamiltonian on the vacuum manifold, leading to unresolvable pathologies that render such theories unfit for cosmological studies. In this work, we show that by introducing an auxiliary vector field inspired by the Stückelberg mechanism to restore the gauge symmetry of the Lagrangian, it is possible to resolve such pathologies on vacuum manifold. The constraint analysis using Dirac-Bergmann method leads to a constraint matrix that acquires dependence on gradients and conjugate momentum of the Stückelberg field and therefore remains non-singular on the vacuum manifold.

</details>


### [61] [Decomposition of Schwarzschild Green's Function](https://arxiv.org/abs/2601.22015)
*Junquan Su,Neev Khera,Marc Casals,Sizheng Ma,Abhishek Chowdhuri,Huan Yang*

Main category: gr-qc

TL;DR: This paper decomposes the Green's function of a non-rotating black hole into direct, quasinormal modes, and tail components, validating them against numerical solutions and prior Schwarzschild research. This aids analysis of gravitational waves during black hole mergers.


<details>
  <summary>Details</summary>
Motivation: To provide a full description of the black hole Green's function components for better understanding gravitational wave signals during black hole coalescence ringdown stages.

Method: Analytical decomposition using complex-frequency domain branch cuts and poles, validated via time-domain Regge-Wheeler code simulations and comparison with Schwarzschild spacetime studies with small cosmological constants.

Result: Successful identification and numerical matching of direct parts, quasinormal modes, and tails in the Green's function, confirming consistency with existing Schwarzschild-based research.

Conclusion: The decomposition enables clearer separation of gravitational wave components during black hole merger ringdown, supporting future studies of nonlinear interactions near merger events.

Abstract: In this work, we present a full description of the spherically decomposed Green's function of a non-rotating black hole, which naturally splits into three components: the direct part, the quasinormal modes, and the tail. Both the direct part and the tail are contributed by branch cut integrals on the complex-frequency domain, and the quasinormal modes correspond to poles of the Green's function. We show that these different components match the Green's function numerically obtained by solving a time-domain Regge-Wheeler code. In addition, the components of the Green's function also agree with earlier studies in Schwarzschild spacetime with small cosmological constant. The identification of all the various parts of the Schwarzschild Green's function represents an important step towards analyzing direct waves and quasinormal modes in the ringdown stage of binary black hole coalescence, as well as their nonlinear interaction near the merger.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [62] [The power of polarimetry for characterising exoplanet atmospheres, clouds, and surfaces with NASA's Habitable Worlds Observatory](https://arxiv.org/abs/2601.20902)
*Katy L. Chubb,Mei Ting Mak,Joanna K. Barstow,Beth Biller,Sarah Rugheimer,Daphne M. Stam,Victor Trees*

Main category: astro-ph.IM

TL;DR: The Habitable Worlds Observatory (HWO) will enable detailed studies of Earth-like exoplanets using high-contrast reflection spectroscopy across UV, optical, and near-infrared wavelengths, focusing on molecular absorption features and surface biosignatures. The paper emphasizes the importance of incorporating spectropolarimetry to break degeneracies in cloud and surface property analyses, advocating for UK leadership in instrument development and theoretical modeling.


<details>
  <summary>Details</summary>
Motivation: Clouds pose a significant challenge in exoplanet studies due to their impact on climate and observability, with current methods struggling to disentangle atmospheric and surface properties. Spectropolarimetry offers a solution by providing unique insights into cloud particle properties and surface types, thus enhancing the scientific return of HWO.

Method: HWO's instrument suite includes a coronagraph, high-resolution imager, and a proposed high-resolution spectropolarimeter. The paper advocates for integrating polarimetric capabilities to analyze reflected light polarization across wavelengths and orbital phases, breaking degeneracies in atmospheric and surface models.

Result: Incorporating spectropolarimetry would significantly improve HWO's ability to characterize exoplanet clouds, atmospheres, and surfaces. This approach is supported by previous studies showing polarimetry's effectiveness across exoplanet types, from hot Jupiters to habitable-zone worlds.

Conclusion: The authors urge the inclusion of polarimetric instruments in HWO to maximize its impact on exoplanet science. They stress the unique opportunity for UK leadership in both instrument development and theoretical modeling, advocating for the UK's active role in shaping HWO's polarimetry capabilities.

Abstract: The Habitable Worlds Observatory (HWO), planned for launch in the 2040s, represents the next major step in exoplanet characterisation. HWO will, for the first time, enable detailed studies of the atmospheres and surfaces of Earth-like exoplanets through high-contrast reflection spectroscopy across the UV, optical, and near-infrared. These wavelength ranges provide access to key molecular absorption features, including O2, O3, H2O, CO2, and CH4, as well as potential surface biosignatures such as the vegetation red edge or ocean glint, making HWO a cornerstone mission for assessing planetary habitability.
  Clouds are a dominant factor in determining planetary climate and observability, yet their properties remain highly degenerate when constrained using reflected flux alone. Spectropolarimetry, a measure of the polarisation state of reflected light as a function of wavelength and orbital phase, provides a powerful complementary diagnostic. Polarisation is highly sensitive to cloud particle size, composition, shape, vertical distribution, and surface type, enabling degeneracies between atmospheric and surface models to be broken. Numerous studies have demonstrated the value of polarimetry for characterising a wide range of exoplanets, from hot Jupiters to cooler potentially habitable worlds.
  HWO's proposed instrument suite includes a coronagraph, a high-resolution imager, and a candidate high-resolution spectropolarimeter, offering multiple pathways to exploit polarimetry across diverse planetary regimes. This white paper argues that incorporating polarimetric capability into HWO instruments would significantly enhance the mission's scientific return. We highlight the unique opportunity for UK leadership in both instrument development and theoretical modelling, and advocate for a strong UK role in shaping HWO's polarimetric capabilities to maximise its impact on exoplanet science.

</details>


### [63] [Teareduce: a Python package with utilities for teaching reduction techniques in Astronomy](https://arxiv.org/abs/2601.20914)
*Nicolás Cardiel,Sergio Pascual,María Chillarón-Víctor,Cristina Cabello,Jesús Gallego,Jaime Zamorano,María Teresa Ceballos*

Main category: astro-ph.IM

TL;DR: The teareduce Python package is an educational tool designed for teaching data reduction in astronomical image processing, used in a Master's course at Complutense University of Madrid, with publicly available code and documentation.


<details>
  <summary>Details</summary>
Motivation: To provide students with practical learning resources for handling astronomical data from diverse instruments, enhancing their understanding through accessible materials like Jupyter notebooks.

Method: Development of a Python package with instructional Jupyter notebooks demonstrating data reduction techniques, integration into university coursework, and open-source publication on GitHub with comprehensive documentation.

Result: Students gain hands-on experience in astronomical image processing using teareduce, which serves as a structured learning environment with real-world applications.

Conclusion: teareduce effectively supports educational objectives by bridging theory and practice in astrophysical data analysis, offering a sustainable tool for academic instruction.

Abstract: The Python package teareduce has been developed to support teaching activities related to the reduction of astronomical data. Specifically, it serves as instructional material for students participating in practical classes on the processing of astronomical images acquired with various instruments and telescopes. These classes are part of the course Experimental Techniques in Astrophysics, which belongs to the Master's Degree in Astrophysics at the Complutense University of Madrid. The code is publicly available on GitHub, accompanied by a documentation page that includes Jupyter notebooks demonstrating the use of its various classes and functions.

</details>


### [64] [DESHIMA 2.0: A 200-400 GHz Ultra-wideband Integrated Superconducting Spectrometer](https://arxiv.org/abs/2601.21603)
*K. Karatsu,A. Endo,A. Moerman,S. J. C. Yates,R. Huiting,A. Pascual Laguna,S. Dabironezare,V. Murugesan,D. J. Thoen,B. T. Buijtendorp,S. Cray,K. Fujita,S. Hähnle,S. Hanany,R. Kawabe,K. Kohno,L. H. Marting,T. Matsumura,S. Nakatsubo,L. G. G. Olde Scholtenhuis,T. Oshima,M. Rybak,F. Steenvoorde,R. Takaku,T. Takekoshi,Y. Tamura,A. Taniguchi,P. P. van der Werf,J. J. A. Baselmans*

Main category: astro-ph.IM

TL;DR: DESHIMA 2.0 is a next-generation broadband superconducting spectrometer with improved performance, including wider frequency coverage, higher sensitivity, and better efficiency compared to its predecessor.


<details>
  <summary>Details</summary>
Motivation: To advance millimeter/sub-millimeter wave astronomy by developing a more capable instrument through improving filter technology, broadband antennas, and measurement techniques.

Method: Laboratory characterization of DESHIMA 2.0's components, including NbTiN microstrip filters with a-SiC:H dielectric, leaky-wave antennas, and KID-based readout systems. Performance metrics were measured using a cryostat setup with precise alignment and a sky chopper.

Result: DEHIMA 2.0 achieved 200-400 GHz coverage (4x wider), filter Q of 340±50, 8% instrument efficiency (4x sensitivity), >98% filter yield, and beam patterns matching design specifications. A new absolute frequency calibration method was validated.

Conclusion: DESHIMA 2.0 successfully demonstrates significant performance improvements over DESHIMA 1.0, enabling future surveys of high-redshift galaxies with enhanced capabilities.

Abstract: DESHIMA (Deep Spectroscopic HIgh-redshift MApper) is a broadband integrated superconducting spectrometer (ISS) for millimeter (mm) / sub-millimeter (sub-mm) wave astronomy based on Kinetic Inductance Detectors (KIDs). This paper describes characterization of DESHIMA 2.0 in laboratory settings. The instrument features NbTiN superconducting microstrip (MS) filters with low-loss a-SiC:H dielectric and an ultra-wideband leaky-wave antenna. A laboratory setup was designed, incorporating the cryostat housing cryogenic optics and ISS chip comprising 339 KIDs connected to MS filters tuned for (sub-)mm wave frequencies. Room-temperature mirrors on a hexapod stage allowed precise positioning and alignment of optical elements. The sky-position chopper was positioned on a motor-controlled stage for fine-tuned control over its position and alignment. Thanks to the multiplexing capability of KIDs, we could simultaneously measure multiple performance metrics across the entire frequency range. We showed that DESHIMA 2.0 achieved significant improvements in performance compared to its predecessor (DESHIMA 1.0): measured instantaneous frequency coverage was 200$-$400 GHz with a mean filter $Q_{filter}$ of $340 \pm 50$; instrument efficiency reached $\sim8$ \%, indicating 4 times wider band coverage and 4 times higher sensitivity. The yield rate for MS filters exceeded 98 \%. The estimated aperture efficiency from measured beam patterns agreed well with the designed value of approximately 70 \%. The telescope far-field beam patterns calculated from measured beam patterns also exhibited good agreement with design specifications. We also demonstrated validity of a new method of absolute frequency calibration using the data from beam pattern measurement.

</details>


### [65] [Critical Evaluation of Studies Alleging Evidence for Technosignatures in the POSS1-E Photographic Plates](https://arxiv.org/abs/2601.21946)
*Wesley Andrés Watters,Laura Dominé,Sarah Little,Cameron Pratt,Kevin H. Knuth*

Main category: astro-ph.IM

TL;DR: The paper refutes previous claims about unidentified features in early photographic plates linking them to artificial objects or nuclear tests, finding methodological flaws and inconsistencies in prior analyses.


<details>
  <summary>Details</summary>
Motivation: To critically evaluate the validity of prior studies suggesting some unidentified features in Palomar Observatory Sky Survey plates might be artificial objects or linked to nuclear tests.

Method: Reanalysis of two existing datasets, assessing features in Earth's shadow, linear clusters, timing correlations with nuclear tests, dataset definitions, and spatial distribution patterns.

Result: No shadow deficit found; 1/3 of clusters indistinguishable from stars; timing correlation insignificant after normalization; dataset inconsistencies and use of unvalidated data identified; features' spatial distribution explained by plate artifacts.

Conclusion: Evidence does not support unidentified features as artificial objects or linked to nuclear tests; prior claims weakened by methodological issues and dataset limitations.

Abstract: Recent studies by B. Villarroel and colleagues have assembled and analyzed datasets of unidentified features measured from digital scans of photographic plates captured by the first-epoch Palomar Observatory Sky Survey (POSS1) in the pre-Sputnik era. These studies have called attention to (i) a purported deficit of features within Earth's shadow; (ii) the sporadic presence of linear clusters; and (iii) a positive correlation between the timing of feature observations and nuclear tests as well as Unidentified Aerial Phenomena (UAP) sighting reports. These observations were cited as evidence that some fraction of the unidentified features represent glinting artificial objects near Earth. We have examined these claims using two related, previously published datasets. When analyzing the most vetted of these, we do not observe the reported deficit in the terrestrial shadow. We determine that a third of the features in the reported linear clusters were not confidently distinguished from catalog stars. We find that the reported correlation between the timing of feature observations and nuclear tests becomes insignificant after properly normalizing by the number of observation days, and is almost completely determined by the observation schedule of the Palomar telescope. We uncover important inconsistencies in the definitions of the datasets used in these studies, as well as the use of unvalidated datasets containing catalog stars, scan artifacts, and plate defects. It has not been shown that any of the features in these datasets represent optical transients. We examine the spatial distribution of the plate-derived features, finding an overall gradual increase in number density toward the corners and edges of plates, as well as examples of (i) empty north-south strips that span multiple plates; (ii) clusters and voids having geometric shapes; and (iii) amorphous clusters.

</details>
