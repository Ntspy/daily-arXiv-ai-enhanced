<div id=toc></div>

# Table of Contents

- [gr-qc](#gr-qc) [Total: 20]
- [hep-ph](#hep-ph) [Total: 16]
- [astro-ph.IM](#astro-ph.IM) [Total: 6]
- [astro-ph.HE](#astro-ph.HE) [Total: 11]


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [1] [Time-Dependent Black Hole Lensing and the Unified Weak-to-Strong Deflection Framework](https://arxiv.org/abs/2510.19849)
*Ali Övgün,Reggie C. Pantig*

Main category: gr-qc

TL;DR: The paper presents an analytical framework for unifying weak-field and strong-deflection gravitational lensing in a time-dependent, perturbed Schwarzschild spacetime modeled by a specific quasinormal mode. It derives time-dependent deflection expressions, showing how ringdown effects cause observable phenomena like centroid wobble and modulations in critical parameters.


<details>
  <summary>Details</summary>
Motivation: To understand how time-dependent spacetime perturbations (specifically through quasinormal modes) affect both weak and strong gravitational lensing phenomena without relying on numerical simulations.

Method: Analytical approach using first-order perturbation theory with an axisymmetric, even-parity quasinormal mode (l=2, m=0). Derives a time-dependent Born kernel for deflection, performs asymptotic expansions to extract weak-field and strong-deflection limits, and ensures gauge-invariance using a specific observer tetrad.

Result: Derived analytically expressions showing ringdown-frequency-induced harmonic centroid wobble in weak-field and time-varying logarithmic terms in strong-deflection. Demonstrated cross-regime consistency, linking near-critical parameters to the Born kernel. Provided gauge-safe observables like image hierarchy and time delays.

Conclusion: A unified analytical framework successfully connects spacetime ringdown dynamics to observable lensing effects, enabling theoretical predictions of imaging observables during black hole perturbations without numerical ray-tracing.

Abstract: We present a fully analytical framework that unifies weak-field and
strong-deflection lensing of light in a time-dependent, perturbed Schwarzschild
spacetime. The spacetime dynamics are modeled by a single, axisymmetric,
even-parity quasinormal mode with $\ell=2$, $m=0$ and complex frequency
$\omega$. Working to first order in a small perturbation amplitude while
keeping background null geodesics exact, we derive a time-dependent
line-of-sight (Born) expression for the screen-plane deflection measured by a
static observer at large radius. From the same integral, an asymptotic
expansion yields the familiar weak-field $1/b$ law with a ringdown-frequency
correction that drives a harmonic centroid wobble, whereas a near-photon-sphere
expansion produces a time-dependent generalization of the logarithmic
strong-deflection limit with modulated coefficients, including a small
oscillation of the critical impact parameter. An observer tetrad built from the
background static frame ensures that all screen-plane quantities like centroid
motion, multi-image hierarchy, and time delays, and photon-ring morphology are
gauge-safe at first order. We provide explicit matching across regimes, showing
that the near-critical coefficients governing spacing and ring-radius
modulations are encoded in the same Born kernel that controls the weak-field
correction. The result is a coherent, purely theoretical account of how
ringdown physics imprints on imaging observables without numerical ray tracing.

</details>


### [2] [Statistical Constraints on Anisotropic Bianchi-III Cosmology in $f(R,T)$-Gravity Using MCMC Methods](https://arxiv.org/abs/2510.19852)
*Mayur Mune,Praveen Kumar Dhankar,Safiqul Islam,Behnam Pourhassan,Muhammad Aamir,Faisal Haroon*

Main category: gr-qc

TL;DR: The paper investigates anisotropic Bianchi type-III cosmology in f(R,T) gravity, using a model where f(R,T)=R+2f(T). Exact solutions are derived, and observational data like Hubble parameters, BAO, and supernovae are analyzed to validate the model, showing it's competitive with ΛCDM.


<details>
  <summary>Details</summary>
Motivation: To explore the viability of anisotropic cosmological models within modified gravity frameworks like f(R,T) and understand the role of matter-geometry coupling in cosmic acceleration.

Method: Used f(R,T)=R+2f(T) formulation; derived exact solutions for background dynamics; applied MCMC with Hubble, BAO, and Pantheon data to constrain parameters.

Result: The model successfully fits observational data, suggesting anisotropic Bianchi-III universe in f(R,T) gravity is a viable alternative, highlighting matter-geometry coupling's role in late-time acceleration.

Conclusion: Anisotropic Bianchi-III models in f(R,T) gravity provide a viable cosmological framework, offering new perspectives on cosmic acceleration beyond ΛCDM.

Abstract: Anisotropic Bianchi type-III cosmology is examined within the framework of
f(R,T) gravity, where R denotes the Ricci scalar and T the trace of the
energy-momentum tensor. In this work, we investigate the statistical
constraints on anisotropic Bianchi type-III cosmology within the framework of
f(R,T) gravity. The specific choice $f(R,T)=R+2f(T)$ is considered and exact
solutions are derived for the background dynamics of the model. The physical
parameters, such as the Hubble parameter H(z), spatial volume V(z), energy
density $\rho(z)$, and pressure p(z), are derived and their evolutionary
behaviors are analyzed. To examine the observational viability of the model, we
employ Markov Chain Monte Carlo (MCMC) methods and perform a comprehensive
statistical analysis using the latest observational datasets, including the
Hubble parameter measurements, Baryon Acoustic Oscillations (BAO), and the
Pantheon compilation of type Ia supernovae. The combined data analysis provides
constraints on the free parameters of the model and allows a comparison with
the standard $\Lambda$CDM cosmology. Our results show that the anisotropic
Bianchi-III universe in f(R,T) gravity can successfully accommodate current
observational data, offering new insights into the role of matter-geometry
coupling in the late-time cosmic acceleration.

</details>


### [3] [Simple Analytic Estimate of Black Hole Shadow Size in an Expanding Universe](https://arxiv.org/abs/2510.19857)
*Debarshi Mukherjee*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The apparent shadow of a black hole provides one of the most direct probes of
strong-field general relativity. While the shadow size in asymptotically flat
spacetimes is well understood, the influence of cosmic expansion on its
apparent angular diameter remains less explored. In this work, we present a
simple analytic framework to estimate the shadow size of a non-rotating black
hole embedded in an expanding universe. By combining the local Schwarzschild
geometry with large-scale cosmological dynamics through the McVittie and
Kottler metrics, we derive a compact relation between the shadow angular size
and the angular diameter distance $D_A(z)$. This approach captures the
essential dependence on cosmological parameters such as the Hubble constant
$H_0$ and the cosmological constant $\Lambda$, while remaining analytically
tractable. We further perform numerical estimates to quantify the redshift
dependence of the apparent shadow size, showing that the effect of cosmic
expansion is negligible for nearby sources but becomes relevant for
high-redshift black holes. Our results demonstrate a clear conceptual
connection between strong-gravity optics and cosmological expansion, providing
a pedagogically transparent and physically motivated extension of black hole
shadow theory to a cosmological context.

</details>


### [4] [Tracing Inflationary Imprints Through the Dark Ages: Implications for Early Stars and Galaxies Formation](https://arxiv.org/abs/2510.19863)
*K. El Bourakadi,M. Yu. Khlopov,M. Krasnov,H. Chakir,M. Bennai*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We explore how inflationary features shape the early stages of cosmic
structure formation. Using the transfer function formalism, we trace the
evolution of primordial perturbations, showing how causal physics and
oscillatory signatures from inflation influence the matter power spectrum. The
variance of smoothed density fields is then applied to model the collapse of
overdense regions and predict dark matter halo abundances through the
Press-Schechter framework. Extending to the baryonic sector, we analyze
primordial gas collapse in minihalos, emphasizing molecular hydrogen cooling
and the thermochemical pathways leading to Population III star formation.
Finally, we examine primordial black holes as potential seeds for early
galaxies, connecting their accretion-driven growth to the stellar masses and
disk properties of high-redshift systems. Our results indicate that oscillatory
features from inflation can leave measurable imprints on halo abundances and
early galaxy properties, providing a testable link between high-energy physics
and astrophysical observations with JWST

</details>


### [5] [Detecting White Dwarf Binary Mergers with Gravitational Waves](https://arxiv.org/abs/2510.19913)
*Giona Sala,Chiara Brandenstein,Sebastian Baum,Peter W. Graham*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Mergers of white dwarf binaries are a possible progenitor channel for Type Ia
supernovae. While white dwarfs are abundant in the universe and relatively well
understood, their gravitational wave signals have not yet been directly
observed. In order to detect gravitational waves from merging white dwarf
binaries, a detector in the mid-band between LVK and LISA appears necessary. In
this paper, we compute and discuss the gravitational waves emitted by
inspiraling and merging white dwarf binaries, and assess their detectability
with proposed space-based atom-interferometer detectors such as MAGIS Space and
AEDGE. Gravitational waves from massive white dwarf binaries can be observed
for many years before merger, offering a unique early warning of their final
explosion. Our projections suggest that MAGIS Space could detect signals from
Type Ia supernova progenitors at least once every four years, while AEDGE could
observe at least a few hundred such events annually. The prolonged
gravitational wave emission captured by atom-interferometers provides precise
sky localisation and can allow observation of the final explosion with
electromagnetic telescopes. The combined observation with electromagnetic
radiation from the white dwarf binary coalescence could open a new pathway for
multi-messenger astronomy involving some of the brightest transient events in
the universe.

</details>


### [6] [Constraining the Swift Memory Burden Effect with GW250114-like Events](https://arxiv.org/abs/2510.19916)
*Chen Yuan,Richard Brito*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Black hole spectroscopy allows to infer the properties of the remnant of a
binary black hole coalescence. Motivated by the recent proposal that a black
hole's information load can alter its classical response to small
perturbations, an effect known as the swift memory burden, we develop a minimal
phenomenological framework to analyze the ringdown of a binary black hole
merger and confront it with the data from the GW250114 event. We perform a
Bayesian analysis combining the frequencies of the (220) and (440) quasi-normal
modes and obtain a lower bound $\log_{10}p \gtrsim 2$, where $p$ controls how
the gaps reopen when the black hole's master mode occupation departs from the
critical value. Moreover, using a Fisher information matrix (high
signal-to-noise ratio) approximation, we forecast the lower bound $\log_{10}p
\gtrsim 5$ for a GW250114-like event observed with Cosmic Explorer. Our results
disfavour rapid gap reopening, shedding light on how the swift memory burden
effect can be probed with current and next-generation detectors.

</details>


### [7] [Dephasing in binary black hole mergers surrounded by scalar wave dark matter clouds](https://arxiv.org/abs/2510.20037)
*Cheng-Hsin Cheng,Giuseppe Ficarra,Helvi Witek*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Scalar fields of masses between $10^{-21}\rm{eV}/c^2$ and $10^{-11}
\rm{eV}/c^2$ can exhibit enhanced gravitational interactions with black holes,
and form scalar clouds around them. Such a cloud modifies the dynamics of a
coalescing black-hole binary, and the resulting gravitational waves may provide
a new channel to detect light scalar fields, such as axion-like particles or
wave-like dark matter candidates. In this work we simulate a series of
black-hole mergers with mass ratios $q=1$ and $q=1/2$, immersed in an scalar
field overdensity with masses in the range $M\mu_{\rm{S}} \in[0,1.0]$. To do
so, we implemented a constraint-satisfying initial data solver based on the
puncture method, we improved the accuracy of our open-source software Canuda to
eighth order finite differences, and we reduced the initial orbital
eccentricity. We investigate the impact of the scalar mass on the gravitational
and scalar radiation. We find that binaries can undergo a delayed or an
accelerated merger with respect to the vacuum. Our study highlights the
challenge and importance of accurately modeling black-hole binaries in dark
matter environments.

</details>


### [8] [Gauss-Bonnet entropy and thermal dynamics of RN-AdS black holes](https://arxiv.org/abs/2510.20183)
*M. Z. Bhatti,Kazuharu Bamba,I. Siddique,Bander Almutairi,Z. Yousaf*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We explore the thermodynamics of a novel solution for the
Reissner-Nordstr\"{o}m-Anti-de Sitter (AdS) black hole, uniquely incorporating
the Gauss-Bonnet term. Unlike previous studies that primarily focused on
standard General Relativity or other modifications, this inclusion allows for a
modified entropy formulation, facilitating the computation of key thermodynamic
quantities such as Gibbs free energy, the first law of thermodynamics, the
equation of state, and Hawking temperature. We identify critical points and
graphically represent the relationship between temperature and Gibbs free
energy as a function of the horizon radius. Ultimately, we assess the thermal
stability of the Reissner-Nordstr\"{o}m-AdS black hole within the framework of
Gauss-Bonnet gravity, emphasizing the influence of the Gauss-Bonnet term unlike
previous studies that primarily focused on standard General Relativity or other
modifications. As a result, it is found that the Gauss-Bonnet coupling
significantly alters the thermodynamic behavior and stability structure of the
black hole, revealing richer phase transition phenomena.

</details>


### [9] [Emergent time and more from wavefunction collapse in general relativity](https://arxiv.org/abs/2510.20207)
*Sung-Sik Lee*

Main category: gr-qc

TL;DR: The paper explores a theory where time arises from wavefunction collapse in quantum gravity, leading to a monotonic scale factor acting as a clock. It identifies scalar gravitons as viable dark matter candidates due to their wavelength-dependent decay rates.


<details>
  <summary>Details</summary>
Motivation: To develop a theory of time based on wavefunction collapse in general relativity, addressing issues like the emergence of a time arrow and the suppression of constraint-violating excitations.

Method: Proposing quantum states violating momentum/Hamiltonian constraints as time instances, with stochastic lapse/shift fluctuations causing collapse toward diffeomorphism-invariant states. Analyzes scalar, vector, tensor gravitons' behavior using semi-classical and adiabatic approximations in a cosmological constant-dominated universe.

Result: Scalar gravitons' decay rates depend on wavelength, making them dark matter candidates. Vector modes are uniformly suppressed; tensor gravitons show emergent unitary dynamics in the long-term. Non-unitary dynamics suppress extra modes strongly.

Conclusion: Wavefunction collapse mechanisms can explain time's arrow and dark matter phenomenology via scalar excitations' survival over long periods at large scales.

Abstract: In this paper, we further develop a recently proposed theory of time based on
wavefunction collapse in general relativity. It is based on the postulations
that quantum states, which violate the momentum and Hamiltonian constraints,
represent instances of time, and stochastic fluctuations of the lapse and shift
generate the time evolution under which an initial state gradually collapses
toward a diffeomorphism-invariant state. Under the wavefunction collapse, the
scale factor monotonically increases, thus acting as a clock. The scalar,
vector, and tensor gravitons arise as physical excitations, and the arrow of
time for their evolution is set by the initial state. In the long-time limit,
the tensor gravitons exhibit emergent unitary dynamics. However, the extra
modes are strongly damped due to the non-unitary dynamics that suppress the
constraint-violating excitations. The vector mode is uniformly suppressed over
all length scales, but the decay rate of the scalar is proportional to its wave
vector. This makes the latter a viable candidate for dark matter; excitations
with large wavelengths survive over long periods, contributing to long-range
interactions, while the fast decay of short-wavelength modes renders them
undetectable without sufficient temporal resolution. These are demonstrated for
the cosmological constant-dominated universe through semi-classical and
adiabatic approximations, which are controlled in the limit of large space
dimension.

</details>


### [10] [Quantum Field Theory in Successive Rindler Spacetimes](https://arxiv.org/abs/2510.20283)
*Nitesh K. Dubey,Jaswanth Uppalapati,Sanved Kolekar*

Main category: gr-qc

TL;DR: The paper examines successive Rindler-like transformations in Minkowski spacetime, showing that each subsequent observer perceives the previous vacuum state as thermal. Using Unruh-DeWitt detectors, they verify thermal behavior with a Planckian spectrum at late times for second-level transformations.


<details>
  <summary>Details</summary>
Motivation: To explore how successive accelerations affect vacuum perception and thermal properties between nested Rindler observers.

Method: Applying iterative Rindler transformations, analyzing Bogoliubov coefficients, and using UDW detectors to measure vacuum state thermalization across different observer frames.

Result: The nth observer sees the (n-1)th vacuum as thermal. For the second-level case, late-time acceleration approaches 2g₂ or diverges. UDW detector responses confirm a Planckian spectrum matching accelerated observers.

Conclusion: Successive Rindler transformations induce thermal effects between nested observers, validated by detector responses, strengthening links between acceleration, horizons, and thermodynamics in quantum field theory.

Abstract: We study successive Rindler-like transformations in Minkowski spacetime and
the corresponding sequence of vacuum states perceived by observers restricted
to respective wedges. Extending the standard Rindler construction to an
$n$-fold iteration, we find via Bogoliubov transformations that the vacuum of
the $(n-1)^{th}$ Rindler observer appears thermal to the $n^{th}$ one. The
characteristic trajectories, confined to nested wedges, exhibit characteristic
accelerations and horizon shifts depending on transformation parameters ${g_1,
g_2, \ldots, g_{n}}$. For the second-level transformation (\emph{Rindler
Rindler} case), the late time acceleration asymptotically approaches $2g_2$ for
one branch and diverges for the other. We study Minkowski, Rindler, and Rindler
Rindler vacuum states from the perspective of Unruh DeWitt (UDW) detectors
along inertial, Rindler, and Rindler Rindler trajectories. The response of the
UDW detector coupled to a real massless scalar field confirms the thermality:
the transition rate of Rindler Rindler observer in Minkowski vacuum matches
that of a standard Rindler detector with acceleration $2g_2$, yielding a
Planckian spectrum at late times. The conclusions are discussed.

</details>


### [11] [Bound State Perturbations in the Interior of Black Holes](https://arxiv.org/abs/2510.20305)
*Hassan Firouzjahi*

Main category: gr-qc

TL;DR: The paper investigates bound state perturbations inside Schwarzschild black holes, confirming their existence for scalar, vector, and tensor modes. It establishes universal bounds on the imaginary frequencies, with the lower bound 2GMTω_I >1 and an upper bound for axial perturbations scaling as ~0.04 ℓ⁴ in the large ℓ limit.


<details>
  <summary>Details</summary>
Motivation: To revisit earlier work and explore the nature of bound states within black holes, understanding their spectral properties and establishing fundamental limits on their frequencies, which is crucial for black hole stability and quantum gravity studies.

Method: Rewrote the Regge-Wheeler equation using the expanding interior's scale factor as a timescale, then solved it semi-analytically and numerically to analyze bound states' behavior and frequency bounds.

Result: Confirmed existence of bound states for all perturbation types (scalar, vector, tensor) with ℓ−s states per ℓ>s. Derived a universal lower frequency bound and a tighter upper bound specifically for axial perturbations at large ℓ.

Conclusion: Bound states inside black holes exhibit quantifiable spectral constraints, suggesting these states may play a role in black hole dynamics and provide testable predictions for future theoretical or observational studies.

Abstract: We revisit our earlier work and investigate the bound state perturbations in
the interior of the Schwarzschild black hole. The bound sates are defined as
the perturbations in the interior of the black hole with an imaginary spectrum
which are regular at the center of black hole while their time-dependent
profile falls off exponentially on the event horizon. Using the scale factor in
the expanding direction in the interior of the black hole as the clock, we
rewrite the corresponding Regge-Wheeler equation and solve it semi-analytically
as well as numerically. We confirm that the bound state solutions exist for
scalar, vector and axial tensor perturbations. It is shown that for a given
value of $\ell >s$, there are total $\ell-s$ such bound states. We obtain the
universal lower bound $2 G M \omega_I >1$ for the spectrum of bound state which
is asymptotically saturated in the large $\ell$ limit. Furthermore, we obtain
an upper bound on the spectrum of axial perturbations which for large $\ell$
scales like $2 G M \omega_I \lesssim 0.04\, \ell^4 $. As observed recently,
these bound states have the curious property that the profile of the total wave
function has a non-zero magnitude near the future event horizon.

</details>


### [12] [On the observation of cosmic strings via gravitational-wave lensing](https://arxiv.org/abs/2510.20442)
*Oleg Bulashenko,Nino Villanueva,Roberto Bada Nerin,José A. Font*

Main category: gr-qc

TL;DR: The paper introduces a framework to detect gravitational waves from binary black hole (BBH) mergers lensed by cosmic strings, leveraging their unique geometric properties and offering a method to distinguish these signals from other lensing effects.


<details>
  <summary>Details</summary>
Motivation: To address the current lack of dedicated searches for gravitational waves lensed by cosmic strings, which could provide insights into high-energy physics and the early universe.

Method: Employs a full-wave transmission factor using Fresnel integrals to model diffraction and interference caused by cosmic strings, contrasting with point mass lensing. Analyzes waveform characteristics like beating patterns and time-separated replicas for BBH signals.

Result: Establishes detectability bounds on cosmic string tension and shows Bayesian distinguishability of cosmic string lensing from other scenarios across parameter space.

Conclusion: Demonstrates the feasibility of detecting cosmic string lensing in gravitational wave data, providing a new observational tool for studying cosmic strings and early universe physics.

Abstract: We present a framework for detecting gravitational-wave signals lensed by
cosmic strings (CSs), addressing a key gap in current searches. CSs, whose
detection would provide a unique probe of high-energy physics and the early
Universe, possess distinct topological and geometric features that require a
dedicated search strategy. Our approach employs a full-wave transmission
factor, expressed analytically via Fresnel integrals, which captures the
characteristic diffraction and interference effects of the conical spacetime
around a straight CS. We contrast CS lensing with the well-studied point mass
lens (PML) model, highlighting their fundamental differences: CS lensing
depends on cosmological distances, string tension $\Delta$, and wavelength
$\lambda$, and produces two non-amplified images set by the global conical
geometry. In contrast, PML lensing is governed by the distance-independent
ratio $\sim M_{Lz}/\lambda$, where $M_{Lz}$ represents the redshifted mass of
the lens, with image properties derived from the lens equation. For BBH mergers
lensed by CSs, we show that the waveforms exhibit a characteristic beating
pattern or time-separated, exact replicas. We derive a detectability bound on
the string tension and, using Bayesian model selection, demonstrate that CS
lensing is distinguishable from both unlensed and PML-lensed signals across a
wide region of parameter space.

</details>


### [13] [Validation of NANOGrav 15-year data and ACT data by modified inflation in entropic cosmology](https://arxiv.org/abs/2510.20484)
*Simone D'Onofrio,Sergei Odintsov,Tanmoy Paul*

Main category: gr-qc

TL;DR: The paper proposes a modified inflationary model using a generalized thermodynamic approach to explain the stochastic gravitational wave background observations from Pulsar Timing Arrays like NANOGrav and align with constraints from the Atacama Cosmology Telescope (ACT).


<details>
  <summary>Details</summary>
Motivation: The standard inflationary model struggles to explain recent PTA observations of an SGWB and the refined constraints from ACT. The paper aims to reconcile these discrepancies by modifying inflationary dynamics.

Method: The authors use a thermodynamic framework where the apparent horizon's entropy follows a generalized form, allowing amplified tensor perturbations in NANOGrav-sensitive scales. They numerically test compatibility with ACT and NANOGrav 15-year data.

Result: The modified model's parameters satisfy both ACT's inflationary observable constraints and the NANOGrav SGWB data, indicating its viability compared to standard inflation.

Conclusion: The generalized entropy-based inflationary model provides a plausible alternative to standard inflation by simultaneously addressing SGWB observations and cosmological parameter constraints.

Abstract: Recent evidences of stochastic gravitational wave background (SGWB) through
Pulsar Time Array (PTA) observations hint towards an alternative inflationary
scenario, compared to the usual inflation, for describing the early stage of
the universe in order to be compatible with the PTA data. Moreover, currently
the Atacama Cosmology Telescope (combined with the Planck 2018 and BAO) refines
the constraint on inflationary observables, compared to the only-Planck 2018
measurements. In the present work, we simultaneously address these two issues
by incorporating certain modification during inflation over the usual
inflationary scenario. Such modification amplifies the primordial tensor
perturbation over the modes that are sensitive to the NANOGrav frequency
region. For this purpose, we take the thermodynamic route of cosmology where
the entropy of the apparent horizon is given by a generalized form of entropy
that is able to generalize the other known form of horizon entropies for
suitable representations. The constraints on the model parameters coming from
the ACT data also fit the NANOGrav 15-year data (based on numerical analysis),
which reveal the model's compatibility with both the ACT and the PTA data.

</details>


### [14] [Quasinormal modes of a charged spherically symmetric black hole in bumblebee gravity](https://arxiv.org/abs/2510.20503)
*Bo-Rui Li,Jia-Zhou Liu,Wen-Di Guo,Yu-Xiao Liu*

Main category: gr-qc

TL;DR: The paper investigates quasinormal modes of charged spherically symmetric black holes in bumblebee gravity using two methods to assess their accuracy and efficiency in a Lorentz-violating context.


<details>
  <summary>Details</summary>
Motivation: To explore how Lorentz symmetry breaking affects quasinormal modes and validate computational methods in such spacetimes.

Method: 使用的两种方法是连续分数法和渐近迭代法，分析标量扰动和引力电磁耦合扰动的准正则频率。

Result: 通过比较两种方法的结果，评估了它们在自发洛伦兹破缺背景中的精度和效率。

Conclusion: 这两种方法在研究洛伦兹对称性破缺的黑洞时具有可靠性和有效性，为未来研究奠定了基础。

Abstract: Recently, some of us have obtained exact charged spherically symmetric black
hole solutions within the framework of bumblebee gravity, where the Lorentz
symmetry is spontaneously broken due to the nonvanishing vacuum expectation
value of the bumblebee field. In this work, we investigate the quasinormal
modes of this black hole. We compute the quasinormal frequencies corresponding
to the scalar perturbation and the gravito-electromagnetic coupled perturbation
using both the continued fraction method and the asymptotic iteration method. A
detailed comparison of the results obtained from the two approaches is
presented to evaluate their accuracy and efficiency in this Lorentz-violating
background.

</details>


### [15] [Regular hairy black holes through gravitational decoupling method](https://arxiv.org/abs/2510.20524)
*Yaobin Hua,Zhenglong Ban,Tian-You Ren,Jia-Jun Yin,Rong-Jia Yang*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Within a framework requiring a well-defined event horizon and matter obeying
the weak energy condition, we employ gravitational decoupling method to
construct non-singular hairy black holes: spherically or axially symmetric.
These solutions arise from a deformation of the Minkowski vacuum, where the
maximum deformation can yield the Schwarzschild metric for the static case, and
the Kerr geometry for the stationary case, respectively.

</details>


### [16] [Can a Dehnen-type dark matter halo affect the neutrino flavor oscillations?](https://arxiv.org/abs/2510.20563)
*Mirzabek Alloqulov,Ahmadjon Abdujabbarov,Bobomurat Ahmedov,Chengxun Yuan*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The gravitational weak lensing of neutrinos in the presence of a
Schwarzschild black hole surrounded by a Dehnen-type dark matter halo is
investigated. The event horizon structure is explored, and the existence of the
BH is studied in two different slices of the parameter space. Additionally, we
derive analytic expressions for the oscillation phase and transition
probabilities for both radial and non-radial neutrino propagation. Finally, we
use a two-flavor toy model, and numerically analyze how the dark matter halo
parameters as density and scale radius, affect oscillation probabilities and
examine the role of decoherence. The results show that the presence of a dark
matter halo modifies the oscillation phase and damping factor, leading to
measurable deviations from the standard Schwarzschild BH case. These findings
suggest that neutrino oscillations could, in principle, serve as a probe for
dark matter distributions around compact astrophysical objects.

</details>


### [17] [Pole inflation from extended metric-affine gravity](https://arxiv.org/abs/2510.20585)
*Damianos Iosifidis,Sotirios Karamitsos*

Main category: gr-qc

TL;DR: This paper analyzes inflation within an extended metric-affine F(R) gravity framework, incorporating all even-parity quadratic invariants of torsion and non-metricity. The theory reduces to a scalar-tensor model with non-canonical kinetic terms, leading to inflationary dynamics and observable predictions independent of the specific F(R) form, dominated by the pole structure in the kinetic terms. The study identifies viable models by classifying them based on pole order, ghost freedom, and tensor-to-scalar ratio constraints, showing that relaxing ghost constraints near the pole allows more viable models and confirms the framework's robustness in reproducing observed inflationary parameters.


<details>
  <summary>Details</summary>
Motivation: To explore the viability of extended metric-affine F(R) gravity as an inflationary framework, examining how its inclusion of torsion and non-metricity invariants affects inflationary dynamics and observables, particularly addressing model independence from F(R) specifics and circumventing ghost issues.

Method: Analytical analysis of a simplified model and comprehensive exploration of an eleven-parameter theory. The models were classified by pole order (second-order), ghost presence (specifically near inflation regions), and tensor-to-scalar ratio. A scalar-tensor description was used with non-canonical kinetic terms featuring poles.

Result: The pole structure dominates inflationary predictions, making F(R) form irrelevant. Relaxing ghost constraints near the pole significantly increases viable models. The framework robustly reproduces the required attractor predictions for spectral index and tensor-to-scalar ratio within observational limits.

Conclusion: Extended metric-affine F(R) gravity is a viable inflationary framework when considering non-canonical poles in kinetic terms. Relaxing ghost conditions locally around the inflationary pole expands permissible models, demonstrating the theory's flexibility and robustness without conflicting with current cosmological observations.

Abstract: We study inflation in the framework of extended metric-affine F(R) gravity,
where all even-parity quadratic invariants of torsion and non-metricity are
included in the Lagrangian alongside the F(R) term. The extended theory admits
a scalar-tensor description with a non-canonical kinetic term featuring poles.
As a result, the inflationary dynamics and predictions for observables of this
model are insensitive to the specific form of F(R), since they are dominated by
the structure of the poles (order and residue). We analyze both a simplified
version analytically and the full eleven-parameter theory, and we classify the
models based on whether they feature second-order poles, whether they are free
from ghosts, and whether they predict a sufficiently small tensor-to-scalar
ratio. By relaxing the ghost-free requirement to only exclude ghosts near the
pole (where inflation occurs), we demonstrate that we can significantly enlarge
the set of viable models. We thus show that extended metric-affine F(R) gravity
can act as a robust framework for inflation, reproducing the attractor
predictions for the spectral index and tensor-to-scalar ratio.

</details>


### [18] [The global nonlinear stability of Minkowski spacetime with self-gravitating massive Dirac fields](https://arxiv.org/abs/2510.20626)
*Philippe G. LeFloch,Yue Ma,Weidong Zhang*

Main category: gr-qc

TL;DR: The paper establishes the global nonlinear stability of a spacelike, asymptotically Euclidean slice of the Einstein-Dirac system for a massive field near Minkowski spacetime, using a gauge-invariant formalism and extending previous results beyond the massless case.


<details>
  <summary>Details</summary>
Motivation: To investigate the global evolution of self-gravitating massive spinor fields and prove stability against gravitational perturbations, addressing limitations in prior massless case analysis and introducing gauge-invariant methods for spinor dynamics.

Method: The authors employ asymptotically hyperboloidal-Euclidean coordinates, Lorentz Clifford algebras, and wave equations with constraints. They derive L2 and pointwise estimates, establish Sobolev inequalities for spinors, and analyze a hierarchy of nonlinear couplings between Dirac and Einstein equations.

Result: They confirm global hyperbolic development retaining Minkowski-like asymptotics, valid for massive spinors, with estimates distinguishing between translations, rotations, and boosts. This extends stability results from massless Dirac fields.

Conclusion: The gauge-invariant approach succeeds in proving stability for massive Einstein-Dirac systems, demonstrating that massive spinor fields don't disrupt spacetime structure asymptotically, and opens paths for future studies on self-gravitating fermionic matter.

Abstract: We consider the Einstein-Dirac system for a massive field, which describes
the evolution of self-gravitating massive spinor fields, and we investigate the
global evolution problem, when the initial data set is sufficiently close to
data describing a spacelike, asymptotically Euclidean slice of the Minkowski
spacetime. We establish the gauge-invariant nonlinear stability of such fields,
namely the existence of a globally hyperbolic development, which remains
asymptotic to Minkowski spacetime in future timelike, null, and spacelike
directions. Previous results on this problem have been limited to the
Einstein-Dirac system in the massless case. Our analysis follows the
asymptotically hyperboloidal-Euclidean framework introduced by LeFloch and Y.
Ma for the massive Klein-Gordon-Einstein system. The structure specific to
spinor fields and the Dirac equation necessitates significantly new elements in
the proof. In contrast with prior approaches, our treatment of spinor fields
and the Dirac equation is gauge-invariant, relying on the formalism of Lorentz
Clifford algebras, principal fiber bundles, etc. Our analysis is carried out
with the metric expressed in light-bending wave coordinates, as we call them.
This leads us to the study of a global existence problem for a system of wave
equations with constraints and a Klein-Gordon-type equations. We derive L2
estimates for the Dirac equation and its coupling with the Einstein equations,
along with $pointwise estimates. New Sobolev inequalities are proven for spinor
fields in a gauge-invariant manner in the hyperboloidal-Euclidean foliation.
The nonlinear coupling between the massive Dirac equation and the Einstein
equations is investigated, and we establish a hierarchy of estimates, which
distinguish between translations, rotations, and boosts.

</details>


### [19] [Radiating black holes in general relativity need not be singular](https://arxiv.org/abs/2510.20649)
*Francesco Di Filippo*

Main category: gr-qc

TL;DR: The paper challenges the notion that black holes must have regions where general relativity breaks down by showing that electromagnetic repulsion and Hawking radiation can prevent both singularities and Cauchy horizons in charged black holes, with potential implications for astrophysical black holes involving angular momentum.


<details>
  <summary>Details</summary>
Motivation: To address the longstanding assumption that black holes inevitably contain regions (singularities or Cauchy horizons) where general relativity fails, by exploring how Hawking radiation and electromagnetic forces might alter this outcome.

Method: Analyzing a charged, spherically symmetric black hole formed via gravitational collapse and considering its evaporation through Hawking radiation. The study examines how electromagnetic repulsion and modified energy conditions influence the formation of singularities and Cauchy horizons.

Result: The authors demonstrate that electromagnetic repulsion combined with Hawking radiation's violation of energy conditions can prevent both curvature singularities and Cauchy horizons in the modeled black holes.

Conclusion: The results suggest that black holes may not necessarily have regions where general relativity breaks down, potentially reshaping our understanding of black hole interiors. The mechanism may extend to astrophysical black holes where angular momentum substitutes electric charge.

Abstract: It is common knowledge that black holes necessarily contain a region where
general relativity breaks down, due to the inevitable formation of either a
curvature singularity or a Cauchy horizon. In this work we challenge this view
by analyzing a charged spherically symmetric black hole formed through
gravitational collapse and evaporating via Hawking radiation. We show that the
electromagnetic repulsion and the violation of energy conditions due to the
presence of Hawking radiation are be sufficient to avoid the formation of both
a singularity and a Cauchy horizon. We argue that a similar mechanism may apply
to astrophysical black holes in which the role of the electric charge is
replaced by the angular momentum.

</details>


### [20] [Quantum black holes: inside and outside](https://arxiv.org/abs/2510.20799)
*Wei-Chen Lin,Dong-han Yeom,Dejan Stojkovic*

Main category: gr-qc

TL;DR: The paper addresses the information loss paradox by analyzing the Wheeler-DeWitt equation. It shows that time slices inside the event horizon can't form coherent states, implying the interior is a quantum superposition, resolving the paradox through a horizon-scale uncertainty.


<details>
  <summary>Details</summary>
Motivation: To justify why time slices avoiding the event horizon are necessary for unitary evolution and resolve the information loss paradox.

Method: Investigating the Wheeler-DeWitt equation's behavior on time slices crossing the event horizon, analyzing wave packet construction and wave function annihilation near the horizon.

Result: Wave functions must be annihilated near the horizon; coherent states cannot cross it, leading to a quantum superposition inside. This creates horizon-scale uncertainty.

Conclusion: Black holes are highly quantum objects with interiors as superpositions, resolving the information loss paradox by enforcing unitary evolution via exterior coherent states.

Abstract: For a unitary description of an evaporating black hole, one usually chooses
the time slices that cover only outside of the event horizon, which is mostly
problem-free because the event horizon is not encountered. However, is there
any justification for avoiding time slices that cover inside the event horizon?
To answer the question, we investigate the Wheeler-DeWitt equation, where the
time slices can cover both inside and outside the event horizon. We find that
one can reasonably construct a wave packet that covers outside, but the wave
function must be annihilated near the event horizon. This observation strongly
suggests that we cannot choose a coherent state for a spacelike hypersurface
that crosses the event horizon. To explain the unitary time evolution, we must
keep the slices as coherent states; hence, they must always be outside the
event horizon. In contrast, inside the horizon, we cannot have a single
coherent state of a classical spacetime. Hence, the interior must be a
superposition of several coherent states, which implies that there exists a
horizon-scale uncertainty and a black hole should be viewed as a highly quantum
macroscopic object. We provide a synthetic approach to understanding the
information loss paradox from this perspective.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [21] [Warped Dimensions at the Cosmological Collider](https://arxiv.org/abs/2510.19900)
*Soubhik Kumar,Michael Nee*

Main category: hep-ph

TL;DR: The paper proposes using primordial non-Gaussianity from inflation to detect imprints of extra dimensions, focusing on a 5D warped geometry with stabilized radion and KK gravitons, whose gravitational interactions create observable oscillatory signals in cosmic data.


<details>
  <summary>Details</summary>
Motivation: Extra dimensions in theories like string theory are hard to detect directly, especially at high energy scales. The early universe's high energy conditions allow production of heavy states (moduli, KK gravitons) which can leave detectable signatures in primordial non-Gaussianity.

Method: Constructed a 5D warped extra dimension model stabilized during inflation. Calculated mass/coupling of radion modulus and KK graviton modes. Modeled their coupling to curvature perturbations to predict NG features with oscillatory shapes and angular dependence.

Result: Derived observable non-Gaussianity signatures with specific oscillations and angular patterns. Provided Planck-comparable benchmark models and highlighted future survey potential for detecting extra-dimensional imprints.

Conclusion: Cosmological observations (like Planck and future surveys) can probe on-shell effects of extra dimensions through primordial non-Gaussianity, offering a new indirect detection method where particle colliders may fail.

Abstract: Extra dimensions are present in many beyond the Standard Model scenarios,
most notably in string theory. However, direct signatures of extra dimensions
are difficult to observe in many cases. This is the situation, for example, if
the energy scales associated with extra dimensions are close to the string or
Grand Unification scale. The energetic early universe provides an exciting
opportunity to overcome this challenge, since the heavy states associated with
high-scale extra dimensions, such as scalar moduli and Kaluza-Klein (KK)
gravitons, could have been produced on-shell at early epochs. In this work, we
illustrate this by focusing on how such states can be produced during inflation
and leave signatures in primordial non-Gaussianity (NG). Specifically, we
consider a 5D spacetime with a warped extra dimension that remains stabilized
as inflation proceeds in the four non-compact dimensions. By discussing an
explicit stabilization mechanism, we compute the masses and couplings of the
radion modulus and the KK graviton modes. Being gravitational degrees of
freedom, these unavoidably couple to the field(s) generating curvature
perturbation, and can lead to observable NG with a distinctive oscillatory
shape and characteristic angular dependence. We give example benchmarks which
can already be probed by the Planck data and identify targets for the future.
Our study shows that cosmological surveys have the potential to observe
on-shell imprints of extra dimensions in the coming years.

</details>


### [22] [Generative Unfolding of Jets and Their Substructure](https://arxiv.org/abs/2510.19906)
*Antoine Petitjean,Anja Butter,Kevin Greif,Sofia Palacios Schweitzer,Tilman Plehn,Jonas Spinner,Daniel Whiteson*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Unfolding, for example of distortions imparted by detectors, provides
suitable and publishable representations of LHC data. Many methods for unbinned
and high-dimensional unfolding using machine learning have been proposed, but
no generative method scales to the several hundred dimensions necessary to
fully characterize LHC collisions. This paper proposes a 3-stage generative
unfolding framework that is capable of unfolding several hundred dimensions. It
is effective to unfold the jet-level kinematics as well as the full
substructure of light-flavor jets and of top jets, and is the first generative
unfolding study to achieve high precision on high-dimensional jet substructure.

</details>


### [23] [Beyond Qubits: Multilevel Quantum Sensing for Dark Matter](https://arxiv.org/abs/2510.19918)
*Xiaolin Ma,Volodymyr Takhistov,Norikazu Mizuochi,Ernst David Herbschleb*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum sensing with qubits has advanced fundamental physics searches, but
higher dimensional systems offer untapped potential. We present a universal
qutrit framework that yields a sequence-independent fourfold increase in
quantum Fisher information and a twofold gain in sensitivity. In ultralight
dark matter searches, spin-1 NV-center qutrits can enhance the axion-electron
coupling reach by an order of magnitude beyond qubits. This principle applies
broadly to multilevel quantum systems including superconducting, neutral atom
and trapped-ion qutrits, establishing higher dimensional sensing as a powerful
tool for probing new physics.

</details>


### [24] [Probing the vacuum as a chiral medium](https://arxiv.org/abs/2510.19921)
*T. Heinzl,B. King,A. Mercuri-Baron*

Main category: hep-ph

TL;DR: The paper investigates circular birefringence in a vacuum with definite chirality caused by colliding linearly polarized photons with a circularly polarized background field. It shows equivalence between three methods for incorporating derivative corrections to the Heisenberg-Euler theory and identifies experimental parameters where these effects might be observable.


<details>
  <summary>Details</summary>
Motivation: The standard Heisenberg-Euler approach fails to describe scenarios with circular birefringence in chiral vacuums created by circularly polarised backgrounds, necessitating derivative corrections to accurately model such phenomena.

Method: Three equivalent approaches are used: (i) adding derivative corrections to the Heisenberg-Euler Lagrangian, (ii) enhancing the locally constant field approximation for the one-loop polarisation tensor, and (iii) low-energy expansion of 2→2 QED photon-photon scattering amplitudes. A plane wave background is initially analyzed, followed by a circularly polarized standing wave example.

Result: Equivalence between the three methods is confirmed, and a parameter regime is identified where derivative corrections could be experimentally tested in non-plane-wave backgrounds like circularly polarized standing waves.

Conclusion: Derivative corrections are essential for accurately modeling circular birefringence in chiral vacuums. The findings open pathways for experimental verification of quantum electrodynamics predictions under specific high-energy conditions.

Abstract: We study the circular birefringence experienced by linearly polarised photons
colliding with a circularly polarised background creating a vacuum of definite
chirality (handedness). For this scenario the standard Heisenberg-Euler
approach fails and must be supplemented by derivative corrections which we
match to known Hilbert series. Choosing a plane wave background, we find
equivalence between three approaches: (i) adding derivative corrections to the
Heisenberg-Euler Lagrangian; (ii) improving the locally constant field
approximation to the one-loop polarisation tensor; (iii) performing a
low-energy expansion of the direct $2\to 2$ QED photon-photon scattering
amplitude. Going beyond plane-wave backgrounds, we analyse an example of a
circularly polarised standing wave sensitive to derivative corrections. We find
a parameter regime where these corrections could be probed in experiments.

</details>


### [25] [Constructive Heavy Particle Effective Theory with Nonlinear Poincaré Symmetry](https://arxiv.org/abs/2510.19929)
*Yong-Kang Li,Yi-Ning Wang,Jiang-Hao Yu*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We develop a constructive heavy particle effective theory (HPET) through the
nonlinear realization of the spontaneously broken Poincar\'{e} symmetry
$R^{3,1} \rtimes SO(3,1) \rightarrow R^{3,1} \rtimes SO(3)$. Starting from the
heavy one-particle state, we find the nonlinear boost transformation indicates
the shift symmetry in the coset construction, corresponding to the
reparameterization invariance. Using the little group Wigner rotation, we
obtain the nonlinear boost transformation for corresponding heavy field,
recovering the Foldy-Wouthuysen transformation. At the operator level, since
interaction terms would modify the nonlinear transformation, we propose a most
general parametrization on the boost transformation only based on symmetry. The
nonlinear boost transformation relates different Wilson coefficients of the
HPET operators, providing a bottom-up approach of constructing the independent
HPET operators, and generalizing the top-down HPET operators beyond the
tree-level integrating out. Utilizing the HPET as example, we obtain additional
constraints for the boost transformation as well as the additional variation
$\delta \mathcal{L}$ at the $1/m^3$.

</details>


### [26] [A simple model for PDFs and nPDFs](https://arxiv.org/abs/2510.20139)
*A. V. Kotikov,A. V. Lipatov*

Main category: hep-ph

TL;DR: We derived analytical solutions to QCD evolution equations for parton distribution functions, ensuring compliance with key sum rules and momentum conservation. Using data from BCDMS, H1, and ZEUS with 933 data points, we determined phenomenological parameters and proposed a rescaling model incorporating Fermi motion to study nuclear medium effects on parton densities.


<details>
  <summary>Details</summary>
Motivation: To address the analytical solutions of QCD evolution equations and understand nuclear medium modifications in parton distributions by fitting experimental data and maintaining fundamental sum rules and momentum conservation.

Method: Derived analytical solutions for QCD evolution equations, ensuring Gross-Llewellyn-Smith and Gottfried sum rules for valence/non-singlet quarks, and momentum conservation for singlet quarks/gluons. Performed a combined fit to 933 data points from BCDMS, H1, ZEUS. Proposed a rescaling model with Fermi motion effects for nuclear data analysis.

Result: Extracted phenomenological parameters via data fits and obtained nuclear parton distribution functions predictions by fitting rescaling parameters to $F_2^A/F_2^D$ ratios for multiple nuclei.

Conclusion: The analytical approach successfully maintains theoretical constraints and provides accurate predictions for nuclear parton distributions, offering a reliable framework for understanding QCD dynamics in nuclei.

Abstract: We present the main results of our recent papers, where we derived an
analytical solution of the QCD evolution equations for parton distribution
functions. The valence and non-singlet quark components satisfy the
Gross-Llewellyn-Smith and Gottfried sum rules, respectively, while momentum
conservation is maintained for the singlet quark and gluon densities. Several
phenomenological parameters were extracted from a combined fit to precision
data on the proton structure function $F_2(x,Q^2)$ collected by the BCDMS, H1,
and ZEUS Collaborations, comprising a total of 933 points from 5 datasets. We
proposed a model for nuclear medium modifications of parton densities. The
approach is based on a global analysis of available deep inelastic scattering
data for different nuclear targets within the rescaling model, incorporating
Fermi motion effects. By fitting the rescaling parameters to experimental data
on the ratio $F_2^A(x,Q^2)/F_2^{D}(x,Q^2)$ for several nuclear targets $A$, we
obtained predictions for nuclear parton distribution functions.

</details>


### [27] [Holographic light-front QCD](https://arxiv.org/abs/2510.20180)
*Hans Guente Dosch,Guy F. de Teramond,Stanley J. Brodsky*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This brief review presents the key components of light-front holographic
quantum chromodynamics (HLFQCD). Particular attention is given to the
introduction of the QCD color confinement scale within the context of a graded
superconformal algebra. A concise overview of applications is provided,
including spectroscopy, form factors, parton distributions of hadrons, and the
relationship between entanglement entropy and high-energy scattering. While
many other recent applications of HLFQCD exist in the literature, they are not
included in this short overview of our latest work.

</details>


### [28] [Eigen-microstate Signatures of Criticality in Relativistic Heavy-Ion Collisions](https://arxiv.org/abs/2510.20336)
*Ranran Guo,Jin Wu,Mingmei Xu,Xiaosong Chen,Zhiming Li,Zhengning Yin,Yuanfang Wu*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce a novel eigen-microstate approach to expose critical patterns in
relativistic heavy-ion collisions. We explicitly construct the original
microstate, defined as the final-state particle fluctuations of a single event.
By examining ensembles of such microstates with controlled critical signals, we
demonstrate that the approach is highly effective in detecting and quantifying
critical patterns, with the largest eigenvalue serving as a robust order
parameter. This framework is directly applicable to RHIC Beam Energy Scan data,
offering a powerful new direction in the search for the QCD critical point.

</details>


### [29] [Symbolic Regression and Differentiable Fits in Beyond the Standard Model Physics](https://arxiv.org/abs/2510.20453)
*Shehu AbdusSalam,Steven Abel,Deaglan Bartlett,Miguel Crispim Romão*

Main category: hep-ph

TL;DR: The paper explores the use of symbolic regression (SR) to efficiently analyze the Constrained Minimal Supersymmetric Standard Model (CMSSM) in particle physics, demonstrating its effectiveness in deriving accurate symbolic expressions for key observables like Higgs mass, dark matter relic density, and muon g-2. SR enables faster global parameter fits using differentiable methods and shows advantages over neural networks by requiring less targeted data.


<details>
  <summary>Details</summary>
Motivation: To accelerate the analysis of BSM models like CMSSM by deriving symbolic expressions for observables, which can replace conventional computational methods and improve fitting processes.

Method: Symbolic regression is applied to derive mathematical expressions linking CMSSM parameters to observables (Higgs mass, dark matter relic density, muon g-2). These expressions are used for global parameter fits, compared against traditional sampling methods and neural networks.

Result: SR-derived expressions match conventional methods' results well, enable differentiable fitting, and outperform neural networks which need focused data for similar performance.

Conclusion: SR is a powerful tool for BSM model analysis, offering speed, global robustness, and efficient parameter estimation without requiring data concentration in specific regions.

Abstract: We demonstrate the efficacy of symbolic regression (SR) to probe models of
particle physics Beyond the Standard Model (BSM), by considering the so-called
Constrained Minimal Supersymmetric Standard Model (CMSSM). Like many
incarnations of BSM physics this model has a number (four) of arbitrary
parameters, which determine the experimental signals, and cosmological
observables such as the dark matter relic density. We show that analysis of the
phenomenology can be greatly accelerated by using symbolic expressions derived
for the observables in terms of the input parameters. Here we focus on the
Higgs mass, the cold dark matter relic density, and the contribution to the
anomalous magnetic moment of the muon. We find that SR can produce remarkably
accurate expressions. Using them we make global fits to derive the posterior
probability densities of the CMSSM input parameters which are in good agreement
with those performed using conventional methods. Moreover, we demonstrate a
major advantage of SR which is the ability to make fits using differentiable
methods rather than sampling methods. We also compare the method with neural
network (NN) regression. SR produces more globally robust results, while NNs
require data that is focussed on the promising regions in order to be equally
performant.

</details>


### [30] [GUT-Scale Smooth Hybrid Inflation with a Stabilized Modulus in Light of ACT and SPT Data](https://arxiv.org/abs/2510.20478)
*Waqas Ahmed,Constantinos Pallis,Mansoor Ur Rehman*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We analyze a generalized framework of smooth F-term hybrid inflation (smFHI)
consistent with gauge coupling unification within the Minimal Supersymmetric
Standard Model (MSSM). The embedding of the model in two specific Supergravity
settings addresses at the same time the $\eta$ problem and the compatibility
with the recent ACT or SPT data. The one relies on the choice of a
shift-symmetric K\"ahler potential for the inflaton which revitalizes the SUSY
predictions of smFHI, whereas the other employs a K\"ahler potential associated
with an hyperbolic K\"ahler manifold. An essential role in both our
constructions is played by a decoupled superheavy field without superpotential
and Kaehler potential inspired by string- and D-brane--based models. Our
proposal can be realized for a variety of representations for the Higgs fields
involved in smFHI and assures monotonic inflationary potential.

</details>


### [31] [NNLO QCD predictions for jet observables in ZH production at electron-positron colliders](https://arxiv.org/abs/2510.20485)
*Simone Caletti,Aude Gehrmann-De Ridder,Matteo Marcoli*

Main category: hep-ph

TL;DR: The paper provides NNLO QCD predictions for jet observables in ZH production at electron-positron colliders, considering different Higgs decay modes and jet resolution parameters.


<details>
  <summary>Details</summary>
Motivation: To improve precision in Higgs boson studies by providing higher-order QCD corrections for jet observables in ZH production, accounting for various decay modes and jet clustering parameters.

Method: Computed next-to-next-to-leading order (NNLO) QCD predictions using Durham or kT jet algorithms for ZH production with Z→ll and H→bb/cc/gg decays. Separate analyses for Yukawa and effective gluon couplings, with comparisons of jet resolution parameters.

Result: Presented detailed differential distributions for Higgs decays into bottom/charm quarks and gluons, showing differences between decay modes and dependencies on jet resolution parameters.

Conclusion: The NNLO calculations enhance prediction accuracy, crucial for precise measurements at future lepton colliders, and highlight the necessity of considering decay mode distinctions and jet clustering choices in theoretical modeling.

Abstract: We present precise predictions for a variety of jet observables in $ZH$
production at electron-positron colliders, with the $Z$ boson decaying
leptonically and the Higgs boson decaying into two hadronic jets, up to NNLO in
perturbative QCD. We consider a Higgs boson decaying into bottom (charm) quark
pairs via Yukawa interaction and into gluons via an effective vertex in the
limit of infinite top quark mass. We present results for the two decay modes
separately, highlighting relevant differences in the differential
distributions, and for the sum of all decay channels, including a comparison
between different choices of the Durham (or $k_T$) jet resolution parameter.

</details>


### [32] [On the Resonance Coupling and Width in Quantum Field Theory](https://arxiv.org/abs/2510.20488)
*Dmitri Melikhov*

Main category: hep-ph

TL;DR: The paper addresses the challenge of calculating finite and scheme-independent resonance properties in quantum field theory by properly defining the resonance coupling constant g_M through renormalization of self-energy diagrams.


<details>
  <summary>Details</summary>
Motivation: To resolve the ultraviolet divergences in self-energy diagrams and ensure that resonance properties are physical quantities independent of renormalization scheme.

Method: The authors propose a method to define resonance coupling g_M such that after renormalization, the calculated properties become finite and scheme-independent, likely involving rigorous renormalization procedures and possibly dispersion relations or on-shell schemes.

Result: Successful demonstration that with properly defined g_M, resonance properties can indeed be calculated as finite and scheme-independent quantities in quantum field theory.

Conclusion: The approach provides a robust framework for accurately determining resonance characteristics without ambiguities introduced by divergences or renormalization schemes.

Abstract: In quantum field theory, characteristics of resonances are related to
self-energy diagrams, which are ultra-violet divergent and require
renormalization. We demonstrate the proper way to define the resonance coupling
$g_M$ such that the resonance properties calculated in quantum field theory are
finite and scheme-independent quantities.

</details>


### [33] [QCD corrections to the electroweak sphaleron rate](https://arxiv.org/abs/2510.20594)
*Dietrich Bödeker,Philipp Klose*

Main category: hep-ph

TL;DR: This paper investigates the impact of strong interaction-mediated quark scattering on the weak-isospin conductivity in the high-temperature Standard Model plasma, finding a reduction of up to 15% in the quark contribution and 6% in total conductivity, which affects the electroweak sphaleron rate.


<details>
  <summary>Details</summary>
Motivation: The electroweak sphaleron rate's dependence on weak-isospin conductivity was previously calculated using only electroweak interactions. Including strong interactions is necessary for an accurate determination of sphaleron dynamics in the early Universe.

Method: The authors analyze quark scattering processes mediated by strong interactions at leading-logarithmic order, incorporating these into the calculation of weak-isospin conductivity to assess their effect on the sphaleron rate.

Result: Including strong interaction effects reduces the quark contribution to conductivity by up to 15% and total conductivity by up to 6%, altering previous estimates of conductivity's temperature dependence.

Conclusion: Strong interaction contributions are essential for precise modeling of the electroweak sphaleron rate in high-energy cosmological scenarios, requiring updated calculations for phenomena like baryogenesis.

Abstract: The electroweak sphaleron rate in the high temperature phase of the Standard
Model is inversely proportional to the weak-isospin conductivity. So far, only
electroweak interactions were included in its computation. Here we take into
account quark scattering through strong interactions at leading-log order.
These reduce the quark contribution to the conductivity by up to 15 %, and the
total conductivity by up to 6 %.

</details>


### [34] [Proposal to use accelerated electrons to probe the axion-electron coupling](https://arxiv.org/abs/2510.20625)
*Georgios Vacalis,Atsushi Higuchi,Robert Bingham,Gianluca Gregori*

Main category: hep-ph

TL;DR: The paper explores axion emission from accelerated electrons using high-intensity lasers, offering a method to set new bounds on axion-electron couplings.


<details>
  <summary>Details</summary>
Motivation: To address the strong CP problem and dark matter mystery by experimentally probing axion-electron interactions.

Method: Calculated axion emission probability and energy via WKB approximation for electrons accelerated by counter-propagating lasers, then analyzed photon conversion detection mechanisms.

Result: Demonstrated potential to achieve competitive model-independent bounds on axion couplings under realistic experimental conditions using tabletop laser setups.

Conclusion: Suggests this laser-based approach provides a feasible pathway for direct axion detection and constraining beyond-standard-model physics without relying on specific theoretical assumptions.

Abstract: The axion is a hypothetical particle associated with a possible solution to
the strong CP problem and is a leading candidate for dark matter. In this paper
we investigate the emission of axions by accelerated electrons. We find the
emission probability and energy within the WKB approximation for an electron
accelerated by an electromagnetic field. As an application, we estimate the
number of axions produced by electrons accelerated using two
counter-propagating high-intensity lasers and discuss how they would be
converted to photons to be detected. We find that, under realistic experimental
conditions, competitive model-independent bounds on the coupling between the
axion and the electron could be achieved in such an experiment.

</details>


### [35] [An Axial-Vector Leptophilic Fifth Force Sourced by Solar Neutrinos](https://arxiv.org/abs/2510.20672)
*Rundong Fang,Ji-Heng Guo,Jia Liu,Xiao-Ping Wang,YanLi Zhao*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate long-range, purely leptophilic axial-vector interactions
mediated by a light gauge boson $A'$ that couples to charged leptons and, by
weak symmetry, to left-handed neutrinos. We analyze two realizations, a minimal
effective model with muon-only couplings and an anomaly-free axial $U(1)'$ with
inter-generation cancellations. In both cases, the solar neutrino flux acts as
an extended current that sources a macroscopic $A'$ field at Earth, with
spatial components aligned along the Sun-Earth direction. This field produces a
distinctive signature in storage-ring measurements of the muon anomalous
magnetic moment, $(g-2)_\mu$, namely a diurnal, sign-changing contribution that
is positive during daytime and negative at night, superimposed on a
time-independent positive offset. We obtain bounds $g' \lesssim {O}(10^{-19})$
in both model frameworks for a light, effectively massless mediator. For
completeness, we map the solar-neutrino-sourced potential to electron
spin-sensor experiments and find $g' \lesssim {O}(10^{-22})$ in the electron
channel.

</details>


### [36] [Shear viscosity of a binary mixture for a relativistic fluid at high temperature](https://arxiv.org/abs/2510.20704)
*Gabriele Parisi,Vincenzo Nugara,Salvatore Plumari,Vincenzo Greco*

Main category: hep-ph

TL;DR: This paper explores the calculation of shear viscosity in binary mixtures using a 2-component Chapman-Enskog approach, showing that while a weighted average of individual component viscosities often works, inter-species interactions significantly affect results in systems like quark-gluon plasma, where combinations fail.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of determining shear viscosity in multi-species fluids with varying interaction cross-sections, and validate theoretical models against numerical simulations.

Method: The authors use the Chapman-Enskog framework for binary mixtures and compare single-component viscosity combinations with full 2-component calculations. They also validate results using Boltzmann equation simulations with Green-Kubo formulas for a quasi-particle system mimicking lattice QCD thermodynamics.

Result: In most cases, the full viscosity is approximated by a weighted linear average of individual viscosities, but inter-species interactions (like in quark-gluon plasma) invalidate this approach, showing system-specific dependencies. Comparisons with Green-Kubo simulations confirm this.

Conclusion: Single-component viscosity combinations are insufficient for systems with strong inter-species scattering; a full multi-component approach is necessary for accurate viscosity determination, especially in complex systems like lattice QCD.

Abstract: The determination of the shear viscosity is a central topic in various areas
of modern physics. In particular, it is often necessary to evaluate the shear
viscosity $\eta$ of fluids made up of more than one species, all interacting
with different cross sections. Since it may be difficult to extract information
on the interaction among different species, various combinations of the
viscosities of the individual components are often used. We work in the
Chapman-Enskog framework and investigate on binary mixtures, by comparing such
single component combinations with a full 2-component formalism: we find that,
in most cases, the full viscosity is well approximated by a weighted linear
average of the single component viscosities, although this result is far from
being general. Moreover, we validate our 2-component Chapman-Enskog results for
$\eta$ by comparing them with an independent numerical simulation of the
Boltzmann equation, which estimates the shear viscosity via a Green-Kubo
formula, in the case of a quasi-particle system that reproduces lattice QCD
thermodynamics. We see that the temperature dependence of $\eta/s$ of such
system of quarks and gluons is not well described by combinations of the
individual components, highlighting the importance of inter-species scattering.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [37] [LyαNNA II: Field-level inference with noisy Lyα forest spectra](https://arxiv.org/abs/2510.19899)
*Parth Nayak,Michael Walther,Daniel Gruen*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Deep learning (DL) has been shown to outperform traditional, human-defined
summary statistics of the Ly{\alpha} forest in constraining key astrophysical
and cosmological parameters owing to its ability to tap into the realm of
non-Gaussian information. An understanding of the impact of nuisance effects
such as noise on such field-level frameworks, however, still remains elusive.
In this work we conduct a systematic investigation into the efficacy of DL
inference from noisy Ly{\alpha} forest spectra. Building upon our previous,
proof-of-concept framework (Nayak et al. 2024) for pure spectra, we constructed
and trained a ResNet neural network using labeled mock data from hydrodynamical
simulations with a range of noise levels to optimally compress noisy spectra
into a novel summary statistic that is exclusively sensitive to the power-law
temperature-density relation of the intergalactic medium. We fit a Gaussian
mixture surrogate with 23 components through our labels and summaries to
estimate the joint data-parameter distribution for likelihood free inference,
in addition to performing inference with a Gaussian likelihood. The posterior
contours in the two cases agree well with each other. We compared the precision
and accuracy of our posterior constraints with a combination of two human
defined summaries (the 1D power spectrum and PDF of the Ly{\alpha}
transmission) that have been corrected for noise, over a wide range of
continuum-to-noise ratios (CNR) in the likelihood case. We found a gain in
precision in terms of posterior contour area with our pipeline over the said
combination of 65% (at a CNR of 20 per 6 km/s) to 112% (at 200 per 6 km/s).
While the improvement in posterior precision is not as large as in the
noiseless case, these results indicate that DL still remains a powerful tool
for inference even with noisy, real-world datasets.

</details>


### [38] [On-sky Demonstration of Subdiffraction-limited Astronomical Measurement Using a Photonic Lantern](https://arxiv.org/abs/2510.19911)
*Yoo Jung Kim,Michael P. Fitzgerald,Sébastien Vievard,Jonathan Lin,Yinzi Xin,Miles Lucas,Olivier Guyon,Julien Lozi,Vincent Deo,Elsa Huby,Sylvestre Lacour,Manon Lallement,Rodrigo Amezcua-Correa,Sergio Leon-Saval,Barnaby Norris,Mathias Nowak,Steph Sallum,Jehanne Sarrazin,Adam Taras,Stephanos Yerolatsitis,Nemanja Jovanovic*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Resolving fine details of astronomical objects provides critical insights
into their underlying physical processes. This drives in part the desire to
construct ever-larger telescopes and interferometer arrays and to observe at
shorter wavelength to lower the diffraction limit of angular resolution.
Alternatively, one can aim to overcome the diffraction limit by extracting more
information from a single telescope's aperture. A promising way to do this is
spatial mode-based imaging, which projects focal-plane field onto a set of
spatial modes before detection, retaining focal-plane phase information crucial
at small angular scales but typically lost in intensity imaging. However, the
practical implementation of mode-based imaging in astronomy from the ground has
been challenged by atmospheric turbulence. Here, we present the first on-sky
demonstration of a subdiffraction-limited, mode-based measurement using a
photonic lantern (PL)-fed spectrometer installed on the SCExAO instrument at
the Subaru Telescope. We introduce a novel calibration strategy that mitigates
time-varying wavefront error and misalignment effects, leveraging
simultaneously recorded focal-plane images and using a spectral-differential
technique that self-calibrates the data. Observing the classical Be star
$\beta$ CMi, we detected spectral-differential spatial signals and
reconstructed images of its H$\alpha$-emitting disk. We achieved an
unprecedented H$\alpha$ photocenter precision of 50$\mu$as in about 10-minute
observation with a single telescope, measuring the disk's near-far side
asymmetry for the first time. This work demonstrates the high precision,
efficiency, and practicality of photonic mode-based imaging techniques to
recover subdiffraction-limited information, opening new avenues for high
angular resolution spectroscopic studies in astronomy.

</details>


### [39] [Living on the edge: Testing for compact population features at the edges of parameter space](https://arxiv.org/abs/2510.20010)
*Asad Hussain,Maximiliano Isi,Aaron Zimmerman*

Main category: astro-ph.IM

TL;DR: Proposes a truncated Gaussian mixture model to address boundary bias in astrophysical population studies, demonstrated on gravitational wave catalogs for accurate and efficient inference of edge-dominated features like zero-spin black hole systems.


<details>
  <summary>Details</summary>
Motivation: Existing methods (Monte Carlo, kernel density, machine learning) suffer from boundary biases (sparse sampling, kernel smoothing, transformation artifacts) when analyzing bounded parameters (e.g., black hole spins [0,1]), necessitating a better approach for detecting clustered distributions near boundaries.

Method: Introduces a truncated Gaussian mixture model framework that mitigates boundary biases, designed for parameters on bounded domains. Applied to gravitational wave catalogs (GWTC-3) to analyze zero-spin binary black holes, showing comparable results to previous analyses at lower computational cost.

Result: Achieves agreement with published GWTC-3 zero-spin fraction results but with significantly reduced computational resources compared to prior reanalysis methods. Demonstrates accurate inference of narrow edge-dominated features without boundary artifacts.

Conclusion: The method provides a computationally efficient and accurate tool for population studies involving bounded parameters, applicable beyond gravitational waves to other astrophysical problems with boundary-anchored distributions.

Abstract: Many astrophysical population studies involve parameters that exist on a
bounded domain, such as the dimensionless spins of black holes or the
eccentricities of planetary orbits, both of which are confined to $[0, 1]$. In
such scenarios, we often wish to test for distributions clustered near a
boundary, e.g., vanishing spin or orbital eccentricity. Conventional approaches
-- whether based on Monte Carlo, kernel density estimators, or machine-learning
techniques -- often suffer biases at the boundaries. These biases stem from
sparse sampling near the edge, kernel-related smoothing, or artifacts
introduced by domain transformations. We introduce a truncated Gaussian mixture
model framework that substantially mitigates these issues, enabling accurate
inference of narrow, edge-dominated population features. While our method has
broad applications to many astronomical domains, we consider gravitational wave
catalogs as a concrete example to demonstrate its power. In particular, we
maintain agreement with published constraints on the fraction of zero-spin
binary black hole systems in the GWTC-3 catalog -- results originally derived
at much higher computational cost through dedicated reanalysis of individual
events in the catalog. Our method can achieve similarly reliable results with a
much lower computational cost. The method is publicly available in the
open-source packages gravpop and truncatedgaussianmixtures.

</details>


### [40] [Performance analysis of a Hadamard Transform Spectral Imaging system](https://arxiv.org/abs/2510.20195)
*John Nijim,Zoran Ninkov,Dmitry Vorobiev,Kevin Kearney*

Main category: astro-ph.IM

TL;DR: Hadamard Transform Spectral Imaging (HTSI) improves signal-to-noise (SNR) ratios in low photon flux scenarios with signal-independent noise by using multi-slit masks and inverse Hadamard matrix decoding. It outperforms single-slit scanning for emission lines under high read noise conditions.


<details>
  <summary>Details</summary>
Motivation: To evaluate HTSI's performance compared to direct measurement methods like single-slit scanning, identifying scenarios where HTSI offers advantages in SNR under different noise conditions.

Method: The paper analyzes HTSI's decoding process using inverse Hadamard matrix multiplication to recover spectra from multi-slit masks. It compares HTSI's output with single-slit scanning under varying noise conditions (signal-independent vs. signal-dependent).

Result: HTSI increases average SNR when signal-independent noise (e.g., detector read noise) is dominant but has no net effect under pure signal-dependent noise (Poisson photon noise). Emission line SNR is consistently higher with HTSI than single-slit scanning, especially as read-to-shot noise ratio increases.

Conclusion: HTSI is advantageous in low-light environments with significant read noise, improving SNR for emission lines. Its effectiveness depends on noise type, making it ideal for scenarios where signal-independent noise dominates.

Abstract: Hadamard Transform Spectral Imaging (HTSI) is a multiplexing technique used
to recover spectra via encoding with multi-slit masks, and is particularly
useful in low photon flux applications where signal-independent noise is the
dominant noise source. This work focuses on the procedure that is used to
recover spectra encoded with multi-slit masks generated from a Hadamard matrix;
the decoding process involves multiplying the output encoded spectral images by
the inverse of the Hadamard matrix, which separates any spectra that were
overlapping in the target object. The output from HTSI is compared to direct
measurement methods, such as single-slit scanning, to evaluate its performance
and identify under which conditions it can provide an advantage or
disadvantage. HTSI resulted in an increase in the average signal-to-noise (SNR)
ratio of spectra when signal-independent noise, such as detector read noise, is
present, and has no average net effect when signal dependent-noise, such as
Poisson photon noise, is the only noise source present. The SNR of emission
lines was found to be greater with HTSI than with single-slit scanning under
both signal-independent and signal-dependent noise, and increases as the ratio
of read-to-shot noise increases.

</details>


### [41] [Satellite Underflight Utility for Thermal Sensor Harmonization](https://arxiv.org/abs/2510.20248)
*Sarah E. Kay,Brian N. Wenny*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Underflight maneuvers provide a unique opportunity to harmonize calibration
of on-orbit sensors. Due to their similar sensor technologies, their
near-identical transmission profiles, orbital properties and platform
operations, the underflight data of Landsat 8 and 9 instruments stand out as a
qualifier to test proposed metrics, methods, and the extent over which to
compare two independently calibrated sensors across their similar operating
bandpasses. This study performed a pixel-to-pixel comparison of thermal imagery
of TIRS and TIRS-2 (aboard Landsat 8 and 9, respectively) during their five-day
underflight maneuver in November 2021, with the ultimate goal of identifying
the key site/scene-selection criteria for a subset of images that are suitable
for radiative calibration validation purposes. If a group of
near-coincidentally observed images by two identical underflying sensors fail
to show consistent Top-of-Atmosphere (TOA) Brightness Temperatures for the same
exact geographical locations, then the scenes with those shared properties
and/or observing conditions will prove unreliable for cross calibration
validation of less-similar underflying sensor pairs. This study demonstrates
that near-coincidental images with Root Mean Square Deviations (RMSDs) of less
than 5\% between their TOA radiances are optimum candidates for
cross-validation of radiative calibration between two independently calibrated
sensors. This criterion is shown to be reliable for coincidental acquisitions
with a wide range of overlapping area, terrain type, land-to-water fraction and
cloud coverage. Important considerations include any time gap between
near-coincident acquisitions as well as the application of pixel quality masks.
The analysis of the selected underflight scenes demonstrated an agreement
between the TIRS on Landsat 8 and 9 to within 0.123 K and 0.066 K for the
10.9um and 12.0um bands respectively.

</details>


### [42] [Capability of using the normalizing flows for extraction rare gamma events in the TAIGA experiment](https://arxiv.org/abs/2510.20334)
*A. P. Kryukov,A. Yu. Razumov,A. P. Demichev,J. J. Dubenskaya,E. O. Gres,S. P. Polyakov,E. B. Postnikov,P. A. Volchugov,D. P. Zhurov*

Main category: astro-ph.IM

TL;DR: Develop a deep learning and normalizing flows-based method for detecting rare gamma quanta amidst charged particle backgrounds, tested on TAIGA-IACT data with room for improvement.


<details>
  <summary>Details</summary>
Motivation: Detect rare gamma rays from cosmic sources amidst dominant charged particle noise, leveraging advanced anomaly detection techniques.

Method: Using deep learning combined with normalizing flows to differentiate gamma quanta from charged particle backgrounds, tested on simulated TAIGA-IACT experiment data.

Result: The method showed potential but quantitative performance metrics remain below existing approaches.

Conclusion: Proposed enhancements to improve the method's implementation and performance.

Abstract: The objective of this work is to develop a method for detecting rare gamma
quanta against the background of charged particles in the fluxes from sources
in the Universe with the help of the deep learning and normalizing flows based
method designed for anomaly detection. It is shown that the suggested method
has a potential for the gamma detection. The method was tested on model data
from the TAIGA-IACT experiment. The obtained quantitative performance
indicators are still inferior to other approaches, and therefore possible ways
to improve the implementation of the method are proposed.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [43] [On the Evolution of Disk-Embedded Binaries: Framing Local Models in Global Context](https://arxiv.org/abs/2510.19925)
*Philip Kirkeberg,Rixin Li,Martin E. Pessah*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The disks of Active Galactic Nuclei (AGN) have in recent years been
recognized as possible sites for gravitational wave sources, leading to a
series of numerical studies on the evolution of disk-embedded black hole
binaries. The majority of these works have been carried out so far using the
shearing box, a local Cartesian domain co-rotating with the binary
center-of-mass around the supermassive black hole. The local nature of this
framework allows for focusing computational power close to the binary at the
expense of detaching the gas flow around the binary from the global dynamics.
In this paper, we provide a framework to assess the applicability of the
shearing box for studying the long-term evolution of the orbital elements of
the embedded binary in viscous hydrodynamic disks. We accomplish this by
identifying the conditions under which relevant global timescales are longer
than the gas-induced evolution timescale of the embedded binary across various
AGN disk models. For black hole masses of interest, we report the existence of
radii beyond which the global influence of the disk may be reasonably
neglected, supporting the use of the shearing box. More generally, we introduce
a systematic approach to link local simulations with the global problem they
aim to approximate while providing a way to gauge their accuracy. This will
prove to be essential as we seek to add additional physics, such as magnetic
fields and radiative transport, to develop more realistic models for black hole
binary mergers and their potential electromagnetic signatures in AGN disks.

</details>


### [44] [Impact of the nuclear equation of state on the explodability of massive stars](https://arxiv.org/abs/2510.20076)
*Jade Powell,Bernhard Müller*

Main category: astro-ph.HE

TL;DR: The study uses 45 2D simulations with three nuclear EoS models constrained by astrophysical observations to show that the EoS significantly impacts core-collapse supernova outcomes. Explosions are common with SFHo/SFHx EoS but rare with the CMF EoS (which includes quark matter), highlighting EoS uncertainties and the need for better understanding to predict supernova explodability.


<details>
  <summary>Details</summary>
Motivation: To assess how uncertainties in the nuclear equation of state affect the feasibility of core-collapse supernova explosions, given recent observational constraints on EoS properties.

Method: Conducted 45 two-dimensional simulations using three EoS models (SFHo, SFHx, CMF) adhering to observational constraints. Analyzed explosion success rates, neutrino luminosities, and proto-neutron star behavior across progenitors.

Result: Explosions succeeded in most cases for SFHo/SFHx EoS, but only 2/15 for CMF. CMF led to lower neutrino luminosities/energies and weaker proto-neutron star contraction, hindering explosions.

Conclusion: Current EoS knowledge is insufficient to predict supernova explodability from first principles. Observational data on explosion success could help refine the nuclear equation of state.

Abstract: In recent years, astrophysical observations have placed tight constraints on
key properties of the nuclear equation of state (EoS). Using 45 two-dimensional
simulations for three different EoS compatible with the current tight
constraints, we show that the EoS remains a major uncertainty for the outcome
of core-collapse supernovae. Whereas explosions are obtained in most cases for
the SFHo and SFHx EoS, for the CMF EoS, which includes a crossover from
nucleonic matter to a quark phase, explosions occur only for 2 out of 15
progenitors. Less favourable conditions for neutrino-driven explosions arise
for the CMF EoS due to lower neutrino luminosities and mean energies and
slightly weaker contraction of the warm proto-neutron star. Our results suggest
that the explodability of massive stars cannot yet be predicted based on first
principles without better knowledge of the nuclear EoS. Conversely,
observational constraints on stellar explodability may help further constrain
the EoS.

</details>


### [45] [XRISM/Resolve Spectroscopy of the Central Engine in the Seyfert-1 AGN Mrk 279](https://arxiv.org/abs/2510.20083)
*Jon M. Miller,Xin Xiang,Doyee Byun,Ehud Behar,Laura Brenneman,Edward Cackett,Elisa Costantini,Luigi Gallo,Keith Horne,Elias Kammoun,Chen Li,Abderahmen Zoghbi*

Main category: astro-ph.HE

TL;DR: The first XRISM/Resolve spectrum of Mrk 279 reveals velocity components in the Fe Kα line associated with the molecular torus, broad line region, and inner accretion disk. Evidence of low-velocity, highly ionized gas (Fe XXVI) is confirmed, while potential ultra-fast outflows (UFOs) at ~0.22c and ~0.33c show modest support. Further observations are needed to confirm fast X-ray winds.


<details>
  <summary>Details</summary>
Motivation: To investigate the central engine of active galactic nuclei (AGN) through high-resolution X-ray spectroscopy, specifically analyzing the complex line profiles and variability in Mrk 279 to understand black hole accretion and feedback mechanisms.

Method: Analysis of the first XRISM/Resolve spectrum of the Seyfert-1 galaxy Mrk 279, decomposing the Fe Kα emission line into components corresponding to different regions (molecular torus, BLR, inner accretion disk). Fitting models included potential ultra-fast outflows (UFOs) represented by shifted Fe lines.

Result: Identified velocity components linked to the molecular torus, BLR, and inner accretion disk. Confirmed low-velocity, highly ionized Fe XXVI emission. Modest statistical support for UFOs via shifted Fe lines at ~0.22c and ~0.33c (reducing AIC by ~3.5 each). No slow winds detected in absorption.

Conclusion: XRISM provides critical insights into AGN structure, highlighting the need for further observations to confirm UFO presence. Results contribute to understanding AGN feedback and the geometry of accretion processes.

Abstract: High-resolution X-ray spectroscopy with XRISM gives an unprecedented view of
the ``central engine'' in active galactic nuclei, providing unique insights
into black hole accretion and feedback. We present an analysis of the first
XRISM/Resolve spectrum of the Seyfert-1 galaxy Mrk 279, known for its complex
line profiles and variability. The data reveal velocity components within the
Fe K$_{\alpha}$ emission line that can be associated with the inner face of the
molecular torus ($r \geq 10^{4}~GM/c^{2})$, the broad line region (BLR; $r =
1650^{+5780}_{-1480}~GM/c^{2}$), and the inner accretion disk ($r =
81^{+280}_{-75}~GM/c^{2}$). We find evidence of low-velocity, highly ionized
gas that contributes an H-like Fe XXVI emission line at 6.97 keV, confirming
suggestions from prior low-resolution spectra. The data do not show slow winds
in absorption, but two pairs of lines - consistent with He-like and H-like Fe
shifted by $v\simeq 0.22c$ and $v\simeq 0.33c$ - improve the fit, and could
represent an ultra-fast outflow (UFO). Their addition to the model only reduces
the Akaike Information Criterion by 3.6 and 3.5, respectively, signaling modest
support. Additional observations are needed to definitively test for the
presence of fast X-ray winds in Mrk 279. We discuss these results in the
context of the geometry of the central engine in AGN, emerging trends in XRISM
studies of AGN, and the nature of the potential UFOs.

</details>


### [46] [Detection of ultra-high-energy cosmic rays in the southern hemisphere with FAST: data acquisition and preliminary results](https://arxiv.org/abs/2510.20522)
*Jakub Kmec,Petr Boril,Fraser Bradfield,Karel Cerny,Ladislav Chytka,Toshihiro Fujii,Pavel Horvath,Miroslav Hrabovsky,Vlastimil Jilek,Jiri Kvita,Max Malacari,Massimo Mastrodicasa,John N. Matthews,Stanislav Michal,Marcus Niechciol,Libor Nozka,Miroslav Palatka,Miroslav Pech,Paolo Privitera,Francesco Salamida,Shunsuke Sakurai,Petr Schovanek,Radomir Smida,Zuzana Svozilikova,Haruka Tachibana,Akimichi Taketa,Stan B. Thomas,Petr Travnicek,Martin Vacula,Jiri Zahora,Dusan Mandat,Petr Hamal*

Main category: astro-ph.HE

TL;DR: This paper proposes two new triggering algorithms for the FAST experiment's fluorescence telescopes to enable autonomous detection of ultra-high-energy cosmic rays, validated via simulations and sensitivity analysis.


<details>
  <summary>Details</summary>
Motivation: To achieve autonomous operation of the FAST telescopes, which are cost-effective and remotely operated in both hemispheres, requires an efficient trigger system to detect rare UHECR events.

Method: Two novel triggering algorithms, inspired by existing observatory methods but adapted for FAST's design, were developed and tested using Monte Carlo simulations of air showers and real UHECR data from the southern hemisphere.

Result: The algorithms demonstrated effective performance in simulations, and the sensitivity analysis confirms FAST's capability in detecting UHECRs at energies above 30 EeV.

Conclusion: The proposed triggers enable autonomous FAST operations, advancing its role in studying UHECR mysteries with improved sensitivity and cost efficiency.

Abstract: Ultra-high-energy cosmic rays (UHECRs) remain one of the greatest mysteries
in astroparticle physics. The Fluorescence detector Array of Single-pixel
Telescopes (FAST) is a next-generation cosmic ray experiment which utilizes
ground-based fluorescence telescopes designed to detect these extremely rare
particles at energies exceeding 30 EeV. FAST offers a cost-effective and
low-maintenance solution to cover the huge detection areas required for UHECR
observation. FAST telescopes are currently installed and remotely operated in
both hemispheres, at the Pierre Auger Observatory and the Telescope Array
experiment. To enable fully autonomous operation, a sophisticated trigger for
data acquisition is essential. In this paper, we present two novel triggering
algorithms inspired by those used at the largest observatories, but improved to
meet the specific requirements imposed by the FAST design. Their performance is
validated using Monte Carlo simulations of extensive air showers and UHECR
events detected by the FAST telescope in the southern hemisphere. Finally, we
present the sensitivity analysis estimate for FAST.

</details>


### [47] [Non-conservative Mass Transfer in the Neutron Star Stripping Model](https://arxiv.org/abs/2510.20545)
*Nikita Kramarev,Andrey Yudin*

Main category: astro-ph.HE

TL;DR: The paper proposes a model where non-conservative mass transfer in a neutron star binary leads to a stable mass transfer phase lasting up to seconds, explaining the 1.7s delay between GW170817 and GRB170817A, and the light curve features of the gamma-ray burst.


<details>
  <summary>Details</summary>
Motivation: To explain the observed time delay between gravitational waves and gamma-ray bursts in GW170817-GRB170817A and account for the light curve anomalies in the gamma-ray burst using neutron star binary mass transfer dynamics.

Method: Simulations of mass transfer in asymmetric neutron star binaries incorporating non-conservative mass loss, tracking system evolution until mass transfer destabilizes and the low-mass star explodes.

Result: Non-conservative mass transfer extends stable phase duration from milliseconds to seconds, naturally explaining the 1.7s delay. The interaction between explosion ejecta and earlier mass loss explains GRB's双波峰现象 (Note: original text mentions 'two episodes' which was translated as 双波峰 in Chinese).

Conclusion: Non-conservative mass transfer mechanisms are critical for modeling binary neutron star mergers, providing a physical basis for observed multimessenger phenomena like GW170817/GRB170817A.

Abstract: The process of long-term stable mass transfer (or stripping) in a close
neutron star binary system is possible at a sufficiently large initial
asymmetry of the component masses. At the final stage of the evolution of such
systems, the low-mass neutron star fills its Roche lobe, whereupon its mass is
gradually transferred to the more massive component. At a certain point, the
stability of the mass transfer is lost, causing the minimum-mass neutron star
to explode. In the present stripping calculations, the effect of
non-conservative mass transfer has been taken into account for the first time,
resulting in an increase in the duration of stable mass transfer from a few
tenths of a second to a few seconds. This allows the time delay of 1.7 s
between the loss of the gravitational-wave signal and the detection of the
gamma-ray burst from the multimessenger event GW170817-GRB170817A to be
naturally explained. The interaction of the envelope of the exploded
minimum-mass neutron star with the matter ejected during non-conservative mass
transfer may explain two episodes in the light curve of this gamma-ray burst.

</details>


### [48] [Magnetic Field-Line Curvature and Its Role in Particle Acceleration by Magnetically Dominated Turbulence](https://arxiv.org/abs/2510.20628)
*Samuel Sebastian,Luca Comisso*

Main category: astro-ph.HE

TL;DR: The study finds that curvature-drift acceleration is a key mechanism by which magnetized turbulence accelerates particles in astrophysical plasmas, particularly when the fluctuating magnetic field dominates over the mean field. Simulations show curvature probability distributions with power-law tails linked to particle energization.


<details>
  <summary>Details</summary>
Motivation: To understand how magnetic field-line curvature in turbulent plasmas contributes to particle acceleration through curvature-drift motion in the presence of motional electric fields, especially under varying magnetic field conditions.

Method: First-principles fully kinetic particle-in-cell (PIC) simulations were used, varying the δB₀/B₀ ratio to analyze curvature statistics and acceleration mechanisms. Guiding-center analysis was applied to assess curvature-drift contributions compared to other drifts.

Result: Curvature probability densities displayed power-law wings; high-κ tails hardened with increasing δB₀/B₀, while stronger mean fields suppressed large curvatures. The vE·κ distribution followed a Pareto distribution, indicating stochastic energy exchange. Curvature-drift acceleration dominated over other mechanisms in magnetized regimes.

Conclusion: Curvature-drift acceleration is a primary pathway for energy transfer from magnetized turbulence to nonthermal particles in astrophysical environments, especially when fluctuating fields are significant.

Abstract: We employ first-principles, fully kinetic particle-in-cell simulations to
investigate magnetic field-line curvature in magnetically dominated turbulent
plasmas and its role in particle acceleration through curvature-drift motion
along the motional electric field. By varying the fluctuation-to-mean
magnetic-field ratio $\delta B_0/B_0$, we examine curvature $\kappa$ statistics
and their connection to particle acceleration. The curvature probability
densities display broad power-law wings, scaling linearly in $\kappa$ below the
peak and developing hard high-$\kappa$ tails for $\delta B_0/B_0 \gtrsim 1$. As
the mean field strengthens, the high-$\kappa$ tails steepen, and
large-curvature events are suppressed when $\delta B_0/B_0 \ll 1$. The
probability density functions of magnetic field-line contraction, ${\bf v}_E
\cdot {\bf \kappa}$, with ${\bf v}_E$ the field-line velocity, develop
power-law tails well described by a symmetric Pareto distribution,
characteristic of stochastic energy exchanges, with the tails becoming harder
as $\delta B_0/B_0$ increases. Our guiding-center analysis shows that
curvature-drift acceleration accounts for a substantial fraction of the
energization via the motional electric field, and that it strengthens with
increasing $\delta B_0/B_0$. For well-magnetized particles, curvature-drift
acceleration typically exceeds ${\bf\nabla}B$ drift, polarization drift, and
betatron contributions. These results identify curvature-drift acceleration as
a principal pathway through which magnetized turbulence transfers energy to
nonthermal particles in astrophysical plasmas.

</details>


### [49] [Search for neutrino emission from LHAASO observed Microquasar with IceCube 10-year data](https://arxiv.org/abs/2510.20687)
*Rong-Lan Li,Hao-Ning He,Da-Ming Wei*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Large High Altitude Air Shower Observatory (LHAASO) has detected
ultra-high-energy (UHE; E>100 TeV) gamma-ray emission from five microquasars,
suggesting their potential as Galactic PeV cosmic-ray accelerators. At these
energies, the Klein-Nishima effect strongly suppresses leptonic processes,
making neutrinos observation a crucial test for hadronic acceleration. We
present a search for neutrino emission from these LHAASO-identified
Microquasars using ten years of IceCube muon-track data. No significant
neutrino signal was found in either single-source or stacking analyses. Our
stacking result further shows that the studied microquasars population can only
account for a small fraction of the diffuse neutrino flux along the Galactic
Plane. Finally, we demonstrate that new-generation neutrino telescopes, such as
HUN, will have the sensitivity to probe harmonic emission from these candidate
PeVatrons.

</details>


### [50] [Multi-messenger constraints on LIGO/Virgo/KAGRA gravitational wave binary black holes merging in AGN disks](https://arxiv.org/abs/2510.20767)
*Tomás Cabrera,Antonella Palmese,Maya Fishbach*

Main category: astro-ph.HE

TL;DR: This paper analyzes potential electromagnetic (EM) counterparts to binary black hole (BBH) mergers detected by the LIGO/Virgo/KAGRA (LVK) collaboration, focusing on coincident active galactic nucleus (AGN) flares. Using statistical methods, they find that less than 3% of BBH mergers likely produce observable AGN flares, though up to 40% could form in AGN disks. All detected flare-merger pairings are deemed more probable background events. The results align with theoretical expectations but highlight the need for better methods to distinguish true counterparts from background flares.


<details>
  <summary>Details</summary>
Motivation: The lack of confirmed electromagnetic counterparts for gravitational wave (GW) events from BBH mergers motivated this study. Previous works identified potential AGN flares coinciding with GW events, suggesting they might arise from BBH remnants interacting with accretion disks. The authors aim to statistically assess the significance of such coincidences and constrain the fraction of BBH mergers producing observable AGN flares.

Method: The authors applied a statistical framework to evaluate the significance of AGN flare-GW event coincidences. They analyzed transient catalogs to determine the fraction of BBH mergers yielding observable flares (finding <3% at 90% confidence). They also assessed individual flare-merger pairs, concluding that background flares were more likely explanations. Comparisons were made with theoretical models predicting counterpart observability in AGN disks and demographics of BBH formation sites.

Result: Statistical analysis shows <3% of BBH mergers produce detectable AGN flares (90% credible interval), but up to ~40% might form in AGN disks. No flare-merger pairing showed significant association, with all flares attributed to background activity. Results align with theories that massive AGNs (in study) host few BBHs, and counterpart detectability is limited by observational constraints.

Conclusion: The study confirms that AGN disks may host a minority of BBH mergers, with most observable counterparts undetectable due to environmental or observational limitations. It underscores the necessity for improved techniques to differentiate true counterparts from background flares and better targeting of follow-up observations. Future efforts should focus on understanding which BBH systems are most likely to produce detectable EM signatures in AGN environments.

Abstract: While the LIGO/Virgo/KAGRA (LVK) gravitational wave (GW) detectors have
detected over 300 binary black hole (BBH) mergers to date, the first
confirmation of an electromagnetic (EM) counterpart to such an event remains
elusive. Previous works have performed searches for counterpart candidates in
transient catalogs and have identified active galactic nuclei (AGN) flares
coincident with GW events; existing theory predicts that such flares may arise
from the interaction of the merger remnant with the embedding accretion disk
environment. We apply a statistical formalism to measure the significance of
coincidence for the catalog as a whole, measuring that less than 3\% (90\%
credible interval) of LVK BBH mergers give rise to observable AGN flares. This
result still allows up to $\sim 40\%$ of BBH mergers to originate in AGN disks.
We also examine the individual coincidences of each merger/flare pairing,
determining that in all cases the flares are more likely to belong to a
background population of flares not associated with GW events. Our results are
consistent with theoretical predictions accounting for the observability of EM
counterparts in AGN disks, as well as based on the fact that the most massive
AGNs (such as those included in the search) are not expected to harbor the
majority of the BBHs. We emphasize that developing both the means to
distinguish BBH counterpart flares from background AGN flares and an
understanding of which BBHs are most likely to produce AGN flares as
counterparts is critical to optimize the use of follow-up resources.

</details>


### [51] [The Opacity Project: R-Matrix Calculations for Opacities of High-Energy-Density Astrophysical and Laboratory Plasmas](https://arxiv.org/abs/2510.20775)
*Anil K. Pradhan,Sultana N. Nahar*

Main category: astro-ph.HE

TL;DR: The study investigates Rosseland Mean Opacities (RMO) in high-energy-density plasmas of solar and inertial confinement fusion environments using R-Matrix atomic data. It focuses on electron collisional and Stark effects on autoionizing resonances, and evaluates EOS impacts on opacity models to address discrepancies in theoretical vs. experimental data.


<details>
  <summary>Details</summary>
Motivation: To address the solar opacity problem and discrepancies between theoretical opacity calculations and experimental measurements in HED plasmas, and to improve EOS models' accuracy in astrophysical and fusion contexts.

Method: Calculations of Rosseland Mean Opacities using R-Matrix atomic data, analysis of electron collisional/Stark broadening effects on autoionizing resonances, and comparison of Mihalas-Hummer-Dappen EOS with level populations from R-matrix computations.

Result: Demonstrated impacts of microfield broadening effects on photoabsorption cross sections and RMO variations under specified plasma conditions. Highlighted EOS effects on opacity, contributing to resolving theoretical-experimental discrepancies.

Conclusion: Enhanced understanding of opacity modeling in HED plasmas, with implications for improving astrophysical models (e.g., solar interior) and inertial confinement fusion experiments through refined EOS and opacity treatments.

Abstract: Accurate determination of opacity is critical for understanding radiation
transport in both astrophysical and laboratory plasmas. We employ atomic data
from R-Matrix calculations to investigate radiative properties in
high-energy-density (HED) plasma sources. Specifically, we analyze environments
such as the base of the convective zone (BCZ) of the Sun 2 x 10^6$ K, N_e =
10^{23}/cc and the inertial confinement fusion (ICF) device at the Sandia Z
facility 2.11 x 10^6 K, N_e = 3.16 x 10^{22}/cc. We calculate Rosseland Mean
Opacities (RMO) within a range of temperatures and densities and analyze how
they vary under different plasma conditions. In this study, we specifically
focus on electron collisional and Stark ion microfield broadening effects on
autoionizing resonances in photoabsorption cross sections. Our results are
relevant to astrophysical models, particularly in the context of the solar
opacity problem, and provide insights into discrepancies between theoretical
calculations and experimental measurements. In addition, we investigate the
equation-of-state (EOS) and its impact on opacities. In addition, we examine
the equation-of-state (EOS) and its impact on opacities of the "chemical
picture" Mihalas-Hummer-Dappen EOS with respect to level populations of excited
levels included in the R-matrix calculations. This study should contribute to
improving opacity models of HED sources such as stellar interiors adn
laboratory fusion plasma experiments.

</details>


### [52] [A Microphysical Probe of Neutron Star Interiors: Constraining the Equation of State with Glitch Dynamics](https://arxiv.org/abs/2510.20791)
*Zhonghao Tu,Ang Li*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Glitches in neutron stars originate from the sudden transfer of angular
momentum between superfluid components and the observable crust. By modeling
this glitch dynamics, including vortex motion, mutual friction, and angular
momentum exchange, we can probe the dense matter equation of state. We match
theoretical predictions of glitch rise times, overshoot patterns, and
relaxation timescales to the well-documented observations of the 2016 Vela
glitch. Our model incorporates microphysical parameters such as the mutual
friction coefficient $\mathcal{B}$, which in the core arises from electron
scattering off magnetized vortices, and in the crust from Kelvin wave
excitation during vortex-lattice interactions. Our Markov Chain Monte Carlo
analysis of the timing residuals reveals detailed glitch dynamics: the crustal
superfluid couples on timescales of $\sim100$ seconds, the core exhibits
overshoot behavior due to strong central behavior, and the inner crust shows
weak entrainment, with $\sim70\%$ of free neutrons remaining superfluid. The
modeled rise times are consistent with the observed upper limit of 12.6
seconds, and the observed overshoot requires strong crustal friction but weak
core friction, supporting a spatially varying $\mathcal{B}$.These findings
highlight the importance of microphysical modeling and demonstrate the
potential of future high-cadence timing observations to further constrain the
internal dynamics and composition of neutron stars.

</details>


### [53] [Simulation-calibrated Bayesian inference for progenitor properties of the microquasar SS 433](https://arxiv.org/abs/2510.20811)
*Nathan Steinle,Matthew Mould,Sarah Al-Humaikani,Austin MacMaster,Brydyn Mac Intyre,Samar Safi-Harb*

Main category: astro-ph.HE

TL;DR: The paper uses Bayesian inference with the COSMIC model and dynesty sampler to determine the progenitor properties of SS 433, identifying ZAMS parameters like primary mass (8-11 solar masses), secondary mass (32-40 solar masses), and constraints on orbital characteristics, common envelope efficiency, and natal kick velocities. This provides new insights into high-accretion systems.


<details>
  <summary>Details</summary>
Motivation: To understand SS 433's progenitor binary system, resolve uncertainties in its evolutionary history, and quantify how specific binary parameters lead to its extreme characteristics like relativistic jets and super-critical accretion.

Method: Applied simulation-based calibration to Bayesian inference, combining observed binary parameters with the COSMIC evolution model. Used dynesty for posterior sampling over a 10D progenitor space, incorporating ML algorithms for reliability metrics.

Result: Identified 90% confidence intervals for progenitor ZAMS properties including masses, orbital parameters, CE efficiency, accretion fractions, and kick velocities. Revealed parameter regions critical for SS 433-like system formation under different assumptions.

Conclusion: Demonstrated the viability of probabilistic progenitor inference for X-ray binaries, offering a framework to study high-accretion systems and refine binary evolution models through statistical methods.

Abstract: SS\,433 is one of the most extreme Galactic X-ray binaries, exhibiting
semi-relativistic jets and super-critical accretion, and harboring a compact
object, likely a black hole. Despite decades of observation and modeling, the
precise nature of its progenitor binary remains uncertain. To estimate the
zero-age main sequence (ZAMS) properties of binaries that evolve into
SS\,433-like systems, we apply simulation-based calibration to Bayesian
inference and convolve a multivariate Gaussian likelihood constructed from six
measured binary parameters of SS\,433 with the isolated binary evolution model
\textsc{COSMIC}. Employing the dynamic nested sampler of \texttt{dynesty}, we
perform posterior inference over a ten-dimensional progenitor parameter space
defined by the masses, orbital parameters, mass transfer possibilities, and
natal kick velocity. We find that SS\,433-like systems arise from specific
regions of binary evolution parameter space depending on key assumptions, such
as the mass transfer rate and uncertainty taken from observations. Our
simulation-based calibration framework, implemented with a suite of machine
learning algorithms and scored by a heuristic reliability metric, allows us to
iteratively build posterior distributions of the progenitors of SS\,433-like
systems. This analysis reveals 90\% confidence intervals for the ZAMS primary
mass $(8, 11)$ M$_\odot$, secondary mass $(32, 40)$ M$_\odot $, orbital period
$(136, 2259)$ days, eccentricity $(0.26, 0.6)$, common envelope evolution
efficiency $(0.44, 0.76)$, accreted fraction in stable mass transfer $(0.22,
0.6)$, and black hole natal kick velocity magnitude $(5, 68)$ km/s. These
results demonstrate the feasibility of direct probabilistic inference of X-ray
binary progenitors to offer new insights into the evolution of
high-accretion-rate systems such as SS\,433.

</details>
