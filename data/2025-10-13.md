<div id=toc></div>

# Table of Contents

- [astro-ph.HE](#astro-ph.HE) [Total: 11]
- [hep-ph](#hep-ph) [Total: 21]
- [gr-qc](#gr-qc) [Total: 9]
- [astro-ph.IM](#astro-ph.IM) [Total: 5]


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [1] [Identification of Gamma Ray Pulsar Candidates in the \emph{Fermi}-LAT 4FGL-DR4 Unassociated Sources Using Supervised Machine Learning](https://arxiv.org/abs/2510.08654)
*A. Pathania,K. K. Singh,S. K. Singh,A. Tolamatti,B. B. Singh,K. K. Yadav*

Main category: astro-ph.HE

TL;DR: The study uses Random Forest and Extreme Gradient Boosting to classify unassociated gamma-ray sources from the Fermi-LAT 4FGL-DR4 catalog, focusing on identifying new pulsar candidates and assessing the impact of data balancing techniques on classification accuracy.


<details>
  <summary>Details</summary>
Motivation: A significant fraction (~33%) of sources in the 4FGL-DR4 catalog lack lower wavelength counterparts, making their classification critical for understanding population characteristics and guiding multi-wavelength observations to study radiative processes.

Method: The researchers applied two supervised machine learning algorithms (Random Forest and XGBoost) to classify unassociated sources using observational features from 14 years of Fermi-LAT data. They also evaluated the effectiveness of data balancing methods to improve classification performance.

Result: The study identified new gamma-ray pulsar candidates through these machine learning models. The results highlighted the importance of data balancing in enhancing the classification of rare source types within the unassociated population.

Conclusion: Machine learning techniques effectively distinguish between pulsar candidates and other unassociated gamma-ray sources, particularly when using balanced datasets. This work aids in prioritizing targets for multi-wavelength follow-up observations to uncover the nature of these sources.

Abstract: The Large Area Telescope (LAT) on board the \emph{Fermi} Gamma-ray Space
Telescope has been continuously providing good quality
  survey data of the entire sky in the high energy range from 30 MeV to 500 GeV
and above since August 2008. A succession of gamma-ray
  source catalogs is published after a comprehensive analysis of the
\emph{Fermi}--LAT data. The most recent release of data in the
  fourth \emph{Fermi}--LAT catalog of gamma-ray sources (4FGL-DR4), based on
the first 14 years of observations in the energy band
  50 MeV-1 TeV, contains 7195 sources. A large fraction ($\sim$ 33\%) of this
population has no known counterparts in the lower wave
  bands. Such high energy gamma-ray sources are referred to as unassociated or
unidentified. An appropriate classification of these
  objects into known type of gamma-ray sources such as the active galactic
nuclei or pulsars is essential for population studies and
  pointed multi-wavelength observations to probe the radiative processes. In
this work, we perform a detailed classification of the
  unassociated sources reported in the 4FGL-DR4 catalog using two supervised
machine learning techniques-Random Forest and
  Extreme Gradient Boosting. We mainly focus on the identification of new
gamma-ray pulsar candidates by making use of different
  observational features derived from the long-term observations with the
\emph{Fermi}--LAT and reported in the incremental 4FGL-DR4 catalog.
  We also explore the effects of data balancing approach on the classification
of the \emph{Fermi}--LAT unassociated sources.

</details>


### [2] [Neutrino signal from the hadron-quark phase transition in the conversion of Neutron Stars into Quark Stars](https://arxiv.org/abs/2510.08707)
*Yossef Zenati,Conrado Albertus Torres,Joseph Silk,M. Ángeles Pérez-García*

Main category: astro-ph.HE

TL;DR: The study investigates neutrino emission during a neutron star's phase transition to a quark star using 1D GR hydrodynamic simulations, identifying detectable signatures of the phase transition in neutrino light curves.


<details>
  <summary>Details</summary>
Motivation: To understand the observable effects of hadron-quark phase transitions in neutron star collapses, providing diagnostics detectable with current experiments like IceCube and Hyper-K.

Method: 1D General Relativistic hydrodynamic simulations with DD2 and MIT Bag model EOSs, incorporating neutrino emission processes pre and post phase transition, including direct Urca processes, opacity-based leakage, and GR redshift effects.

Result: Neutrino light curves show a short, hard feature at deconfinement (shoulder or secondary peak), with distinct temporal and spectral signatures (R_pp, Δt, Δ⟨E_ν⟩) that remain detectable post-MSW conversion.

Conclusion: Phase transition events can be distinguished from standard CCSNe via neutrino diagnostics, with potential detection by IceCube/Hyper-K for nearby (10 kpc) events.

Abstract: We calculate in a 1D General Relativistic (GR) hydrodynamic simulation the
neutrino luminosity in an astrophysical scenario where a neutron star (NS)
displays a hadron-quark phase transition (HQPT) into a Quark Star (QS).
Deconfinement is triggered once the central density exceeds a critical
threshold above $\sim 3n_0$ being $n_0$, saturation density. We use
descriptions based on DD2 and the MIT Bag model equations of state (EOSs). We
account for neutrinos using a microphysics forward emission model including
$e^-e^+$ annihilation, plasmon decay, nucleon (N) modified (or direct) Urca
processes, and $NN$ bremsstrahlung, and, for the post transition, the quark
direct Urca and an opacity-based leakage scheme with GR redshift. We find that
the neutrino light curve generically develops a short $\simeq$10-50 ms,
spectrally harder feature near deconfinement, appearing as either a prompt
shoulder or a distinct secondary peak. Heavy lepton neutrinos result in a
delayed peak with respect to the previous. We identify three diagnostics that
are only mildly degenerate with hadronic uncertainties: (i) an enhanced
peak-to-plateau ratio $R_{\rm pp}$ sourced by latent-heat release, (ii) a
characteristic lag $\Delta t$ between the collapse rise and the HQPT feature
that tracks the central density trajectory, and (iii) a flavor hardening
$\Delta\!\langle E_\nu\rangle$ driven by quark-matter phase space. After MSW
flavor conversion, these signatures remain detectable with current experiments.
For a Galactic event ($d\sim 10$ kpc), IceCube and Hyper-K should resolve the
HQPT feature and distinguish it from both no transition NS collapse and
canonical core-collapse supernova (CCSN) templates.

</details>


### [3] [Low-Frequency Gravitational Waves in Three-Dimensional Core-Collapse Supernova Models](https://arxiv.org/abs/2510.08764)
*Colter J. Richardson,Anthony Mezzacappa,Kya Schluterman,Haakon Andresen,Eric J. Lentz,Pedro Marronetti,Daniel Murphy,Michele Zanolin*

Main category: astro-ph.HE

TL;DR: The paper analyzes low-frequency gravitational wave signals from three 3D core-collapse supernova models using the Chimera code, focusing on both fluid and neutrino anisotropic emission contributions, and assesses the templatability of these signals for future detection efforts.


<details>
  <summary>Details</summary>
Motivation: To investigate the detailed gravitational wave signals from core-collapse supernovae, particularly the contributions from neutrino anisotropic emission, and to evaluate the potential for template-based detection and parameter estimation in future studies.

Method: Three-dimensional core-collapse supernova models were simulated using the Chimera code. The gravitational wave signals were derived by considering both fluid dynamics and neutrino emission anisotropies. The templatability of low-frequency signals was analyzed for applicability in matched filtering techniques.

Result: The study provides a comprehensive gravitational wave signal combining fluid and neutrino sources. The templatability of low-frequency components was established, offering a foundation for future signal detection and parameter estimation efforts.

Conclusion: The results highlight the importance of including neutrino emission contributions in gravitational wave models and demonstrate the feasibility of creating templates for low-frequency signals, which is critical for enhancing detection capabilities through matched filtering methods.

Abstract: We discuss the low-frequency gravitational wave signals from three
state-of-the-art three-dimensional core-collapse supernova models produced with
the \textsc{Chimera} supernova code. We provide a detailed derivation of the
gravitational wave signal sourced from the anisotropic emission of neutrinos
and provide the total (fluid sourced and neutrino sourced) gravitational waves
signal generated in our models. We discuss the templatablity of this
low-frequency signal, which is useful for future work involving matched
filtering for signal detection and parameter estimation.

</details>


### [4] [Event Horizon Telescope Pattern Speeds in the Visibility Domain](https://arxiv.org/abs/2510.08848)
*Nicholas S. Conroy,Michi Bauböck,Vedant Dhruv,Daeyoung Lee,Chi-kwan Chan,Abhishek V. Joshi,Ben Prather,Charles F. Gammie*

Main category: astro-ph.HE

TL;DR: The paper introduces the visibility amplitude pattern speed (Ω_{VA}) as a method to analyze time-varying black hole images from the Event Horizon Telescope (EHT), showing its dependence on source parameters like inclination, spin, and baseline length. It highlights Ω_{VA}'s sensitivity to baseline length for MAD models and its potential to constrain black hole spin. The technique aligns with theoretical expectations, suggesting it measures wave propagation phase speeds.


<details>
  <summary>Details</summary>
Motivation: To extend the autocorrelation technique to the visibility domain for upcoming EHT time sequences, enabling analysis of rotational motion and constraints on black hole parameters using measurable quantities like Ω_{VA}.

Method: Developed Ω_{VA} in the visibility domain, tested it against the Illinois v3 EHT source models, analyzed dependencies on parameters (inclination, mass, spin, accretion state, baseline length), and provided empirical fits. Comparisons with Keplerian frequencies and wave propagation phase speeds were conducted.

Result: Ω_{VA} shows measurable dependencies on inclination, spin, accretion state, and baseline length, especially sensitive to baseline in MAD models. The slope of this dependence can constrain black hole spin. Ω_{VA} is consistently below Keplerian frequencies, consistent with measuring wave phase speeds. Space-based VLBI (e.g., BHEX) could significantly enhance these analyses.

Conclusion: Ω_{VA} offers a robust tool to study black hole dynamics using EHT data. Combined with future space-based observations, it could improve constraints on black hole properties and validate theoretical models of accretion and magnetohydrodynamics.

Abstract: The Event Horizon Telescope is preparing to produce time sequences of black
hole images, or movies. In anticipation, we developed an autocorrelation
technique to measure apparent rotational motion using the image-domain pattern
speed $\Omega_p$. Here, we extend this technique to the visibility domain and
introduce the visibility amplitude pattern speed $\Omega_{\mathrm{VA}}$. We
show that in the Illinois v3 library of EHT source models,
$\Omega_{\mathrm{VA}}$ depends on the source inclination, black hole mass,
black hole spin, accretion state (MAD or SANE), and baseline length, and then
provide approximate fits for this dependence. We show that
$\Omega_{\mathrm{VA}}$ is particularly sensitive to baseline length for MAD
(strongly magnetized) models, and that the slope of this dependence can be used
to constrain black hole spin. As with $\Omega_p$, models predict that
$\Omega_{\mathrm{VA}}$ is well below the Keplerian frequency in the emission
region for all model parameters. This is consistent with the idea that
$\Omega_{\mathrm{VA}}$ measures an angular phase speed for waves propagating
through the emission region. Finally, we identify the information that would be
provided by space-based millimeter VLBI such as the proposed BHEX mission.

</details>


### [5] [A Sharper View of the X-ray Spectrum of MCG--6-30-15 with XRISM, XMM-Newton and NuSTAR](https://arxiv.org/abs/2510.08926)
*Laura W. Brenneman,Daniel R. Wilkins,Anna Ogorzałek,Daniele Rogantini,Andrew C. Fabian,Javier A. García,Anna Juráňová,Misaki Mizumoto,Hirofumi Noda,Ehud Behar,Rozenn Boissay-Malaquin,Matteo Guainazzi,Takashi Okajima,Erika Hoffman,Noa Keshet,Jelle Kaastra,Erin Kara,Makoto Yamauchi*

Main category: astro-ph.HE

TL;DR: The analysis of XRISM, XMM-Newton, and NuSTAR data of MCG-6-30-15 reveals relativistic Fe Kα emission from an accretion disk corona and an outflowing wind with components at 2300 and 20,000 km/s. It challenges traditional AGN torus models and highlights the need for time-resolved high-resolution spectroscopy due to flux variability.


<details>
  <summary>Details</summary>
Motivation: To study the broadband X-ray spectra of MCG-6-30-15 using high-resolution data to better understand accretion disk reflection, outflows, and the structure of AGN environments, addressing limitations from previous lower-resolution studies.

Method: Joint spectral analysis of simultaneous XRISM/Resolve, XMM-Newton, and NuSTAR observations. Employed a reflection model with ionized absorption components to fit the data, incorporating relativistic effects and multi-zone outflow structures.

Result: Confirmed relativistic Fe Kα line; identified wind components at 2300 km/s and tentative 20,000 km/s. Suggested non-uniform reflection regions instead of a classical torus. Spin results were consistent with rapid prograde but affected by flux variability.

Conclusion: High-resolution, time-resolved spectroscopy is crucial for AGN studies due to variability. The observed wind and reflection properties challenge existing AGN models, necessitating further studies with advanced instrumentation.

Abstract: We present a time-averaged spectral analysis of the 2024 XRISM observation of
the narrow-line Seyfert-1 galaxy MCG--6-30-15, taken contemporaneously with
XMM-Newton and NuSTAR. Our analysis leverages a unique combination of broadband
and high-resolution X-ray spectroscopy to definitively isolate and characterize
both broad and narrow emission and absorption features in this source. The
best-fitting model for the joint spectral analysis is very well described by
reflection from the inner accretion disk illuminated by a compact corona,
modified by multi-zone ionized absorption from an outflowing wind along the
line of sight. The XRISM/Resolve data confirm that a strong,
relativistically-broadened Fe K$\alpha$ emission line is required in order to
obtain an adequate model fit. The Resolve data additionally verify the presence
of a $v_{\rm out} \sim 2300$ km/s component of this outflowing wind, find
tentative evidence for a $v_{\rm out} \sim 20,000$ km/s wind component, and
indicate that the reflection from distant, neutral material may originate in a
non-uniform structure rather than the traditional torus of AGN unification
schemes. Though a rapid prograde black hole spin is statistically preferred by
the best-fitting model, consistent with previous results, the AGN flux
variability over the course of the observation complicates the interpretation
of the time-averaged spectra. This insight, clarified by the combination of
high signal-to-noise and high spectral resolution in the joint dataset,
emphasizes the importance of time-resolved, high-resolution spectral analysis
in unambiguously measuring the physical properties of variable AGN.

</details>


### [6] [A study of 80 known pulsars at 185 MHz using MWA incoherent drift-scan observations](https://arxiv.org/abs/2510.09046)
*Ting Yu,Hongyu Gong,Zhifu Gao,Zhongli Zhang,Zhigang Wen,Yujie Wang,Tao An*

Main category: astro-ph.HE

TL;DR: The paper describes a systematic study of 80 known pulsars observed at 185 MHz using MWA data, detecting 30 pulsars for the first time at this frequency. The study provides new insights into pulsar emission and propagation effects through spectral analysis and highlights the potential of low-frequency surveys like SKA-Low.


<details>
  <summary>Details</summary>
Motivation: The motivation was to expand the census of pulsars at low frequencies (185 MHz) and investigate their properties, addressing gaps in existing data and improving understanding of pulsar emission mechanisms and interstellar effects.

Method: The team used archival MWA incoherent-sum data from 48 drift-scan observations covering 30,000 square degrees. An optimized PRESTO-based pipeline processed the data on China SKA Regional Centre infrastructure to detect pulsars and analyze their spectral, scattering, and pulse-width properties.

Result: Detected 80 known pulsars (60% increase over prior), including 30 first-time detections at 185 MHz. Presented pulse profiles and flux densities for these, revealing insights into low-frequency emission turnovers, scattering effects, and pulsar width-period relations.

Conclusion: The study demonstrates the effectiveness of wide-field low-frequency surveys for pulsar research, underscores importance of MWA's sensitivity, and provides empirical data useful for informing future low-frequency instruments like SKA-Low.

Abstract: A systematic study of 80 known pulsars observed at 185 MHz has been conducted
using archival incoherent-sum data from the Murchison Widefield Array (MWA).
The dataset comprises 48 drift-scan observations from the MWA Voltage Capture
System, covering approximately 30,000 square degrees of sky with sensitivities
reaching about 8 mJy in the deepest regions. An optimized PRESTO-based search
pipeline was deployed on the China SKA Regional Centre infrastructure. This
enabled the detection of 80 known pulsars, representing a 60 percent increase
over the previous census. Notably, this includes 30 pulsars with first-time
detections at this frequency, of which pulse profiles and flux densities are
presented. Spectral, scattering, and pulse-width properties were examined for
the sample, providing observational constraints on low-frequency turnover,
propagation effects, and width-period relations. This study highlights the
value of wide-field, low-frequency time-domain surveys for constraining pulsar
emission and propagation, offering empirical insights that may inform future
observations with instruments such as SKA-Low.

</details>


### [7] [3D Moving-mesh Hydrodynamical Simulations of Wind/Jet Driven Ultraluminous X-ray Source Bubbles](https://arxiv.org/abs/2510.09066)
*Jiahui Huang,Ken Ohsuga,Hua Feng,Hui Li*

Main category: astro-ph.HE

TL;DR: The study uses 3D moving-mesh hydrodynamical simulations with AREPO to model bubble nebulae around ultraluminous X-ray sources (ULXs). They find that bubble morphology is primarily determined by outflow initial momentum, while mechanical power affects bubble size and cooling timescale. Observational comparison supports confined disk outflows in narrow funnels for NGC 55 ULX-1 and NGC 1313 X-2.


<details>
  <summary>Details</summary>
Motivation: To understand how outflow properties (momentum, mechanical power) and geometrical factors (opening angle, viewing angle) shape the observed morphology of ULX bubble nebulae, and to reconcile simulation results with observational data from specific ULX systems.

Method: 3D moving-mesh hydrodynamical simulations using AREPO, with Monte-Carlo injection of outflows having uniform mass/momentum in conical funnels. Parameters varied include outflow momentum, mechanical power, half-opening angle, and viewing angle effects.

Result: Bubble morphology depends on initial momentum, not mechanical power. Mechanical power influences bubble size and cooling timescale (low power → shorter cooling → early shell collapse). Observed eccentricity arises from both outflow opening angle and viewing angle. Simulations align with NGC 55 ULX-1 and NGC 1313 X-2 observations, supporting narrow funnel outflows from accretion disks.

Conclusion: Outflow momentum and geometric confinement are key drivers of ULX nebula morphology. Observational features like eccentricity can be explained by combining outflow funnel structure with line-of-sight perspectives. These findings highlight the importance of high-resolution simulations in interpreting ULX bubble systems.

Abstract: We perform 3 dimensional moving-mesh hydrodynamical simulations of bubble
nebulae around ultraluminous X-ray sources, using state-of-the-art software
AREPO. We use a Monte-Carlo method to inject outflows with uniform mass outflow
rate and momentum, in a conical funnel with a specific half opening angle.
Simulation results show that the morphology of the bubble is determined by the
initial momentum of the outflows, while the mechanical power of the outflows
only influences the size of the bubble without changing its shape. Low
mechanical power also results in a short cooling timescale of the system,
leading to an early collapse of the bubble shell. The half opening angle of the
outflows and the viewing angle of the system determine the observed bubble
eccentricity together. Compared with the observational morphology of the ULX
bubble sources NGC 55 ULX-1 and NGC 1313 X-2, our simulation favors the fact
that the high velocity outflows of the accretion disks in these two systems are
confined in a narrow funnel region.

</details>


### [8] [Sub-Threshold Fermi-LAT Sources in the Vicinity of KM3-230312A](https://arxiv.org/abs/2510.09101)
*Angelina Sherman,Nestor Mirabal,David Guevel,Ke Fang,Kohta Murase,Elizabeth Hays*

Main category: astro-ph.HE

TL;DR: The KM3NeT collaboration detected a 220 PeV ultra-high-energy neutrino, prompting an investigation for correlated gamma-ray signals using Fermi-LAT data. Three sub-threshold gamma-ray sources were found near the neutrino's direction, but their flaring activity and likelihood of being background fluctuations suggest they might not be directly linked to the neutrino.


<details>
  <summary>Details</summary>
Motivation: To determine if the KM3NeT neutrino is accompanied by detectable gamma-rays from cosmic-ray interactions, which would indicate a common astrophysical origin.

Method: Analyzed Fermi-LAT data for transient/sub-threshold gamma-ray sources within 3.5° of the neutrino direction, identifying three sources with TS ~16 not in existing catalogs.

Result: Three sub-threshold sources found; one appeared post-neutrino (microquasar candidate), another near a radio blazar. However, their flaring could be background fluctuations, and similar counts expected elsewhere at same Galactic latitude.

Conclusion: No conclusive evidence linking the gamma-ray sources to the neutrino; observed signals are likely background, suggesting the neutrino’s origin remains elusive.

Abstract: The KM3NeT collaboration has recently reported the detection of an
extraordinary ultra-high-energy neutrino event with an energy of 220 PeV.
Ultrahigh energy neutrinos and gamma-rays are co-produced in ultrahigh energy
cosmic-ray interactions. The ultrahigh energy gamma-rays produced alongside the
KM3NeT neutrino may quickly cascade down to lower energies due to interactions
with intergalactic photons and magnetic fields. Because of this, the KM3NeT
neutrino could be accompanied by an observable GeV - TeV gamma-ray signal. We
investigate the data collected by the Large Area Telescope (LAT) on-board the
\textit{Fermi} Gamma-ray Space Telescope for transient and sub-threshold
gamma-ray sources in the vicinity of the KM3NeT neutrino. We find three
sub-threshold sources with TS $\gtrsim 16$ within $3.5^{\circ}$ of the neutrino
event not included in any existing \textit{Fermi}-LAT catalogs. One of the
three, J0616.1-0428, is a transient sub-threshold gamma-ray source that appears
only after the neutrino observation, but may be the unrelated flaring of a
nearby microquasar. Another sub-threshold source, J0621.1-0610, also exhibits
fluctuations in gamma-rays immediately following the neutrino observation, and
may be coincident with a radio blazar. We note that the number of sub-threshold
sources observed around the KM3NeT neutrino could be expected at another sky
region of the same Galactic latitude, and that the fluctuations they exhibit
appear to be consistent with background.

</details>


### [9] [Light Travel Time Effects in Kilonova Models](https://arxiv.org/abs/2510.09261)
*F. McNeill,S. A. Sim,C. E. Collins,L. J. Shingles,R. Damgaard,A. Sneppen,J. H. Gillanders*

Main category: astro-ph.HE

TL;DR: The paper demonstrates that time-dependent light travel time effects significantly impact the spectral evolution of kilonovae, particularly in the prominent Sr II P Cygni feature. By modeling photon travel paths, the study shows that neglecting time delays leads to mismatches in synthesized spectra during rapid temperature changes, emphasizing the necessity of incorporating time dependency in kilonova models.


<details>
  <summary>Details</summary>
Motivation: To address the unfamiliar rapid spectral evolution of kilonovae compared to slower transients like supernovae, especially the anomalous delay between absorption and emission components in Sr II features. The delay is hypothesized to stem from light echo/reverberation effects requiring time-dependent modeling.

Method: Developed a simple model tracking photon travel time to observers, comparing spectra generated with/without time delay considerations during phases of rapid photospheric temperature changes.

Result: Time-independent models produced visually distinct spectra from time-dependent ones in rapidly evolving phases. The Sr II emission component's delayed emergence and persistence aligns with reverberation predictions via scattered photons arriving later.

Conclusion: For accurate kilonova spectral analysis, time-dependent light travel effects are essential, especially critical during epochs of swift photometric changes. This challenges previous static assumptions and mandates updated modeling frameworks.

Abstract: The extremely rapid evolution of kilonovae results in spectra that change on
an hourly basis. These spectra are key to understanding the processes occurring
within the event, but this rapid evolution is an unfamiliar domain compared to
other explosive transient events, such as supernovae. In particular, the most
obvious P Cygni feature in the spectra of AT2017gfo -- commonly attributed to
strontium -- possesses an emission component that emerges after, and ultimately
outlives, its associated absorption dip. This delay is theorised to arise from
reverberation effects, wherein photons emitted earlier in the kilonova's
evolution are scattered before reaching the observer, causing them to be
detected at later times. We aim to examine how the finite speed of light -- and
therefore the light travel time to an observer -- contributes to the shape and
evolution of spectral features in kilonovae. Using a simple model, and tracking
the length of the journey photons undertake to an observer, we are able to test
the necessity of accounting for this time delay effect when modelling
kilonovae. In periods where the photospheric temperature is rapidly evolving,
we show spectra synthesised using a time independent approach are visually
distinct from those where these time delay effects are accounted for.
Therefore, in rapidly evolving events such as kilonovae, time dependence must
be taken into account.

</details>


### [10] [Direct observation of the X-ray counterpart of the Hα filaments and of the sloshing spiral in the Perseus galaxy cluster](https://arxiv.org/abs/2510.09559)
*Adrien Picquenot,Fabio Acero,Valeria Olivares,Michela Negro,Gabriel W. Pratt*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Deep Chandra observations of the Perseus galaxy cluster have allowed for the
discovery of X-ray counterparts to the H{\alpha} filamentary structures and of
a sloshing spiral. However, both components are extremely faint, and their
study is largely hindered by the volume-filling hot intracluster medium (ICM).
Using the Poisson General Morphological Component Analysis (pGMCA) algorithm, a
blind source separation method adapted for Poissonian statistics, we were able
to extract detailed, clean morphological maps of these components. We then
introduced a template fitting method to investigate their spectral
characteristics. We report the first direct observation of about 1.35 keV
low-energy emission from the sloshing spiral, and produce the most detailed and
unpolluted map of the X-rays filaments thus far obtained.

</details>


### [11] [SN 2021lwz: Another Exotic Luminous and Fast Evolving Optical Type Ic Broad-Lined Supernova ?](https://arxiv.org/abs/2510.09569)
*F. Poidevin,S. L. West,C. M. B. Omand,R. Könyves-Tóth,S. Schulze,L. Yan,T. Kangas,I. Pérez-Fournon,S. Geier,J. Sollerman,P. J. Pessi,C. M. Gutiérrez,T. -W. Chen,K-Ryan Hinds,R. Marques-Chaves,R. Shirley,C. Jimenez Angel,R. Lunnan,D. A. Perley,N. Sarin,Y. Yao,R. Dekany,J. Purdum,A. Wold,R. R. Laher,M. J. Graham,M. M. Kasliwal,T. Jegou Du Laz*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Context. Current large-scale, high-cadence surveys, such as the Zwicky
Transient Facility (ZTF), provide detections of new and rare types of
transients and supernovae whose physical origins are not well understood. Aims.
We investigate the nature of SN 2021lwz at a redshift z=0.065, an overluminous
supernova (SN) of absolute magnitude, $M_{g} \sim -20.1$ AB, falling in the
lower range of superluminous supernovae (SLSNe) luminosities, and discovered in
a faint dwarf galaxy with an absolute magnitude of $M_{g} \simeq -14.5$ AB.
Methods. SN 2021lwz is studied using optical spectroscopy, photometry and
imaging linear polarimetry obtained during several follow-up campaigns. All the
data are used to analyse and model the evolution of the explosion. Comparisons
with other SNe of well known or rarer types are investigated. Results. SN
2021lwz belongs to the rare class of rapidly evolving transients. The
bolometric light curve rises in about 7 days to a peak luminosity of about 5
x10^{43} erg/s, at a rate of 0.2 mag/day close to the peak. Spectroscopy
modeling reveals more similarities with a normal Type Ic-like SN than with a
SLSN before peak, showing broadened lines after peak. Light curve modeling
shows that the Arnett model of the bolometric light curve using a radioactive
source ($^{56}$ Ni) is not able to reasonably explain the light curve
evolution. A magnetar model seems more appropriate, suggesting that the
explosion of low ejecta mass ($M_{\rm ej} \sim 0.24 ~M_\odot$) took place in a
low mass ($M \sim 10^{6.66}~M_\odot$) dwarf galaxy of specific star-formation
rate about ten times larger than typical star-forming galaxies. Conclusions.
Given its spectroscopic properties and the low ejecta mass needed to model its
light-curve, SN 2021lwz does not match with many core-collapse H-poor SNe
Types. It shares similarities with rarer transients like SN 2014ft, iPTF 16asu
and SN 2018gep.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [12] [Expanding the Landscape of Exotic Muon Decays](https://arxiv.org/abs/2510.08674)
*Admir Greljo,Ajdin Palavrić,Mirsad Tunja,Jure Zupan*

Main category: hep-ph

TL;DR: The paper explores new-physics models that predict exotic muon decays with high-multiplicity electrons, photons, and missing energy, analyzing conditions for their observability and proposing dark-sector particle frameworks to test these hypotheses at existing and upcoming experiments.


<details>
  <summary>Details</summary>
Motivation: The motivation is to identify and characterize new-physics scenarios beyond the Standard Model that produce distinctive muon decay signatures, which can be tested at experiments like MEG II and Mu3e, offering insights into lepton-flavor breaking mechanisms.

Method: The authors use an effective-field-theory approach to estimate the reach of new-physics scales and conditions for suppressing lower-multiplicity decay modes. They then construct minimal dark-sector models incorporating light feebly interacting particles (e.g., dark photons, axion-like particles) to generate the predicted decay signatures.

Result: They identify viable models where high-multiplicity muon decays (e.g., μ→5e, μ→7e) can occur alongside prompt or displaced e⁺e⁻ pairs and photons. The study shows these signals are accessible at current and future experiments, potentially revealing new physics.

Conclusion: The proposed models and signatures offer a pathway to probe short-distance dynamics and lepton-flavor symmetry breaking mechanisms. A discovery at experiments like MEG II or Mu3e would provide crucial insights into beyond-Standard-Model physics.

Abstract: We chart new-physics models that produce exotic, high-multiplicity muon
decays featuring prompt or displaced $e^+e^-$ pairs and/or photons, with or
without missing energy, such as $\mu \to 5e$, $\mu \to 7e$, etc. Starting from
an effective-field-theory perspective, we estimate the reach on the ultraviolet
scale and identify conditions under which lower-multiplicity modes are
suppressed or occur at comparable rates. We then construct explicit
realizations in minimal dark-sector models with light, feebly interacting
particles, such as flavor-protected scalars, dark photons, inelastic dark
matter, and axion-like particles. The predicted novel signatures can be probed
at MEG II and Mu3e, as well as during calibration runs of COMET and Mu2e. A
future discovery would provide valuable insights into short-distance dynamics
and the mechanism of lepton-flavor symmetry breaking.

</details>


### [13] [Dark matter Simplified models in the Resonance Region](https://arxiv.org/abs/2510.08677)
*Mattia Di Mauro,Bohan Xie*

Main category: hep-ph

TL;DR: The paper explores the viability of a resonant dark matter (DM) scenario where the DM mass is approximately half the mediator mass (m_DM ≈ m_med/2), showing this regime remains unconstrained by current experiments and offers potential explanations for the Fermi-LAT Galactic Center Excess. The authors propose two minimal models to naturally achieve this mass relationship without fine-tuning.


<details>
  <summary>Details</summary>
Motivation: To investigate the unexplored resonant regime in simplified dark matter models (DMSimps) that evades existing experimental constraints, potentially explaining both the observed DM relic density and the Galactic Center Excess anomaly.

Method: The study employs a full Boltzmann equation analysis allowing for non-equilibrium conditions near resonance. It also examines s-wave annihilation mechanisms and proposes two simplified models to naturally set m_med ≈ 2m_DM.

Result: The resonant regime can reproduce the correct relic density with couplings under direct detection limits. s-wave annihilation models can explain the Galactic Center Excess. Proposed models make the resonance condition generic.

Conclusion: The resonant m_DM ≈ m_med/2 scenario is a viable and promising direction for future dark matter studies, offering multiple observable signatures testable by upcoming experiments like LUX-ZEPLIN and CTA.

Abstract: The particle-physics nature of dark matter (DM) remains one of the central
open questions in modern physics. A widely used framework to investigate DM
properties is provided by simplified models (DMSimps), which extend the
Standard Model with a DM particle and a mediator that connects the visible and
dark sectors. Much of the DMSimps parameter space is already constrained by
direct and indirect detection, collider searches, and the measured DM relic
abundance. We show, however, that the resonant regime $m_{\rm DM}\simeq m_{\rm
med}/2$ remains viable under current bounds and will be stringently tested by
forthcoming experiments. Using a full Boltzmann treatment that allows for
departures from kinetic equilibrium near resonance, we demonstrate that this
regime can reproduce the observed relic density with couplings compatible with
direct-detection limits. We also show that models with s-wave-dominated
annihilation can explain the Fermi-LAT Galactic Center Excess with couplings
consistent with relic-density and direct-detection constraints. Finally, we
propose two minimal constructions that naturally realize $m_{\rm med} \approx
2m_{\rm DM}$, making the resonant scenario generic rather than fine-tuned.

</details>


### [14] [Revealing signals of higher-order nonlinear showers in particle-laser collisions](https://arxiv.org/abs/2510.08679)
*T. G. Blackburn,B. King,M. Samuelsson*

Main category: hep-ph

TL;DR: The paper explores the detection of higher-order QED processes in high-power laser experiments by analyzing asymmetries in outgoing particle spectra, offering a method to validate current theoretical frameworks.


<details>
  <summary>Details</summary>
Motivation: As next-gen laser facilities approach field strengths where higher-order QED processes may dominate, existing calculation methods may fail. The study aims to identify experimental signatures (spectral asymmetries) to detect these effects and assess theory validity.

Method: Focuses on nonlinear showers and analyzes momentum spectra of outgoing particles from processes like nonlinear phototrident, trident, and Compton scattering. It proposes using measured incident particle spectra to predict observable asymmetries indicative of higher-order effects.

Result: Identifies that spectral asymmetries in outgoing particles could signal the presence of higher-order QED processes, providing a practical way for experiments to test the accuracy of current theoretical models under extreme field conditions.

Conclusion: These proposed signatures offer a critical tool for experimental validation of strong-field QED theories at higher orders, ensuring reliability of calculational methods as laser technologies advance toward unexplored field regimes.

Abstract: Several high power laser facilities are reaching field strengths where
leading order strong-field quantum electrodynamical (QED) processes can be
measured in the non-perturbative regime for the first time. At very high, as
yet unobtainable in the laboratory, field strengths, the contribution of
higher-order processes is predicted to dominate, implying a breakdown of
current calculational methods. Focusing on nonlinear showers and considering
currently available experimental parameters, we find that if the momentum
spectrum of the \emph{incident} particles is well known, asymmetries in the
\emph{outgoing} particle spectrum may provide a useful signature of higher
orders of nonlinear phototrident, trident and Compton scattering. These
signatures could be used by experiment to test how accurate the current
calculational framework is when applied to strong-field QED at higher orders.

</details>


### [15] [Two-loop anomalous dimensions for baryon-number-violating operators in SMEFT](https://arxiv.org/abs/2510.08682)
*Sumit Banik,Andreas Crivellin,Luca Naterop,Peter Stoffer*

Main category: hep-ph

TL;DR: The paper calculates two-loop renormalization-group equations for baryon-number-violating operators in the Standard Model Effective Field Theory (SMEFT), including all Standard Model interactions. It also provides one-loop matching for the S₁ scalar leptoquark model, showing how it generates Wilson coefficients for all gauge-invariant baryon-number-violating operators. The authors demonstrate scheme and scale dependence cancellation and discuss the enabling of next-to-leading-log analyses for nucleon decay studies with sufficient matrix element accuracy.


<details>
  <summary>Details</summary>
Motivation: The motivation is to improve precision in analyzing baryon-number-violating processes like nucleon decay by providing a consistent next-to-leading-log framework. This requires accounting for higher-order effects (two-loop RGEs and one-loop matching) to reduce theoretical uncertainties from renormalization group evolution and matching procedures.

Method: The method involves calculating two-loop renormalization-group equations (RGEs) for dimension-six operators in the SMEFT, considering all gauge, Yukawa, and Higgs contributions. They perform a one-loop matching of the S₁ scalar leptoquark model onto the SMEFT to compute Wilson coefficients. Numerical analysis is used to demonstrate cancellation of scheme and scale dependencies.

Result: Key results include the derived two-loop RGEs for SMEFT operators, the one-loop matching conditions for the S₁ leptoquark model, and validation of scheme/scale dependence cancellation. This framework now allows for NLL accuracy in nucleon decay analyses pending precise matrix elements.

Conclusion: The conclusion emphasizes that combining their two-loop RGEs with known lower-order calculations enables consistent next-to-leading-log studies of baryon-number-violating processes. However, experimental verification requires high-precision calculations of relevant hadronic matrix elements at NLO accuracy.

Abstract: We compute the two-loop renormalization-group equations for the
baryon-number-violating dimension-six operators in the SMEFT. This includes all
three gauge interactions, the Yukawa, and Higgs self-interaction contributions.
In addition, we present the one-loop matching of the $S_1$ scalar leptoquark on
the SMEFT, which can generate the Wilson coefficients of all four
gauge-invariant baryon-number-violating SMEFT operators. Using this example, we
demonstrate the cancellation of scheme and matching-scale dependences. Together
with the known two-loop renormalization-group evolution below the electroweak
scale in the LEFT, as well as the one-loop matching of SMEFT onto LEFT, our
results enable consistent next-to-leading-log analyses of nucleon decays,
provided that the relevant matrix elements are known at next-to-leading-order
accuracy.

</details>


### [16] [Hydrodynamic models of Reheating](https://arxiv.org/abs/2510.08685)
*Juan Pablo Elía,Lucas Cantarutti,Nahuel Mirón-Granese,Esteban Calzetta*

Main category: hep-ph

TL;DR: The paper presents a causal hydrodynamic model to describe the early reheating phase's dynamics, capturing dissipative effects and parametric resonance leading to gravitational wave production, validated against lattice simulations.


<details>
  <summary>Details</summary>
Motivation: To effectively model the early stages of reheating with a stable, causal framework that connect microscopic field dynamics to macroscopic observables.

Method: Develops a causal hydrodynamic model treating the inflaton condensate as a background coupled to a relativistic fluid. Uses divergence-type theory from kinetic considerations to include dissipative and non-equilibrium effects. Analyzes parametric resonance in the tensor sector causing viscous stress amplification and gravitational wave generation.

Result: The model successfully predicts a gravitational wave spectrum with a characteristic peak, matching lattice simulations from CosmoLattice. Demonstrates the model's validity and its role as a bridge between micro and macro cosmological phenomena.

Conclusion: The causal hydrodynamic approach provides a reliable macroscopic description of reheating dynamics, enabling improved understanding and prediction of cosmological observables like gravitational waves.

Abstract: We develop a causal hydrodynamic model that provides an effective macroscopic
description of the field-theoretic dynamics during the early stages of
reheating. The inflaton condensate is treated as a homogeneous background
coupled to a relativistic fluid that represents its inhomogeneous fluctuations.
Within the divergence-type theory framework derived from kinetic
considerations, the model captures essential dissipative and non-equilibrium
effects while remaining stable and causal. We find that the coupling between
the oscillating condensate and the fluid induces a parametric resonance in the
tensor sector, leading to the amplification of the viscous stress tensor and
the generation of gravitational waves with a characteristic spectral peak. The
predicted spectrum agrees with lattice simulations performed with CosmoLattice.
This hydrodynamic approach offers an effective bridge between microscopic field
dynamics and macroscopic cosmological observables.

</details>


### [17] [Loop functions of sunset graphs in 2+1 space-time dimensions](https://arxiv.org/abs/2510.08704)
*N. Kaiser*

Main category: hep-ph

TL;DR: The paper presents an iterative calculation of the relativistic n-body phase-space in 2+1 dimensions, leading to a power-law result dependent on total mass. This allows expressing sunset graph integrals through elementary functions. Analyses in 4+1 and 1+1 dimensions are also provided.


<details>
  <summary>Details</summary>
Motivation: To understand relativistic n-body phase-space behavior in different dimensions and simplify complex multi-loop integrals using power-law expressions and elementary functions.

Method: Iterative calculation of n-body phase-space in 2+1D, deriving power-law expressions and expressing sunset integrals via arctangent/logarithmic functions. Extends analysis to 4+1D for n=2-5 and examines 1+1D's elliptic integral dependency.

Result: Phase-space follows α_n(μ−M)^{n-2}/μ power-law. Sunset integrals J_n(-q²) are expressed using elementary functions modulo polynomial terms. 4+1D results show mass-symmetric dependencies; 1+1D three-body phase-space involves complete elliptic integrals.

Conclusion: The derived power-law and dimension-specific integral expressions provide a simplified framework for multi-loop calculations in quantum field theory, suggesting similar approaches for higher dimensions and potential applications in scattering amplitude computations.

Abstract: In these notes the relativistic $n$-body phase-phase is calculated
iteratively in $2+1$ space-time dimensions for all $n$. The obtained result
shows a simple power-law behavior $\alpha_n (\mu-M)^{n-2}/\mu$ with a
dependence only on the total mass $M=m_1+\dots + m_n$. As a consequence of this
feature, the $(n-1)$-loop integrals $J_n(-q^2)$ associated to sunset graphs
with $n$ internal lines can be expressed through of elementary (arctangent and
logarithmic) functions, modulo polynomial terms in $q^2$ with
regularization-dependent coefficients. An outlook to the analogous situation in
$4+1$ space-time dimensions is given by computing the $n$-body phase-phases for
$n=2,3,4,5$ with their totally symmetric dependence on the involved masses.
Moreover, a degression to $1+1$ space-time dimensions reveals that there the
three-body phase-space is already proportional to a complete elliptic integral.

</details>


### [18] [Taming forward scattering singularities in partial waves](https://arxiv.org/abs/2510.08784)
*Marta Fuentes Zamoro,Benjamín Grinstein,Pablo Quílez*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Perturbative partial-wave amplitudes diverge in cases with a massless
exchanged particle in the $t$-channel. We argue that the divergence is an
artifact of perturbation theory and give a prescription for the all-orders
correction factor that renders the partial waves finite. As an example, we
apply this to longitudinal $W^+W^-$ elastic scattering, for which there is a
photon exchange $t$-channel contribution, and derive improved
quasi-perturbative unitarity bounds on the mass of the Higgs. The method is
also useful for $t$-channel exchange of very light particles.

</details>


### [19] [Exclusive photoproduction of light and heavy vector mesons: thresholds to very high energies](https://arxiv.org/abs/2510.08845)
*Lin Tang,Hui-Yu Xing,Minghui Ding,Craig D. Roberts*

Main category: hep-ph

TL;DR: The paper presents a unified reaction model for photon-proton interactions producing vector mesons (ρ⁰, φ, J/ψ, Υ) by modeling photon fluctuations into quark-antiquark pairs coupled to proton via Pomeron exchange. It describes data across a wide energy range and cautions against interpreting results in terms of gluon distributions or QCD phenomena without further validation.


<details>
  <summary>Details</summary>
Motivation: To provide a comprehensive theoretical framework that解释s experimental data on γ+p→V+p reactions across various energies, challenges the oversimplified link to QCD concepts like gluon distributions, and guides future experimental/theoretical advancements.

Method: Uses a quark-antiquark fluctuation model of the photon coupled with Pomeron exchange to the proton's valence quarks. Analyzes differential and total cross sections from near threshold to high energies (e.g., 10-2000 GeV for Υ) and compares with available data. Employs vector meson dominance ideas to interpret scattering lengths.

Result: Successful unified description of existing data for all V-mesons. Predicts power-law exponents for high-energy cross sections and slope parameters. Indicates current data insufficient to establish connections between reactions and QCD trace anomaly/gluon distributions/pentaquarks.

Conclusion: Stresses that observed phenomena do not yet confirm links to gluon distributions or other QCD phenomena. Calls for refined reaction theories and higher precision data to validate such connections in the future.

Abstract: A reaction model for $\gamma + p \to V + p$, $V=\rho^0, \phi, J/\psi,
\Upsilon$, which exposes the quark-antiquark content of the photon in making
the transition $\gamma\to {q} \bar{q} + \mathbb P \to V$, where ${q}$ depends
on $V$, and couples the intermediate ${q} \bar{q}$ system to the proton's
valence quarks via Pomeron ($\mathbb P$) exchange, is used to deliver a unified
description of available data -- both differential and total cross sections --
from near threshold to very high energies, $W$, for all the $V$-mesons. For the
$\Upsilon$, this means $10\lesssim W/{\rm GeV} \lesssim 2\,000$. Also provided
are predictions for the power-law exponents that are empirically used to
characterise the large-$W$ behaviour of the total cross sections and slope
parameters characterising the near-threshold differential cross sections.
Appealing to notions of vector meson dominance, the latter have been
interpreted as vector-meson--proton scattering lengths. The body of results
indicate that it is premature to link any $\gamma + p \to V + p$ data with, for
instance, in-proton gluon distributions, the quantum chromodynamics trace
anomaly, or pentaquark production. Further developments in reaction theory and
higher precision data are required before the validity of any such links can be
assessed.

</details>


### [20] [Towards Quantum Simulations of Sphaleron Dynamics at Colliders](https://arxiv.org/abs/2510.08910)
*Min Huang,Ying-Ying Li,Yandong Liu,Hao Zhang*

Main category: hep-ph

TL;DR: The paper proposes a quantum simulation approach to study sphaleron dynamics in the Standard Model, focusing on the 1+1D O(3) model as a stepping stone for electroweak theory analysis. It addresses the challenge of simulating nonperturbative real-time dynamics inaccessible to classical methods.


<details>
  <summary>Details</summary>
Motivation: Sphaleron dynamics in high-energy collisions is theoretically and experimentally challenging due to its nonperturbative nature. Classical computations struggle with real-time evolutions involving topological objects like sphalerons, necessitating alternative approaches like quantum simulation.

Method: The authors use a 1+1D O(3) model to approximate sphaleron behavior in electroweak theory. They identify the sphaleron configuration, optimize lattice parameters for continuum precision, and develop quantum algorithms to simulate its evolution with quantum effects.

Result: They establish a foundational framework for quantum simulations of sphaleron dynamics, demonstrating feasibility and accuracy in capturing topological interactions that classical methods cannot handle.

Conclusion: This work opens avenues for quantum computing to tackle complex QFT problems involving classical-quantum interactions of topological objects, paving the way for future studies in electroweak theory and beyond.

Abstract: Sphaleron dynamics in the Standard Model at high-energy particle collisions
remains experimentally unobserved, with theoretical predictions hindered by its
nonperturbative real-time nature. In this work, we investigate a quantum
simulation approach to this challenge. Taking the $1+1$D $O(3)$ model as a
protocol towards studying dynamics of sphaleron in the electroweak theory, we
identify the sphaleron configuration and establish lattice parameters that
reproduce continuum sphaleron energies with controlled precision. We then
develop quantum algorithms to simulate sphaleron evolutions where quantum
effects can be included. This work lays the ground to establish quantum
simulations for studying the interaction between classical topological objects
and particles in the quantum field theory that are usually inaccessible to
classical methods and computations.

</details>


### [21] [Open heavy-flavor transport and hadronization in heavy-ion collisions](https://arxiv.org/abs/2510.08923)
*Yu Fu,Tharun Krishna,Weiyao Ke,Steffen A. Bass,Ralf Rapp*

Main category: hep-ph

TL;DR: The paper presents a comprehensive model for heavy-quark evolution in the QGP, incorporating Langevin dynamics with medium-induced radiation, viscous hydrodynamics, non-perturbative transport coefficients, and two hadronization schemes. It compares predictions for heavy-flavor observables to LHC data.


<details>
  <summary>Details</summary>
Motivation: To improve understanding of heavy-quark dynamics in QGP and better align theoretical predictions with LHC measurements of heavy-flavor observables like nuclear modification factor and elliptic flow.

Method: Combination of Langevin transport equations with hydrodynamic bulk flow, non-perturbative T-matrix transport coefficients, and dual fragmentation/recombination hadronization models (improved coalescence and resonance recombination).

Result: Model successfully reproduces LHC Pb-Pb data at 5.02 TeV for nuclear modification and elliptic flow of heavy flavors, validating the inclusion of viscous effects and non-perturbative coefficients.

Conclusion: The integrated framework provides a robust description of heavy-quark evolution in QGP, emphasizing the importance of medium-induced radiation and non-perturbative interactions for accurately modeling heavy-flavor observables in high-energy collisions.

Abstract: We develop a comprehensive model for heavy-quark evolution in a realistic
QGP, from their production in the initial collision to hadronic freeze-out.
Heavy-quark transport is described by a Langevin approach including
medium-induced radiation, coupled to a 2+1D viscous hydrodynamic bulk
evolution. Transport coefficients are obtained from non-perturbative $T$-matrix
calculations with resonant correlations near the transition temperature.
Hadronization is implemented via two fragmentation+recombination schemes: an
improved sudden coalescence model and a resonance recombination model. We
present results for key open heavy-flavor observables, i.e., the nuclear
modification factor and elliptic flow, and compare to LHC Pb-Pb data at
$\sqrt{s_{\NN}}$=5.02\,TeV.}

</details>


### [22] [Jet Energy-Energy Correlator in Cold QCD Matter](https://arxiv.org/abs/2510.08927)
*Yu Fu,Berndt Müller,Chathuranga Sirimanna*

Main category: hep-ph

TL;DR: This paper examines how cold nuclear matter affects the energy-energy correlator (EEC) for jets in electron-nucleus collisions, deriving an analytic expression for EEC modifications dependent on opening angle, jet energy, nuclear properties, and path length. It also extends the analysis to gluon jets in proton-nucleus collisions and compares with LHC data, considering comover effects.


<details>
  <summary>Details</summary>
Motivation: Understand medium-induced effects on jet substructure observables (EEC) in nuclear collisions to better characterize cold nuclear matter properties and validate theoretical models against experimental data.

Method: Leading-order QCD analysis of EEC in electron-nucleus collisions, deriving analytic expressions, parametrizing dependence on opening angle, jet energy, nuclear transport properties, and path length. Extends to proton-nucleus collisions with gluon jets, incorporating comover effects in medium interactions.

Result: EEC modifications are strongest at large angles within jet cones, showing explicit dependencies on jet energy and nuclear medium parameters. Theoretical predictions align with preliminary LHC proton-lead data, highlighting comover effects' role in proton-nucleus collisions.

Conclusion:  cold nuclear matter significantly alters jet substructure via medium-induced radiation, with EEC serving as a sensitive probe. Results support using EEC measurements to extract nuclear medium properties and improve jet quenching models in high-energy nuclear physics.

Abstract: We present a study of medium-induced modifications to the energy-energy
correlator (EEC) for jets in cold nuclear matter. For electron-nucleus
collisions, at leading order in the QCD coupling and in the jet-medium
interaction, we derive an analytic expression for the EEC modification as a
function of the opening angle and show that the modification is strongest at
large angles within the jet cone. The dependence on jet energy, the transport
properties of cold nuclear matter, and the in-medium path length is made
explicit. We further extend the analysis to gluon jets in proton-nucleus
collisions and compare with preliminary proton-lead data from the LHC. Possible
effects of comovers on the EEC in proton-nucleus collisions are also discussed.

</details>


### [23] [Semihard interactions at TeV energies](https://arxiv.org/abs/2510.08963)
*T. V. Iser,E. G. S. Luna*

Main category: hep-ph

TL;DR: The paper examines the high-energy behavior of proton-proton and antiproton-proton scattering processes using a QCD-based model driven by gluon-induced semihard processes. It addresses inconsistencies between ATLAS/ALFA and TOTEM data regarding the ρ parameter at 13 TeV, suggesting an odd component in the semihard amplitude.


<details>
  <summary>Details</summary>
Motivation: To resolve discrepancies between experimental results from ATLAS/ALFA and TOTEM collaborations in the scattering amplitude ratio (ρ) at 13 TeV and explore the underlying particle interactions at ultrahigh energies.

Method: A QCD-inspired model emphasizing gluon-mediated semihard processes to predict total cross sections (σtot) and ρ parameter. Independent dataset analyses and comparison with experimental data.

Result: The model provides statistically consistent descriptions of the data but does not fully match the central ρ values at 13 TeV. A slight discrepancy indicates possible contributions from crossing-odd components in the amplitude at high energies.

Conclusion: The observed mismatch suggests the presence of an odd component in the semihard amplitude, highlighting the need for further exploration of non-asymptotic or subleading effects in high-energy scattering models.

Abstract: We investigate the high-energy behavior of the total cross section,
$\sigma_{\text{tot}}$, and the ratio of the real to imaginary parts of the
scattering amplitude, $\rho$, in both proton-proton and antiproton-proton
channels. Our analysis is based on a QCD-inspired model in which the rise of
the cross sections is predominantly driven by semihard processes involving
gluons. We address the tension between measurements from the ATLAS/ALFA and
TOTEM Collaborations, showing that independent analyses of their datasets can
provide statistically consistent descriptions of the overall data, even though
they do not fully reproduce the central values of the $\rho$ parameter at
$\sqrt{s} = 13$ TeV. The slight discrepancy between these central values and
the model's predicted values, obtained using an asymptotic dominant
crossing-even elastic scattering amplitude, points to the potential presence of
an odd component in the semihard amplitude at high energies.

</details>


### [24] [When inverse seesaw meets inverse electroweak phase transition: a novel path to leptogenesis](https://arxiv.org/abs/2510.09000)
*Wen-Yuan Ai,Peisi Huang,Ke-Pan Xie*

Main category: hep-ph

TL;DR: The paper introduces a nonthermal leptogenesis mechanism using a first-order phase transition involving TeV-scale vectorlike leptons to generate the baryon asymmetry, potentially testable in current/future experiments.


<details>
  <summary>Details</summary>
Motivation: To explain the origin of the observed baryon asymmetry in the universe through a mechanism that is testable with modern particle experiments, leveraging first-order phase transitions and vectorlike leptons.

Method: Extending the Standard Model with two generations of TeV-scale vectorlike leptons. The lighter generation triggers an inverse electroweak phase transition at ~200 GeV, creating expanding bubbles. The heavier generation generates neutrino masses via inverse seesaw. Interaction between bubble walls and plasma produces vectorlike leptons, which decay CP-asymmetrically to produce baryon asymmetry.

Result: The mechanism successfully links phase transitions with leptogenesis, offering a testable model that can be probed by current/future particle colliders and neutrino experiments.

Conclusion: This nonthermal leptogenesis model provides a viable explanation for the baryon asymmetry with experimental validation possibilities, bridging cosmology and particle physics.

Abstract: We propose a new nonthermal leptogenesis mechanism triggered by the cosmic
first-order phase transition. The Standard Model is extended with two
generations of TeV-scale vectorlike leptons. The lighter generation gives rise
to an inverse electroweak phase transition of the Higgs field at $T\sim200~{\rm
GeV}$, restoring the symmetry, and resulting in relativistic bubble expansion
in the space. The heavier generation is responsible for neutrino masses via the
inverse seesaw mechanism. The interaction between bubble walls and particles in
the plasma abundantly produces the vectorlike leptons, and they subsequently
undergo CP-violating decay to generate the baryon asymmetry. This mechanism is
testable at current and future particle experiments.

</details>


### [25] [Inclusive processes in the modified Quark-Gluon String Model](https://arxiv.org/abs/2510.09284)
*M. N. Sergeenko*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Inclusive processes at high energies are studied in a non-perturbative
approach in QCD using a modified Quark-Gluon String Model. Theoretical and
experimental aspects of diffraction dissociation are discussed. In the
calculations of cross sections, the parameters of complex nonlinear
trajectories of Pomeranchuk and Reggeons are used. Particular attention is paid
to elastic and inelastic processes at LHC energies.

</details>


### [26] [HOPPET v2.0.0 release note](https://arxiv.org/abs/2510.09310)
*Alexander Karlberg,Paolo Nason,Gavin Salam,Giulia Zanderighi,Frédéric Dreyer*

Main category: hep-ph

TL;DR: HOPPET 2.0.0 introduces N³LO QCD evolution, massless quark structure functions at N³LO, QED evolution at NNLO-equivalent accuracy, a Python interface, CMake build option, and LHAPDF grid export with performance improvements.


<details>
  <summary>Details</summary>
Motivation: The motivation behind HOPPET 2.0.0 is to advance precision in particle physics calculations by extending the code's capabilities to higher-order perturbative QCD and QED calculations, improving user accessibility through new interfaces, and enhancing computational efficiency for modern high-precision experiments.

Method: The method includes implementing variable flavour number scheme for N³LO QCD evolution, calculating structure functions for massless quarks up to N³LO, integrating QED evolution matching NNLO QCD accuracy, developing a Python interface, enabling CMake builds, and optimizing PDF interpolation with LHAPDF grid export.

Result: The release achieves accurate N³LO QCD and equivalent NNLO QED evolution, faster computations via optimized interpolation, user-friendly Python access, and compatibility with LHAPDF standards, supported by updated performance benchmarks.

Conclusion: HOPPET 2.0.0 represents a significant step in precision PDF tools, enabling state-of-the-art analyses for next-generation collider experiments through enhanced accuracy, accessibility, and performance.

Abstract: We document the three main new features in release 2.0.0 of the HOPPET parton
distribution function evolution code, specifically support for N$^3$LO QCD
evolution in the variable flavour number scheme, for the determination of
hadronic structure functions for massless quarks up to N$^3$LO, and for QED
evolution to an accuracy phenomenologically equivalent to NNLO QCD.
Additionally we describe a new Python interface, CMake build option,
functionality to save a hoppet table as an LHAPDF grid and update our
performance benchmarks, including optimisations in interpolating PDF tables.

</details>


### [27] [Dark matter production from evaporation of regular primordial black holes](https://arxiv.org/abs/2510.09395)
*Ngo Phuc Duc Loc*

Main category: hep-ph

TL;DR: The paper examines dark matter production from evaporating regular primordial black holes (RPBHs), using Hayward and Simpson-Visser metrics to explore modified cosmological constraints and parameter space for achieving observed dark matter abundance.


<details>
  <summary>Details</summary>
Motivation: To investigate how RPBHs, which avoid singularities, contribute to dark matter production through evaporation, considering their different Hawking temperatures and lifetimes compared to standard black holes.

Method: Analyze RPBHs using Hayward and Simpson-Visser metrics to model their Hawking radiation and evaporation processes, calculate cosmological constraints and parameter spaces that explain the observed dark matter density.

Result: Derives modified cosmological constraints and identifies parameter regions where RPBH evaporation can account for the correct dark matter abundance.

Conclusion: RPBHs with specific metrics offer viable scenarios for dark matter production, extending beyond traditional black hole models by considering singularity-free structures and their unique evaporation characteristics.

Abstract: We study dark matter (DM) production from evaporation of regular primordial
black holes (RPBHs). While there are many available metrics that describe
singularity-free RPBHs, we focus on the Hayward metric and the Simpson-Visser
metric for illustrative purpose. The framework can be applied straightforwardly
to other metrics. RPBHs generally have different Hawking temperature and
therefore different lifetime from the standard singular black holes. The
resulting modified cosmological constraints for this DM production mechanism
and the allowed parameter space to obtain the correct DM abundance are
calculated.

</details>


### [28] [MSHT Approximate N3LO PDFs: Updates and Consequences for Phenomenology](https://arxiv.org/abs/2510.09321)
*T. Cridge,L. A. Harland-Lang,R. S. Thorne*

Main category: hep-ph

TL;DR: The paper updates the MSHT approximate N3LO PDFs by incorporating newly calculated splitting functions and transition matrix elements, resulting in minimal changes to the PDFs and further reduced impacts on PDF luminosities.


<details>
  <summary>Details</summary>
Motivation: To incorporate the latest theoretical advancements (new splitting functions and transition matrix elements) into the MSHT20aN3LO PDF set to assess their impact on parton distribution functions and luminosities after the public release.

Method: The authors examined the effects of newly determined splitting functions and transition matrix elements on the MSHT PDFs. They compared the updated PDFs with the previously released MSHT20aN3LO set, analyzing changes in both PDF uncertainties and luminosities.

Result: The updates led to only small changes in the PDFs, which are mostly within or smaller than the existing uncertainties. The PDF luminosities show even smaller variations compared to the PDFs themselves.

Conclusion: The new calculations do not significantly alter the existing MSHT20aN3LO PDF results, indicating that the original PDF set was robust and that the recent theoretical improvements have minimal practical impact on current PDF fits.

Abstract: We present updates to the MSHT approximate N3LO PDFs focusing upon recent
developments, examining the impacts of newly determined splitting function and
transition matrix element calculations, performed since the public MSHT20aN3LO
PDF set was released. We observe only small changes to the output PDFs, at most
of similar size to their quoted uncertainties and typically notably less.
Finally, we also present the impacts on the PDF luminosities, where changes are
generally further reduced.

</details>


### [29] [The two-mass contributions to the three-loop massive operator matrix elements $\tilde{A}_{Qg}^{(3)}$ and $Δ\tilde{A}_{Qg}^{(3)}$](https://arxiv.org/abs/2510.09403)
*J. Ablinger,J. Blümlein,A. De Freitas,A. von Manteuffel,C. Schneider,K. Schönwald*

Main category: hep-ph

TL;DR: The paper computes two-mass three-loop contributions for unpolarized and polarized massive operator matrix elements using a semi-analytic method and Mellin moments, completing the calculation of all such elements at three loops.


<details>
  <summary>Details</summary>
Motivation: To determine the complete set of unpolarized and polarized massive three-loop operator matrix elements, which are crucial for precise predictions in QCD phenomenology, particularly in deep-inelastic scattering and flavor physics.

Method: Combines a semi-analytic approach with independent Mellin moment calculations (up to N=2000/3000) for cross-validation, using the Larin scheme for polarized cases. Focuses on x-space results for a general mass ratio.

Result: The two-mass contributions constitute ~50% of the full O(T_F²) and O(T_F³) terms in the operator matrix elements. The analysis confirms consistency between x-space and Mellin moment methods, finalizing the three-loop massive OMEs.

Conclusion: This work completes the three-loop massive operator matrix elements necessary for high-precision QCD calculations, enabling accurate theoretical predictions for collider and fixed-target experiments.

Abstract: We calculate the two-mass three-loop contributions to the unpolarized and
polarized massive operator matrix elements $\tilde{A}_{Qg}^{(3)}$ and $\Delta
\tilde{A}_{Qg}^{(3)}$ in $x$-space for a general mass ratio by using a
semi-analytic approach. We also compute Mellin moments up to $N = 2000 (3000)$
by an independent method, to which we compare the results in $x$-space. In the
polarized case, we work in the Larin scheme. We present numerical results. The
two-mass contributions amount to about $50 \%$ of the full
\textcolor{blue}{$O(T_F^2)$} and \textcolor{blue}{$O(T_F^3)$} terms
contributing to the operator matrix elements. The present result completes the
calculation of all unpolarized and polarized massive three-loop operator matrix
elements.

</details>


### [30] [Manifestations of Dark Matter in processes with three and four Top-Quarks](https://arxiv.org/abs/2510.09428)
*E. Abasov,E. Boos,V. Bunichev,P. Volkov,G. Vorotnikov,L. Dudko,A. Zaborenko,E. Iudin,A. Markina,M. Perfilov,N. Savkova*

Main category: hep-ph

TL;DR: The study investigates Dark Matter (DM) signatures in multi-top-quark processes at the LHC using simplified models, showing that resonant DM mediator production has better discovery potential than associated production.


<details>
  <summary>Details</summary>
Motivation: To explore DM manifestations in multi-top quark processes and assess the viability of different production channels for DM detection at the LHC.

Method: Analyzed associated production of scalar/pseudoscalar DM mediators with up to four top quarks and resonant production in top-rich final states using CompHEP/MadGraph for cross-section calculations with LHC DM WG benchmark parameters.

Result: Differential cross-section comparisons show significant deviations from Standard Model predictions. Associated production channels have limited feasibility, while resonant production offers realistic discovery prospects.

Conclusion: Multi-top-quark final states are promising probes for DM at current/future colliders, emphasizing the importance of resonant production channels over associated production.

Abstract: This study explores possible manifestations of Dark Matter (DM) in processes
involving multiple top quarks at the LHC. We analyze both the associated
production of scalar and pseudoscalar DM Mediators with up to four top quarks,
as well as their resonant production in top-rich final states, within a
simplified model framework. Cross sections were calculated using the CompHEP
and MadGraph packages with benchmark parameters recommended by the LHC Dark
Matter Working Group. A detailed comparison of differential cross sections for
key kinematic observables in three- and four-top-quark production demonstrates
pronounced deviations from Standard Model predictions. The results highlight
the limited feasibility of associated production channels, while resonant DM
Mediator production offers realistic discovery prospects. Overall, the analysis
underscores the potential of multi-top-quark final states as sensitive probes
of Dark Matter at current and future collider experiments.

</details>


### [31] [Lie symmetry analysis of the two-Higgs-doublet model field equations](https://arxiv.org/abs/2510.09542)
*M. Aa. Solberg*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We apply Lie symmetry analysis of partial differential equations (PDEs) to
the Euler-Lagrange equations of the two-Higgs-doublet model (2HDM), to
determine its scalar Lie point symmetries. A Lie point symmetry is a
structure-preserving transformation of the spacetime variables and the fields
of the model, which is also continuous and connected to the identity.
Symmetries of PDEs may in general be divided into strict variational
symmetries, divergence symmetries and non-variational symmetries, where the
first two are collectively referred to as variational symmetries. Variational
symmetries are usually preserved under quantization, and variational Lie
symmetries yield conservation laws. We demonstrate that there are no scalar Lie
point divergence symmetries or non-variational Lie point symmetries in the
2HDM, and re-derive its well-known strict variational Lie point symmetries,
thus confirming the consistency of our implementation of Lie's method.
Moreover, we prove three general results which may simplify Lie symmetry
calculations for a wide class of particle physics models. Lie symmetry analysis
of PDEs is a broadly applicable method for determining Lie symmetries. As
demonstrated here by example, it can be applied to models with many variables,
parameters and reparametrization freedom, while any missing discrete symmetries
may be identified through the automorphism groups of the resulting Lie symmetry
algebras.

</details>


### [32] [A LENS on DUNE-PRISM: Characterizing a Neutrino Beam with Off-Axis Measurements](https://arxiv.org/abs/2510.09546)
*Julia Gehrlein,Joachim Kopp,Margot MacMahon,George A. Parker*

Main category: hep-ph

TL;DR: The paper introduces LENS, a method using off-axis neutrino measurements to constrain flux models by separately extracting meson-specific spectra, enhancing flux predictions for better neutrino oscillation studies.


<details>
  <summary>Details</summary>
Motivation: Precision experiments in neutrino oscillations are limited by systematic uncertainties from neutrino flux and cross-section predictions. Existing PRISM technique requires some theoretical input, so improving flux models through data-driven methods like LENS is necessary to reduce uncertainties.

Method: LENS uses off-axis near detector data to separately extract fluxes and spectra of different mesons in the neutrino beam. This improved flux model is then applied to better predict the oscillated flux at the far detector, enhancing oscillation parameter measurements.

Result: The LENS method effectively constrains flux models by leveraging off-axis measurements, leading to more accurate flux predictions and reduced systematic uncertainties in far detector oscillation analyses.

Conclusion: LENS provides a complementary approach to PRISM, significantly improving the reliability of neutrino flux predictions, which is crucial for achieving precision in upcoming long-baseline neutrino experiments.

Abstract: Upcoming precision long-baseline neutrino oscillation experiments will be
severely limited by the large systematic uncertainties associated with neutrino
flux predictions and neutrino--nucleus cross sections. A promising remedy is
the PRISM (Precision Reaction Independent Spectrum Measurement) technique,
whereby the near detector measures the neutrino spectrum at different angles
with respect to the beam axis. These measurements are then linearly combined
into a prediction of the oscillated neutrino flux at the far detector. This
prediction is data-driven, but still dependent on some theoretical knowledge
about the neutrino flux. In this paper, we study to what extent off-axis
measurements themselves can be used to directly constrain neutrino flux models.
In particular, we use them to extract separately the fluxes and spectra of
different meson species in the beam. We call this measurement LENS (Lateral
Extraction of Neutrino Spectra). Second, we demonstrate how the thus improved
flux model helps to further constrain the far detector flux prediction, thereby
ultimately improving oscillation measurements.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [33] [Constraining the Cosmological Evolution of Post-Newtonian Parameters with Gravitational Wave Signals from Compact Binary Inspirals](https://arxiv.org/abs/2510.08756)
*Oliver Pitt,Timothy Clifton*

Main category: gr-qc

TL;DR: The paper explores how gravitational waves from compact binary inspirals can be used to constrain the time-evolving gravitational coupling parameters in modified gravity theories by developing theory-independent equations of motion and signal predictions.


<details>
  <summary>Details</summary>
Motivation: To leverage the precise measurements of gravitational waves and the cosmological redshifts of compact binaries for testing the time dependence of gravitational constants, supplementing cosmological probes with observational data from these systems.

Method: Deriving theory-independent equations of motion for binary systems, incorporating post-Newtonian gravitational coupling parameters, radiative flux parameters, and compact body sensitivities to model gravitational wave signals.

Result: Derived expressions for wave phase and amplitude in terms of these parameters, enabling constraints on modified gravity models using inspiral observations.

Conclusion: Gravitational wave data from compact binaries offers a novel and complementary approach to studying the time-evolution of gravitational parameters, extending cosmological tests with unique observational constraints.

Abstract: Gravitational waves from compact binary inspirals offer a new opportunity to
constrain the cosmological time dependence of gravitational coupling
parameters, due to the high precision of the observations themselves as well as
the significant cosmological redshifts at which such systems exist. We
calculate theory-independent equations of motion for compact objects in a
binary system, implementing a new approach to sensitivities, and subsequently
determine the gravitational wave signal that one should expect to measure from
their inspiral. Expressions for the wave phase and amplitude are derived in
terms of post-Newtonian gravitational coupling parameters, radiative flux
parameters, and compact body sensitivities. These results complement recent
attempts to gain theory-independent constraints on the time-evolution of
gravitational coupling parameters from cosmological probes, and represent a new
opportunity to constrain modified gravity with gravitational wave data.

</details>


### [34] [Noncommutative Bianchi I and III Cosmology Models: Radiation Era Dynamics and gamma Estimation](https://arxiv.org/abs/2510.08796)
*G. Oliveira-Neto,Y. Soncco Apaza*

Main category: gr-qc

TL;DR: The paper investigates the impact of noncommutative phase space on the early universe's dynamics using Bianchi cosmological models under different gamma parameters. It finds that negative gamma promotes expansion and isotropy, while positive gamma retards expansion and keeps anisotropy, offering a potential alternative to dark energy.


<details>
  <summary>Details</summary>
Motivation: To explore how quantum effects (via noncommutative geometry) influence the early universe's anisotropies and expansion beyond classical (commutative) models.

Method: Applied noncommutative phase space framework (with gamma parameter) to Bianchi I and III models using Hamiltonian formulation with Schutz's fluid formalism. Solved numerically with varying initial conditions to examine gamma and energy density C's effects.

Result: Negative gamma enhances expansion and isotropization; positive gamma slows expansion and preserves anisotropy, especially in open (Bianchi III) models. Noncommutative effects were significant early on, fading over time.

Conclusion: Noncommutative geometry could be a viable alternative to the cosmological constant in explaining early universe dynamics, highlighting gamma's role in shaping expansion and isotropy evolution.

Abstract: Understanding the early evolution of the universe requires models that
incorporate possible quantum and anisotropic effects in its dynamics. In this
work, we analyze the dynamical evolution of locally rotationally symmetric
anisotropic cosmological models of Bianchi type I (flat curvature) and Bianchi
type III (open curvature) within a noncommutative phase space framework
characterized by a deformation parameter gamma. Using a Hamiltonian formulation
based on Schutz formalism for a perfect radiation fluid, we introduce
noncommutative Poisson brackets that allow for geometric corrections to
commutative dynamics. The resulting equations are solved numerically under
various initial conditions, enabling the study of the impact of gamma and the
energy density C on the universe expansion and anisotropy evolution. The
results show that gamma < 0 enhances expansion and favors isotropization, while
gamma > 0 tends to slow expansion and preserve residual anisotropy, especially
in the open curvature model. It is estimated that the influence of
non-commutativity was significant during the early stages of the universe,
decreasing toward the present time, suggesting that this approach could serve
as an effective alternative to the cosmological constant in describing the
evolution of the early universe.

</details>


### [35] [Distinguishing between Black Holes and Neutron Stars within a Population of Weak Tidal Measurements](https://arxiv.org/abs/2510.08832)
*Michael Müller,Reed Essick*

Main category: gr-qc

TL;DR: The study evaluates the effectiveness of using tidal signatures in gravitational wave (GW) inspiral signals to differentiate between neutron stars (NSs) and black holes (BHs), and to constrain the population fraction of NSs as a function of mass. It concludes that distinguishing NSs from low-mass BHs requires hundreds of GW events, achievable only with next-generation detectors like Cosmic Explorer and Einstein Telescope.


<details>
  <summary>Details</summary>
Motivation: To determine whether tidal effects in GW data can reliably distinguish NSs from BHs and quantify the number of observations needed to establish theNS population fraction in different mass ranges without relying on electromagnetic counterparts.

Method: Simulated GW catalogs with realistic measurement uncertainties were analyzed to assess the feasibility of measuring f_NS(m), the NS fraction as a function of mass. The study evaluated the required number of events to confidently distinguish NSs from BHs and constrain f_NS(m).

Result: Over 200 events are needed for precise measurement of f_NS, and over 100 events to rule out all low-mass objects being BHs using GW data alone. Current advanced detectors are insufficient, but next-generation facilities could achieve this.

Conclusion: While advanced detectors cannot yet determine NS/BH populations reliably, future detectors like Cosmic Explorer and Einstein Telescope will enable this, highlighting the importance of expanding GW observational capabilities.

Abstract: We study the ability of tidal signatures within the inspiral of compact
binaries observed through gravitational waves (GWs) to distinguish between
neutron stars (NSs) and black holes (BHs). After quantifying how hard this
measurement is on a single-event basis, we investigate the ability of a large
catalog of GW detections to constrain the fraction of NS in the population as a
function of mass: $f_{\mathrm{NS}}(m)$. Using simulated catalogs with realistic
measurement uncertainty, we find that $> O(200)$ events will be needed before
we can precisely measure $f_{\mathrm{NS}}$, and catalogs of $> O(100)$ events
will be needed before we can even rule out the possibility that all low-mass
objects are BHs with GW data alone (i.e., without electromagnetic
counterparts). Therefore, this is unlikely to occur with advanced detectors,
even at design sensitivity. Nevertheless, it could be feasible with
next-generation facilities like Cosmic Explorer and Einstein Telescope.

</details>


### [36] [Chaos of charged particles near a renormalized group improved Kerr black hole in an external magnetic field](https://arxiv.org/abs/2510.08954)
*Junjie Lu,Xin Wu*

Main category: gr-qc

TL;DR: The paper investigates how renormalization group corrections to the Kerr metric affect the dynamics of charged particles in an external magnetic field, finding that chaos strength is influenced by parameters like energy, magnetic field, angular momentum, and black hole spin, with quantum corrections reducing chaos.


<details>
  <summary>Details</summary>
Motivation: To explore the effects of quantum gravity corrections on the integrability of geodesic motion and to understand how external fields and particle properties influence chaotic behavior in such scenarios.

Method: The authors modified the Kerr metric by making the Newton's gravitational constant a function of radial distance. They analyzed the motion of neutral and charged particles, focusing on the transition to chaos using numerical simulations and statistical analysis.

Result: Neutral particles' motion remains integrable, but charged particles exhibit nonintegrable dynamics under an external magnetic field. Chaos strength increases with particle energy and magnetic field but decreases with angular momentum and black hole spin. Quantum corrections via the running gravitational constant reduce chaos by weakening gravitational attraction.

Conclusion: Quantum gravity effects, through renormalization group improvements, can significantly alter the dynamical behavior of particles around black holes, particularly reducing chaos. This highlights the importance of quantum corrections in understanding high-energy astrophysical phenomena.

Abstract: In a quantum theory of gravity, a renormalization group improved Kerr metric
is obtained from the Kerr metric, where the Newton gravitational constant is
modified as a function of the radial distance. The motion of neutral test
particles in this metric is integrable. However, the dynamics of charged test
particles is nonintegrable when an external asymptotically homogeneous magnetic
field exists in the vicinity of the black hole. The transition from regular
dynamics to chaotic dynamics is numerically traced as one or two dynamical
parameters vary. From a statistical point of view, the strength of chaos is
typically enhanced as both the particle energy and the magnetic field increase,
but it is weakened with increasing the particle angular momentum and the black
hole spin. In particular, an increase of the quantum corrected parameter
weakens the extent of chaos. This is because the running Newton gravity
constant effectively weakens the central gravitational attraction and results
in decreasing sensitivity to initial conditions.

</details>


### [37] [Gravitational lensing of gravitational waves: universal characteristics of strongly lensed memory waveforms](https://arxiv.org/abs/2510.09132)
*Ruanjing Zhang,Zhi-Chao Zhao,Shaoqi Hou,Xi-Long Fan,Kai Liao,Zong-Hong Zhu*

Main category: gr-qc

TL;DR: The paper explores how strong gravitational lensing affects the memory signal of gravitational waves, revealing that lensing acts as a high-pass filter, causing oscillatory waveforms with specific symmetries depending on the image type. These features aid in identifying image types and improving parameter estimation.


<details>
  <summary>Details</summary>
Motivation: To understand the impact of strong lensing on gravitational wave memory signals, enabling better identification of lensed image types and enhancing parameter estimation through tailored waveform templates.

Method: Analyzes the memory signal in the geometric optics limit, comparing lensed (oscillatory) vs. unlensed (monotonic) signals. Examines the role of high-frequency Fourier modes and the step-function nature of unlensed waveforms. Derives symmetry properties (odd/even) of lensed memory waveforms for different image types (I, II, III).

Result: Lensed memory signals exhibit universal symmetries (reflection about a time-axis) specific to image type: Type I and III are odd, Type II is even. The slope sign at the symmetry axis differs between Type I and III. These features are model-independent.

Conclusion: The identified symmetries provide a method to determine lensed image types using memory waveforms approximated by step functions. Combining this with space-based interferometer data allows for optimized gravitational wave parameter estimation using appropriate waveform templates.

Abstract: In this work, the strong lensing effect of the memory signal was considered.
In the geometric optics limit, the lensed memory signal becomes oscillatory,
while the unlensed is basically monotonic. This is because only the high
frequency Fourier modes contribute to the lensed signal. Therefore, the strong
lensing system serves as a high-pass filter for the memory signal. Due to the
step function like behavior of the unlensed memory waveform, the lensed
waveform possesses characteristic morphology that is dependent on the type of
the image, and independent of the lens model and the binary system. That is,
for each type of the lensed image, the lensed memory waveform has an
approxmiate reflection symmetry about a symmetrical axis in the time domain.
More specifically, for the type I and type III images, the lensed memory
signals are nearly odd under the reflection, while the type II signal is
roughly even. In addition, at the symmetrical axis, the sign of the slope for
type I image is different from that for the type III image. These universal
characteristic features would help determine the type of the lensed image. This
is particularly because the memory waveform can be well approximated by a
suitable step function, which involves two parameters. In addition, the
detection of multiple images by the space-borne interferometer would also be
helpful. Once the type of the lensed image is determined with the approximated
memory waveform, one can use the appropriate waveform template for the
oscillatory component of the gravitational wave to perform the parameter
estimation.

</details>


### [38] [Particle creation in a cosmological background in analogy to the Schwinger effect](https://arxiv.org/abs/2510.09481)
*Walter D. van Suijlekom,Michael F. Wondrak,Heino Falcke*

Main category: gr-qc

TL;DR: The paper explores the gravitational analogue of the Schwinger effect in an FLRW spacetime, using Heun equations to calculate particle production probabilities. It finds a frequency threshold and black-body radiation with temperature linked to the apparent horizon's radius.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the Schwinger effect's dependency on a switching electric field and the authors' prior work on gravitational particle production. They aim to rigorously apply this to a cosmological context using a long gravitational pulse to mimic a static background.

Method: The method involves solving the Heun equation to derive connecting formulas for Bogolyubov coefficients, determining particle production probabilities in the limit of an infinitely long gravitational pulse in FLRW spacetime.

Result: Key results include a lower frequency threshold for particle production tied to background field duration and black-body radiation with temperature inversely proportional to the apparent horizon's radius in the flat case. Comparisons to Schwinger's electromagnetic results are provided.

Conclusion: The study confirms gravitational Schwinger-like particle production in cosmological settings, highlighting differences from electromagnetic cases due to spacetime curvature effects and the role of the apparent horizon.

Abstract: We consider a gravitational analogue of the Schwinger effect in a
cosmological context. While the Schwinger effect is usually attributed to a
static electric background, its derivation is actually based on a switching
on/off of the electric field in the infinite past/future. Motivated by this,
and our previous work on particle production in a gravitational background, we
consider a long pulse of the gravitational field in an FLRW-spacetime, thus
simulating a static background. We rigorously derive particle production by a
novel application of the Heun equation. In fact, the recently obtained
connecting formulas between its local solutions can be used to determine the
Bogolyubov coefficients, and subsequently the particle production
probabilities, in the limit of an infinitely long pulse.
  The particle production in the FLRW-model is found to have a lower threshold
on the outgoing frequencies, which can be related to the duration of the time
interval of the switching on/off the background field. For large frequencies
and in the spatially flat case, we find black-body radiation whose temperature
is inversely proportional to the radius of the apparent horizon that appears in
the FLRW-model during the phase of scale change.
  We compare our findings to Schwinger's result on particle production for a
long pulse of an electromagnetic background field, for which we also include a
detailed derivation.

</details>


### [39] [A physically interesting singularity in general relativity](https://arxiv.org/abs/2510.09506)
*Bob Holdom*

Main category: gr-qc

TL;DR: The paper investigates a benign timelike and naked singularity in an inhomogeneous generalization of the Einstein static universe, finding that the singularity's Weyl curvature scalar is finite, the spacetime remains causally geodesically complete, and singularities contribute to Komar mass, allowing a smaller positive cosmological constant. In expanding universes, these singularities enhance acceleration.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of singularities in inhomogeneous spacetimes and their effects on cosmological parameters like the cosmological constant and accelerate expansion.

Method: Generalizing the Einstein static universe model to include inhomogeneities, analyzing the resulting singularity's properties using Weyl curvature and Komar mass calculations.

Result: The singularity is found to be benign with finite energy density, spacetime maintains causal completeness, singularities reduce required cosmological constant size, and they promote accelerated expansion in expanding models.

Conclusion: Naked singularities in such models can compatibly exist with physical conditions, influence cosmological dynamics, and offer new insights into accelerated expansion mechanisms without requiring excessively large cosmological constants.

Abstract: We explore what appears to be a very benign timelike and naked singularity of
the Weyl curvature scalar. This singularity arises in an inhomogeneous
generalization of the Einstein static universe. The matter energy density is
everywhere finite and it vanishes at the singularity. The spacetime still
enjoys causal geodesic completeness and unambiguous wave dynamics. Each
singularity contributes to the Komar mass of the spacetime, and this reduces
the required size of the positive cosmological constant. In an expanding
universe, the effect of the singularities is to push the acceleration towards
more positive values.

</details>


### [40] [Theoretical filters for shift-symmetric Horndeski gravities](https://arxiv.org/abs/2510.09547)
*Athanasios Bakopoulos,Christos Charmousis,Nikos Chatzifotis,Theodoros Nakas*

Main category: gr-qc

TL;DR: The paper examines nontrivial maximally symmetric vacua and compact-object solutions in shift-symmetric scalar-tensor theories, particularly Horndeski gravity. It introduces stealth vacua where an active scalar field doesn't alter the vacuum and derives solutions using disformal transformations on Einstein-Gauss-Bonnet black holes. The work offers criteria for viable Horndeski models and explores beyond-Horndeski gravities.


<details>
  <summary>Details</summary>
Motivation: To identify subclasses of scalar-tensor theories that support nontrivial scalar-field vacua without modifying the metric (stealth vacua), establish a data-independent filtering mechanism, and explore exact solutions in extended gravitational theories to understand scalar hair and spacetime modifications.

Method: Deriving consistency conditions from field equations for Horndeski gravity, constructing exact solutions via linear disformal transformations applied to regularized Einstein-Gauss-Bonnet black holes, and analyzing parameter spaces where transformations remain valid.

Result: Discovered subclasses of Horndeski theories admitting Minkowski/de Sitter vacua with active scalars (stealth vacua), derived exact solitonic spacetimes and hairy black holes in beyond-Horndeski gravity, established criteria to select viable models without observational data.

Conclusion: Demonstrates how disformal mappings qualitatively alter solutions and provides foundational tools for selecting theoretical models and exploring solution spaces in modified gravity theories without relying on observational data.

Abstract: We investigate the structure of nontrivial maximally symmetric vacua and
compact-object solutions in shift-symmetric scalar-tensor theories. Focusing on
Horndeski gravity, we derive consistency conditions directly from the field
equations to identify the subclasses that admit Minkowski and de Sitter vacua
with a nontrivial scalar field. In doing so, we obtain a filtering mechanism
that operates independently of observational data. In this context, we
introduce the notion of stealth vacua, where the scalar field remains active
without altering the vacuum. Following this, we examine the theoretical
framework of Horndeski theories that admit homogeneous geometries and we
extract the implicit form of the solution pertaining to the entire family of
theories. Building upon these frameworks, we construct exact solutions in
beyond-Horndeski gravity by applying a linear disformal transformation to the
regularized Einstein-Gauss-Bonnet black hole. This procedure yields solitonic
spacetimes with scalar hair as well as black holes carrying primary scalar
hair, demonstrating how disformal maps can qualitatively modify solution
properties. We delineate the parameter space in which the transformation is
well-defined and analyze the solutions. Our results provide both a principled
criterion for selecting viable Horndeski models and a framework for exploring
rich solution spaces in beyond-Horndeski gravity.

</details>


### [41] [Particles with precessing spin in Kerr spacetime: analytic solutions for eccentric orbits and homoclinic motion near the equatorial plane](https://arxiv.org/abs/2510.09597)
*Gabriel Andres Piovano*

Main category: gr-qc

TL;DR: The paper presents analytic solutions for nearly-equatorial motion of a spinning test particle in Kerr spacetime, including eccentric and homoclinic orbits, and introduces a new 'fixed eccentricity spin gauge' parametrization.


<details>
  <summary>Details</summary>
Motivation: The motivation is to extend analytical solutions beyond geodesic approximations by incorporating spin effects, improving modeling of inspiral and transition-to-plunge phases in asymmetric mass binaries, particularly within the two-time-scale framework.

Method: The method involves solving the equations of motion for a test particle with precessing spin up to linear order in spin, using Legendre elliptic integrals and Jacobi elliptic functions for eccentric orbits. Homoclinic orbits are derived using closed-form elementary functions and a new spin gauge is introduced.

Result: The solutions match numerical data from prior studies, provide first analytical homoclinic orbits in Kerr spacetime, and demonstrate that the new spin gauge ensures finite corrections near separatrix while smoothly connecting to last stable orbits.

Conclusion: The findings enhance the ability to model extreme mass ratio inspirals, especially in capturing spin-dependent effects during inspiral and plunge phases, validating the approach against numerical results and offering a robust framework for future gravitational wave studies.

Abstract: We present a family of analytic solutions for the nearly-equatorial motion of
a test particle with precessing spin in Kerr spacetime. We solve the equations
of motion up to linear order in the small body's spin for periodic and
homoclinic orbits. At zero order, the particle moves along equatorial
geodesics. The spin-curvature force introduces post-geodesic corrections which,
for generic spin orientations, cause the precession of the orbital plane. We
derive the solutions for eccentric orbits in terms of Legendre elliptic
integrals and Jacobi elliptic functions for generic referential geodesics
(known as ``spin gauges"). Our analytical solutions perfectly match the
numerical trajectories obtained by Drummond and Hughes in Phys. Rev. D 105,
124041 (2022), and Piovano et al. in Phys. Rev. D 111, 044009 (2025).
Furthermore, we present, for the first time, the solutions for homoclinic
orbits for a spinning particle in Kerr spacetime, and the spin-corrections to
the location of the separatrix. The homoclinic trajectories are described in
closed form using elementary functions. Finally, we introduce a novel
parametrization for the motion of a spinning particle, called ``fixed
eccentricity spin gauge". The latter is the only spin gauge in which the
corrections to periodic orbits are finite at the geodesic separatrix, and
continuously reduce to the last stable orbits under appropriate limits. Our
results will be useful for modeling the inspiral and transition-to-plunge
phases of asymmetric mass binaries within the two-time-scale framework.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [42] [Foundation Models for Astrobiology: Paper I -- Workshop and Overview](https://arxiv.org/abs/2510.08636)
*Ryan Felton,Caleb Scharf,Stuart Bartlett,Nathalie A. Cabrol,Victoria Da Poian,Diana Gentry,Jian Gong,Adrienne Hoarfrost,Manil Maskey,Floyd Nichols,Conor A. Nixon,Tejas Panambur,Joseph Pasterski,Anton S. Petrov,Anirudh Prabhu,Brenda Thomson,Hamed Valizadegan,Kimberley Warren-Rhodes,David Wettergreen,Michael L. Wong,Anastasia Yanchilina*

Main category: astro-ph.IM

TL;DR: The paper discusses the potential of Foundation Models in astrobiology, highlighting their ability to integrate disparate data and reduce development costs. It presents workshop findings on developing models for biosignature detection, mission operations, and natural language processing support.


<details>
  <summary>Details</summary>
Motivation: The motivation is to leverage Foundation Models' versatility and scalability for astrobiology research, addressing challenges in data integration and reducing resource demands for developing specialized applications.

Method: The analysis is based on a workshop conducted by NASA Ames and SETI Institute, assessing current Foundation Models in agencies like NASA (e.g., Prithvi) and ESA (TerraMind), and identifying application areas through collaborative discussion.

Result: The workshop identified actionable steps for building astrobiology-focused Foundation Models, emphasizing near-term and future opportunities across biosignature detection, mission development, and natural language tasks.

Conclusion: Foundation Models offer transformative potential for astrobiology by enabling efficient data synthesis and interdisciplinary research. Prioritizing model development and interdisciplinary collaboration is recommended to advance astrobiology objectives.

Abstract: Advances in machine learning over the past decade have resulted in a
proliferation of algorithmic applications for encoding, characterizing, and
acting on complex data that may contain many high dimensional features.
Recently, the emergence of deep-learning models trained across very large
datasets has created a new paradigm for machine learning in the form of
Foundation Models. Foundation Models are programs trained on very large and
broad datasets with an extensive number of parameters. Once built, these
powerful, and flexible, models can be utilized in less resource-intensive ways
to build many different, downstream applications that can integrate previously
disparate, multimodal data. The development of these applications can be done
rapidly and with a much lower demand for machine learning expertise. And the
necessary infrastructure and models themselves are already being established
within agencies such as NASA and ESA. At NASA this work is across several
divisions of the Science Mission Directorate including the NASA Goddard and
INDUS Large Language Models and the Prithvi Geospatial Foundation Model. And
ESA initiatives to bring Foundation Models to Earth observations has led to the
development of TerraMind. A workshop was held by the NASA Ames Research Center
and the SETI Institute, in February 2025, to investigate the potential of
Foundation Models for astrobiological research and to determine what steps
would be needed to build and utilize such a model or models. This paper shares
the findings and recommendations of that workshop, and describes clear
near-term, and future opportunities in the development of a Foundation Model
(or Models) for astrobiology applications. These applications would include a
biosignature, or life characterization, task, a mission development and
operations task, and a natural language task for integrating and supporting
astrobiology research needs.

</details>


### [43] [The Astronomical Plate Digitization at SHAO](https://arxiv.org/abs/2510.08643)
*Yong Yu,Meiting Yang,Zhengjun Shang,Liangliang Wang,Jing Yang,Zhenghong Tang,Jianhai Zhao,Massinissa Hadjara*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The digitization of historical astronomical plates is essential for
preserving century-long observational data. This work presents the development
and application of the specialized digitizers at the Shanghai Astronomical
Observatory (SHAO), including technical details, international collaborations,
and scientific applications on the plates.

</details>


### [44] [Identification of molecular line emission using Convolutional Neural Networks](https://arxiv.org/abs/2510.09119)
*Nina Kessler,Timea Csengeri,David Cornu,Sylvain Bontemps,Laure Bouscasse*

Main category: astro-ph.IM

TL;DR: The paper introduces a machine learning approach using CNNs to identify complex organic molecules (COMs) in millimeter spectra, demonstrating robust detection probabilities with minimal false positives in both synthetic and real data.


<details>
  <summary>Details</summary>
Motivation: COMs are abundant in star-forming regions but their complex spectra with many blended lines complicate analysis. A reliable method is needed to detect molecular signatures amid this complexity.

Method: The authors developed a supervised CNN trained on LTE-generated synthetic spectra of 20 molecules under varying star-forming conditions. The model outputs per-species detection probabilities considering noise, frequency coverage, and spectral complexity.

Result: The CNN achieved high detection accuracy without false positives in synthetic tests and applied successfully to observational data from hot-core sources, showing practical utility for analyzing real-world spectra.

Conclusion: CNN-based analysis effectively tackles challenges of blended millimeter spectra, enabling quantitative molecular identification in astrophysical environments and setting a precedent for machine learning in spectral interpretation.

Abstract: Complex organic molecules (COMs) are observed to be abundant in various
astrophysical environments, in particular toward star forming regions they are
observed both toward protostellar envelopes as well as shocked regions.
Emission spectrum especially of heavier COMs may consists of up to hundreds of
lines, where line blending hinders the analysis. However, identifying the
molecular composition of the gas leading to the observed millimeter spectra is
the first step toward a quantitative analysis. We develop a new method based on
supervised machine learning to recognize spectroscopic features of the
rotational spectrum of molecules in the 3mm atmospheric transmission band for a
list of species including COMs with the aim to obtain a detection probability.
We used local thermodynamic equilibrium (LTE) modeling to build a large set of
synthetic spectra of 20 molecular species including COMs with a range of
physical conditions typical for star forming regions. We successfully designed
and trained a Convolutional Neural Network (CNN) that provides detection
probabilities of individual species in the spectra. We demonstrate that the
produced CNN-model has a robust performance to detect spectroscopic signatures
from these species in synthetic spectra. We evaluate its ability to detect
molecules according to the noise level, frequency coverage, and line-richness,
and also test its performance for incomplete frequency coverage with high
detection probabilities for the tested parameter space, and no false
predictions. Ultimately, we apply the CNN-model to obtain predictions on
observational data from the literature toward line-rich hot-core like sources,
where detection probabilities remain reasonable with no false detection. We
prove the use of CNNs facilitating the analysis of complex millimeter spectra
both on synthetic spectra as well as first tests on observational data.

</details>


### [45] [deep-REMAP: Probabilistic Parameterization of Stellar Spectra Using Regularized Multi-Task Learning](https://arxiv.org/abs/2510.09362)
*Sankalp Gilda*

Main category: astro-ph.IM

TL;DR: Developed deep-REMAP, a deep learning framework using a regularized multi-task approach to predict stellar parameters from spectra. Trained on synthetic data and fine-tuned on MARVELS observed spectra, achieving high precision in T_eff, log g, and [Fe/H]. The method is interpretable, robust to imbalances, and applicable to other surveys.


<details>
  <summary>Details</summary>
Motivation: Traditional spectroscopic analysis methods are overwhelmed by increasing survey data volumes. There is a need for automated, scalable solutions to accurately characterize large numbers of stellar spectra.

Method: A deep convolutional neural network trained on PHOENIX synthetic spectra, then fine-tuned via transfer learning on MARVELS FGK dwarf spectra. Uses an asymmetric loss function and embedding loss in a regression-as-classification framework to handle parameter imbalances and capture non-Gaussian uncertainties.

Result: Accurate parameter recovery (e.g., ~75 K precision in T_eff) on MARVELS calibration stars. Applied to 732 uncharacterized FGK giant candidates, demonstrating scalability. The model shows robustness and interpretability.

Conclusion: deep-REMAP provides an efficient, automated method for stellar parameter estimation. Its framework is adaptable to other surveys and synthetic libraries, offering a promising solution for handling large-scale spectroscopic data.

Abstract: In the era of exploding survey volumes, traditional methods of spectroscopic
analysis are being pushed to their limits. In response, we develop deep-REMAP,
a novel deep learning framework that utilizes a regularized, multi-task
approach to predict stellar atmospheric parameters from observed spectra. We
train a deep convolutional neural network on the PHOENIX synthetic spectral
library and use transfer learning to fine-tune the model on a small subset of
observed FGK dwarf spectra from the MARVELS survey. We then apply the model to
732 uncharacterized FGK giant candidates from the same survey. When validated
on 30 MARVELS calibration stars, deep-REMAP accurately recovers the effective
temperature ($T_{\rm{eff}}$), surface gravity ($\log \rm{g}$), and metallicity
([Fe/H]), achieving a precision of, for instance, approximately 75 K in
$T_{\rm{eff}}$. By combining an asymmetric loss function with an embedding
loss, our regression-as-classification framework is interpretable, robust to
parameter imbalances, and capable of capturing non-Gaussian uncertainties.
While developed for MARVELS, the deep-REMAP framework is extensible to other
surveys and synthetic libraries, demonstrating a powerful and automated pathway
for stellar characterization.

</details>


### [46] [Hierarchical Progressive Survey (HiPS) format: moving from visualisation to scientific analysis](https://arxiv.org/abs/2510.09533)
*Fabrizio Giordano,Yago Ascasibar,Luca Cortese,Ivan Valtchanov,Bruno Merín*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Context. In the current era of multi-wavelength and multi-messenger
astronomy, international organisations are actively working on the definition
of new standards for the publication of astronomical data, and substantial
effort is devoted to make them available through public archives. Aims. We
present a set of tools that allow user-friendly access and basic scientific
analysis of observations in Hierarchical Progressive Survey (HiPS) format, and
we use them to gauge the quality of representative skymaps at ultraviolet,
optical, and infrared wavelengths. Methods. We apply a fully-automatic
procedure to derive aperture photometry in 10 different bands for the 323
nearby galaxies in the Herschel Reference Sample (HRS), and compare its results
with the rigorous analyses involving specialised knowledge and human
intervention carried out by the HRS team. Results. Our experiment shows that 9
of the 10 skymaps considered preserve the original quality of the data, and the
photometric fluxes returned by our pipeline are consistent with the HRS
measurements within a few per cent. In the case of Herschel PACS maps at 100
{\mu}m, we uncovered a systematic error that we ascribe to an inconsistent
combination of data products with different spatial resolution. For the
remaining skymaps, the estimated statistical uncertainties provide a realistic
indication of the differences with respect to the HRS catalogue. Conclusions.
In principle, the currently available HiPS skymaps in Flexible Image Transport
System (FITS) format allow to carry out broadband photometric analyses with an
accuracy of the order of a few percent, but some level human intervention is
still required. In addition to assessing data quality, we also propose a series
of recommendations to realise the full potential of the HiPS format for the
scientific analysis of large astronomical data sets.

</details>
