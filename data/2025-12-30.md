<div id=toc></div>

# Table of Contents

- [hep-ph](#hep-ph) [Total: 43]
- [gr-qc](#gr-qc) [Total: 33]
- [astro-ph.HE](#astro-ph.HE) [Total: 14]
- [astro-ph.IM](#astro-ph.IM) [Total: 8]


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [1] [Temperature Dependence of the Masses of Various Meson States: A Comparative Study in SU(3) and SU(4) extended Linear-Sigma Model](https://arxiv.org/abs/2512.22198)
*Alexandra Friesen,Yu. Kalinovsky,Norhan M. Rfeek,Azzah A. Alshehri,Abdel Nasser Tawfik*

Main category: hep-ph

TL;DR: The study investigates the chiral phase structure of mesons in the extended Linear-Sigma Model (eLSM) using SU(3) and SU(4) configurations, finding that SU(4) better aligns with experimental data. Meson masses show distinct temperature dependencies, though dissolution temperatures are similar. Quarkonium states remain stable under temperature changes.


<details>
  <summary>Details</summary>
Motivation: To compare SU(3) and SU(4) configurations in the eLSM for accuracy in meson mass predictions and understand temperature effects on meson masses and phase transitions.

Method: Applied mean-field approximation in eLSM to analyze meson states (pseudoscalars, scalars, vectors, axial-vectors) under SU(3) and SU(4) frameworks. Systematically compared mass estimations and temperature dependencies of these states.

Result: SU(4) eLSM yields meson masses closer to experimental values. Temperature affects meson masses uniquely, but dissolution temperatures are similar across states. Quarkonium masses are insensitive to temperature changes.

Conclusion: Increasing quark degrees of freedom (SU(4)) improves meson mass simulation accuracy. Phase transitions exhibit slight variations across meson states, but quarkonium states remain stable with temperature.

Abstract: In the extended Linear-Sigma Model (eLSM), the chiral phase structure of meson states, including pseudoscalars ($J^{pc}=0^{-+}$), scalars ($J^{pc}=0^{++}$), vectors ($J^{pc}=1^{--}$), and axial-vectors ($J^{pc}=1^{++}$), is investigated with the mean-field approximation. A systematic comparison between SU(3) and SU(4) configurations is provided. It has been found that the estimations of meson masses derived from SU(4) eLSM are more congruent with experimental values than those derived from SU(3) eLSM. Consequently, we conclude that an increase in quark degrees of freedom significantly enhances the accuracy of meson mass simulations. We investigate the effect of temperature on the masses of various meson states calculated in the SU(3) and SU(4) eLSM. After establishing all the fitting parameters, the temperature dependence of meson masses shows that although various meson states exhibit unique patterns in their mass changes with temperature, they all seem to share a similar range of dissolution temperatures. This means that the critical temperature that marks the phase transition from hadrons to quarks appears to vary slightly depending on the meson states. In this regard, we find that the quarkonium states, formed by a quark and its antiquark, are largely unaffected by variations in the temperature.

</details>


### [2] [Gravitational waves from seesaw assisted collapsing domain walls](https://arxiv.org/abs/2512.22339)
*Debasish Borah,Indrajit Saha*

Main category: hep-ph

TL;DR: The paper explores the connection between quantum corrections from heavy right-handed neutrinos (RHNs) in the type-I seesaw model and the spontaneous breaking of Z₂ symmetry, which generates bias terms to annihilate domain walls. This process also produces stochastic gravitational waves (GWs) with detectable peak amplitude and frequency. Additionally, in flavor-symmetric models with degenerate RHNs, the tiny couplings to a Z₂-odd scalar can cause small mass splittings, enabling resonant leptogenesis to explain the Universe's baryon asymmetry.


<details>
  <summary>Details</summary>
Motivation: The motivation is twofold: first, to resolve the cosmological domain wall problem caused by spontaneous Z₂ symmetry breaking by introducing quantum-generated bias terms that annihilate domain walls and emit GWs. Second, to link these processes with the seesaw mechanism for neutrino masses and resonant leptogenesis, providing testable predictions for GW observations and CMB measurements.

Method: The authors consider heavy RHNs in the type-I seesaw model, which induce Z₂-breaking bias terms via quantum corrections. They calculate the resulting gravitational wave spectrum's peak amplitude and frequency as functions of the seesaw scale. In flavor-symmetric scenarios with degenerate RHNs, they analyze how small mass splittings from these couplings can achieve resonant conditions for leptogenesis.

Result: The study establishes correlations between the seesaw scale, GW peak characteristics, and the baryon asymmetry explained via resonant leptogenesis. These predictions are observable through gravitational wave detectors and CMB experiments, offering a pathway to test the model's validity.

Conclusion: The proposed mechanism connects particle physics (seesaw mechanism, leptogenesis) with cosmological observables (domain walls, GWs, CMB). It highlights the potential for future experiments to probe ultrahigh energy scales and validate scenarios where particle physics beyond the Standard Model resolves cosmological puzzles.

Abstract: Spontaneous breaking of discrete symmetries like $Z_2$ leads to the formation of stable topological defects such as domain walls which, if allowed to dominate, can potentially be in conflict with cosmological observations. Incorporating explicit $Z_2$-breaking bias terms can lead to annihilation of such walls while also emitting stochastic gravitational wave (GW). We study the role of heavy right-handed neutrinos present in type-I seesaw origin of light neutrino masses to generate such bias term via quantum corrections. This offers interesting correlation among the seesaw scale, GW peak amplitude and peak frequency which can be probed at present and future experiments related to GW as well as precision measurements of the cosmic microwave background (CMB). In flavor symmetric UV complete scenarios with degenerate RHNs at leading order, such tiny coupling of RHNs to a $Z_2$-odd scalar can also lead to small mass splittings suitable for explaining the observed baryon asymmetry of the universe via resonant leptogenesis.

</details>


### [3] [Minimal A4 Type-II Seesaw Realization of Testable Neutrino Mass Sum Rules](https://arxiv.org/abs/2512.22343)
*Salvador Centelles Chuliá,Ranjeet Kumar*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose a flavour model based on an $A_4$ symmetry combined with a type-II seesaw mechanism for neutrino mass generation. The resulting neutrino mass matrix obeys a sum rule that, together with the measured mass-squared differences, fully determines the absolute neutrino mass spectrum. The constrained flavour structure yields correlated predictions for lepton mixing parameters, leads to inverted ordering after imposing mixing constraints, restricts the Majorana phases and implies a neutrinoless double beta decay rate close to its maximal value for inverted ordering. In the charged lepton sector an approximate triality symmetry arises in the seesaw limit, suppressing muon flavour-violating processes and allowing only specific $τ$ decay channels. The model provides a tightly constrained and experimentally testable framework linking neutrino masses, lepton mixing and lepton-number-violating observables.

</details>


### [4] [Can high-$p_\perp$ theory and data constrain $η/s$?](https://arxiv.org/abs/2512.22358)
*Bithika Karmakar,Dusan Zigic,Igor Salom,Jussi Auvinen,Pasi Huovinen,Marko Djordjevic,Magdalena Djordjevic*

Main category: hep-ph

TL;DR: The paper analyzes the temperature dependence of the specific shear viscosity (η/s) of QCD matter created in heavy-ion collisions, using high-p_⊥ data and energy loss mechanisms to constrain η/s(T).


<details>
  <summary>Details</summary>
Motivation: To better characterize QCD matter properties by overcoming the weak sensitivity of low-p_⊥ data to η/s(T), especially at high temperatures.

Method: Utilizes high-p_⊥ particle data and a theoretical framework involving dynamical radiative and collisional energy loss to constrain the temperature dependence of η/s.

Result: The approach successfully imposes additional constraints on η/s(T) where traditional methods (low-p_⊥) are insufficient.

Conclusion: High-p_⊥ data combined with energy loss mechanisms provide a promising method for precisely determining the temperature dependence of η/s in QCD matter.

Abstract: Understanding the temperature dependence of the specific shear viscosity $(η/s)$ is crucial for characterizing the properties of the QCD matter produced in ultrarelativistic heavy-ion collisions. Since, low-$p_\perp$ theory and data are only weakly sensitive to the typical forms of $η/s(T)$, especially at high temperatures, we use high-$p_\perp$ data and theory to impose additional constraints on it. Our approach, based on dynamical radiative and collisional energy loss of high-$p_\perp$ particles, provides promising results in constraining the temperature dependence of $η/s$.

</details>


### [5] [Orbital angular momentum in the pion and kaon: rest-frame and light-front](https://arxiv.org/abs/2512.22359)
*Y. -Y. Xiao,Z. -N. Xu,Z. -Q. Yao,C. D. Roberts,J. Rodríguez-Quintero*

Main category: hep-ph

TL;DR: The paper examines the role of observer-dependent orbital angular momentum (OAM) in hadron wave functions, despite its lack of Poincaré invariance, by analyzing pion and kaon structures using Schwinger function methods. Results show pions and kaons have significant intrinsic OAM components (50/50 and 60/40 mixes), implying all hadrons require OAM consideration in observable calculations.


<details>
  <summary>Details</summary>
Motivation: To address how OAM, though observer-dependent, contributes to hadron structure in Poincaré-invariant QCD and its impact on pion/kaon observables.

Method: Continuum Schwinger function methods applied to light-front Bethe-Salpeter wave functions for analyzing OAM contributions in pion and kaon systems.

Result: Pions show ~50% OAM=0 and 50% OAM=1 components; kaons ~60%/40%. This indicates significant intrinsic OAM in these hadrons, necessitating its inclusion in observable calculations.

Conclusion: Hadrons, particularly Nambu-Goldstone modes, have substantial Poincaré-invariant intrinsic OAM contributions, requiring explicit consideration in theoretical models for accurate observable predictions.

Abstract: Orbital angular momentum (OAM) is not a Poincaré invariant quantity; so, its value is observer dependent. Notwithstanding that, in quantum chromodynamics, a Poincaré-invariant theory, OAM is part of every hadron wave function. Using continuum Schwinger function methods, we elucidate both the subjective character of in-hadron OAM and expose some of its impacts on pion and kaon structure and observables. For instance, working with light-front projections of their Bethe-Salpeter wave functions, it is found that the pion is a roughly 50/50 mix of light-front OAM zero and one components and the kaon is a 60/40 system. The overall picture is that (near) Nambu-Goldstone modes are complex bound states, each with significant intrinsic OAM, independent of the observer's reference frame. This feature must be accounted for in the calculation of observables. Inductively, the same is true for all hadrons.

</details>


### [6] [Nonequilibrium QCD in heavy-ion collisions: Kinetic theory and jet modifications during the initial stages](https://arxiv.org/abs/2512.22384)
*Florian Lindenbauer*

Main category: hep-ph

TL;DR: This thesis examines how jets are modified by the nonequilibrium quark-gluon plasma during the initial stages of heavy-ion collisions. It derives the jet quenching parameter $â q$ throughout the pre-equilibrium stage, computes an elastic collision kernel, enhances QCD simulations with HTL screening, and identifies a new weak-coupling attractor for better modeling plasma dynamics.


<details>
  <summary>Details</summary>
Motivation: To understand jet-medium interactions during the pre-equilibrium phase of heavy-ion collisions and improve kinetic theory simulations with realistic plasma dynamics.

Method: Derivation of the dipole cross section's small distance behavior ($â q$), Fourier transform to obtain the collision kernel, implementation of HTL screening in kinetic simulations, and analysis of gluon splitting rates using anisotropic kernels.

Result: Computed $â q$ values comparable to the Glasma stage, reduced plasma anisotropy and $η/s$, significant differences in splitting rates with anisotropic kernels, and discovery of a novel weak-coupling attractor ratio.

Conclusion: The improved kinetic theory models and new attractor provide enhanced understanding of nonequilibrium QCD plasma equilibration and hydrodynamization processes during the initial stages of heavy-ion collisions.

Abstract: This thesis focuses on how jets are modified by the nonequilibrium quark-gluon plasma during the initial stages in heavy-ion collisions. Its influence on their propagation is typically encoded in a single medium function, the dipole cross section. Its small distance behavior is characterized by the jet quenching parameter $\hat q$, and we obtain its numerical value throughout the pre-equilibrium stage, finding values comparable in magnitude to the earlier Glasma stage. We also compute the more general elastic collision kernel, obtained by Fourier transforming the dipole cross section. This constitutes an important step to facilitate the understanding of jet-medium interactions during the initial stages in heavy-ion collisions. Additionally, we improve QCD kinetic theory simulations by employing a more realistic (HTL) screening mechanism to incorporate medium effects, which we compare with simpler screening mechanisms. An expanding plasma realized in the initial stages of heavy-ion collisions exhibits a significantly reduced maximum anisotropy and reduced specific shear viscosity $η/s$ when using the improved screening prescription. Moreover, we investigate the gluon splitting rates, which are typically obtained using an isotropic model for the collision kernel. Going beyond that approximation, we find that the splitting rates obtained from the nonequilibrium anisotropic kernel differ significantly both in magnitude and in their qualitative time evolution. We further identify a novel type of weak-coupling attractor, which can be observed in the ratio of the jet quenching parameter and pressure ratio, and is obtained by extrapolating to vanishing coupling. This improved kinetic theory description and novel limiting attractors contribute towards a more realistic modeling of the nonequilibrium QCD plasma and its equilibration and hydrodynamization process during the initial stages.

</details>


### [7] [Unveiling Primordial Black Hole Relics Through Induced Gravitational Waves](https://arxiv.org/abs/2512.22450)
*Misao Sasaki,Jianing Wang*

Main category: hep-ph

TL;DR: The paper explores the possibility that remnants of primordial black holes (PBHs) could constitute dark matter, with their number density and properties inferred from gravitational wave signals.


<details>
  <summary>Details</summary>
Motivation: To investigate whether PBH remnants, formed from evaporated tiny PBHs before BBN, can account for dark matter and determine their detectability via gravitational waves.

Method: Analyzing the relationship between PBH relic number density, gravitational wave peak frequency/amplitude, and their connection to dark matter density and initial PBH abundance.

Result: For Planck-mass PBH relics composing all DM, a number density of ~10^-25 cm^-3 and peak 60 Hz gravitational wave frequency is predicted. Amplitude could be detectable by future experiments for specific PBH parameters.

Conclusion: Gravitational wave observatories might validate PBH relics as dark matter by measuring frequency/ amplitude linked to relic density and initial PBH abundance.

Abstract: Black hole relics are of significant interest in cosmology and theoretical physics. In this work, we consider tiny primordial black holes (PBHs) ( $M_{\text {PBH }} \lesssim 10^7 \mathrm{~g}$ ) which are generated soon after the end of inflation and evaporate and reheat the Universe before big bang nucleosynthesis (BBN), but leave their remnants due to incomplete evaporation. These PBHs remnants may contribute as part or all of the dark matter (DM) today. Assuming that there exist PBH relics, we point out that the number density of PBH today can be directly read from the peak positions of the induced gravitational waves due to the inhomogeneous PBH distribution. If PBH relics are of Planck mass and they forms all the DM today, the PBH number density would be of $10^{-25} \mathrm{~cm}^{-3}$ with the peak frequency 60 Hz . The peak frequency scales as $f_{\text {relic }}^{1 / 3}$ where $f_{\text {relic }}$ is the fraction of the PBH relics in the total DM density. The peak amplitude carries the information of initial PBH abundance. For monochromatic-mass PBH with the current number density $10^{-41} \sim 10^{-25} \mathrm{~cm}^{-3}$ and initial abundance $10^{-13} \sim 10^{-7}$, the amplitude may be large enough to be detected by planned gravitational wave experiments in the near future.

</details>


### [8] [Quark Coalescence: Formation of Mesons Including Excited States](https://arxiv.org/abs/2512.22465)
*R. J. Fries,P. Virupapuram,J. Purcell,H. Anconetani,W. Lippincott,S. Robicheaux,M. Kordell,C. M. Ko*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We discuss the quantum mechanics of coalescence of quark-antiquark pairs into mesons using a non-relativistic quark model. We derive the coalescence probabilities assuming a harmonic oscillator potential and generic Gaussian wave packet shapes for the initial quarks and antiquarks. Our particular emphasis is on modeling excited states of the meson spectrum consistently. We provide the formalism to systematically include excited states from the Particle Data Book, and many more predicted by the quark model, up to $L=4$ and masses of about 2.2 GeV for light flavors. We provide estimates of masses and decay branching ratios for unconfirmed states. We use a phase space picture which is appropriate for the quasi-classical nature of the information typically available for the quarks and antiquarks in applications like Monte Carlo simulations. We demonstrate that for typical parton configurations expected in jets, excited meson states are populated abundantly.

</details>


### [9] [Defect Formation in NaI Crystals: A Novel Pathway to Dark Matter Detection](https://arxiv.org/abs/2512.23553)
*G. Angloher,M. R. Bharadwaj,A. Böhmer,M. Cababie,I. Colantoni,I. Dafinei,N. Di Marco,C. Dittmar,F. Ferella,F. Ferroni,S. Fichtinger,A. Filipponi,T. Frank,M. Friedl,D. Fuchs,L. Gai,M. Gapp,M. Heikinheimo,M. N. Hughes,K. Huitu,M. Kellermann,R. Maji,M. Mancuso,L. Pagnanini,F. Petricca,S. Pirro,F. Pröbst,G. Profeta,A. Puiu,F. Reindl,K. Schäffner,J. Schieck,P. Schreiner,C. Schwertner,P. Settembri,K. Shera,M. Stahlberg,A. Stendahl,M. Stukel,C. Tresca,S. Yue,V. Zema,Y. Zhu,N. Zimmermann,M. Di Giambattista,F. Giannessi,R. Rollo*

Main category: hep-ph

TL;DR: The study examines defect formation in NaI crystals caused by dark matter collisions using molecular dynamics and DFT, exploring their impact on dark matter detection and proposing defects as a new detection mechanism through electronic band gap modifications.


<details>
  <summary>Details</summary>
Motivation: To investigate how defects in NaI crystals affect dark matter detection signals, particularly in experiments like COSINUS aiming to validate DAMA/LIBRA's modulating signal.

Method: Molecular dynamics simulations and density functional theory (DFT) were employed to simulate dark matter particle collisions, analyze defect structures/properties, and assess energetic costs and anisotropic displacement thresholds.

Result: The study identified electronic states related to defects, quantified defect formation energies, and determined anisotropic threshold displacement energies, suggesting defects could create new electronic states in the band gap.

Conclusion: Dark matter-induced defects in NaI crystals offer a potential new detection channel via their impact on electronic band gaps, enhancing detection methods in experiments like COSINUS.

Abstract: Sodium iodide (NaI) is a widely used scintillator in direct dark matter searches. In particular, NaI-based cryogenic scintillating calorimeters have emerged as promising candidates, like in the COSINUS experiment, for testing the annually modulating signal reported by DAMA/LIBRA. In this study, we investigate defect formation within NaI crystals and its impact on the dark matter detection signal. Using molecular dynamics simulations and density functional theory techniques, we simulate a DM particle collision on an NaI crystal, focusing on the possible defects formation and their structural and electronic properties. Our analysis includes a detailed study of the electronic states associated with the interstitial atoms and vacancies, the energetic cost of defect formation, and the anisotropic threshold displacement energy. Finally, we highlight the potential to exploit dark matter-induced defects as a novel detection channel, enabled by the introduction of new states within the electronic band gap.

</details>


### [10] [Probing the pair production of first-generation vector-like leptons at future $e^+e^-$ colliders](https://arxiv.org/abs/2512.22490)
*Yao-Bei Liu,Stefano Moretti*

Main category: hep-ph

TL;DR: The paper investigates the discovery potential of First-generation Weak Isosinglet Vector-Like Leptons (E±) via pair production at future electron-positron colliders, focusing on multilepton signatures. It shows that these colliders can extend the detectable mass range up to 1.4 TeV with high luminosities, outperforming current hadron collider limits.


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore the potential of future electron-positron colliders to detect VLLs, leveraging their cleaner experimental environment compared to hadron colliders and using beam polarization/detector simulations for precise analysis.

Method: The study uses a comprehensive framework combining beam polarization configurations and detailed detector simulations. It analyzes two multilepton signatures (2ℓ+2j+ETF and 3ℓ+2j+ETF) arising from E± decays into Z/W bosons. Optimized selection criteria are applied to signal/background events to compute exclusion/discovery prospects across VLL mass spectra.

Result: For luminosities of 25, 90, and 1000 fb⁻¹ at c.m. energies of 1, 1.5, and 3 TeV, the accessible VLL mass ranges extend to ~490, 740, and 1440 GeV respectively. This significantly surpasses current hadron collider detection limits.

Conclusion: Future electron-positron colliders equipped with sufficient luminosity can significantly extend the detectable mass range of VLLs, highlighting their superiority over existing hadron colliders for precision studies of these particles.

Abstract: This work explores the discovery potential of the first-generation weak isosinglet Vector-Like Leptons (VLLs), denoted by $E^\pm$, via pair production at future electron-positron colliders. Our analysis adopts a comprehensive framework that incorporates beam polarization configurations and leverages detailed detector simulations. We focus on two distinct multilepton signatures: the $2\ell + 2j + \slashed{E}_T$ and $3\ell + 2j + \slashed{E}_T$ final states ($\ell = e, μ$). Both signatures arise from the decay $E^{\pm} \to Z e^{\pm} / W^{\pm} ν_\ell$ and are distinguished by the decay patterns of the associated gauge bosons. By applying optimized selection criteria to both signal and background events, we establish exclusion sensitivities and discovery prospects across the VLL mass spectrum. Our findings demonstrate that, for integrated luminosities of $\SI{25}{fb^{-1}}$, $\SI{90}{fb^{-1}}$ and $\SI{1000}{fb^{-1}}$ at corresponding center-of-mass (c.m.) energies of $\SI{1}{TeV}$, $\SI{1.5}{TeV}$ and $\SI{3}{TeV}$, the accessible mass range extends to approximately $\SI{490}{GeV}$, $\SI{740}{GeV}$ and $\SI{1440}{GeV}$, which represents a substantially improvement over the detection limits of existing hadron collider experiments.

</details>


### [11] [Radiative symmetry breaking in a gauged Zee-Babu model and its gravitational wave imprints](https://arxiv.org/abs/2512.22549)
*Indra Kumar Banerjee,Nabarun Chakrabarty,Ujjal Kumar Dey*

Main category: hep-ph

TL;DR: The paper presents a classically scale-invariant Zee-Babu model with U(1)_{B-L} symmetry and a Z_2 symmetry, generating dark matter, neutrino masses, and leptogenesis via radiative breaking at a scale v_{BL} ~10-55 TeV. It connects these phenomena to stochastic gravitational waves detectable by LISA/BBO.


<details>
  <summary>Details</summary>
Motivation: To explore a classically scale-invariant extension of the Zee-Babu model that naturally incorporates dark matter, neutrino mass generation, and leptogenesis, while avoiding fine-tuning issues. The motivation also includes connecting particle physics phenomena to gravitational wave observables for experimental verification.

Method: Imposing U(1)_{B-L} with three right-handed neutrinos and a Z_2 symmetry to stabilize the lightest right-handed neutrino as dark matter. Radiative symmetry breaking via RG effects sets the scale v_{BL}, linking neutrino physics, LFV, and dark matter dynamics. Thermal history analysis including phase transitions and gravitational wave production is considered.

Result: The model successfully accommodates observed neutrino parameters, suppresses LFV within experimental bounds, and matches dark matter relic density for 10-55 TeV v_{BL}. A strongly first-order phase transition generates detectable stochastic gravitational waves (frequencies suitable for LISA/BBO).

Conclusion: This framework provides a testable scale-invariant theory connecting neutrino masses, dark matter, and gravitational wave signals. It highlights the potential of future gravitational wave detectors to validate or constrain such models, offering a unified approach to key open questions in particle physics.

Abstract: We construct a classically scale invariant version of the Zee-Babu model governed by an $U(1)_{B-L}$ gauge symmetry wherein three right handed neutrinos with identical gauge charges are present. A $\mathbb{Z}_2$ symmetry is additionally imposed such that the lightest right handed neutrino becomes a dark matter candidate. A spontaneous breakdown of the $U(1)_{B-L}$ gauge group is triggered radiatively through renormalisation group effects and the dimensionful parameters thus emerging are proportional to the corresponding breaking scale $v_{BL}$. We demonstrate in this study how the same $v_{BL}$ controls the dynamics of neutrino mass generation, lepton flavour violation and dark matter phenomenology. It is revealed that the scenario can simultaneously accommodate the observed neutrino masses and mixings, an appropriately low lepton flavour violation and the observed dark matter relic density for 10 TeV $\lesssim v_{BL} \lesssim$ 55 TeV. In addition, the very radiative nature of the set-up signals a strong first order phase transition in the presence of a non-zero temperature. Stochastic gravitational waves stemming from this phase transition are within the reach of detectors such as LISA and BBO. The scenario therefore emerges as a concrete platform to test classical scale invariance that is tied to neutrino masses and dark matter, through gravitational waves.

</details>


### [12] [The $B^{+(0)} \to \bar D^{0(-)} D^{*}_{s0}(2317)^+$ decays and the molecular structure of $D^*_{s0}(2317)$](https://arxiv.org/abs/2512.22604)
*Wei-Hong Liang,Zhuo-Ran Hu,Eulogio Oset*

Main category: hep-ph

TL;DR: The study analyzes the reactions $B^{+(0)} \to \bar D^{0(-)} D_{s0}^*(2317)^+$, treating $D_{s0}^*(2317)^+$ as a molecular state of $KD$ and $D_s η$. By examining related $B$ decays and their $DK$ pairs, it calculates branching ratios compatible with experiments but allows for possible nonmolecular contributions.


<details>
  <summary>Details</summary>
Motivation: To investigate whether the $D_{s0}^*(2317)^+$ resonance can be explained as a molecular state and to determine its impact on branching ratios of $B$ decays.

Method: Analyzed experimental data from $B$ meson decays involving $D^0 K^+$ and $D^+ K^0$ pairs. Focused on weak process branching ratios and strong interactions forming the $D_{s0}^*(2317)^+$ resonance.

Result: Computed branching ratios for $B^{+(0)} \to \bar D^{0(-)} D_{s0}^*(2317)^+$ agree with experimental data. While errors permit nonmolecular contributions, a significant component from molecular states is robustly supported.

Conclusion: The molecular interpretation of $D_{s0}^*(2317)^+$ is viable, but further studies are needed to account for potential nonmolecular effects and reduce uncertainties.

Abstract: We have conducted a study of the $B^{+(0)} \to \bar D^{0(-)} D^{*}_{s0}(2317)^+$ reactions from the perspective that the $D^*_{s0}(2317)$ resonance is a molecular state of the $KD$ and $D_s η$ components. We have followed a method to evaluate the branching fractions obtaining information from the experimental data on the $B^+\to \bar D^0 K^+ D^0$, $B^+\to \bar D^0 K^0 D^+$, $B^0 \to D^- K^+ D^0$, $B^0 \to D^- K^0 D^+$ reactions, which have the $D^0 K^+$ and $D^+ K^0$ pairs in the final state. The approach concentrates the dynamics of the weak process in the branching ratios of these reactions and pays attention to the propagation of the $DK$ components and their strong interaction to form the $D^*_{s0}(2317)$ resonance. We find branching ratios for the $B^{+(0)} \to \bar D^{0(-)} D^{*}_{s0}(2317)^+$ reactions, which are compatible with the experimental data, but considering errors there is room for contributions of other nonmolecular components, although a sizeable fraction from the molecular components is a solid conclusion.

</details>


### [13] [Stringent constraints on non-standard neutrino interactions using high-purity $ν_μ$ CC events in IceCube DeepCore](https://arxiv.org/abs/2512.22632)
*J Krishnamoorthi,Anil Kumar,Sanjib Kumar Agarwalla*

Main category: hep-ph

TL;DR: The study uses atmospheric neutrino data from IceCube DeepCore to constrain neutral-current non-standard interaction parameters εμτ and εττ−εμμ, finding no significant deviation from standard model predictions and setting new limits.


<details>
  <summary>Details</summary>
Motivation: Neutral-current non-standard interactions (NC-NSI) can alter neutrino oscillations, so the research aims to constrain these parameters using high-purity atmospheric neutrino data to test beyond-standard-model physics.

Method: Analyzed a 7.5-year IceCube DeepCore dataset of νμ charged-current events. Evaluated impacts of εμτ and εττ−εμμ on νμ disappearance, comparing observations to NC-NSI models.

Result: Best fits align with no NSI, with 90% CL limits: -0.0094 < εμτ < 0.0079 and -0.030 < εττ−εμμ < 0.029, representing the tightest constraints to date.

Conclusion: Results support the Standard Model by excluding significant NC-NSI contributions, advancing particle physics searches for new interactions.

Abstract: The neutral-current (NC) non-standard interactions (NSI) of neutrinos with fermions can modify the flavor oscillations of atmospheric neutrinos as they propagate through the Earth. We present constraints on the NC-NSI parameters $\varepsilon_{μτ}$ and $\varepsilon_{ττ}-\varepsilon_{μμ}$ (one at a time) using a high-purity sample of $ν_μ$ charged-current (CC) atmospheric neutrino events collected by IceCube DeepCore over 7.5 years of livetime. These two parameters significantly affect the $ν_μ$ disappearance channel for which this golden event sample is optimized by the IceCube Collaboration. The best fit to this dataset is consistent with no NSI hypothesis, and we place the most stringent constraints to date: $-\,0.0094 < \varepsilon_{μτ} < 0.0079$ and $-\,0.030 < \varepsilon_{ττ}-\varepsilon_{μμ} < 0.029$ at 90% confidence level.

</details>


### [14] [DGLAP evolution at N$^3$LO with the $\texttt{Candia}$ algorithm](https://arxiv.org/abs/2512.22667)
*Casey Hampson,Marco Guzzi*

Main category: hep-ph

TL;DR: The paper generalizes the Candia algorithm to N³LO accuracy in QCD for solving DGLAP evolution equations, focusing on unpolarized parton densities in the nucleon. It provides an exact solution in the non-singlet sector using logarithmic expansions and offers approximate N³LO PDFs for benchmarking.


<details>
  <summary>Details</summary>
Motivation: The motivation for this work is to achieve higher precision in QCD calculations by extending the Candia algorithm to N³LO, which improves the accuracy of parton density function (PDF) evolution and enables more reliable comparisons with experimental data.

Method: The method involves extending the Candia algorithm to N³LO via logarithmic expansions of the DGLAP evolution equation solution. The paper presents an exact expansion in the non-singlet sector and uses recent N³LO splitting function approximations to evolve PDFs.

Result: The results include approximate N³LO PDFs generated using the updated algorithm, provided for benchmarking purposes. The generalized Candia-v2 code is made publicly available for further research.

Conclusion: The successful extension of the Candia algorithm to N³LO enhances precision in QCD analyses, offering a valuable tool for future experiments requiring higher-order corrections in particle physics.

Abstract: We present a generalization of the $x$-space $\texttt{Candia}$ algorithm to next-to-next-to-next-to-leading order (N$^3$LO) accuracy in Quantum Chromodynamics (QCD) for solving the DGLAP evolution equations for unpolarized parton densities in the nucleon. The algorithm is based on logarithmic expansions of the solution and can be extended to all orders in QCD. An expansion equivalent to the exact solution of the DGLAP equation at N$^3$LO is presented in the non-singlet sector. Results for approximate N$^3$LO PDFs, evolved using the most recent approximations to the N$^3$LO DGLAP splitting functions, are provided for benchmarking. The new version of the code, $\texttt{Candia-v2}$, is publicly available at https://github.com/champso1/candia-v2.

</details>


### [15] [Lepton Number Violation at the LHC in Radiative Neutrino Mass Models with Leptoquarks](https://arxiv.org/abs/2512.22756)
*K. S. Babu,Rahool Kumar Barman,Dorival Gonçalves*

Main category: hep-ph

TL;DR: The paper explores the possibility of observing lepton number violation (LNV) by two units at the HL-LHC using a leptoquark model within the Zee Model framework. It identifies dominant production channels for the LNV signature (same-sign dilepton plus jets) and estimates the HL-LHC's sensitivity to probe leptoquark masses up to ~1.5 TeV, which would confirm neutrinos' Majorana nature and LNV.


<details>
  <summary>Details</summary>
Motivation: To test the Majorana nature of neutrinos and observe LNV experimentally, leveraging the LHC's potential to detect leptoquarks that mediate such rare processes.

Method: Analysis of leptoquark interactions in the Zee Model, calculation of dominant production channels for the LNV signature (same-sign dilepton plus jets), collider simulation considering experimental constraints, and estimation of HL-LHC's reach for leptoquark masses.

Result: Identifies that the HL-LHC can probe leptoquark masses up to ~1.5 TeV with this process. Observation would confirm Majorana neutrinos and LNV.

Conclusion: The HL-LHC offers a viable pathway to observe LNV via leptoquark-mediated processes, providing a direct test of Majorana neutrinos and extending beyond the Standard Model physics.

Abstract: We investigate the prospects for observing lepton number violation (LNV) by two units, $|ΔL| = 2$, at the LHC within the leptoquark variant of the Zee Model, where Majorana neutrino masses arise radiatively at one-loop. The model features an $SU(2)_L$ doublet and singlet leptoquarks, whose interactions produce a distinctive same-sign dilepton plus jets signature, $pp \to \ell^{\pm}\ell'^{\pm} + \text{jets}$. Taking into account current experimental constraints, we identify the dominant production channels for this LNV signal and perform a detailed collider analysis. We find that the HL-LHC can probe leptoquark masses up to $m_{\rm LQ} \sim 1.5~\mathrm{TeV}$ with this process. Observation of this signal would provide a direct test of LNV and would unambiguously establish the Majorana nature of neutrinos.

</details>


### [16] [Toward the Effective Light and Heavy QCD Axion Scenarios](https://arxiv.org/abs/2512.22829)
*Hai-Jun Li*

Main category: hep-ph

TL;DR: This paper examines the parameter space of QCD axion models focusing on mass and decay constant ratios for single, two, and multiple axion scenarios, revealing contrasting behaviors between mass and decay constant ratios.


<details>
  <summary>Details</summary>
Motivation: To understand the parameter relationships in axion physics across different scenarios (light vs. heavy) and extend insights to multiple axions.

Method: Quantitative analysis of two-axion systems in both light and heavy QCD axion scenarios, then generalization to multiple axions.

Result: Mass ratios show similarity between scenarios, whereas decay constant ratios are opposed; findings extend to multiple axions.

Conclusion: The behaviors of axion mass and decay constant ratios differ fundamentally between the two scenarios, suggesting distinct physical interpretations and guiding future multi-axion model explorations.

Abstract: In this work, we investigate the effective parameter space associated with the axion mass and the axion decay constant in both the light and heavy QCD axion scenarios. We initiate our discussion by considering the simplest case of two axions, quantitatively analyzing the parameter space in these two distinct scenarios. We find that the axion mass ratios exhibit a high degree of similarity in these two situations. In contrast, the ratios of axion decay constants display a complete opposition. Furthermore, we generalize our conclusions to encompass the case of multiple axions.

</details>


### [17] [Bell nonlocality and entanglement in $χ_{cJ}$ decays into baryon pair](https://arxiv.org/abs/2512.22837)
*PengCheng Hong,RongGang Ping,WeiMin Song*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a systematic analysis of Bell nonlocality and entanglement in $χ_{cJ}$ decays into baryon pair ($B\bar{B}$) ($J=0,1,2$). From the baryon-antibaryon spin density matrix, we construct measurable Bell observables and concurrence, revealing a striking hierarchy of quantum correlations: $χ_{c0}$ decays exhibit maximal violation and entanglement; $χ_{c1}$ decays violate Bell inequalities for $θ_1 \in (0, π)$ with angle-modulated strength; we find that $B\bar B$ in $χ_{c2}$ decays is in separable state, and no indication is found for the Bell inequality violation. We provide complete analytical results for $J=0,1$ and quantitative, uncertainty-aware estimations for $J=2$ using experimental inputs. The results indicates that the $χ_{cJ}$ system as a novel platform for testing quantum entanglement in high-energy collisions.

</details>


### [18] [Probing Lorentz Invariance Violation at High-Energy Colliders via Intermediate Massive Boson Mass Measurements: Z Boson Example](https://arxiv.org/abs/2512.22916)
*Z. Kepuladze,J. Jejelava*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Lorentz invariance (LI) is a foundational principle of modern physics, yet its possible violation (LIV) remains an intriguing window to physics beyond the Standard Model. While stringent constraints exist in the electromagnetic and hadronic sectors, the weak sector-particularly unstable bosons-remains largely unexplored. In this work, based on our recent studies and conference presentation, we analyze how LIV manifests in high-energy collider experiments, focusing on modifications of Z boson dispersion relations and their impact on resonance measurements in Drell--Yan processes. We argue that precision measurements of resonance masses at colliders provide sensitivity to LIV at the level of $10^{-9}$, comparable to bounds derived from cosmic rays. We also discuss the interplay between LIV and gauge invariance, highlighting why only specific operators provide physical effects. The phenomenological implications for both Z and W bosons are outlined, with emphasis on experimental strategies for current and future colliders.

</details>


### [19] [Low-energy $e^+\,e^-\toγ\,γ$ at NNLO in QED](https://arxiv.org/abs/2512.22929)
*Tim Engel,Marco Rocco,Adrian Signer,Yannick Ulrich*

Main category: hep-ph

TL;DR: The paper presents a fully differential computation of electron-positron annihilation into two photons at NNLO QED, implemented in the McMule framework for applications in low-energy e+e- colliders.


<details>
  <summary>Details</summary>
Motivation: To achieve precise predictions for low-energy electron-positron collider experiments, particularly for luminosity measurements requiring high precision cross-section calculations.

Method: Computed the process $e^+e^-→γγ$ at next-to-next-to-leading order (NNLO) in Quantum Electrodynamics using the McMule framework, incorporating fully differential results.

Result: Implementation into McMule now provides NNLO accuracy for all key 2→2 processes, enabling precise event simulation and analysis up to a few GeV center-of-mass energies.

Conclusion: This advances precision standards in low-energy collider physics, offering critical tools for luminosity determination and theory-experiment comparisons.

Abstract: We present a fully differential computation of $e^+\,e^-\toγ\,γ$ at next-to-next-to-leading order in QED. The process has been implemented into McMule, completing its set of next-to-next-to-leading-order calculations for the most important $2 \to 2$ processes. The results allow for generic applications to electron-positron colliders with centre-of-mass energies up to a few GeV, particularly for luminosity measurements.

</details>


### [20] [TauSpinner algorithms for including spin and New Physics effects in $\bar q q \rightarrow Z/γ^* \to ττ$ process](https://arxiv.org/abs/2512.22971)
*A. Yu. Korchin,E. Richter-Was,Z. Was*

Main category: hep-ph

TL;DR: This paper discusses the impact of anomalous New Physics contributions to τ lepton dipole and weak dipole moments on CP-violating signatures in τ-pair production from Z-boson decay. Using the TauSpinner program with Monte Carlo methods, it extends the Standard Model's spin amplitudes to analyze polarization and spin correlations, including phase shifts between Z-τ vector/axial-vector couplings.


<details>
  <summary>Details</summary>
Motivation: To explore New Physics effects in τ-lepton interactions, particularly CP violation signals, by revisiting Z→τ⁺τ⁻ processes with updated analysis methods that account for anomalous dipole moments and spin correlations.

Method: Implementation of extended Standard Model spin amplitudes in TauSpinner, using Improved Born Approximation and Monte Carlo event reweighting. Includes analysis of τ polarization, spin correlations, and specific decay channels (τ→ρν→ππν). Phase shifts in Z-τ couplings are incorporated to study transverse spin effects.

Result: Presented distributions of spin correlation matrices and numerical examples for τ decay signatures. Demonstrated the program's capability to simulate New Physics effects, applicable beyond just dipole moments to arbitrary 2→2 matrix element interactions.

Conclusion: TauSpinner provides a flexible tool for analyzing CP-violating and New Physics effects in τ-pair production. The study highlights the importance of considering spin correlations and polarization in detecting anomalous interactions, guiding future LHC experiments.

Abstract: The possible anomalous New Physics contributions to dipole and weak dipole moments of the $τ$ lepton bring renewed interest in development and revisiting charge-parity violating signatures in $τ$-pair production in $Z$-boson decay at energies of the LHC. In this paper, we discuss effects of anomalous contributions to polarisation and spin correlations in the $\bar q q \to τ^+ τ^-$ production processes, with $τ$ decays included. Because of the complex nature of the resulting distributions, Monte Carlo techniques are useful, in particular of event reweighing with studied New Physics phenomena. Extensions of the Standard Model spin amplitudes, within Improved Born Approximation used for matrix element, are implemented in the TauSpinner program. This is mainly with $τ$ dipole and weak dipole moments in mind, but is applicable to arbitrary New Physics interactions, provided they can be encapsulated into the Standard Model $2 \to 2$ structure of matrix element extensions. Implementation allows one also to introduce arbitrary phase-shift between vector and axial-vector couplings of $Z$ boson to $τ$ leptons, which would have impact on observed transverse spin correlations. Basic formulas and algorithm principles are presented, together with distributions for spin correlation matrix. Numerical examples of impact on experimental signatures are shown in case of $τ^\pm \to ρ^\pm ν_τ\to π^\pm π^0 ν_τ$ decays. Information on how to use and configure the TauSpinner program is given in Appendix.

</details>


### [21] [Mini-review on the production of Primordial Black Holes from First-Order Phase Transitions in the Early Universe](https://arxiv.org/abs/2512.22989)
*Indra Kumar Banerjee,Ujjal Kumar Dey,Shaaban Khalil*

Main category: hep-ph

TL;DR: The paper examines how primordial black holes form during first-order phase transitions, exploring both model-dependent and independent mechanisms, and connects these mechanisms' properties to the resulting black holes.


<details>
  <summary>Details</summary>
Motivation: To understand the origins and characteristics of primordial black holes by analyzing the phase transitions in the early universe, providing insights into cosmological phenomena.

Method: Reviewing and discussing various mechanisms (both model-dependent and independent) that lead to primordial black hole formation during first-order phase transitions, with specific model examples.

Result: Establishes links between phase transition properties and primordial black hole characteristics, offering detailed case studies for different theoretical models.

Conclusion: Primordial black holes can arise from first-order phase transitions through multiple mechanisms, with their properties tied to the transition's specifics, supporting their potential role in dark matter or gravitational wave signals.

Abstract: We review the creation mechanism of primordial black holes from first order phase transitions. We discuss various model-dependent and independent mechanisms and relate the properties of these mechanisms to the properties of primordial black holes. For each of these mechanisms, we provide model-specific examples.

</details>


### [22] [${\mathcal{O}(α_s^2 α)}$ corrections to quark form factor](https://arxiv.org/abs/2512.22992)
*Tanmoy Pati,Narayan Rana,V. Ravindran*

Main category: hep-ph

TL;DR: The paper presents analytic results for non-singlet three-loop mixed strong-electroweak $\mathcal{O}(α_s^2α)$ virtual corrections to quark form factors, addressing challenges from massive vector boson loops and demonstrating complex reduction and evaluation techniques.


<details>
  <summary>Details</summary>
Motivation: To address the complexities introduced by massive vector bosons in loop calculations and compute precise virtual corrections essential for high-precision physics predictions in particle interactions.

Method: The authors used integration-by-parts reduction and differential equations to handle scalar integrals, performed ultraviolet renormalization, and subtracted infrared divergences. Results are expressed via Harmonic Polylogarithms and Generalized Polylogarithms.

Result: Finite remainders after renormalization and divergence subtraction, expressed analytically using specialized polylogarithmic functions, which are crucial for precision calculations in particle physics.

Conclusion: The successful computation of these corrections provides a foundation for improving theoretical predictions in high-energy processes involving quark interactions, enabling better comparisons with experimental data.

Abstract: We present the analytic results for the non-singlet contributions to the three-loop mixed strong-electroweak ${\mathcal{O}}(α_s^2α)$ virtual corrections to the quark form factors. The primary challenge of this computation arises from the presence of massive vector bosons within the loops. This significantly increases the complexity of the integration-by-parts reduction of the scalar integrals and complicates their evaluation via the method of differential equations. To obtain the physical results, we perform the appropriate ultraviolet renormalization and subtract the universal infrared divergences. The resulting finite remainders are expressed in terms of Harmonic Polylogarithms and Generalized Polylogarithms.

</details>


### [23] [Total decay rate of a muon bound to a light nucleus](https://arxiv.org/abs/2512.23023)
*Andrzej Czarnecki,A. O. Davydov,M. Y. Kaygorodov*

Main category: hep-ph

TL;DR: The paper resolves a discrepancy in the total decay rate of muons bound to atoms (Z=4 to 9) by identifying convergence issues in prior non-relativistic calculations and confirms a negative (αZ)^3 correction in relativistic calculations.


<details>
  <summary>Details</summary>
Motivation: To address the inconsistency between perturbative and fully relativistic calculations of muon decay rates, specifically for oxygen (Z=8), and ensure accurate theoretical predictions.

Method: Performed accurate relativistic calculations using a convergent partial-wave series to overcome convergence limitations in previous studies, allowing comparison with perturbative (αZ)^2 results.

Result: Found that earlier relativistic work had convergence issues explaining the discrepancy; new calculations align with perturbative results and reveal a negative (αZ)^3 term.

Conclusion: Establishes relativistic methods with improved convergence for precise muon decay rate predictions, highlighting the importance of higher-order terms in atomic QED calculations.

Abstract: We revisit the total decay rate of a muon being in the ground state of a Coulomb potential with atomic charge numbers $4\leq Z \leq 9$. The discrepancy between the perturbative $(αZ)^2$ result of [Phys. Rev. \textbf{119}, 365 (1960)] and the fully relativistic partial-wave calculation of [At. Data Nucl. Data Tables \textbf{54}, 165 (1993)] for oxygen ($Z=8$) is shown to originate from insufficient convergence of the partial-wave series in the latter work. Our accurate relativistic calculations restore agreement with the perturbative $αZ$~expansion and indicate a negative sign for the next-order $(αZ)^3$ correction.

</details>


### [24] [Molecular states $J/ψB_{c}^{+}$ and $η_{c}B_{c}^{\ast +} $](https://arxiv.org/abs/2512.23030)
*S. S. Agaev,K. Azizi,H. Sundu*

Main category: hep-ph

TL;DR: The paper investigates the hadronic molecules J/ψB_c^+ and η_cB_c^{*+} using QCD sum rules, predicting a mass of 9740±70 MeV and a width of 121±17 MeV. Decay mechanisms include fall-apart and annihilation processes.


<details>
  <summary>Details</summary>
Motivation: To explore the existence and properties of exotic hadronic molecules composed of heavy quarks, specifically those with cc̄b̄ quark content, and to provide predictions for their masses and decay modes that can be tested experimentally.

Method: QCD sum rule method is applied to calculate the mass and current couplings of the molecules. Three-point sum rules are used to compute partial decay widths for both fall-apart and annihilation decay mechanisms.

Result: The mass of the molecule is found to be 9740±70 MeV, and its total decay width is 121±17 MeV. Both molecules are treated as identical due to their similar properties, with decay channels dominated by fall-apart processes but also including subdominant annihilation modes.

Conclusion: The predicted mass and decay width suggest the molecule极易通过强相互作用衰变为普通介子对，为当前和未来实验提供了有价值的研究目标。The results support the possibility of observing these exotic states in experimental searches, emphasizing the need for further experimental validation.

Abstract: Hadronic molecules $\mathfrak{M}=J/ψB_{c}^{+}$ and $\widetilde{\mathfrak{ M}}=η_{c}B_{c}^{\ast +}$ are investigated in the framework of QCD sum rule method. These particles with spin-parities $J^{\mathrm{P}}=1^+$ have the quark contents $cc \overline{c}\overline{b}$. We compute their masses and current couplings and find that they are numerically very close to each other. Because it is difficult to distinguish reliably the molecules $J/ψB_{c}^{+}$ and $J/ψB_{c}^{+}$, we treat them as identical structures, and consider in details the state $\mathfrak{M}$. Our prediction $m=(9740 \pm 70)~\mathrm{MeV}$ for its mass means that $\mathfrak{M}$ easily decays to pairs of ordinary mesons through strong interactions. There are two mechanisms responsible for transformations of $\mathfrak{M}$ to conventional mesons. The fall-apart mechanism generates the dominant decay channels $ \mathfrak{M} \to J/ψB_{c}^{+}$ and $\mathfrak{M} \to η_{c}B_{c}^{\ast +}$. Annihilation of $\overline{c}c$ quarks triggers subdominant processes with various final-state $B$ and $D$ mesons: Six of such channels are explored in this work. The partial widths of all decays are computed using the three-point sum rule approach. The width $Γ[ \mathfrak{M}]=(121 \pm 17)~ \mathrm{MeV}$ of the hadronic axial-vector molecule $\mathfrak{M}$, as well as its mass are valuable for running and future experiments.

</details>


### [25] [Partonic Entropy of the Proton from DGLAP Evolution](https://arxiv.org/abs/2512.23102)
*Krzysztof Golec-Biernat*

Main category: hep-ph

TL;DR: The paper explores partonic entropy in the proton under DGLAP evolution, showing its monotonic increase with scale. It introduces simplified models, emphasizing saturation effects at small x and proposes partonic entropy as an entanglement entropy observable for experiments.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of partonic entropy during DGLAP evolution and its implications, particularly the role of saturation effects at small x in parton distributions.

Method: Analysis of DGLAP evolution effects on partonic entropy, development of simplified models incorporating saturation effects, and identification of partonic entropy with entanglement entropy as an experimental observable.

Result: Partonic entropy increases monotonically with evolution scale; saturation models show importance of small x effects; one model proposes partonic entropy as an experimentally testable observable.

Conclusion: Partonic entropy's growth under DGLAP evolution reflects underlying dynamics requiring saturation effects. The proposal to treat it as entanglement entropy opens avenues for experimental verification.

Abstract: We investigate the concept of partonic entropy of the proton within the Dokshitzer--Gribov--Lipatov--Altarelli--Parisi (DGLAP) evolution scheme of collinear parton distributions. We show that such entropy increases monotonically with the evolution scale. The mechanism underlying this growth is illustrated using a simplified model of DGLAP evolution, which highlights the importance of including saturation effects at small $x$ in the evolution of parton distributions. Based on existing literature, we present two simplified models of parton saturation at small $x$. In one of these models, partonic entropy is identified with entanglement entropy and proposed as an observable to be tested experimentally.

</details>


### [26] [From QCD-Based Descriptions to Direct Fits: A Unified Study of Nucleon Electromagnetic Form Factors](https://arxiv.org/abs/2512.23107)
*Hossein Vaziri,Mohammad Reza Shojaei,Pere Masjuan*

Main category: hep-ph

TL;DR: The paper combines three methods to study nucleon electromagnetic form factors, achieving accurate descriptions of nucleon structure across a broad momentum range.


<details>
  <summary>Details</summary>
Motivation: To provide a precise and physically grounded description of nucleon electromagnetic form factors by integrating GPD-based models and vector-meson exchange, ensuring accuracy across various momentum transfers.

Method: Combines two GPD-based contributions with vector-meson exchange; fits experimental data to determine weights and parameters; constructs global Padé-based fits from local Taylor expansions for four form factor groups.

Result: Obtained stable, model-dependent parametrizations of nucleon form factors valid over the studied momentum transfer range, yielding an accurate and physically motivated description.

Conclusion: The hybrid approach successfully offers a controlled, accurate method for nucleon structure analysis, demonstrating the effectiveness of integrating GPD models and vector-meson components.

Abstract: We present a detailed study of the nucleon electromagnetic form factors in the spacelike region by combining three complementary approaches: two GPD-based contributions and a vector-meson exchange component. By fitting experimental data, we extract the optimal weights and shape parameters describing the proton and neutron form factors. Global Padé-based fits are then constructed for four distinct groups of form factors, starting from local Taylor expansions and yielding stable analytic parametrizations over the analyzed $t$ range. The combined framework provides an accurate and physically motivated description of nucleon structure within a controlled model-dependent setting across a wide range of momentum transfers.

</details>


### [27] [Discovery prospects for photophobic axion-like particles at a 100 TeV proton--proton collider](https://arxiv.org/abs/2512.23155)
*Zilong Ding,Jiaojiao Feng,Ying-nan Mao,Kechen Wang,Yiheng Xiong*

Main category: hep-ph

TL;DR: The study investigates heavy photophobic axion-like particles (ALPs) with negligible diphoton coupling at a future 100 TeV proton-proton collider. It examines production and decay mechanisms via electroweak interactions, analyzing three final states using BDT classification to determine ALP-W coupling sensitivities and cross-section times branching ratios. Results show enhanced discovery reach compared to 14 TeV projections.


<details>
  <summary>Details</summary>
Motivation: To explore ALPs with suppressed diphoton couplings where traditional collider signatures fail, focusing on electroweak-driven interactions at higher energy colliders to extend sensitivity beyond existing 14 TeV limits. The work aims to establish model-independent discovery thresholds and validate results across multiple channels for systematic robustness.

Method: Detector-level analysis using 20 ab⁻¹ at 100 TeV SppC/FCC-hh. Considered ALP decays to Zγ and WW, plus production via s-channel electroweak exchange and VBF-like processes for jj+a, and associated W±a production. Three final states analyzed with BDT classification: Zγjj (Z→ℓ⁺ℓ⁻), tri-W (ss dimuons + jets), and W⁺W⁻jj (OSDF dilepton + jets). Model-independent σ×Br thresholds evaluated.

Result: Reported discovery sensitivities for gaWW across ALP masses from 100 GeV to 7 TeV. Model-independent σ×Br thresholds determined for all channels. The combined analyses provide overlapping coverage, improving robustness against systematic uncertainties. The 100 TeV setup significantly extends reach beyond 14 TeV projections within a general EFT framework without UV completion assumptions.

Conclusion: Future 100 TeV colliders enable discovery of heavy ALPs with suppressed photon couplings through electroweak signatures. Multi-channel analysis strengthens discovery potential by cross-validating results. These findings support the importance of high-energy colliders for probing beyond-Standard-Model physics within effective field theories.

Abstract: We study heavy photophobic axion-like particles (ALPs) in the limit of an effectively vanishing diphoton coupling, $g_{aγγ}\simeq 0$, for which diphoton production and decay are suppressed and collider phenomenology is driven by electroweak interactions ($aWW$, $aZγ$, $aZZ$). We perform detector-level searches at a future $\sqrt{s}=$ 100 TeV $pp$ collider (SppC/FCC-hh), with an integrated luminosity of $L =$ 20 ab$^{-1}$. We consider $a\to Zγ$ and $a\to W^+W^-$ decays. For $pp\to jj\,a$ we include both $s$-channel electroweak exchange and vector boson fusion (VBF)-like topologies, while the tri-$W$ signature arises from associated production $pp\to W^\pm a$ (via $s$-channel exchange) followed by $a\to W^+W^-$. We analyze three final states--$Zγjj$ with $Z\to\ell^+\ell^-$, tri-$W$ ($W^\pm W^\pm W^\mp$) with same-sign dimuons plus jets, and $W^+W^-jj$ with opposite-sign, different-flavor dilepton ($e^\pmμ^\mp$) plus jets. A boosted-decision-tree (BDT) classifier built from kinematic observables provides the final signal--background separation. At $\sqrt{s}=100$ TeV and $L =$ 20 ab$^{-1}$, we present discovery sensitivities to the ALP--$W$ coupling $g_{aWW}$ over $m_a\in[100,\,7000]$ GeV. In parallel, we report model-independent discovery thresholds on $σ\times\mathrm{Br}$ for $pp\to jj\,a$ with $a\to Zγ$ and $a\to W^+W^-$, as well as for associated production $pp\to W^\pm a$ with $a\to W^+W^-$. Taken together, the three channels deliver broad coverage and mutually reinforcing checks across decay modes and production regimes, strengthening robustness against channel-dependent systematics. The 100~TeV program extends the discovery reach well beyond 14~TeV projections within a general effective field theory (EFT) description that does not assume a specific ultraviolet completion.

</details>


### [28] [Muonphilic asymmetric dark matter at a future muon collider](https://arxiv.org/abs/2512.23159)
*Arnab Roy,Raymond R. Volkas*

Main category: hep-ph

TL;DR: The paper analyzes constraints and future muon collider sensitivities for muonphilic portals to fermionic asymmetric dark matter (ADM) using effective operators and UV models, considering both vector and axial-vector couplings. It evaluates current and future experimental probes for dark matter masses in GeV and higher ranges.


<details>
  <summary>Details</summary>
Motivation: To explore how current direct detection and collider constraints limit the parameter spaces of muonphilic ADM models and assess the potential of upcoming muon colliders to further probe these scenarios, especially addressing the ADM approaches to the Ωb ∼ ΩDM/5 coincidence problem.

Method: The study employs both WEFT-level dimension-6 effective field theory operators and two UV-complete models based on gauged Lμ−Lτ symmetry. One model uses a vector coupling and the other an axial-vector coupling to ADM. Constraints from direct detection, collider experiments (including muon g-2 anomalies), and neutron star heating are analyzed. Future sensitivity of 3 and 10 TeV muon colliders with 1 ab⁻¹ is evaluated.

Result: Identifies allowed parameter regions in current models compliant with ADM relic density requirements. Projects that muon colliders could significantly extend the explored parameter space, particularly for dark matter masses in the few-GeV range and beyond. Highlights the role of neutron star heating constraints in bounding certain scenarios.

Conclusion: Muon colliders offer substantial potential to probe muonphilic ADM models beyond current limits, especially for specific mass ranges tied to cosmological coincidences. The analysis underscores the necessity of both high-energy colliders and astrophysical constraints in validating or ruling out these models.

Abstract: We explore phenomenological constraints on, and future muon collider sensitivities to, the parameter spaces of various muonphilic portals to fermionic asymmetric dark matter (ADM). Both WEFT-level dimension-6 effective operators and two UV models based on gauged $L_μ- L_τ$ are considered. One of the latter features a vector coupling to the dark matter and the other an axial vector coupling. The ADM criterion that at least $99\%$ of the dark matter relic density is asymmetric is also imposed. We identify which of these scenarios are currently allowed by direct detection and collider constraints, and then determine how much more of the parameter space could be probed by 3 and 10 TeV muon colliders with 1 ab$^{-1}$ of data. For the UV models, the constraints from $g-2$ of the muon are included. The future sensitivity curves due to neutron star heating considerations are also depicted. We present results for both the few-GeV dark matter mass regime motivated by ADM approaches to the $Ω_b \simeq Ω_\text{DM}/5$ coincidence problem, and for larger masses in the context of more general ADM.

</details>


### [29] [Constraints on SMEFT operators from $Z \to μμbb$ decay](https://arxiv.org/abs/2512.23226)
*Zijian Wang,Tianyi Yang,Tianyu Mu,Andrew Levin,Qiang Li*

Main category: hep-ph

TL;DR: This study explores Z → μμbb decays within the Standard Model Effective Field Theory (SMEFT) framework to derive constraints on dimension-six operators affecting four-fermion interactions involving muons and bottom quarks, utilizing advanced Monte Carlo simulations and likelihood analysis to provide new process-specific limits.


<details>
  <summary>Details</summary>
Motivation: To address the under-explored mixed leptonic-hadronic Z decay modes and expand SMEFT constraints beyond traditional channels like purely leptonic Z decays, focusing on less studied flavor-resolved four-fermion operators.

Method: Simulated signal/background events with Monte Carlo tools including detector effects (e.g., b-tagging), analyzed kinematic distributions, and applied a profile likelihood method to extract constraints on SMEFT Wilson coefficients.

Result: First process-specific limits on flavor-resolved four-fermion operators involving muons and bottom quarks from Z decays, complementing existing SMEFT studies.

Conclusion: Highlights the importance of mixed leptonic-hadronic Z decay channels for probing SMEFT beyond Standard Model physics, opening new avenues for precision tests of particle interactions.

Abstract: The Standard Model Effective Field Theory (SMEFT) provides a systematic framework to probe indirect effects of heavy new physics via precision measurements. While SMEFT constraints have been extensively studied using purely leptonic $Z$ decays and inclusive $Z$ production, mixed leptonic-hadronic modes remain largely unexplored. In this work, we analyze $Z \to μμbb$ decays within the SMEFT framework, deriving constraints on dimension-six operators that affect four-fermion interactions between leptons and bottom quarks, as well as $Z$-fermion couplings. Signal and background events are simulated with state-of-the-art Monte Carlo tools, including detector effects such as $b$-tagging, and limits on the relevant Wilson coefficients are extracted using kinematic distributions and a profile likelihood approach. Our results provide complementary constraints to existing SMEFT studies and yield the first process-specific limits on flavor-resolved four-fermion operators involving muons and bottom quarks from $Z$ decays.

</details>


### [30] [Complex scalar dark matter with effective Higgs portals beyond radiation domination](https://arxiv.org/abs/2512.23228)
*Manimala Mitra,Dipankar Pradhan,Subham Saha*

Main category: hep-ph

TL;DR: The paper explores complex scalar dark matter scenarios, addressing challenges from direct detection limits by incorporating a dimension-5 Higgs-portal operator and considering non-standard cosmological epochs like reheating. It finds viable parameter regions during reheating that avoid over-abundance issues in radiation-dominated models, and assesses collider production cross-sections.


<details>
  <summary>Details</summary>
Motivation: To circumvent tight constraints on Higgs-portal couplings from direct detection experiments in the minimal complex scalar DM model, the study investigates modifications like non-renormalizable operators and altered cosmological histories to maintain viable DM freeze-out scenarios.

Method: The authors analyze DM production in both reheating and radiation-dominated epochs within an effective field theory framework, calculate relic density constraints, and evaluate cross-sections for collider phenomenology including direct/indirect detection and production at hadron/lepton colliders.

Result: Freeze-out during reheating allows new viable parameter regions excluded in radiation-dominated scenarios due to over-abundance. The dimension-5 EFT coupling avoids some direct detection bounds, with constraints coming from relic density and semi-annihilation limits. Collider production cross-sections show detectability potential.

Conclusion: Non-standard cosmological epochs and non-renormalizable interactions offer solutions to reconcile complex scalar DM models with experimental constraints. Further collider searches can test these scenarios by probing predicted production cross-sections.

Abstract: The increasingly stringent bounds on the Higgs-portal coupling, arising from dark matter (DM) direct-detection searches, confront the minimal renormalizable complex scalar DM scenario with thermal production, where freeze-out occurs in the standard radiation-dominated era. This limitation can be alleviated by introducing a dimension-5 Higgs-portal operator in the minimal renormalizable complex scalar DM model and/or by modifying the standard cosmological history of the Universe. In this article, we analyze complex scalar DM production in both the reheating and radiation-dominated epochs within an effective field theory (EFT) framework. While both scenarios exhibit sizeable regions of parameter space consistent with existing constraints, freeze-out during reheating opens up additional viable regions that are otherwise ruled out by DM overabundance in the radiation-dominated scenario. Notably, the renormalizable Higgs-portal coupling is constrained by relic density, direct- and indirect-detection limits, whereas the EFT coupling associated with the dimension-5 operator is constrained by relic density and indirect-detection bounds arising from DM semi-annihilation. We further study the production cross section of complex scalar DM at hadron and lepton colliders.

</details>


### [31] [Azimuthal asymmetry in $J/ψ+γ$ and $J/ψ+J/ψ$ production in ultraperipheral heavy-ion collisions at LHC](https://arxiv.org/abs/2512.23306)
*Yu Jia,Wen-Long Sang,Xiaonu Xiong,Jian Zhou,Ya-jin Zhou*

Main category: hep-ph

TL;DR: This paper investigates the production of J/ψ particles through two-photon collisions in ultraperipheral heavy-ion collisions at the LHC, focusing on azimuthal asymmetries caused by photon polarization effects. These observables provide a new test of quarkonium production mechanisms and photon transverse momentum distributions.


<details>
  <summary>Details</summary>
Motivation: The study addresses the previously unexplored effects of photon polarization on heavy quarkonium (J/ψ) production in UPCs. Existing work has considered polarization effects in dilepton or light hadrons, but not for quarkonia. Understanding these effects is crucial for probing QCD dynamics and validating theoretical frameworks like NRQCD and photon TMD distributions.

Method: The authors combine NRQCD factorization with TMD photon distributions to analyze the γγ→J/ψ+γ(J/ψ) process. They calculate helicity amplitudes at lowest-order strong coupling and velocity expansion to predict azimuthal asymmetries (cos2φ and cos4φ). Observables are defined as ratios of weighted to unweighted cross sections to enhance robustness against uncertainties.

Result: Significant azimuthal asymmetries (up to ~20% level) from interference of linearly polarized photon states are predicted. These observables exhibit stability against higher-order QCD corrections and NRQCD matrix element variations, suggesting their viability as clean experimental signatures.

Conclusion: The predicted azimuthal asymmetries offer a novel probe of quarkonium production mechanisms and photon TMD structure in the ultra-relativistic regime. Experimental measurement of these asymmetries at the LHC would test theoretical models and shed light on QCD dynamics at extreme conditions.

Abstract: Two-photon collision in ultraperipheral heavy-ion collisions (UPCs) provides a unique and powerful platform for probing QCD with linearly polarized quasi-real photons. While photon polarization effects have been recognized in dilepton and even in light hadrons production, their consequences for heavy quarkonium production remain unexplored. In this work we investigate for the first time the $γγ\to J/ψ+γ(J/ψ)$ channels in Pb-Pb UPCs at the Large Hadron Collider (LHC), by integrating the non-relativistic QCD (NRQCD) factorization approach with the transverse-momentum-dependent (TMD) photon distributions. Based on the helicity amplitudes at lowest order in strong coupling and velocity expansion, we predict sizable $\cos(2φ)$ and $\cos(4φ)$ azimuthal asymmetries arising from the interference of linearly polarized photon states. These azimuthal-dependent observables, defined as the ratios of weighted to unweighted cross sections, are expected to be stable against including the higher-order radiative corrections and varying nonperturbative NRQCD matrix elements, thus offering a fresh test of quarkonium production mechanism and the photon TMD structure in the ultrarelativistic limit.

</details>


### [32] [125 GeV Higgs boson rare decays in a flavor-dependent $U(1)_F$ model](https://arxiv.org/abs/2512.23341)
*Zhan Cao,Jin-Lei Yang,Ti-Bin Hou,Tai-Fu Feng*

Main category: hep-ph

TL;DR: This paper analyzes various Higgs boson decay channels and flavor-changing neutral current processes within the flavor-dependent U(1)_F model (FDM), comparing its predictions with the Standard Model. The FDM introduces two Higgs doublets and a singlet, altering Higgs properties and interactions, and the study includes constraints from electroweak precision observables via S, T, U parameters.


<details>
  <summary>Details</summary>
Motivation: To explore how the extension of the Standard Model's scalar sector with a flavor-dependent U(1)_F gauge symmetry impacts Higgs boson properties, decay channels, and flavor physics processes, while addressing constraints from electroweak precision data.

Method: The paper investigates Higgs decay channels (γγ, VV*, f f̄), flavor-changing neutral current processes (e.g., B→X_sγ, τ→3e), and vector meson associated decays (Zγ, MZ, Mγ) within the FDM. Scalar sector modifications and Yukawa couplings are analyzed for their effects on signal strengths and Higgs mass using S, T, U parameters for electroweak precision constraints.

Result: The FDM significantly alters the Higgs boson's decay properties, particularly in γγ and VV* channels. The model's extended scalar sector and Yukawa couplings lead to measurable deviations in signal strengths and Higgs mass compared to the Standard Model, while remaining consistent with electroweak precision observables.

Conclusion: The flavor-dependent U(1)_F model provides a viable framework to explain anomalies in Higgs decays and flavor physics, offering testable predictions for future collider experiments and precision measurements, especially regarding the modified scalar sector's impact on Higgs properties.

Abstract: In this work, we analyze the Higgs boson decay channels, specifically, $h{\rightarrow}γγ$, $h{\rightarrow} VV^*$ (with $V=Z,W$), and $h{\rightarrow} f\bar{f}$ (for $f=b,c,τ$) within the flavor-dependent $U(1)_F$ model (FDM). We also investigate processes induced by flavor-changing neutral currents, including the decays $\bar B \to X_sγ$ and $B_s^0 \to μ^+μ^-$, the top quark decays $t\to c h$ and $t\to u h$, and the lepton flavor-violating decays $τ\to 3e$, $τ\to 3μ$, and $μ\to 3e$. Furthermore, we incorporate the electroweak precision observables constraints via the S, T, and U parameters. Compared to the Standard Model, the scalar sector of the FDM is extended by two Higgs doublets and one Higgs singlet, which affects the 125 GeV Higgs properties significantly. Meanwhile, the decays $h{\rightarrow} Zγ$, $h\rightarrow MZ$, and $h{\rightarrow} Mγ$ (where $M$ is a vector meson $(ρ,ω,φ,J/Ψ,Υ)$ of the Standard-Model-like Higgs are studied, and we illustrate how changes in the scalar sector and the Yukawa coupling influence the signal strengths for the 125 GeV Higgs decay channels and the Higgs mass in the FDM.

</details>


### [33] [Fine-tuning final state interactions model in NuWro Monte Carlo event generator](https://arxiv.org/abs/2512.23350)
*Hemant Prasad,Jan T. Sobczyk,Rwik Dharmapal Banerjee,J. Luis Bonilla,Krzysztof M. Graczyk,Beata E. Kowal,Artur M. Ankowski*

Main category: hep-ph

TL;DR: The paper uses MINERvA data to improve NuWro's modeling of final state interactions by developing an event reweighting tool, indicating stronger nucleon reinteractions are needed within existing uncertainty ranges.


<details>
  <summary>Details</summary>
Motivation: To refine the modeling of final state interaction effects in NuWro using new MINERvA transverse kinematics data across multiple nuclear targets.

Method: Analyzed MINERvA experimental data from carbon, oxygen, iron, and lead targets to develop an event reweighting tool for adjusting final-state interaction strengths in NuWro.

Result: Found that stronger nucleon reinteractions are required compared to previous assumptions, though still within the uncertainty range of proton transparency studies.

Conclusion: The results highlight the necessity of enhanced final-state interaction modeling in NuWro, impacting both experimental and theoretical neutrino physics applications.

Abstract: Recent experimental data from MINERvA on transverse kinematics observables across four different nuclear targets - carbon, oxygen, iron, and lead - have been utilized to refine the modeling of final state interaction effects in the NuWro Monte Carlo neutrino event generator. For this purpose, we have developed an event reweighting tool for future applications to adjust the strength of final-state interactions. This study highlights the requirement for stronger nucleon reinteractions than previously assumed, but it still falls within the uncertainty range observed in a study comparing proton transparency measurements. This conclusion has significant implications for both experimental and theoretical work involving NuWro.

</details>


### [34] [Prospects for detecting charged long-lived BSM particles at MoEDAL-MAPP experiment: A mini-review](https://arxiv.org/abs/2512.23387)
*Rafał Masełek,Kazuki Sakurai*

Main category: hep-ph

TL;DR: This mini-review evaluates MoEDAL-MAPP's potential in detecting charged long-lived particles, comparing it to ATLAS and CMS, highlighting its unique background-free method for slow-moving or stable particles despite lower luminosity.


<details>
  <summary>Details</summary>
Motivation: Expand LHC searches for physics beyond the Standard Model by investigating unconventional signatures like long-lived particles, focusing on MoEDAL's capabilities.

Method: Synthesizes recent studies on supersymmetric models, radiative neutrino mass scenarios, and generic multiply charged objects. Conducts comparative analysis of MoEDAL's sensitivity against ATLAS and CMS.

Result: MoEDAL's lower luminosity limits its reach but its passive detection method offers unique advantages for slow-moving or stable charged particles, complementing ATLAS and CMS.

Conclusion: MoEDAL provides complementary coverage to major detectors for specific long-lived particle signatures despite luminosity constraints.

Abstract: The search for physics beyond the Standard Model at the Large Hadron Collider is expanding to include unconventional signatures such as long-lived particles. This mini-review assesses the prospects for detecting electrically charged long-lived particles using the MoEDAL-MAPP experiment. We synthesize findings from recent studies that evaluate sensitivity to supersymmetric models, radiative neutrino mass scenarios, and generic multiply charged objects. A key component of this review is the comparative analysis of MoEDAL's reach against the general-purpose ATLAS and CMS experiments. We conclude that while MoEDAL is constrained by lower integrated luminosity, its passive, background-free detection methodology offers a unique advantage. Specifically, the experiment provides complementarity to the major detectors, particularly for signals involving slow-moving particles and stable states with intermediate electric charges.

</details>


### [35] [Analytical results for the C-angularity soft function at NNLO](https://arxiv.org/abs/2512.23398)
*Alexander Bennett,Emmet P. Byrne,Jonathan R. Gaunt,Elsa C. Lang*

Main category: hep-ph

TL;DR: The paper calculates the NLO and NNLO soft functions for C-angularity, a family of event shapes including C-parameter, showing its analytic advantages and precision for parameter values between -1 and 1.


<details>
  <summary>Details</summary>
Motivation: To develop a continuum differentiable event shape variable (C-angularity) that simplifies analytic calculations while maintaining equivalence with conventional angularity in the collinear limit, extending the applicability of C-parameter analyses.

Method: Computed soft functions at NLO/NNLO using expansions in the parameter 'a', analyzing how C-angularity's smoothness reduces computational complexity compared to traditional angularity measures.

Result: Obtained third/fourth-order expansions in 'a' for the soft function and anomalous dimension, achieving sub-percent accuracy (-1 ≤ a < 1), demonstrating C-angularity's computational efficiency.

Conclusion: C-angularity provides a numerically precise and analytically manageable framework for event shape studies, particularly advantageous for parameter ranges near the C-parameter case.

Abstract: We compute the soft function at NLO and NNLO for a one-parameter family of event shapes we call C-angularity. This family contains C-parameter as a specific choice of the parameter, in close analogy with how conventional angularity contains thrust as a special case. By construction, C-angularity and angularity coincide in the collinear limit such that the anomalous dimensions are equal. However, unlike angularity, C-angularity is a continuously differentiable function of the final state momenta, which makes the analytic calculation of the C-angularity soft function simpler. We obtain analytical results for the C-angularity soft function and anomalous dimension as an expansion in the C-angularity parameter $a$, to third and fourth order in $a$ respectively. These expansions yield results that are accurate at the few per mille level for $-1\le a < 1$.

</details>


### [36] [Are 2HDMs with a gauged $U(1)$ symmetry alive?](https://arxiv.org/abs/2512.23450)
*Yuanchao Lou,Takaaki Nomura,Xinran Xu,Kei Yagyu*

Main category: hep-ph

TL;DR: The paper studies 2 Higgs doublet models with a U(1)_X gauge symmetry, predicting a Z' boson and extra Higgs particles with TeV-scale mass limits. Due to new decay modes involving four leptons, current LHC data excludes minimal scenarios unless vector-like fermions (χ) are included to allow Z' decays to dark matter. Benchmark models (U(1)_H and U(1)_R) are analyzed, showing viable mass ranges for Higgs and Z' particles, with future collider experiments needed for further exploration.


<details>
  <summary>Details</summary>
Motivation: To address flavor changing neutral currents (FCNCs) suppression at tree level in 2HDMs while exploring viable parameter spaces consistent with current experimental constraints from LHC and theoretical requirements.

Method: The authors analyze 2HDMs extended with a U(1)_X symmetry, examine the consequences of spontaneous symmetry breaking on particle masses and decay channels. Benchmark models with specific charge assignments (U(1)_H and U(1)_R) are considered. They perform parameter space scans using theoretical and experimental data to determine allowed regions for Higgs boson masses, tan β values, and Z' mass constraints.

Result: The minimal 2HDM with U(1)_X is excluded by current LHC four-lepton searches. Introducing vector-like fermions χ allows Z' decays to dark matter, preserving the models. For U(1)_H: Higgs mass 160-220 GeV, tan β 3-4.4; for U(1)_R: Higgs 160-380 GeV, tan β 1.6-4.4. Z' mass constrained to ~100-110 GeV in both. Future colliders (HL-LHC, lepton colliders) can probe these ranges.

Conclusion: The study shows that while minimal U(1)_X extended 2HDMs are excluded by current data, introducing χ fermions opens viable parameter regions. Experimental efforts at future colliders are crucial to test the proposed models and explore dark matter candidates.

Abstract: We investigate the phenomenology of 2 Higgs doublet models (2HDMs) with a new $U(1)$ gauge symmetry, $U(1)_X$, by which flavor changing neutral currents are forbidden at tree level. As an important consequence of the spontaneous breaking of both the $U(1)_X$ and electroweak symmetries by electroweak vacuum expectation values, upper limits appear on masses of an additional gauge boson $Z'$ and extra Higgs bosons which are less than the TeV scale. In addition, the standard model (SM) like Higgs boson $h$ and a heavier Higgs boson $H$ mainly decay into a pair of $Z'$ which induces four lepton final states. These new decay modes cannot be suppressed by taking no $Z$-$Z'$ mixing and/or the Higgs alignment limit. We find that the minimum setup of these 2HDMs has been excluded by current data for four lepton searches at LHC. Such severe constraints can, however, be avoided by introducing a pair of vector-like fermions $χ$ which are singlet under the SM symmetry but charged under $U(1)_X$, and can be a candidate of dark matter. Thanks to the existence of $χ$, $Z'$ can mainly decay into $χ\barχ$ instead of SM leptons. As benchmark models, we consider the $U(1)_H$ and $U(1)_R$ models realized by fixing specific $U(1)_X$ charges, and find regions of parameter space allowed by theoretical and current experimental constraints. We clarify that $m_H \in [160, 220]$ GeV and $\tan β\in [3, 4.4]$ are allowed in the $U(1)_H$ model, while $m_H \in [160, 380]$ GeV and $\tan β\in [1.6, 4.4]$ are allowed in the $U(1)_R$ model. In both the models, the $Z'$ mass is constrained to be $100~\text{GeV} \lesssim m_{Z'} \lesssim 110$ GeV. Such a quite limited parameter space can further be explored at future collider experiments, e.g., High-Luminosity LHC and lepton colliders.

</details>


### [37] [False-vacuum decay and flaws in Frampton's model of the origin of life](https://arxiv.org/abs/2512.23460)
*Andrzej Czarnecki,Jishnu Khanna*

Main category: hep-ph

TL;DR: The paper critiques Frampton's model of biogenesis as a phase transition, highlighting dimensional inconsistencies in the probability calculation and physical implausibilities in the initial conditions, thereby dismissing the conclusion of extreme rarity of life.


<details>
  <summary>Details</summary>
Motivation: To assess Frampton's hypothesis that the emergence of the first single-celled organism (SCO) represents a false-vacuum decay event and its implications for the likelihood of extraterrestrial life.

Method: Critical analysis of Frampton's dimensional analysis of the probability exponent, evaluation of the proposed initial structure (a toroidal molecule configuration) in the prebiotic environment, and comparison with soft-matter physics principles.

Result: Frampton's probability calculation is found to be mathematically invalid due to dimensional errors, and the model's assumptions about initial conditions conflict with known prebiotic chemistry and environmental conditions.

Conclusion: The critique undermines Frampton's conclusion that life is exponentially suppressed and thus extraterrestrial life is likely absent, asserting that the model's flaws render it unsupported by physics and chemistry principles.

Abstract: We briefly review false-vacuum decay and examine a recent proposal by Frampton to model the origin of the first single-celled organism (SCO) as a phase transition between no-life and life vacua. In his calculation the exponent $n$ entering the probability $P_{\rm SCO}\sim 10^{-n}$ has dimensions of inverse time: it is an energy barrier divided by the Planck constant, rather than a dimensionless tunnelling action. The resulting probability is mathematically ill-defined and does not determine a tunnelling rate. Apart from this dimensional issue, the assumed initial configuration, a toroidal structure made of long molecules, and its treatment in empty space are inconsistent with soft-matter physics and with the hot, collisional environment expected for prebiotic chemistry. Consequently, the claimed exponential suppression of biogenesis, and the inference that extraterrestrial life is likely absent, are not supported.

</details>


### [38] [Simulation of tau decays, ambiguities and anomalous couplings](https://arxiv.org/abs/2512.23475)
*Zbigniew Was,Ananya Tapadar,J. M. John,S. Banerjee*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: From the perspective of low energy tau decays and radiative corrections in decays, not much has changed since the last, Tau23 conference. Also, TAUOLA, tau decay library, and PHOTOS for radiative corrections in decays have not changed much, neither for QED nor for New Physics processes application. Progress was in the domain of flexibilities for applications and in the domain of New Physicists. There was progress with use of exclusive exponentiation (KKMC Monte Carlo) to evaluate quality of tau pair formation and decay factorization, with Collins-Soper and Mustraal frames. Ambiguities for New Physics or other processes could be thus addressed. Associated projects of KKMC f77 and KKMCee C++, are presented: (i) pi+ pi- pair production at Belle II energies, interesting input for Pi_gammagamma(s), (ii) attribution of helicity like labels for taus in simulated HepMC3 format events, (iii) also tau polarimetric vectors prepared for user application of New Physics.

</details>


### [39] [Perturbative results for the matrix elements of the vector current and the role of different infrared regulators](https://arxiv.org/abs/2512.23563)
*Alessio Carmelo Alvaro,Ignacio Castelli,Cédric Lorcé,Andreas Metz,Barbara Pasquini,Simone Rodini*

Main category: hep-ph

TL;DR: The paper investigates twist-2 unpolarized generalized parton distributions (GPDs) for quarks in an on-shell gluon target using quantum chromodynamics (QCD), computed at one-loop accuracy with quark mass and dimensional regularization. It extends previous work on axial currents by examining the vector current and the limit of vanishing momentum transfer.


<details>
  <summary>Details</summary>
Motivation: To extend previous studies on GPDs for axial currents to vector currents in QCD, providing insights into the structure of gluon targets through matrix elements of nonlocal light-like flavor-singlet vector currents.

Method: Computed twist-2 unpolarized GPDs at one-loop accuracy using perturbative QCD, employing quark mass and dimensional regularization as infrared regulators. Analyzed the limit of vanishing momentum transfer.

Result: Derivation and analysis of GPDs for gluon targets, highlighting their behavior in the vanishing momentum transfer limit, building upon earlier axial current results.

Conclusion: The study successfully computes vector current GPDs for gluon targets, offering a comprehensive framework for understanding QCD dynamics at leading twist and guiding future investigations into hadron structure.

Abstract: We investigate the twist-2 unpolarized generalized parton distributions (GPDs) of quarks for an on-shell gluon target in quantum chromodynamics. These GPDs parametrize the leading-twist matrix elements of the nonlocal light-like flavor-singlet vector current. We compute them at one-loop accuracy in perturbation theory using a quark mass and dimensional regularization as infrared regulators. In particular, we discuss the limit of vanishing momentum transfer. The present work extends our previous related study on the axial current.

</details>


### [40] [Scrutinizing the KNT model with vacuum stability conditions](https://arxiv.org/abs/2512.23662)
*Tim Huesmann,Michael Klasen,Vishnu P. K*

Main category: hep-ph

TL;DR: This paper examines how renormalization group effects impact the parameter space of the Krauss-Nasri-Trodden (KNT) model, which unifies neutrino mass generation and dark matter abundance. It finds that many previously viable parameter regions fail vacuum stability checks when these effects are considered, leaving most remaining areas testable by future charged lepton flavor violation experiments.


<details>
  <summary>Details</summary>
Motivation: To assess the stability of the KNT model's parameter space under renormalization group effects and determine its compatibility with vacuum stability conditions while aligning with experimental data.

Method: A Markov Chain Monte Carlo analysis was conducted to explore parameter space under experimental and theoretical constraints, incorporating renormalization group effects to evaluate vacuum stability.

Result: Renormalization group effects invalidate much of the previously viable parameter space in terms of vacuum stability, leaving a reduced regions that future experiments could test.

Conclusion: Renormalization group effects significantly constrain the KNT model's viable parameter space, emphasizing the importance of including these effects in model testing and highlighting future experimental directions for validation.

Abstract: The Krauss-Nasri-Trodden (KNT) model provides a unified framework for addressing the smallness of neutrino masses (by a three-loop radiative mechanism) and the dark matter abundance (via thermal freeze-out) simultaneously. In this work, we investigate the implications of renormalization group effects on the model's parameter space. To this end, we perform a Markov Chain Monte Carlo analysis to identify the viable regions of parameter space that is consistent with all the relevant experimental and theoretical constraints at low energies. We show that a significant portion of the low-energy viable region is incompatible with the vacuum stability conditions once the renormalization group effects are taken into account. Most of the remaining parameter space of the model can be probed in future charged lepton flavor violating experiments.

</details>


### [41] [Soft and Jet functions for SCET at four loops in QCD](https://arxiv.org/abs/2512.23666)
*Saurav Goyal,Sven-Olaf Moch,Vaibhav Pathak,V. Ravindran*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Soft-Collinear Effective Theory is a framework for systematically organizing and resumming the logarithmic contributions that occur in high-energy reactions. It provides a factorized description of cross sections in terms of hard, jet, soft, and beam functions. As the latter are universal, they can be obtained from the well-known perturbative results in quantum chromodynamics (QCD) for deep-inelastic scattering, Drell-Yan and Higgs boson productions. Using the recent results ~\cite{Kniehl:2025ttz} on four-loop eikonal $(f^I)$ and collinear anomalous dimensions $(B^I)$ for quarks and gluons, $I=q,g$, as well as perturbative results from previous orders, we present four-loop predictions for the quark and gluon soft and jet functions. They constitute an important component of the $N$-jettiness subtraction method at $\rm{N^4LO}$ accuracy in QCD, which eventually may enable the calculation of fully-differential cross sections at higher orders.

</details>


### [42] [Coupled-channel Omnès matrix for the $D$-wave isoscalar $ππ/K\bar K$ system and its application to $J/ψ\toπ^{0}π^{0}γ,\,K_{S}K_{S}γ$](https://arxiv.org/abs/2512.23669)
*Igor Danilkin,Oleksandra Deineka,Emilie Passemar,Marc Vanderhaeghen*

Main category: hep-ph

TL;DR: The paper constructs a coupled-channel Omnès matrix for D-wave isoscalar ππ/KK̄ processes, incorporating unitarity and incorporating f₂(1270) and f₂'(1525) resonances via a K-matrix model. It validates this matrix against experimental data and demonstrates its effectiveness in describing BESIII experimental spectra for J/ψ decays.


<details>
  <summary>Details</summary>
Motivation: To develop a unitary and reliable dispersive framework for tensor-meson sector studies by accurately modeling coupled-channel ππ/KK̄ interactions, addressing limitations of previous approaches using Breit-Wigner phase sums.

Method: A two-channel K-matrix model with poles for f₂(1270) and f₂'(1525) is used to generate a unitary scattering matrix. This serves as input to coupled-channel Muskhelishvili-Omnès equations, ensuring satisfaction of unitarity, analyticity, and asymptotic conditions. The approach is validated against ππ→ππ/KK̄ data and PDG parameters.

Result: The constructed Omnès matrix effectively reproduces experimental scattering data and outperforms previous models based on Breit-Wigner phase summation. It successfully describes BESIII's J/ψ→π⁰π⁰γ and KsKsγ spectra in the J=2 E1 partial wave, demonstrating its utility for resonance studies and form factor calculations.

Conclusion: The method provides a robust dispersive input for tensor meson studies, enabling precise descriptions of exclusive decay processes. Future applications can extend this framework to other multi-channel systems and precision tests of QCD dynamics.

Abstract: In this work, we construct the $D$-wave isoscalar $ππ/K\bar K$ coupled-channel Omnès matrix, formulated to satisfy unitarity, analyticity, and the appropriate asymptotic behavior. We employ a two-channel $K$-matrix model containing poles associated with the $f_{2}(1270)$ and $f_{2}'(1525)$ resonances. The resulting unitary scattering matrix, which reproduces the experimental $ππ\toππ$ and $ππ\to K\bar K$ data and PDG information, serves as input to the homogeneous two-channel Muskhelishvili-Omnès equation. We compare our Omnès matrix with previous constructions based on $ππ\to K\bar K$ phases extracted from sums of Breit-Wigner amplitudes. The Omnès matrix developed here provides a reliable dispersive input for form-factor calculations and resonance studies in the tensor-meson sector. As an application, we show that it enables a simultaneous and accurate description of the BESIII $J/ψ\toπ^{0}π^{0}γ$ and $J/ψ\to K_{S}K_{S}γ$ spectra in the $J=2$ electric-dipole (E1) partial wave.

</details>


### [43] [The Effect of Hadronic Matter on Parton Energy Loss](https://arxiv.org/abs/2512.23692)
*Ritoban Datta,Abhijit Majumder*

Main category: hep-ph

TL;DR: The paper introduces modified thermal distributions in MATTER and LBT event generators within JETSCAPE to model jet modification in heavy-ion collisions, incorporating a $(1 + a/T)$ correction to dispersion relations. This allows extending energy loss calculations into the hadronic phase and reconciles nuclear modification factors and elliptic flow data across collision conditions.


<details>
  <summary>Details</summary>
Motivation: Existing models fail to accurately describe jet quenching and collective flow in heavy-ion collisions, particularly in the hadronic phase. The modified distributions aim to better capture parton-medium interactions and extend valid physics to lower temperatures.

Method: A simple $(1 + a/T)$ correction is applied to quark/gluon dispersion relations, introducing an effective fugacity. This modifies transport coefficients ($\hat{q}/T^3$) to decay at lower temps, while preserving light-like relations at high temps. Combined with initial state shadowing effects, simulations are run using JETSCAPE's MATTER/LBT frameworks.

Result: Successful simultaneous description of R_AA (nuclear modification) and elliptic anisotropy for jets/leading hadrons across multiple centralities and collision energies (e.g., LHC and RHIC data). Shows depreciation behavior matching expectations in hadronic phase.

Conclusion: Modified thermal distributions provide a unified framework explaining jet quenching and collective effects across all collision phases. This advances our understanding of parton energy loss and nuclear matter dynamics in high-energy collisions.

Abstract: Modified thermal distributions (dispersion relations) are introduced within both the MATTER and LBT event generators used to describe jet modification in a heavy-ion collision, within the JETSCAPE framework. Hard partons, propagating through dense matter, scatter off the partonic substructure of the medium, leading to stimulated emission, accompanied by recoiling medium partons. We introduce a simple modification, a multiplicative $(1 + a/T)$ correction to the dispersion relation of quarks and gluons (equivalent to an effective fugacity). This leads to calculated transport coefficients (e.g. $\hat{q}/T^3$) showing the expected behavior of depreciating at lower temperatures, including within the hot hadronic gas. This simple modification recovers the light-like dispersion relations at high temperatures, and introduces an excess depreciation factor for parton populations at lower temperatures, allowing partonic energy loss and recoil calculations to be extended into the hadronic phase. This modified distribution, in combination with initial state cold nuclear matter effects (shadowing), is used to simultaneously describe the nuclear modification factor and elliptic anisotropy of jets and leading hadrons, over multiple centralities and collision energies.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [44] [Matter environments around black holes: geodesics, light rings and ultracompact configurations](https://arxiv.org/abs/2512.22267)
*Dylan S. Fonseca,Caio F. B. Macedo,Mateus Malato Corrêa,Diego Rubiera-Garcia*

Main category: gr-qc

TL;DR: This paper explores how different dark-matter distributions around astrophysical black holes affect spacetime geometry, geodesic structures, and ringdown signals. Key effects include shifts in ISCO and light ring positions, emergence of additional orbits/horizons, and modified ringdown signatures.


<details>
  <summary>Details</summary>
Motivation: Understanding gravitational influence of matter environments on black hole spacetime properties and observational signatures.

Method: Using Einstein clusters with Hernquist, NFW, and Jaffe density profiles to model dark-matter distribution, deriving analytical expressions for low-compactness regimes, and performing numerical simulations of scalar perturbations to study ringdown phenomena.

Result: Environmental effects shift ISCO inward and principal light ring outward, create additional light rings and horizons in high-compactness cases, and produce unique ringdown features like trapped modes and echoes.

Conclusion: Matter distributions significantly alter black hole spacetime properties, critical for interpreting electromagnetic and gravitational-wave observations needing environmental corrections in future studies.

Abstract: Astrophysical black holes are invariably embedded in matter environments whose gravitational influence can alter key strong-field features of the spacetime. In this work, we investigate the impact of spherically symmetric dark-matter distributions on black hole geometry, geodesic structure, and ringdown phenomenology. Modeling the surrounding matter through Einstein clusters, we construct self-consistent spacetimes for three widely used density profiles - the Hernquist, Navarro-Frenk-White (NFW), and Jaffe models - and examine how their near-horizon behavior modifies the location and stability of circular timelike and null geodesics, including the innermost stable circular orbit (ISCO) and light rings. In the low-compactness regime, we derive analytical expressions showing that environmental effects generically shift the ISCO inward and the principal light ring outward, leading to parametric deviations in their associated orbital frequencies and Lyapunov exponents. At higher compactness, we explore the emergence of additional light rings, marginally stable orbits, and secondary horizons, identifying the regions of parameter space in which these ultracompact configurations arise. Using time-domain evolutions of scalar perturbations, we demonstrate how such structures can imprint characteristic signatures on the ringdown signal, including long-lived trapped modes and echo-like modulations associated with multiple potential barriers. Our results provide a unified framework for assessing environmental effects around black holes and highlight the importance of matter-induced corrections for interpreting upcoming electromagnetic and gravitational-wave observations.

</details>


### [45] [Oscillating kink behavior in a traversable wormhole](https://arxiv.org/abs/2512.22281)
*Tian-Chi Ma,Hai-Qing Zhang*

Main category: gr-qc

TL;DR: The study examines how the throat parameter of a Simpson-Visser wormhole affects the dynamics of radial domain walls, showing that larger throat parameters allow wider oscillations while smaller ones confine motion, with energy loss via emitted scalar waves each traversal.


<details>
  <summary>Details</summary>
Motivation: To understand the influence of wormhole geometry on topological defect dynamics and energy transfer in exotic spacetimes.

Method: Numerically solving the scalar-field equation with a double-well potential in a spherically symmetric traversable wormhole background.

Result: Larger throat parameters (a) permit broader domain wall oscillations with larger amplitudes, while smaller a confines motion near the throat. Each kink passage through the throat emits scalar waves, causing amplitude decay.

Conclusion: Wormhole geometry significantly impacts defect dynamics and energy emission, offering new insights into topological defect behavior in exotic spacetimes.

Abstract: We investigate the time evolution of spherically symmetric radial domain walls (kinks) in the background of a two-way traversable Simpson-Visser wormhole. By numerically solving the scalar-field equation with a double-well potential, we show that the wormhole throat parameter $a$ has a strong impact on the dynamics of the radial kink: larger $a$ leads to wider throats and allows the domain wall to oscillate across the throat with large amplitude, whereas smaller $a$ confines the motion nearby the throat. In addition, each time the kink crosses the wormhole throat, it emits scalar wave packets, causing its oscillation amplitude to gradually decrease. Our results reveal how the wormhole geometry influences the motion of defects and their energy transfer, providing new insights into the dynamics of topological defects in exotic spacetime.

</details>


### [46] [Topological Quantum Gravity through Harmonic S$^{2}$ Maps](https://arxiv.org/abs/2512.22289)
*M. Halilsoy,S. Habib Mazharimousavi*

Main category: gr-qc

TL;DR: The paper proposes a topological quantization method using harmonic maps on S², leading to discrete physical quantities. It explores its application to Schwarzschild black holes, non-black holes, and wormholes, revealing macroscopic quantum effects detectable by thermometers or curvature sensors.


<details>
  <summary>Details</summary>
Motivation: To understand the quantization of physical quantities in spacetime and demonstrate how macroscopic quantum effects can be observed in gravitational systems like black holes and wormholes.

Method: Employing harmonic maps on two-dimensional spheres (S²) to achieve topological quantization, analyzing different geometries (Schwarzschild, non-black hole, wormhole) to study quantum hair effects and detectable quantum spacetime properties.

Result: Shows that physical quantities become discrete due to topological quantization. Quantum hair effects become significant in the considered geometries, and macroscopic quantumness of spacetime can be measured via thermometers or curvature-detecting devices.

Conclusion: Topological quantization via harmonic maps provides a natural framework for discrete physical properties in spacetime. Observational methods (e.g., curvature sensors) to detect quantum gravity effects are feasible in specific gravitational geometries.

Abstract: By virtue of harmonic maps on two-dimensional spheres (S$^{2}$), a topological quantization in spacetime is proposed. The discrete character of all physical quantities follows naturally. A Schwarzschild black hole, non-black hole and wormhole based geometries are considered in which a quantum hair becomes effective. A thermometer or curvature-detecting device can record the macroscopic quantumness of spacetime.

</details>


### [47] [Accelerating FJNW Metric](https://arxiv.org/abs/2512.22328)
*Homayon Anjomshoa,Behrouz Mirza,Alireza Azizallahi*

Main category: gr-qc

TL;DR: The paper presents an accelerating Fisher-Janis-Newman-Winicour (FJNW) metric derived via a perturbative method and Buchdahl transformations, analyzes its singularities, and examines geodesics and orbital stability.


<details>
  <summary>Details</summary>
Motivation: To explore the dynamics and structure of accelerating black hole spacetimes, understand singularity effects, and characterize orbital behavior in such metrics.

Method: Derivation of the accelerating FJNW metric using a perturbative approach and Buchdahl transformations; analysis of spacetime singularities, geodesic equations, and orbital stability.

Result: Exact form of the accelerating FJNW metric obtained, singularities characterized, geodesic structures mapped, and conditions for stable circular orbits determined.

Conclusion: The accelerating FJNW metric provides insights into spacetime dynamics with acceleration, offering a tool for studying black hole physics and relativistic orbital mechanics.

Abstract: We derive exact form of accelerating Fisher-Janis-Newman-Winicour (FJNW) metric by a simple perturbative method. We also argue that by using Buchdahl transformations one can obtain the same accelerating FJNW metric. We investigate singularities of the accelerating FJNW metric and study their effects on global and local structures of this spacetime. We also study geodesics and stability of circular orbits.

</details>


### [48] [Traversable ghost wormholes](https://arxiv.org/abs/2512.22361)
*Alberto Guilabert,Ernesto Fuenmayor,Pedro Bargueño,Ernesto Contreras*

Main category: gr-qc

TL;DR: The paper explores the existence of ghost stars as configurations with minimal mass using wormhole physics, finding topological challenges beyond spherical symmetry but demonstrating a viable Casimir-like wormhole model through Hawking mass analysis.


<details>
  <summary>Details</summary>
Motivation: To investigate if ghost stars (objects with nearly zero mass) can be physically realized through wormhole geometries, which naturally incorporate negative energy densities required for such structures.

Method: Analyzing Hawking mass under ghost conditions beyond spherical symmetry and constructing a Casimir-like wormhole model, followed by Penrose-Carter diagram analysis.

Result: Topological obstructions prevent straightforward realization of ghost configurations outside spherical symmetry, but a valid Casimir-like wormhole example is successfully constructed and analyzed.

Conclusion: While generalization beyond spherical symmetry poses challenges, ghost star analogs can exist in specific wormhole systems, highlighting the interplay between exotic matter conditions and spacetime topology.

Abstract: Ghost stars are compact configurations characterized by an arbitrarily small total mass. Such objects require regions of negative energy density -a condition typically regarded as unphysical within the context of conventional stellar models. Nevertheless, negative energy densities arise naturally in traversable wormhole geometries, where the violation of the null energy condition is essential to sustain the flaring-out behavior at the throat. This connection suggests that ghost-like configurations may find a natural realization within wormhole physics. In this work, we investigate the existence of ghost configurations by analyzing their associated Hawking mass. Although in spherical symmetry the Misner and Hawking masses are known to coincide, we show that when the ghost condition is extended beyond spherical symmetry and applied to the Hawking mass, it faces topological obstructions that hinder its straightforward realization. As a concrete example, we demonstrate that a Casimir-like traversable wormhole can be naturally constructed within this framework. Finally, to illustrate the properties of the resulting geometry, we analyze its Penrose-Carter diagram.

</details>


### [49] [Canonical description of Pontryagin and Euler classes with a Barbero-Immirzi parameter](https://arxiv.org/abs/2512.22400)
*Alberto Escalante,Edmundo Suárez-Polo,Luis A. Huerta-del Campo*

Main category: gr-qc

TL;DR: The paper conducts a canonical analysis of Pontryagin and Euler classes with a Barbero-Immirzi parameter using Holst-like variables. It examines constraints, symmetries, and degrees of freedom, showing that γ=±i recovers the self-dual representation. Coupling to the Holst action is also analyzed.


<details>
  <summary>Details</summary>
Motivation: To explore the canonical structure of topological invariants with BI parameters, understand their constraints, symmetries, and degrees of freedom, and investigate the implications of specific BI parameter values (γ=±i) on self-dual representations. Additionally, coupling these invariants to the Holst action is studied to extend gravitational theories.

Method: Rewriting Pontryagin and Euler classes using Holst-like variables, performing canonical analysis to identify constraints, counting physical degrees of freedom, and analyzing reducibility conditions. The BI parameter's effect is tested, particularly at γ=±i, and the invariants are coupled with the Holst action.

Result: Complete canonical structure and symmetries are obtained. The analysis confirms that γ=±i recovers the self-dual representation of the invariants. Coupling to Holst action provides insights into modified gravitational dynamics.

Conclusion: The study establishes the role of BI parameters in shaping topological invariants' canonical structure and their compatibility with Holst action. The self-dual limit at γ=±i is validated, offering foundational insights for quantum gravity and modified gravity theories.

Abstract: A detailed canonical analysis for Pontryagin and Euler classes with a Barbero-Immirzi [BI] parameter is developed. We rewrite the topological invariants by introducing a set of Holst-like variables, and then study the set of all constraints. We report the complete canonical structure and the symmetries of the theory; we count the physical degrees of freedom and identify reducibility conditions among the constraints. In addition, in our results, if we consider the $BI$ parameter takes the value of $γ= \pm i $, then the self-dual representation of these invariants is reproduced. Finally, we couple the invariants to the Holst action and explore the canonical analysis.

</details>


### [50] [Thick brane in Palatini formalism with a non-minimally coupled bulk scalar field](https://arxiv.org/abs/2512.22405)
*Tahereh Azizi,Mojtaba Alimoradi*

Main category: gr-qc

TL;DR: The paper investigates a thick brane scenario in Palatini gravity, achieving a stable configuration with a bell-shaped warp factor and volcano-like scalar potential. It confirms four-dimensional gravity localization through localized graviton modes and stable Kaluza-Klein spectrum.


<details>
  <summary>Details</summary>
Motivation: To explore thick brane solutions in Palatini gravity, addressing stability and gravity localization without tachyonic modes, and to understand braneworld phenomenology within this framework.

Method: Non-minimal coupling of a bulk scalar field with Ricci scalar in Palatini formulation, analytic solutions for flat Poincaré-invariant metric with kink-like scalar, supersymmetric factorization of tensor perturbations, and numerical analysis of Kaluza-Klein modes.

Result: Obtained stable thick brane solutions with regular energy density, localized graviton zero mode, volcano-shaped potential blocking tachyons, and delocalized massive modes confirming 4D gravity recovery.

Conclusion: Palatini gravity supports viable thick branes with stable configurations, advancing understanding of gravity localization and phenomenology in higher-dimensional models.

Abstract: We study a thick brane scenario within the Palatini formulation of gravity, where the metric and affine connection are treated as independent variables. By introducing a non-minimal coupling between a bulk scalar field and the Ricci scalar, we obtain analytic solutions under a flat, four-dimensional Poincaré-invariant metric with a kink-like scalar configuration. The warp factor exhibits a bell-shaped profile, while the scalar potential forms a symmetric volcano-like structure, characteristic of a finite-thickness brane. The corresponding energy density is regular and localized, featuring a central peak with symmetrically placed negative minima. Through the analysis of linear tensor perturbations, we derive a Schrödinger-like equation with supersymmetric factorization, ensuring the absence of tachyonic modes and thus the stability of the background configuration. The effective potential also takes a volcano-like form that supports a localized graviton zero mode, confirming the recovery of four-dimensional gravity on the brane. A numerical study of the massive Kaluza--Klein spectrum reveals the progressive delocalization of massive modes into the bulk.
  Our results demonstrate a stable and physically consistent thick brane configuration within the Palatini gravity framework, offering new insights into gravity localization and braneworld phenomenology.

</details>


### [51] [Scalar-hairy AdS Black Hole in the Einstein-Maxwell-Scalar Theory: first-order phase transition with a critical point](https://arxiv.org/abs/2512.22433)
*Hong Guo,Hang Liu,Yun Soo Myung*

Main category: gr-qc

TL;DR: The paper investigates scalar-hairy and tachyonic-hairy black hole solutions in asymptotically AdS spacetime within the EMS model, finding coexisting phases and a first-order transition linked to parameter variations and coupling strength.


<details>
  <summary>Details</summary>
Motivation: To explore how nonminimal coupling to the Maxwell field and scalar potentials influence hairy black hole solutions in AdS spacetime, and to understand phase transitions between different hairy phases.

Method: Analyzing the Einstein-Maxwell-scalar model with a real massive scalar field, considering both vanishing and non-vanishing scalar potentials. Numerical and analytical methods are used to study black hole solutions, parameter space, and phase transitions.

Result: Scalar-hairy black holes similar to flat spacetime solutions exist when the scalar potential is absent. With a scalar potential, tachyonic-hairy solutions emerge, leading to coexisting phases. A first-order phase transition between these phases is identified, originating from a critical point influenced by temperature and chemical potential, with increasing coupling strength shifting the critical point to higher values.

Conclusion: The EMS model in AdS spacetime exhibits rich phase behavior with two distinct hairy phases and a first-order transition dependent on scalar coupling and potential parameters, highlighting the role of nonminimal couplings and potentials in black hole physics.

Abstract: In asymptotically anti-de Sitter (AdS) spacetime, we consider a real massiver scalar field in the Einstein-Maxwell-scalar (EMS) model and examine both scalar-hairy black hole solutions induced by the nonminimal coupling to the Maxwell field and tachyonic-hairy solutions driven by the scalar potential. When the scalar potential vanishes, scalar-hairy black holes emerge with profiles and properties similar to those observed in flat spacetime. The presence of the scalar potential additionally induces tachyonic-hairy solutions, leading to the coexistence of these two distinct hairy phases in different regions of the parameter space. The phase diagram reveals a first-order phase transition line between the tachyonic-hairy and scalar-hairy phases, originating at a critical point in the extreme temperature and chemical potential regime. Our detailed analysis shows that this phase transition is directly associated with the self-overlap region of the scalar-hairy phase and its start point. Moreover, increasing the coupling strength $λ$ shifts the critical point to higher temperature and chemical potential.

</details>


### [52] [Cosmological long-wavelength solutions in non-adiabatic multi-fluid systems](https://arxiv.org/abs/2512.22531)
*Hayami Iizuka,Tomohiro Harada*

Main category: gr-qc

TL;DR: The paper develops a nonlinear formulation for cosmological perturbations in multi-fluid systems on superhorizon scales using the ADM formalism and gradient expansion. It constructs nonlinear solutions showing both adiabatic and entropy modes, discusses non-uniqueness in entropy perturbations, and analyses their evolution in two-fluid systems.


<details>
  <summary>Details</summary>
Motivation: To extend understanding of nonlinear dynamics of cosmological perturbations in multi-fluid scenarios beyond linear theory, addressing non-adiabatic effects and entropy mode contributions on superhorizon scales.

Method: Uses the Arnowitt-Deser-Misner (ADM) formalism combined with spatial gradient expansion (small expansion parameter k/H). Constructs nonlinear solutions for multi-fluid systems, defines adiabatic/entropy perturbations, and examines different entropy initial conditions in a two-fluid model.

Result: Nonlinear solutions include both adiabatic and entropy modes at leading order. Shows non-uniqueness in defining pure entropy perturbations. Demonstrates time evolution of curvature and density perturbations depending on initial entropy conditions.

Conclusion: Nonlinear superhorizon perturbations in multi-fluid cosmology require simultaneous consideration of adiabatic and entropy modes. Initial entropy conditions significantly influence evolution of observables, highlighting the importance of precise entropy perturbation definitions in cosmological models.

Abstract: We develop a formulation of nonlinear cosmological perturbations on superhorizon scales in multi-fluid systems. It is based on the Arnowitt-Deser-Misner formalism combined with a spatial gradient expansion characterized by a small expansion parameter defined as the ratio of the comoving wavenumber to the Hubble scale. The background spacetime is assumed to be a flat Friedmann-Lemaitre-Robertson-Walker universe. Within this framework, we explicitly construct nonlinear long-wavelength solutions for cosmological perturbations. Since multi-fluid systems are inherently non-adiabatic, these solutions admit both adiabatic and entropy modes already at leading nonlinear order. We define adiabatic and entropy perturbations and discuss the non-uniqueness in defining pure entropy perturbations. Using different choices of pure entropy initial conditions, we analyze the time evolution of physical quantities such as the curvature perturbation and density perturbations in the geodesic slicing for two-fluid systems.

</details>


### [53] [Topological Mod(A)Max AdS black holes](https://arxiv.org/abs/2512.22654)
*B. Eslam Panah,B. Hamil,Manuel E. Rodrigues*

Main category: gr-qc

TL;DR: The paper explores new topological black hole solutions in AdS spacetime using ModMax and ModAMax nonlinear electrodynamics. It examines thermodynamic properties, thermal stability, Joule-Thomson effects, and heat engine efficiency, showing that Mod(A)Max parameters and horizon topology significantly influence these aspects.


<details>
  <summary>Details</summary>
Motivation: To investigate how nonlinear electrodynamics (ModMax/ModAMax) and topology affect thermodynamic behaviour and performance of AdS black holes, extending gravitational and thermodynamic understanding.

Method: Constructed black hole solutions with ModMax/ModAMax models, calculated thermodynamic quantities, validated first law of thermodynamics, analyzed Joule-Thomson expansion inversion curves, evaluated heat engine efficiency in extended phase space.

Result: Mod(A)Max parameters and topology drastically alter thermal stability, cooling/heating regions in Joule-Thomson process, and heat engine efficiency, demonstrating their critical role in thermodynamic performance.

Conclusion: Nonlinear electrodynamics parameters and horizon topology are essential factors in tuning thermodynamic properties and efficiency of AdS black hole systems, offering new insights for gravitational theories and applications.

Abstract: In this work, we construct new classes of topological black hole solutions in anti-de Sitter (AdS) spacetime using a novel model of nonlinear electrodynamics called Modification Maxwell (ModMax) and Modification phantom or Modification anti-Maxwell (ModAMax). We then evaluate the thermodynamic quantities and verify the first law of thermodynamics. Our study examines how the parameters of the ModMax and ModAMax fields, as well as the topological constant, affect the black hole solutions, thermodynamic quantities, and local and global thermal stabilities. Furthermore, within the framework of extended phase space thermodynamics, we analyze the Joule-Thomson expansion process and determine the inversion curves. This analysis reveals that the ModMax and ModAMax parameters significantly alter the cooling and heating behavior of these AdS black holes, depending on their topology. Finally, by treating these topological Mod(A)Max AdS black holes as heat engines, we assess their efficiencies, demonstrating that the parameters of nonlinear electrodynamics and horizon topology play crucial roles in enhancing or suppressing the system's thermodynamic performance.

</details>


### [54] [When spacetime vibrates: An introduction to gravitational waves](https://arxiv.org/abs/2512.22679)
*José P. S. Lemos*

Main category: gr-qc

TL;DR: This paper provides an overview of gravitational wave physics, covering theoretical foundations from general relativity, historical milestones like the detection of GW150914, detection methods using observatories like LIGO, and future prospects for gravitational wave astronomy.


<details>
  <summary>Details</summary>
Motivation: To explore gravitational wave physics comprehensively, highlighting their theoretical basis, experimental validations, and the transformative impact on astronomy through multi-messenger observations.

Method: Analyzes theoretical concepts of general relativity, reviews historical predictions and experiments, discusses detection mechanisms via interferometers (LIGO/Virgo/KAGRA), and evaluates observed events like GW150914 alongside potential cosmological sources.

Result: Confirmed general relativity predictions through GW150914 detection, established gravitational wave astronomy as a new observational tool, and outlined future projects to enhance detection capabilities and explore cosmological origins.

Conclusion: Gravitational wave observations complement electromagnetic data, revolutionizing astrophysics by providing new insights into cosmic events and the universe's early moments, underscoring the importance of multi-channel observational strategies.

Abstract: This article presents a comprehensive analysis of the physics of gravitational waves, exploring both the theoretical foundations and the most recent experimental advances. After a general introduction to the theory of general relativity and its major implications, the article discusses the history of gravitational waves, from their prediction by Einstein to their actual detection. It then explains what gravitational waves are and how they interact with appropriate detectors. The main mechanisms of gravitational radiation emission are analyzed, with a focus on compact binary systems of compact objects, whose orbits typically evolve in three phases: inspiral, merger, and the final ringdown phase, each of these phases leaving distinct signatures in the emitted waves. The article highlights the fundamental role of the giant interferometers LIGO, Virgo, and KAGRA, true cathedrals of modern science, and revisits the historic event GW150914, the first direct detection of gravitational waves, which confirmed the predictions of general relativity and opened a new era for astronomy. This achievement was recognized with the 2017 Nobel Prize in Physics. Other observed events are also discussed, along with their astrophysical sources, and the possibility of detecting gravitational waves of cosmological origin, originating from the Big Bang itself. Finally, current and future projects are analyzed, including observatories based on increasingly sophisticated interferometers, as well as proposals for alternative detection methods, illustrating how gravitational-wave astronomy is shaping the present and future of our exploration of the universe. In concluding, the detection of gravitational waves is set in a broader context by examining the discoveries across the electromagnetic spectrum, thereby illustrating the complementary perspectives these different observational channels provide.

</details>


### [55] [A Machian wave effect in conformal, scalar-tensor gravitational theory](https://arxiv.org/abs/2512.22687)
*José Rodal*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Woodward proposed that driven mass-energy fluctuations could yield a frequency-dependent "Machian" gravitational response $\propto \partial_t^2 M_{\rm loc}(t)$, amplified by a Sciama-scale cosmic potential $Φ/c^2\sim -1$. We test this claim covariantly in (i) Einstein gravity and (ii) Hoyle-Narlikar (HN) conformal scalar-tensor gravity. In GR, the Landau-Lifshitz relaxed equations in harmonic gauge contain nonlinear terms of the form $H^{αβ}\,\partial_α\partial_βH^{μν}$, including a near-zone piece $H^{00}\,\partial_t^2 H^{μν}$. These terms are not independent matter sources; they arise from expanding the curved wave operator about a flat background. Moving them back to the left-hand side restores the quasilinear principal part, and for laboratory devices their size is suppressed by $\sim (U_N/c^2)(ωL/c)^2\ll 1$, with no enhancement by any cosmological potential. In HN theory, the conformal scalar satisfies $\nabla_a\nabla^a m + (R/6)m=λN$. For a localized device of size $L$ driven at angular frequency $ω$, $|(c^{-2}\partial_t^2 m_s)|/|\nabla^2 m_s|\sim (ωL/c)^2\ll 1$, so the response is effectively instantaneous (Poisson-like), not wave-amplified. Baryon-number conservation fixes the scalar charge, so the rest-mass monopole cannot oscillate; any radiating monopole requires nonconservative internal-energy variations, further suppressed by $E_{\rm int}/(M c^2)$ and by $M_{\rm dev}/M_H$. Thus any Mach-effect thrust is far too small for practical propulsion.

</details>


### [56] [Solving the constraint equation for general free data](https://arxiv.org/abs/2512.22704)
*Xuantao Chen,Sergiu Klainerman*

Main category: gr-qc

TL;DR: The paper introduces a novel method to solve the Einstein constraint equations in vacuum by prescribing four scalar quantities. The method transforms the equations into transport and elliptic equations on 2-spheres, solvable via iteration, allowing exterior solutions to match given interiors. This expands initial data sets for black hole evolution, improving on previous results like Li and Yu's trapped surface formation, and can handle various decay rates from O(r^{-1−δ}) to arbitrarily fast decaying data. A key aim is to demonstrate the sharpness of Shen's decay conditions by constructing counterexamples where stability of Minkowski space fails.


<details>
  <summary>Details</summary>
Motivation: The motivation lies in addressing limitations of prior methods in solving the Einstein constraint equations and constructing initial data sets. The authors seek to leverage flexibility in specifying four scalar quantities as free data to generate diverse solutions, including those matching interior/exterior regions. Specifically, they aim to test the necessity of Shen's decay assumptions by creating initial data violating these to show Minkowski space instability.

Method: The method involves selecting gauge conditions and freely specifying four scalar fields (excluding ℓ≤1 modes). This transforms the constraint equations into a coupled system of transport and elliptic equations on 2-spheres. Solving via iterative procedures allows construction of exterior solutions compatible with gluing techniques. The approach adapts easily to different decay rates, accommodating scenarios from O(r^{-1-δ}) behaviors down to slower decays like Shen's and arbitrarily fast ones.

Result: They prove a main theorem yielding existence of initial data sets under O(r^{-1-δ}) and O(r^{-2-δ}) decay conditions. The method's versatility enables solutions across decay regimes, including potential applications to construct data violating Shen's decay conditions. This provides a tool for constructing black hole initial data and studying stability conjectures.

Conclusion: The conclusions confirm the method's effectiveness in generating rich families of initial data beyond existing frameworks. It validates applications in testing extremal conditions of prior results like Shen's, offering a pathway to explore the sharpness of stability thresholds in general relativity.

Abstract: We revisit the problem of solving the Einstein constraint equations in vacuum by a new method, which allows us to prescribe four scalar quantities, representing the full dynamical degrees of freedom of the constraint system. We show that once appropriate gauge conditions have been chosen and four scalars freely specified (modulo $\ell\leq 1$ modes), we can rewrite the constraint equations as a well-posed system of coupled transport and elliptic equations on $2$-spheres, which we solve by an iteration procedure. Our method provides a large class of exterior solutions of the constraint equations that can be matched to given interior solutions, according to the existing gluing techniques. As such, it can be applied to provide a large class of initial Cauchy data sets evolving to black holes, generalizing the well-known result of the formation of trapped surfaces due to Li and Yu. Though in our main theorem, we only specify conditions consistent with $g-g_{Schw}=O(r^{-1-δ})$, $k=O(r^{-2-δ})$, the method is flexible enough to be applied in many other situations. It can, in particular, be easily adapted to construct arbitrarily fast decaying data. We expect, moreover, that our method can also be applied to construct data with slower decay, such as that used by Shen. In fact, an important motivation for developing our method is to show that the result of Shen is sharp, i.e., construct small, smooth initial data sets which violate Shen's decay conditions, and for which the stability of the Minkowski space result is wrong.

</details>


### [57] [The new generation lunar gravitational wave detectors: sky map resolution and joint analysis](https://arxiv.org/abs/2512.23556)
*Xiaolin Zhang,Chengye Yu,Haoran Li,Sobhan Kazempour,Mingqiu Li,Sichun Sun*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Lunar-based gravitational-wave interferometry is a fascinating endeavor, and was proposed as a promising approach to bridge the observational gap between space-borne and ground-based detectors. In this work, we adopt the Fisher-matrix method to examine the angular-resolution performance of the newly proposed Crater Interferometry Gravitational-wave Observatory (CIGO) on the lunar crater rim near the north pole, together with TianQin and LISA, for monochromatic sources in the 0.1-10 Hz band. We find that above 0.1 Hz, CIGO achieves better localization accuracy than the other two space-based missions and dominates the combined detector network's performance, provided that lunar noise mitigation is achieved in the 0.1-2.87 Hz frequency range. We further explore an upgraded Tetrahedron configuration, TCIGO, with a fourth station at the bottom of a crater, which forms a regular tetrahedral constellation on the lunar surface. The result shows that TCIGO yields a five-fold improvement in angular-resolution capability over CIGO and gets better sky coverage across the target frequency band.

</details>


### [58] [Probing higher curvature gravity via ringdown with overtones](https://arxiv.org/abs/2512.22728)
*Keisuke Nakashi,Masashi Kimura,Hayato Motohashi,Kazufumi Takahashi*

Main category: gr-qc

TL;DR: The study examines how higher curvature terms in gravity theories affect metric perturbations of spherically symmetric black holes, finding significant deviations in quasinormal mode frequencies, particularly for overtone modes, which become more pronounced as the curvature term order increases.


<details>
  <summary>Details</summary>
Motivation: To understand the impact of higher curvature corrections on black hole perturbations and quasinormal modes, which are crucial for testing gravity theories beyond general relativity using observational data from black hole ringdowns.

Method: The researchers analyzed metric perturbations in higher curvature gravity by studying deformations in the near-horizon effective potential and their effect on quasinormal mode frequencies. They also examined ringdown waveforms to identify shifted QNMs through waveform fitting.

Result: Higher curvature terms cause deformations in the effective potential near the horizon, leading to increasingly large deviations in overtone QNM frequencies as the curvature term order increases. The study shows that these shifted frequencies can be detected in ringdown signals even when deviations are mild for lower overtones.

Conclusion: Higher curvature gravity models produce measurable deviations in black hole ringdown signals, especially for higher overtone modes, providing a potential observational test to distinguish these theories from general relativity.

Abstract: We investigate metric perturbations of a spherically symmetric black hole in higher curvature gravity. We show that higher curvature corrections deform the near-horizon region of the effective potential, and that the deviations of the quasinormal mode (QNM) frequencies from their general relativity (GR) values become more pronounced for overtone modes. We find that, as the order of the higher curvature term increases, the deformations approach the horizon and the deviations of the overtone QNM frequencies grow progressively larger. We also analyze the ringdown waveforms in the higher curvature gravity model. We consider setups in which the deviations from the vacuum-GR QNMs remain mild for the fundamental mode and the first few overtones, and show that these shifted QNMs can be identified in the ringdown signal through waveform fitting.

</details>


### [59] [Constraining the dynamical Chern-Simons gravity with future gravitational wave detectors](https://arxiv.org/abs/2512.22762)
*Xinyi Che,Xiangyu Lyu,Changfu Shi*

Main category: gr-qc

TL;DR: This paper evaluates the potential of future gravitational-wave detectors to constrain dynamical Chern-Simons gravity using stellar mass black hole binaries, considering detector variations, source parameters, and astrophysical mass distributions.


<details>
  <summary>Details</summary>
Motivation: Current gravitational wave observations cannot effectively constrain dynamical Chern-Simons gravity due to detector noise and waveform model limitations. The study aims to assess future prospects for testing this modified gravity theory.

Method: The authors analyze how different gravitational wave detectors and source parameters affect constraints on dynamical Chern-Simons gravity. They also apply an astrophysically motivated mass distribution model to estimate detection potential for upcoming observatories.

Result: The study identifies parameter space regions compliant with the small-coupling condition and quantifies how detector capabilities and binary properties influence constraint strengths.

Conclusion: Future gravitational-wave observatories, combined with improved astrophysical models, will significantly enhance the ability to test dynamical Chern-Simons gravity through stellar mass black hole binary observations.

Abstract: Dynamical Chern-Simons gravity, a parity-violating modification of general relativity, is regarded as a low-energy effective theory arising from string theory. Gravitational waves provide a powerful probe for testing its predictions. However, current gravitational wave observations are unable to place meaningful constraints on this theory through phase measurements, due to limitations from detector noise and the validity requirements of the waveform models. In this paper, we conduct a comprehensive assessment of the prospects for constraining the dynamical Chern-Simons gravity with future gravitational-wave detectors using stellar mass black holes binary. We quantify how the constraining capacities vary across different detectors and source parameters, and identify the regions of parameter space that satisfy the small-coupling condition. Furthermore, by incorporating an astrophysically motivated mass distribution model for stellar mass black hole binaries, we estimate the potential of upcoming observatories.

</details>


### [60] [Polarized image of an equatorial emitting ring around a Konoplya-Zhidenko rotating non-Kerr black hole](https://arxiv.org/abs/2512.22764)
*Xin Qin,Fen Long,Songbai Chen,Jiliang Jing*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the polarized images of an equatorial emitting ring around a Konoplya-Zhidenko rotating non-Kerr black hole, which introduces an additional deformation parameter. The deformation parameter $η$ allows the spin parameter to extend beyond the bounds imposed by the standard Kerr black hole. The results indicate that the polarized images depend not only on the magnetic field configuration, fluid velocity, and observer inclination angle, but also on the deformation parameter and the spin parameter. As the deformation parameter increases, the polarization intensity decreases monotonically when the magnetic field lies in the equatorial plane, whereas it does not vary monotonically when the magnetic field is perpendicular to the equatorial plane. The variation of the electric vector position angle with the deformation parameter is complex. For a fixed deformation parameter, the polarization intensity exhibits a non-monotonic dependence on the spin parameter and varies with azimuthal angle. We also investigate the impact of the deformation parameter on the Stokes Q-U loops. The imprint of the deformation parameter in polarized images may serve as a high-precision observational probe for detecting deviations of black hole spacetime from the Kerr geometry and testing general relativity.

</details>


### [61] [Topological Complex Analysis of Kerr--Newman Black Hole Microstructure in f(R) Gravity](https://arxiv.org/abs/2512.22853)
*Wen-Xiang Chen*

Main category: gr-qc

TL;DR: The paper studies the microstructure of Kerr Newman black holes in f(R) modified gravity using a topological complex analytic method inspired by holography. It introduces a discrete topological index that classifies black hole microstates based on horizon structure and stability, finding that non-extremal black holes with both horizons have zero index, while single-horizon ones have a unit index. It also validates the method with a Starobinsky model and hints at phase protection in black hole thermodynamics.


<details>
  <summary>Details</summary>
Motivation: To understand the microstructure of black holes in modified gravity theories (specifically f(R)), providing a topological classification that connects horizon properties with thermodynamic stability. The existing approaches might not fully capture the microstate structure, so this work seeks a more robust framework using complex analysis and holography.

Method: Uses a topological complex analytic framework where black hole microstates are singularities of an analytically continued partition function. The entropy is calculated via residues weighted by winding numbers. The classification relies on a discrete topological index derived from these properties. Tested with a Starobinsky-type f(R) model.

Result: Derives a classification via a topological index showing non-extremal Kerr Newman black holes with two horizons have zero index (unstable?), single-horizon configurations have unit index (stable?). Validates this with a Starobinsky model, indicating robustness under gravity modifications. Limits of analytic continuation are noted, suggesting potential phase protection in thermodynamics.

Conclusion: The topological index offers a new way to categorize black hole microstates and thermal stability in modified gravity. While the method has limitations, it implies possible phase protection mechanisms in black hole thermodynamics, opening avenues for further exploration in holographic approaches to quantum gravity.

Abstract: We investigate the microstructure of Kerr Newman black holes in modified gravity of the f(R) type using a topological complex analytic framework inspired by holography. In this approach, black hole microstates are identified with singularities of an analytically continued partition function, and the entropy is obtained from residues weighted by winding numbers. We show that the microstructure is characterized by a discrete topological index, which encodes both horizon structure and thermodynamic stability. Non extremal Kerr Newman black holes with both inner and outer horizons correspond to a vanishing topological index, while single horizon configurations correspond to a positive unit topological index. An explicit Starobinsky type modified gravity model demonstrates that this classification is robust under changes to the gravitational sector. We further discuss the limitations of the analytic continuation procedure and suggest that this topological classification may indicate a form of phase protection in black hole thermodynamics.

</details>


### [62] [A Geometric Area Bound for Information Transfer Through Semiclassical Traversable Wormholes](https://arxiv.org/abs/2512.22928)
*Fuat Berkin Altunkaynak,Aslı Tuncer*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We prove a rigorous geometric bound on the transmission of quantum information through semiclassical traversable wormholes. We initially prove an area theorem showing that the minimal throat surface of a traversable wormhole cannot increase using Raychaudhuri's equation together with the null energy condition for the infalling matter. Then, the max-flow in the bit-thread picture, which corresponds to the initial minimal throat area, is shown to set the upper bound on information transfer. We also discuss two glued HaPPY codes as a toy model for a wormhole.

</details>


### [63] [Multi-messenger detectability of continuous gravitational waves from the near future to next generation detectors](https://arxiv.org/abs/2512.22938)
*Benjamin J. Owen,Binod Rajbhandari*

Main category: gr-qc

TL;DR: The paper assesses the detectability of continuous gravitational waves using theoretical and observational data, focusing on neutron stars and future detectors like Cosmic Explorer. It suggests upcoming detectors could make many detections, which would validate theories on neutron star spin and magnetic fields. A lack of detections might challenge current formation theories.


<details>
  <summary>Details</summary>
Motivation: To evaluate the potential for detecting continuous gravitational waves from neutron stars, which could provide insights into astrophysics and test theories on millisecond pulsar formation. The study updates previous estimates for detectors like Cosmic Explorer and the Einstein Telescope.

Method: Combining theoretical models and observational data from known astronomical objects, systematically applying these to projected detection capabilities of future gravitational wave detectors. This includes re-evaluating assumptions about neutron star spin regulation by gravitational waves and the buried magnetic field hypothesis in millisecond pulsars.

Result: The analysis indicates that upcoming detector upgrades may lead to the first continuous gravitational wave detections, with next-gen detectors enabling numerous detections. Conversely, no detections within the next few years could undermine current neutron star formation theories.

Conclusion: Successful detection validates prevailing theories on neutron star spin and magnetic fields. A failure to detect would necessitate rethinking millisecond pulsar formation mechanisms, emphasizing the critical role of advanced gravitational wave observatories in testing astrophysical theories.

Abstract: Continuous gravitational waves have the potential to transform gravitational wave astronomy and yield fresh insights into astrophysics, nuclear and particle physics, and condensed matter physics. We evaluate their detectability by combining various theoretical and observational arguments from the literature and systematically applying those arguments to known astronomical objects and future gravitational wave detectors. We detail and update previous estimates made in support of Cosmic Explorer [M. Evans et al., arXiv:2306.13745; I. Gupta et al., Class. Quantum Grav. 41, 245001 (2024)]. It is commonly argued that the spins of accreting neutron stars are regulated by gravitational wave emission and that millisecond pulsars contain a young pulsar's magnetic field buried under accreted material. If either of these arguments holds, the first detection of continuous gravitational waves is likely with near future upgrades of current detectors, and many detections are likely with next generation detectors such as Cosmic Explorer and the Einstein Telescope. A lack of detections in the next several years would begin to raise serious doubts about current theories of millisecond pulsar formation.

</details>


### [64] [Colloquium: Multimessenger astronomy with continuous gravitational waves and future detectors](https://arxiv.org/abs/2512.22945)
*Benjamin J. Owen*

Main category: gr-qc

TL;DR: The paper discusses the potential detection of continuous gravitational waves from neutron stars and how such detections, combined with electromagnetic observations, can reveal new insights into extreme matter physics.


<details>
  <summary>Details</summary>
Motivation: To explore the prospects and scientific significance of detecting continuous gravitational waves from rapidly rotating neutron stars, emphasizing interdisciplinary connections and future observational synergies.

Method: The author surveys existing theories, electromagnetic observations, and anticipated capabilities of next-generation detectors like Cosmic Explorer and the Einstein Telescope, evaluating how multi-messenger astronomy can enhance understanding.

Result: The first detections of such waves are anticipated within a few years, with many more expected in the next generation detector era. These signals promise unprecedented insights into neutron star physics and extreme matter due to their extensive signal cycles.

Conclusion: Continuous gravitational wave detection, especially when paired with advanced electromagnetic facilities, offers transformative potential for studying neutron star interiors and extreme matter states that are inaccessible through current methods.

Abstract: Continuous gravitational waves from rapidly rotating neutron stars are on the new frontiers of gravitational wave astrophysics and have strong connections to electromagnetic astronomy, nuclear astrophysics, and condensed matter physics. In this Colloquium I survey prospects for detection of continuous gravitational waves from various neutron star populations, especially aided by electromagnetic observations. Although there are caveats, current theories and observations suggest that the first detections are likely within a few years, and that many are likely in the era of next generation detectors such as Cosmic Explorer and the Einstein Telescope. I also survey what can be learned from these signals, each one of which will contain more cycles than all the compact binary mergers ever detected. Since continuous gravitational wave emission mechanisms depend on aspects of neutron star physics, such as crustal elasticity, which are not well constrained by current astronomical observations and physical experiments, their detection can tell us a great deal that is new about extreme matter. Even more can be learned by combining gravitational wave observations with data from the Square Kilometre Array, the Next Generation Very Large Array, FAST, and other electromagnetic detectors operating in the next generation era.

</details>


### [65] [Frozen Neutron Stars in Four-Dimensional Non-polynomial Gravities](https://arxiv.org/abs/2512.23525)
*Chen Tan,Yong-Qiang Wang*

Main category: gr-qc

TL;DR: Investigates neutron star properties in four-dimensional non-polynomial gravity, finding that increasing α leads to larger neutron stars and a frozen state resembling black holes, which is a universal endpoint independent of EOS.


<details>
  <summary>Details</summary>
Motivation: To explore how neutron stars behave in non-polynomial gravity models and determine observational constraints on the theory's parameters.

Method: Solved modified Tolman-Oppenheimer-Volkoff equations for BSk19, SLy4, and AP4 equations of state, analyzing effects of the α parameter on neutron star structure.

Result: Increased α enlarges neutron star mass and radius, leading to a frozen state with a critical horizon when α is large enough; this state is a universal endpoint independent of EOS. Derived α bounds consistent with observations.

Conclusion: Frozen neutron stars are viable within observational limits, offering a novel endpoint for neutron-star evolution in non-polynomial gravity theories.

Abstract: This paper investigates the structure and properties of neutron stars in four-dimensional non-polynomial gravities. Solving the modified Tolman-Oppenheimer-Volkoff equations for three different equations of state (BSk19, SLy4, AP4), we confirm that neutron star solutions remain in existence. As the modification parameter $α$ increases, neutron stars grow in both radius and mass. We find that, when the parameter $α$ is sufficiently large, a frozen state emerges at the end of the neutron-star sequence. In this state, the metric functions approach zero extremely close to the stellar surface, forming a critical horizon, making it nearly indistinguishable from a black hole to an external observer. Such a frozen neutron star constitutes a universal endpoint of the neutron-star sequence in this theory, independent of the choice of the equation of state. Based on our results and current observational constraints, we derive bounds on the modification parameter $α$ and show that frozen neutron stars remain allowed in the bounds.

</details>


### [66] [Gravitational Noether-Ward identities for scalar field](https://arxiv.org/abs/2512.22958)
*Tomislav Prokopec*

Main category: gr-qc

TL;DR: The paper examines gravitational Noether-Ward identities in the context of metric perturbations on quantum matter backgrounds, specifically in Einstein gravity with a massive non-minimally coupled scalar field. It shows that individual terms in gravitational perturbation equations are non-transverse but the overall equation maintains transversality. Each renormalization counterterm for graviton self-energy also obeys its own Noether identity. Additionally, the analysis confirms that Noether-Ward identities hold regardless of the metric perturbation definition used, demonstrating their universal validity across different formulations.


<details>
  <summary>Details</summary>
Motivation: To understand how gravitational Noether-Ward identities behave under different definitions of metric perturbations and in the presence of quantum matter fields, ensuring consistency in renormalization procedures for graviton self-energies in curved spacetime.

Method: The authors analyze equations of motion for gravitational perturbations covariantly coupled to a quantum scalar field. They decompose the equations into terms, check transversality and Noether-Ward compliance for each term, derive counterterms' Noether identities, and compare results under two inequivalent metric perturbation definitions.

Result: Each term in gravitational perturbation equations individually satisfies Noether-Ward identities despite non-transversality, collectively maintaining transversality. Counterterms for renormalization each have their own Noether identities. Changing metric perturbation definitions doesn't violate Noether-Ward identities; they remain valid in all formulations.

Conclusion: Gravitational Noether-Ward identities are fundamental constraints persisting across different metric perturbation definitions and renormalization processes, ensuring physical consistency in quantum gravitational systems with non-minimal scalar couplings. These findings clarify the structural requirements for maintaining covariance and unitarity in quantum gravity calculations.

Abstract: We consider the gravitational Noether-Ward identities for the evolution of general metric perturbations on quantum matter backgrounds. In this work we consider Einstein's gravity covariantly coupled to a massive, non-minimally coupled, quantum scalar field in general curved backgrounds. We find that each term in the equation of motion for gravitational perturbations satisfies its own Noether-Ward identity. Even though each term is non-transverse, the whole equation of motion maintains transversality. In particular, each counterterm needed to renormalize the graviton self-energy satisfies its own Noether identity, and we derive the explicit form for each. Finally, in order to understand how the Noether-Ward identities are affected by the definition of the metric perturbation, we consider two inequivalent definitions of metric perturbations and derive the Noether-Ward identities for both definitions. This implies that there are Noether-Ward identities for every definition of the metric perturbation.

</details>


### [67] [Scalar-Field Wave Dynamics and Quasinormal Modes of the Teo Rotating Wormhole](https://arxiv.org/abs/2512.23104)
*Ramesh Radhakrishnan,Gerald Cleaver,Delaram Mirfendereski,Eric Davis,Claudio Cremaschini*

Main category: gr-qc

TL;DR: The study investigates scalar field perturbations of a rotating Teo wormhole, analyzing its quasinormal mode (QNM) spectrum using WKB methods. It finds that the QNM frequency and damping rate decrease with increasing spin, showing a monotonic dependence on rotation. The wormhole's lack of an event horizon leads to longer-lived modes compared to Kerr black holes. Eikonal analysis links photon-ring properties to QNMs, revealing differences from Kerr's symmetric mode splitting. The Teo wormhole's ergoregion cannot support classical superradiant amplification due to no horizon.


<details>
  <summary>Details</summary>
Motivation: To explore how rotation and horizonless geometry affect wave dynamics in compact objects, contrasting with Kerr black holes. The goal is to identify distinct spectral signatures of wormholes through QNM analysis.

Method: Scalar perturbations were modeled via separated Klein-Gordon equation leading to a Schrödinger-like radial equation. WKB methods computed QNM spectra across spins. Eikonal limit analysis connected QNMs to photon-ring properties.

Result: QNM frequencies and damping rates decline with spin, showing non-symmetric, one-sided splitting. Teo wormholes exhibit confined spin response and partial throat reflection. No superradiant amplification occurs due to no horizon. Photon-ring parameters match eikonal QNM predictions.

Conclusion: Rotation and boundary conditions (horizonless) significantly alter QNM behavior compared to Kerr. These spectral features serve as observational tests to distinguish rotating wormholes from black holes.

Abstract: We analyze scalar field perturbations of the rotating Teo wormhole and compute its quasinormal mode (QNM) spectrum using WKB methods in a fully horizonless geometry. The Klein Gordon equation separates and yields a Schrödinger type radial equation with a single, smooth potential barrier shaped by the localized frame dragging profile of the wormhole throat. This barrier supports damped oscillatory modes across the full spin range examined. The resulting QNM spectrum exhibits a coherent and monotonic dependence on rotation. As the spin increases, both the oscillation frequency and the damping rate decrease, indicating progressively longer-lived modes in the absence of horizon induced absorption. In the eikonal limit, we extract the photon-ring radius, orbital frequency, and Lyapunov exponent, and verify the standard QNM-Eikonal correspondence. Comparison with Kerr black holes reveals qualitative differences. Whereas Kerr QNMs are governed by horizon absorption and exhibit symmetric prograde/retrograde mode splitting, the Teo wormhole displays a stronger but spatially confined spin response, partial reflection at the throat, and a distinctive one-sided splitting that saturates rapidly with increasing spin. Although the rotating Teo wormhole admits an ergoregion and superradiant compatible frequency kinematics, the absence of an event horizon or dissipative boundary prevents classical superradiant amplification. These results demonstrate how rotation and boundary conditions jointly shape wave propagation in horizonless compact objects and provide characteristic spectral signatures distinguishing rotating wormholes from Kerr black holes.

</details>


### [68] [Lense-Thirring Acoustic Black Holes : Shadows and Light](https://arxiv.org/abs/2512.23113)
*Anas El Balali,Alessio Marrani*

Main category: gr-qc

TL;DR: The paper introduces the Lense-Thirring Acoustic Black Hole (LTABH) model, analyzing its spacetime geometry and effects of parameters ξ and a on shadow sizes, critical radii, and frame-dragging effects. Results show ξ expands shadow sizes while a alters optical shadow positioning and critical radii, with notable frame dragging near horizons.


<details>
  <summary>Details</summary>
Motivation: To explore analogue black hole models in physical systems like cosmological backgrounds or superfluids, focusing on how parameters influence geometric and dynamical properties in LTABH spacetime.

Method: Analysis of LTABH metric's roots partitioning spacetime into four regions, examination of acoustic and photon sphere radii dependence on ξ and a, computation of precession frequency Ω to study frame-dragging effects, and light deflection calculations.

Result: The acoustic parameter ξ enlarges both acoustic and optical shadow sizes, while rotation parameter a shifts the optical shadow and impacts critical radii. Frame-dragging effects (via Ω) intensify near horizons but vanish in certain regions. Detailed shadow distortions and deflection data confirm these dependencies.

Conclusion: The LTABH model effectively demonstrates how ξ and a modulate spacetime properties, offering insights into frame-dragging effects and observational signatures through shadow dynamics and precession measurements in analogue systems.

Abstract: We introduce the Lense-Thirring Acoustic Black Hole (LTABH), motivated by the relevance of analogue models for black holes embedded in various physical systems, such as the cosmological microwave background or quantum superfluids. We investigate the LTABH spacetime geometry, showing that the roots of the metric function determine a partition of the spacetime into four regions, depending on the acoustic parameter $ξ$ (whereas the dependence vanishes for the rotation parameter $a$); on the other hand, the parameter $a$ turns out to affect the critical radii associated to the maxima of the effective potential. All in all, both the acoustic sphere radius $r_{as}$ and the photon sphere radius $r_{ps}$, respectively giving rise to the acoustic shadow $R_{as}$ and to the optical shadow $R_{s}$, depend on $ξ$ and $a$. More precisely, the rotation parameter $a$ is more relevantly affecting $R_{s}$ (through a right shift), while $R_{as}$ retains its circular shape. For what concerns the acoustic parameter, we notice that the higher $ξ$ is, the larger the size of both shadows. All of these results are confirmed through a detailed analysis of the distortions and of the shadows radii. Moreover, by deriving the magnitude of the precession frequency $Ω$, we observe that it significantly increases near the acoustic horizons, both in the extremal and in the non-extremal cases, which implies that the Lense-Thirring (frame dragging) effect, which can be traced back to $ξ$ itself, becomes important near such regions. On the other hand, we also show that there are regions of the LTABH spacetime in which $% Ω$ vanishes, suggesting that therein possible probe particles would not be affected by the frame dragging at all. Finally, we derive the deflection of the light near the LTABH.

</details>


### [69] [Mass distribution of ultralight boson in binary black hole systems](https://arxiv.org/abs/2512.23279)
*Hang Yang,Daiqin Su*

Main category: gr-qc

TL;DR: This paper explores the dynamics of ultralight boson clouds around binary black hole systems, focusing on mass transfer effects influenced by mass ratios and companion spin orientation.


<details>
  <summary>Details</summary>
Motivation: Ultralight bosons, as dark matter candidates, form clouds via black hole superradiance. Their dynamics in binary systems, especially mass transfer and spin effects, are crucial for potential gravitational wave observations.

Method: Investigated boson dynamics in unequal-mass binary black hole systems with arbitrary companion spin orientations. Analyzed how mass transfer affects cloud absorption efficiency and how misalignment of spins modifies cloud depletion.

Result: Mass ratio significantly impacts cloud absorption through mass transfer. Spin misalignment between companions and primary black holes further alters the efficiency of boson cloud depletion.

Conclusion: These findings highlight the importance of considering binary system parameters in understanding ultralight boson dark matter dynamics, offering insights for future gravitational wave detection strategies.

Abstract: Ultralight bosons are compelling dark-matter candidates. Both scalar and vector bosons can be produced through black hole superradiance, forming a boson cloud surrounding a rotating black hole. Self-interaction of bosons, together with transition mixing in binary black hole systems, give rise to dynamical phenomena that could be potentially observable with future gravitational wave observations. In this work, we investigate the dynamics of bosons in binary black hole systems. In particular, we focus on boson mass transfer in unequal-mass binary black hole systems with arbitrary spin-orientation of the companion. Our results show that the mass ratio between the companion and the primary black holes significantly affects cloud absorption through mass transfer. Moreover, when the companion's spin is not aligned with that of the primary, the efficiency of cloud depletion is further modified.

</details>


### [70] [Motion of extended fluid bodies in the Newtonian limit of $f(R)$ gravity](https://arxiv.org/abs/2512.23283)
*Bofeng Wu,Xiao Zhang*

Main category: gr-qc

TL;DR: This paper studies the dynamics of an isolated self-gravitating system with N extended fluid bodies in the Newtonian limit of f(R) gravity, deriving multipole expansions for acceleration, gravitational potential, conserved energy, and spin angular momentum. For two-body systems, effective equations for motion and energy are also provided.


<details>
  <summary>Details</summary>
Motivation: To explore how modifications from f(R) gravity affect the inter-body dynamics compared to General Relativity, particularly through the inclusion of Yukawa-type terms involving scalar multipole moments.

Method: The symmetric and trace-free formalism using irreducible Cartesian tensors is applied to analyze multipole expansions of acceleration, gravitational potential energy, and spin dynamics in the Newtonian limit. The study considers both mass and scalar multipole moments for each body.

Result: The derived expansions include Coulomb-type terms (matching GR) and Yukawa-type terms unique to f(R) gravity. Expressions for total energy and spin dynamics equations are obtained, along with effective one-body equations for two-body systems.

Conclusion: The findings provide a coarse-grained framework to describe inter-body dynamics in f(R) gravity, highlighting the role of scalar multipole moments. This offers a basis for testing modified gravity theories against observations.

Abstract: In the Newtonian limit of $f(R)$ gravity, for an isolated self-gravitating system consisting of $N$ extended fluid bodies, the inter-body dynamics are studied by applying the symmetric and trace-free formalism in terms of irreducible Cartesian tensors. The multipole expansion of each body's center-of-mass acceleration is derived, and the expansion comprises the Coulomb-type part and the Yukawa-type part, where the former, identical to that in General Relativity, is encoded by the products of the mass multipole moments of the body with those of other bodies, and the latter, as the modification introduced by $f(R)$ gravity, is encoded by the products of the scalar multipole moments of the body with those of other bodies. As an essential component of the system's orbital dynamics, the multipole expansion for the total gravitational potential energy is provided, and the expression for the total conserved energy in terms of the mass and scalar multipole moments of the bodies is offered. To investigate the system's spin dynamics, the equation of motion for each body's spin angular momentum is further deduced and presented in the form of multipole expansion. These findings constitute the main content of the coarse-grained description of inter-body dynamics for the system within the framework of the Newtonian limit of $f(R)$ gravity. As a by-product, for a two-body system, the effective one-body equation governing the relative motion between the two bodies and the total energy of this system are achieved.

</details>


### [71] [The axion coupling accelerates the Universe through PT-symmetric phases](https://arxiv.org/abs/2512.23376)
*Leqian Chen,Nick E. Mavromatos,Sarben Sarkar*

Main category: gr-qc

TL;DR: The paper revisits and enhances the conjecture that CP T-symmetric phases are crucial for understanding singular RG flows in Chern-Simons axion theories, using the Wetterich equation with gravitational couplings. This supports the role of repulsive gravity in string-effective models and offers a new perspective on cosmic acceleration through such phases at large scales.


<details>
  <summary>Details</summary>
Motivation: The motivation is to validate and refine the earlier conjecture about CP T-symmetric phases' role in singular RG flows of CS axion theories, particularly addressing limitations in prior approaches that didn't systematically include gravitational couplings. The study aims to explain cosmological phenomena like accelerated expansion through these phases.

Method: The authors employ the Wetterich equation (an exact RG flow equation) incorporating gravitational couplings from the start. They analyze the resulting RG flows to identify the emergence of CP T-symmetric phases and their implications for the CS gravitational theories with axions as massless string axions/torsion fields.

Result: Including gravitational couplings via the Wetterich equation confirms the persistence of singular RG flow structures, reinforcing the conjecture. This links CP T-symmetric phases of repulsive gravity to cosmic acceleration, proposing such phases dominate at cosmological scales.

Conclusion: The analysis strengthens the conjecture that CP T-symmetric phases are fundamental in describing singular RG flows for CS-axion gravitational theories. It introduces a novel interpretation where these phases explain the Universe's accelerated expansion through repulsive gravitational effects at large scales.

Abstract: The conjecture by two of the authors (N.E.M. and S.S.) that a \cPT-symmetric phase plays a role in understanding singular renormalisation group (RG) flows for a Chern-Simons (CS) gauge theory of axions, has been reexamined and significantly improved. We have used the more complete Wetterich equation, which includes gravitational couplings in a systematic way from the start, to understand the emergence of this phase. The singular structure of the RG flows has persisted on including gravitational-couplings, thereby offering further support to the conjecture that \cPT -symmetric phases of (repulsive) gravity characterise string-effective CS gravitational theories, where the axion is the massless string-model independent axion, which can also play a role of a totally-antisymmetric torsion degree of freedom. This has suggested a novel interpretation of the currently observed acceleration of the expansion of the Universe in terms of such a phase at large (cosmological) scales.

</details>


### [72] [Quasinormal mode/grey-body factor correspondence for Kerr black holes](https://arxiv.org/abs/2512.23510)
*Zun-Xian Huang,Peng-Cheng Li*

Main category: gr-qc

TL;DR: The paper establishes a correspondence between quasinormal modes and grey-body factors for Kerr black holes in the eikonal limit using WKB methods, validated against numerical results.


<details>
  <summary>Details</summary>
Motivation: To extend the understanding of black hole perturbations by connecting quasinormal frequencies with grey-body factors beyond leading-order approximations.

Method: Transform the Teukolsky equation into a Schrödinger form with short-range potentials, apply higher-order WKB approximations, and compare results with numerical solutions from the Sasaki-Nakamura equation.

Result: Agreement between predicted grey-body factors and numerical data improves at higher angular quantum numbers, but the method fails in the superradiant regime.

Conclusion: The WKB-based correspondence effectively connects quasinormal modes and grey-body factors in most regimes except the superradiant region where assumptions break down.

Abstract: We establish a quasinormal-mode/grey-body factor correspondence for Kerr black holes in the eikonal limit. By recasting the radial Teukolsky equation into a Schrödinger-type form with a short-range potential, we derive WKB connection formulas that relate Kerr quasinormal frequencies to grey-body transmission coefficients. Higher-order WKB corrections are included, extending the correspondence beyond the leading eikonal regime. For gravitational perturbations, the predicted grey-body factors agree with numerical results obtained from the generalized Sasaki-Nakamura equation, with increasing accuracy at large angular quantum number. The correspondence breaks down in the superradiant regime, where the WKB assumptions fail.

</details>


### [73] [Optical Signatures of q-deformed solution in Einstein-Maxwell-dilaton Gravity](https://arxiv.org/abs/2512.23551)
*Chawit Sakkawattana,Chatchai Promsiri,Supakchai Ponglertsakul*

Main category: gr-qc

TL;DR: Analyzes null geodesics in EMD theory with specific coupling function, deriving photon trajectories, deflection angles, and optical images using GLM model, while exploring ISCO radius.


<details>
  <summary>Details</summary>
Motivation: To study gravitational effects on photon paths and emission profiles around spherically symmetric objects in EMD theory, considering parameters like λ, D, and P.

Method: Employed Hamilton-Jacobi approach for geodesic equations, analyzed effective potential, plotted deflection angles and trajectories, applied GLM model for accretion disk images, and calculated ISCO radius.

Result: Derived photon trajectory dependencies on λ, D, P; linked photon ring width to Lyapunov exponent; generated optical images with three emission profiles; determined ISCO radius variations.

Conclusion: Demonstrates EMD theory's impact on spacetime phenomena via geodesic analysis, offering insights for observational tests and accretion disk modeling around compact objects.

Abstract: We consider null geodesics in the background of spherically symmetric object in Einstein-Maxwell-Dilaton (EMD) theory with coupling function $f(Φ)=e^{-2λΦ}$. The spherical solution is characteristically described by dilaton coupling $λ$, integrated dilaton flux $D$ and magnetic charge $P$. Then, we derive geodesic equations by using the Hamilton-Jacobi approach. The radial photon orbital equation on equatorial plane and effective potential are analyzed. The total deflection angle and trajectories of photon as a function of impact parameter $b$ are plotted with the variation of $λ,D$ and $P$. Furthermore, the relation between photon ring's width and the Lyapunov exponent is also explored. In addition, we use the Gralla-Lupsasca-Marrone (GLM) model to model intensity profile of optically thin accretion disk around the object. Hence, we construct optical images of the object surrounded by three distinct emission profiles. Lastly, we investigate the radius of innermost stable circular orbit (ISCO) for timelike geodesics.

</details>


### [74] [Transitioning late-time cosmology with the Hubble parameterization](https://arxiv.org/abs/2512.23561)
*Vinod Kumar Bhardwaj,Saibal Ray,Kazuharu Bamba,Akram Ali*

Main category: gr-qc

TL;DR: The paper examines a late-time cosmological model in Rastall theory, using recent datasets to constrain the Hubble parameter. It finds a phase shift from deceleration to cosmic acceleration and estimates H0 as 66.945 ± 1.094, aligning with observations.


<details>
  <summary>Details</summary>
Motivation: To investigate how Rastall theory explains the universe's transition from deceleration to acceleration and address tensions in Hubble parameter measurements using updated observational data.

Method: The authors analyze a homogeneous, isotropic spacetime model in Rastall theory. They use combined datasets (Planck CMB, DESI BAO, Union 3.0 SNeIa, CC) to constrain the Hubble parameter and study cosmological evolution phases.

Result: Observational constraints show a clear redshift transition where the universe shifted from deceleration to acceleration. The estimated H0 value (66.945 ± 1.094) is consistent with current observational data.

Conclusion: Rastall theory successfully models the cosmic acceleration transition using modern datasets. The derived H0 reduces tensions with other measurements, supporting its applicability in late-time cosmology.

Abstract: We investigate a late-time cosmological model for a homogeneous and isotropic space-time in the Rastall theory. We explore the observational constraints on the Hubble parameter by using the latest cosmological datasets such as cosmic microwave background radiation (Planck), baryon acoustic oscillations (DESI) and Type Ia Supernovae (Union 3.0). As a result, we explicitly demonstrate that the specific redshift transition occurs, namely, there happens a phase shift in the evolution of the universe from the initial deceleration era to the current accelerating phase of the cosmological scenario. Furthermore, we show that with the latest dataset of DESI-BAO clubbed with CC, CMB, and Union 3.0, the current value of the Hubble parameter is estimated as $H_0 = 66.945 \pm 1.094$, which can be compatible with the available observations.

</details>


### [75] [Primary black-hole scalar charges and kinetic screening in $K$-essence-Gauss-Bonnet gravity](https://arxiv.org/abs/2512.23683)
*Guillermo Lara,Georg Trenkler,Leonardo G. Trombetta*

Main category: gr-qc

TL;DR: Explores the effects of nontrivial kinetic terms on scalar charges of black holes in modified gravity theories, finding that kinetic terms can transform scalar charges from secondary to primary and influence stability and screening mechanisms.


<details>
  <summary>Details</summary>
Motivation: To understand how non-standard charges, particularly those induced by scalar-Gauss-Bonnet couplings, are altered by kinetic terms in black holes and their implications for cosmological models like self-accelerating universes.

Method: Analysis of asymptotically flat, static black hole solutions with scalar-Gauss-Bonnet coupling and nontrivial kinetic terms $K(X)$. Examined the transition of scalar charge from secondary to primary in time-dependent cosmological scenarios. Stability analysis and dispersion relation studies for scalar and gravitational modes were conducted.

Result: Kinetic terms $K(X)$ enable a broader parameter space in self-accelerating cosmologies, changing the nature of black hole scalar charges. Stability and the strength of kinetic screening were determined through dispersion relation analysis.

Conclusion: Kinetic terms significantly impact black hole charges and cosmological viability in modified gravity, offering new pathways to reconcile theoretical predictions with observational data.

Abstract: Black holes beyond General Relativity may carry non-standard charges that impact their phenomenology. We study how the scalar charge that is induced by the scalar-Gauss-Bonnet coupling is affected by the presence of a nontrivial kinetic term $K(X)$. We discuss the corresponding kinetic screening in the asymptotically flat, static solution first. We then turn to the case where self-accelerating cosmology is driven by $K(X)$, finding that the time-dependence of the scalar field opens up the parameter space, turning the black-hole scalar charge from secondary to primary. We provide a stability analysis and a measure of the intensity of the kinetic screening from the quartic dispersion relation of the mixed scalar and gravitational modes.

</details>


### [76] [Note on the Kerr Spinning-Particle Equations of Motion](https://arxiv.org/abs/2512.23697)
*Joon-Hwi Kim*

Main category: gr-qc

TL;DR: The paper presents a probe version of the Newman-Janis algorithm to explore the gravitational dynamics of a Kerr black hole in a point-particle effective theory, uncovering spin exponentiation of same-helicity gravitational Compton amplitudes across all multiplicities by leveraging a hidden symmetry.


<details>
  <summary>Details</summary>
Motivation: To understand the gravitational dynamics of Kerr black holes and investigate the role of hidden symmetries in their effective field theory descriptions.

Method: Implements a probe counterpart of the Newman-Janis algorithm, Wick rotating the all-orders geodesic deviation equation into spinning-particle equations of motion, constraining dynamics in the self-dual sector of a hidden symmetry.

Result: Shown that the Kerr black hole's gravitational dynamics in this framework is entirely contained within the self-dual sector, leading to spin exponentiation of same-helicity Compton amplitudes.

Conclusion: This hidden symmetry-based approach provides a novel pathway for analyzing black hole dynamics and gravitational scattering amplitudes in spinning systems.

Abstract: We implement a probe counterpart of Newman-Janis algorithm, which Wick rotates the all-orders geodesic deviation equation into a part of exact spinning-particle equations of motion. Consequently, the gravitational dynamics of the Kerr black hole in its point-particle effective theory is completely constrained in the self-dual sector for a hidden symmetry, implying the spin exponentiation of same-helicity gravitational Compton amplitudes to all multiplicities.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [77] [Multi-Messenger Predictions for T Coronae Borealis: Probing Particle Acceleration in Novae](https://arxiv.org/abs/2512.22338)
*Prantik Sarmah,Sovan Chakraborty,Xilu Wang*

Main category: astro-ph.HE

TL;DR: The paper analyzes the potential detection of neutrinos and gamma-rays from the upcoming outburst of nova T CrB, comparing two proton-acceleration mechanisms (external shock and magnetic reconnection). It finds that while gamma-rays from the external shock scenario are detectable, neutrino detection is challenging, whereas the magnetic reconnection mechanism offers better prospects for neutrino detection, with a unique time delay signature.


<details>
  <summary>Details</summary>
Motivation: To determine the production mechanism (hadronic vs. leptonic) through observing neutrinos, as the non-detection in RS Oph's outburst left uncertainties. T CrB's closer proximity and imminent outburst provide a critical opportunity to test models and potentially detect nova neutrinos.

Method: Developed model-based estimates of secondary fluxes from T CrB using two proton-acceleration mechanisms (ES and MR). Evaluated detectability with current/future telescopes (LHAASO, IceCube, etc.). Calculated neutrino and gamma-ray fluxes, considered observational sensitivities, and analyzed temporal signatures.

Result: ES scenario: Gamma-rays are detectable across facilities but neutrino detection is poor except for extreme parameters. MR scenario: Higher neutrino detectability with IceCube/KM3NeT, and unique delay between neutrinos and photons due to absorption. Only MR offers feasible neutrino detection chances.

Conclusion: T CrB's outburst is crucial for distinguishing hadronic mechanisms. The MR mechanism's predicted neutrino signals with temporal delays could resolve uncertainties from RS Oph. Observatories should prioritize timing and multi-messenger strategies for potential detection.

Abstract: The MAGIC detection of near-TeV gamma-rays from the 2021 outburst of the recurrent nova RS Ophiuchi (RS Oph) has established it as a TeV-scale particle accelerator. However, the underlying production mechanism --\textit{hadronic} versus \textit{leptonic}-- remains uncertain due to the non-detection of coincident neutrinos at IceCube. Indeed, the neutrino flux predicted by the hadronic model for RS Oph was below IceCube sensitivity. T Coronae Borealis (T CrB), a nova similar to RS Oph, is anticipated to undergo an outburst soon. Being closer to Earth (0.8 kpc versus 2.45 kpc for RS Oph), T CrB is expected to yield a higher neutrino flux, making the upcoming outburst a once in a lifetime opportunity to test-and potentially detect-nova neutrinos. In this work, we present the first model-based estimates of the hadronic secondary fluxes from T CrB and assess their detectability with gamma-ray (LHAASO, Fermi-LAT, MAGIC, H.E.S.S., MACE, and HERD) and neutrino (IceCube and KM3NeT) telescopes. We adopt two proton-acceleration mechanisms: (i) an external shock (ES) driven mechanism at the interaction ($10^{13}$ cm) of nova ejecta and the red giant wind, and (ii) magnetic reconnection (MR) near the white dwarf surface ($10^{9}$ cm). The latter, arising deep inside the nova system, will fully absorb gamma-rays while allowing only neutrinos to escape. This could potentially produce neutrino signals hours before the ES origin photons or neutrinos-a unique temporal delay signature. For our benchmark ES model, gamma-rays are detectable across all facilities, while the neutrino detection prospect is poor. Only a tiny upper part of the ES model parameter space is above IceCube/KM3NeT sensitivity. In contrast, both observatories have significantly better prospects for detecting neutrinos in the MR scenario.

</details>


### [78] [Hierarchical Test of Lorentz Invariance with Gamma-Ray Burst Spectral-Lag Measurements](https://arxiv.org/abs/2512.22875)
*Shen-Shi Du,Yi Gong,Jun-Jie Wei,Zi-Ke Liu,Zhi-Qiang You,Yan-Zhi Meng,Xing-Jiang Zhu*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Gamma-ray bursts (GRBs) are among the most potent probes of Lorentz invariance violation (LIV), offering direct constraints on the quantum gravity energy scale ($E_{\rm QG}$) based on observations of energy-dependent time lags. Individual GRBs with well-defined positive-to-negative lag transitions have been used to set lower limits on $E_{\rm QG}$, but they suffer from uncertainties of spectral-lag measurements and systematics due to theoretical modeling of each burst. Here, we combine observations of 32 GRBs with positive-to-negative lag transitions to derive a statistically robust constraint on $E_{\rm QG}$ through hierarchical Bayesian inference. We find that the dominant systematic uncertainty in LIV constraints arises from the intrinsic lag modeling. Accounting for this uncertainty with cubic spline interpolation, we derive robust limits of $E_{\rm QG,1} \ge 4.37 \times 10^{16}$~GeV for linear LIV and $E_{\rm QG,2} \ge 3.02 \times 10^{8}$~GeV for quadratic LIV. We find that the probability for LIV, i.e., $E_{\rm QG,1}$ being below the Planck scale, is estimated to be around 90\%, which we conclude as no significant evidence for LIV signatures in current GRB spectral lag observations. Our hierarchical approach provides a rigorous statistical framework for future LIV searches and can be extended to incorporate multi-messenger observations.

</details>


### [79] [Pulsed, Polarized X-ray Emission from Neutron Star Surfaces: the Effects of Vacuum Birefringence in the Magnetosphere](https://arxiv.org/abs/2512.22978)
*Hoa Dinh Thi,Matthew G. Baring,Kun Hu,Alice K. Harding,Rachael E. Stewart,George A. Younes,Joseph A. Barchas*

Main category: astro-ph.HE

TL;DR: The MAGTHOMSCATT simulation models the polarized X-ray emission from neutron star atmospheres, incorporating quantum effects like vacuum birefringence. By analyzing pulse profile data from magnetar 1RXS J11708-4009, the study constraints geometric parameters of emission regions and highlights the role of strong magnetic fields in enhancing linear polarization.


<details>
  <summary>Details</summary>
Motivation: To understand the influence of intense magnetic fields on the polarization properties of X-ray emission from neutron stars, particularly magnetars, and to constrain geometrical parameters (e.g., magnetic/observer angles, emission region sizes) using observational data.

Method: Developed MAGTHOMSCATT, a Monte Carlo simulation that includes general relativistic effects, quantum electrodynamic birefringence, and detailed angular/polarization tracking. Simulated polarized X-ray emission from neutron star atmospheres with optically thick, fully ionized outer layers. Applied the model to magnetar 1RXS J11708-4009's pulse profile data to derive emission geometry parameters.

Result: Found that vacuum birefringence significantly boosts linear polarization. Identified best-fit geometric parameters for 1RXS J11708-4009's emission regions. Demonstrated that the model can distinguish between magnetar and weaker-field neutron star (e.g., RX J0822.0-4300) polarization characteristics.

Conclusion: Quantum effects like vacuum birefringence are critical for accurately modeling neutron star X-ray polarization. MAGTHOMSCATT provides a framework to constrain neutron star geometry and magnetic field impacts, with future work needed to incorporate vacuum resonance effects.

Abstract: Intense magnetic fields in the atmospheres of neutron stars render non-trivial angular dependence of intensity and polarization of soft X-ray emission originating from their surfaces. By tracking the complex electric field vector for each photon during its atmospheric transport and propagation in general relativistic and birefringent magnetospheres, our Monte Carlo simulation, named MAGTHOMSCATT, allows for capturing the complete polarization properties, including the intricate interplay between linearity and circularity. The new inclusion in MAGTHOMSCATT of quantum electrodynamical influences on polarization in the magnetosphere is presented. We simulate the pulsed and polarized X-ray emission from the outer layers of optically thick, fully ionized atmospheres of neutron stars, with a focus on the radiation emitted from extended polar caps of magnetars, which are the most highly magnetized neutron stars. Using the recent intensity pulse profile data for the magnetar 1RXS J11708-4009, we constrain the geometric parameters, namely the angles between the magnetic axis and the observer's viewing direction relative to the spin axis, as well as the sizes of emission regions. The distributions of these parameters and the best-fit configuration are provided. In addition, we discuss the important impacts of vacuum birefringence in the magnetosphere on increasing the linear polarization degree. A comparison with the case of a weakly magnetized neutron star, RX J0822.0-4300, is also discussed. Our simulation still needs further development, particularly to incorporate the vacuum resonance effect. Nevertheless, the formalism presented here can be employed to constrain geometric parameters for various types of neutron stars.

</details>


### [80] [Unveiling Multimessenger Emission from Hidden Cores of Microquasars](https://arxiv.org/abs/2512.23231)
*Yu-Jia Wei,Kohta Murase,B. Theodore Zhang*

Main category: astro-ph.HE

TL;DR: The study uses AMES to model gamma-ray and cosmic-ray emissions from microquasars like Cygnus X-1 and X-3, showing thatTeV photons likely result from pγ or pp interactions. Predictions include variable spectra in the 0.1-10 TeV range and suppressed neutrino fluxes.


<details>
  <summary>Details</summary>
Motivation: Recent detections of TeV/PeV photons from Cygnus X-1 and X-3 by LHAASO drive the need to model their multimessenger emission and validate microquasars as cosmic-ray accelerators.

Method: AMES simulation framework models emission from compact outflow regions, analyzing pγ/pp interaction scenarios across radio to UHE gamma rays. Variability and spectral predictions tested against observations.

Result: TeV photons explained by pγ/pp mechanisms depending on emission region conditions. 0.1-10 TeV spectra predict dips, suppression, or power-laws. Neutrino fluxes are suppressed due to cooling effects.

Conclusion: Microquasars' multimessenger signals depend on emission zone scale/dynamics. Future observations in intermediate TeV ranges and neutrino detection require revised expectations due to suppressed fluxes.

Abstract: Microquasars are radio-emitting X-ray binaries accompanied by relativistic jets. They are established sources of 100~TeV gamma rays and are considered promising candidates for cosmic-ray acceleration. Motivated by recent detections of $\sim 100~$TeV photons from Cygnus~X-1 and $\sim~$PeV photons from Cygnus~X-3 by the Large High Altitude Air Shower Observatory (LHAASO), we employ the Astrophysical Multimessenger Emission Simulator (AMES) to model their multimessenger emission considering compact outflow regions as cosmic-ray accelerators, spanning from radio to ultra-high-energy gamma rays. Our results show that the observed $>$TeV gamma rays can originate from either $pγ$ or $pp$ interactions, depending on the location and physical conditions of the emission region, while also reproducing the lower-energy spectra. The different configurations yield unique, observationally testable predictions. In the $0.1-10$~TeV energy range, where current observations provide only upper limits, they predict either a deep dip, a mild suppression, or a power-law spectrum. Additionally, models involving AU-scale blob regions predict strong variability, while those invoking more extended and static external zones show more stable behavior. We also provide a possible qualitative explanation for the distinct modulation patterns across different energy bands, which relies primarily on changes in the Doppler factor and external $γγ$ absorption. Finally, our neutrino predictions, which properly account for muon and pion cooling effects, reveal a significantly suppressed flux, indicating that detecting these sources may be more challenging than previously anticipated.

</details>


### [81] [Interpreting the diversity of afterglow emission from radio-detected tidal disruption events with instantaneous and delayed outflows](https://arxiv.org/abs/2512.23252)
*Yuri Sato,Mukul Bhattacharya,Jose Carpio,Jewel Capili,Kohta Murase*

Main category: astro-ph.HE

TL;DR: The paper examines radio flares in tidal disruption events (TDEs), finding that delayed outflow mechanisms, either wind or jets, better explain late-time radio emissions than instantaneously launched winds. Multiwavelength observations are key to differentiating between these models.


<details>
  <summary>Details</summary>
Motivation: To understand the origin of delayed radio flares in TDEs, which are not easily explained by immediate post-disruption winds.

Method: Three models are tested: instantaneous wind, delayed wind, and delayed jet. Radio light curves from TDEs are simulated and compared with observations.

Result: Instantaneous wind models fail for delayed flares. Delayed wind explains most cases, while delayed jets also fit some events but predict detectable X-ray/optical emissions. Both mechanisms are viable for certain events like ASASSN-15oi.

Conclusion: Delayed outflows (wind or jet) are necessary to explain observed radio phenomena. Multiwavelength data is essential to determine the dominant mechanism in specific TDEs.

Abstract: Tidal disruption events (TDEs) occur when a star is gravitationally disrupted by the tidal field of a supermassive black hole during a close encounter. Radio emission has recently been detected in TDEs and is commonly attributed to synchrotron radiation from both wind and jetted outflows. However, several TDEs exhibit bright radio flares at late times, which cannot be easily explained if the wind is launched promptly after the stellar disruption. In this study, we model the radio light curves of TDEs with delayed radio flares using three scenarios: an instantaneous wind, a delayed wind, and a delayed relativistic jet. We show that the instantaneous wind model struggles to reproduce delayed radio flare events, indicating the necessity of an additional delayed outflow component. In contrast, the delayed wind model provides a consistent explanation for the observed radio phenomenology, successfully reproducing events both with and without delayed radio flares. For some delayed radio flare events (e.g., ASASSN-15oi and AT 2019dsg), both the delayed wind and delayed jet models can reproduce the observed radio light curves. The delayed jet model produces x-ray and optical emission that is detectable at typical TDE distances, in contrast to wind-driven scenarios. This highlights how multiwavelength observations offer an effective means of distinguishing among possible outflow mechanisms.

</details>


### [82] [SN 2022acko: a low-luminosity SNe IIP with signs of early circumstellar interaction](https://arxiv.org/abs/2512.23267)
*Lin Han,Zhang Jujia,Wang Xiaofeng,Hu Maokai,Zha Shuai,Xiang Danfeng,Li Liping,Reguitti Andrea,Zhang Xinghan,Cai Yongzhi,Wang Zhenyu,Zhao Zeyi,Zhai Qian,Huang Fang,Lin Weili,Bai Jinming*

Main category: astro-ph.HE

TL;DR: The paper presents analysis of SN 2022acko, a low-luminosity Type II supernova with unique early spectral features indicating a low-mass progenitor and constrained circumstellar medium interaction.


<details>
  <summary>Details</summary>
Motivation: To study the properties of low-luminosity Type II SNe and understand the role of progenitor mass and circumstellar medium (CSM) interactions in early SN evolution.

Method: The study employed optical-ultraviolet photometry and optical spectroscopy spanning phases 1.5 to 60 days post-explosion. Spectral analysis focused on identifying emission features (e.g., He II 4686 Å 'ledge', Hα emission) and modeling CSM parameters using a hybrid light curve approach.

Result: SN 2022acko's low peak luminosity (-15.5 mag) suggests a 9-10 M☉ progenitor. Early 'ledge' features and Hα flash-ionization indicate interaction with confined CSM (radius ~2×10¹⁴ cm), with mass loss rate ~5×10⁻⁴ M☉/yr. Similar features in other SNe imply early CSM interaction may be common.

Conclusion: The findings highlight the importance of CSM interactions in shaping observational properties of low-luminosity SNe, and suggest such interactions occur more frequently than previously recognized in the early phases of Type II supernovae.

Abstract: We present optical-ultraviolet photometry and optical spectra for the type II supernova (SN) 2022acko. The spectroscopic observations span phases from $\sim$ 1.5 to $\sim$ 60 days after the explosion, while the light curve was observed up to $\sim$ 300 days. The V-band peak is $-15.5 \pm 0.3$ mag, suggesting that SN 2022acko is a low-luminosity SN II (LLSN). The overall observed properties of SN 2022acko are consistent with those produced by a lower mass progenitor ($\rm M_{ZAMS} \sim $9-10M$_{\odot}$). The spectra at $t=1.5$d and $t=2.5$d exhibit a broad emission feature peaking near 4600 Å(the ``ledge'' feature), which we interpret as blueshifted He II 4686 Ålines arising from the ionized ejecta. Moreover, a possible flash-ionized (FI) emission line of H$α$ (FWHM $\sim 1100\ \rm km \ s^{-1}$) was superposed on the broad emission component of H$α$ P-Cgyni profile in the $t=1.5$d spectrum. Assuming an ejecta velocity of $\rm 12000\ km\ s^{-1}$, the rapid disappearance of this narrow H$α$ emission line within two days suggests highly confined CSM within $\sim \rm 2\times10^{14}\, cm$. Assuming a spherically symmetric CSM, the mass loss rate within this radius is estimated to be $\rm \sim 5 \times 10^{-4} M_{\odot} \ year^{-1}$ based on our hybrid light curve model. The early ``ledge'' feature observed in SN 2022acko have also been observed in other SNe II, suggesting that early-phase circumstellar interaction (CSI) is more common than previously thought.

</details>


### [83] [New Constraints on Cosmic-ray boosted Sub-GeV Dark Matter via Light Mediators](https://arxiv.org/abs/2512.23282)
*Yang Yu,Guan-Sen Wang,Bo Zhang,Tian-Peng Tang,Bing-Yu Su,Lei Feng*

Main category: astro-ph.HE

TL;DR: This paper explores using cosmic-ray upscattering to detect sub-GeV dark matter via underground experiments, analyzing four DM-nucleon interaction models and deriving constraints from LZ, XENON, and Borexino data.


<details>
  <summary>Details</summary>
Motivation: Traditional direct detection experiments cannot sense low-energy recoils from sub-GeV dark matter. Cosmic-ray upscattering could amplify DM velocities to detectable levels underground, opening new observational possibilities.

Method: Analyzed scalar, vector, pseudoscalar, and axial-vector DM-nucleon mediator models, deriving coupling parameter constraints using data from three experiments across mediator masses 10^-6 to 1 GeV. Explored momentum transfer vs. mediator mass dominance shifts.

Result: Discovered a constraint turnover around 0.01-0.001 GeV mediator mass due to momentum/mass dominance shifts, extending direct detection sensitivity into sub-GeV range and highlighting momentum dependence importance in light-mediator scenarios.

Conclusion: Cosmic-ray upscattering significantly enhances sub-GeV DM detectability. The study advances light-mediator DM models understanding by showing how momentum dependence critically affects constraints across different mass scales.

Abstract: Traditional direct detection experiments lack the sensitivity to probe the sub-GeV dark matter (DM), primarily due to the low energy of the expected nuclear recoils. In this work, we investigate cosmic-ray (CR) upscattering as a mechanism to accelerate DM particles to detectable velocities in underground experiments. By analyzing four models of DM-nucleon interactions -- namely scalar, vector, pseudoscalar, and axial-vector mediators -- we derive constraints on the coupling parameters using data from the LZ, XENON, and Borexino experiments, covering mediator mass from $10^{-6}$ to $1$ GeV. As the mediator mass varies, the shift in dominance between momentum transfer and mediator mass leads to a turnover in the constraints around $10^{-2}$--$10^{-3}~\mathrm{GeV}$. Our results extend the reach of direct detection into the sub-GeV window and clarify the critical role of momentum dependence in light-mediator scenarios.

</details>


### [84] [Kilonova and progenitor properties of merger-driven gamma-ray bursts](https://arxiv.org/abs/2512.23354)
*P. Singh,G. Stratta,A. Rossi,P. T. H. Pang,M. Bulla,F. Ragosta,A. De Rosa,D. A. Kann,F. Cogato*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Gamma-Ray Burst (GRB) prompt and afterglow emission, as well as a kilonova (KN), are the expected electromagnetic (EM) counterparts of Binary Neutron Star (BNS) and Neutron Star -- Black Hole (NSBH) mergers. We aim to infer the KN ejecta parameters and the progenitor properties by modeling merger-driven GRBs with a claim of KN, good data and robust redshift measurement. We model the afterglow and KN, and perform a Bayesian analysis, within the Nuclear physics and Multi-Messenger Astrophysics (NMMA) framework. The KN emission is modeled with the radiative transfer code POSSIS and for afterglow we use the afterglowpy library. In contrast to previous approaches, our methodology simultaneously models both afterglow and KN. We find that all GRBs in our sample have a KN, but we were unable to confirm or exclude its presence in GRB 150101B. A BNS progenitor is favored for GRB 160821B, GRB 170817A/AT2017gfo, GRB 211211A, and GRB 230307A. For GRB 150101B and GRB 191019A, we obtain a slight preference for NSBH scenario, while a BNS is also viable. For KN emission, we find that the median wind mass $\langle M_{\rm wind}\rangle=0.027^{+0.046}_{-0.019}$ $M_{\odot}$ is larger than the dynamical $\langle M_{\rm dyn}\rangle = 0.012^{+0.007}_{-0.006}$ $M_{\odot}$. We find that $M_{\rm wind}$ and the beaming corrected kinetic energy of the jet can be attributed as $log(M_{\rm wind})=-20.23+0.38\,log(E_{0,J})$. We confirm the results of numerical simulation that $\tildeΛ$ increases with decrease in $\mathcal{M}_{\rm \,Chirp}$. Our work shows that EM modeling can be effective for probing the progenitors, and for the first time presents the progenitor properties of a sizable sample of merger-driven GRBs.

</details>


### [85] [Revisiting the Reported Period of FRB 20201124A Using MCMC Methods](https://arxiv.org/abs/2512.23392)
*Jun-Yi Shen,Yuan-Chuan Zou*

Main category: astro-ph.HE

TL;DR: The paper presents an efficient method combining phase folding and MCMC for detecting periodic signals in repeating fast radio bursts (FRBs), tested on FRB 20201124A.


<details>
  <summary>Details</summary>
Motivation: To address the uncertain physical origin of FRBs and evaluate magnetar-based models which propose that FRB emission is modulated by magnetar spin periods. Existing methods for detecting periodic signals in FRBs are computationally inefficient.

Method: The method combines phase folding (to align and stack signals based on trial periods) with Markov Chain Monte Carlo (MCMC) parameter estimation to efficiently search for periodicities in FRB data. It was tested on observational data from the repeating FRB 20201124A.

Result: The method successfully recovered previously reported candidate periods for FRB 20201124A, demonstrating its effectiveness in accelerating period searches.

Conclusion: The proposed method improves the efficiency of detecting periodic signals in repeating FRBs, supporting further exploration of magnetar-based models and aiding in understanding FRB origins.

Abstract: Fast radio bursts (FRBs) are millisecond-duration radio transients whose phys- ical origin remains uncertain. Magnetar-based models, motivated by observed properties such as polarization and large rotation measures, suggest that FRB emission may be modulated by the magnetar spin period. We present an efficient method to search for periodic signals in repeating FRBs by combining phase folding and Markov Chain Monte Carlo (MCMC) parameter estimation. Our method accelerates period searches. We test the method using observational data from repeater FRB 20201124A, and show that it can recover reported candidate periods.

</details>


### [86] [Possibility of Month-scale Quasi-periodic Oscillations in the Gamma-ray Light Curve of OP 313](https://arxiv.org/abs/2512.23416)
*Sandeep Kumar Mondal,Shubham Kishore,Alok C. Gupta,Gwenael Giacinti*

Main category: astro-ph.HE

TL;DR: The paper presents tentative evidence for a month-scale QPO in the gamma-ray emissions of OP 313 using 16.8 years of Fermi-LAT data. Analysis via WWZ and LSP methods identified potential periodicity in the fourth high-flux state, though significance is limited by few cycles. A curved-jet model is proposed as a plausible physical explanation.


<details>
  <summary>Details</summary>
Motivation: To explore the presence of QPOs in gamma-ray light curves and understand their physical origins, addressing gaps in detecting such phenomena in blazar sources despite theoretical predictions.

Method: 1. Bayesian block analysis on monthly-binned Fermi-LAT data to identify four high-flux states. 2. Applied WWZ and LSP methods to detect periodicity in the fourth high-flux state (MJD 59482-60832). 3. Evaluated curved-jet model against observed data.

Result: Tentative detection of ~month-scale QPO with low significance due to limited cycle numbers. The curved-jet model aligns with observed behavior but requires more data for confirmation.

Conclusion: Future longer-term observations are needed to confirm QPO significance. The curved-jet model provides a viable framework for interpreting the periodicity, advancing understanding of blazar emission mechanisms.

Abstract: In this work, we report evidence suggesting the potential future detection of a month-scale quasi-periodic oscillation (QPO) in the gamma-ray light curve of OP 313. We analysed almost 16.8 years of Fermi-LAT gamma-ray data and applied the Bayesian block method to the monthly-binned light curve. We identified four high-flux states and investigated the possibility of a QPO in the fourth high-flux state (MJD 59482-60832). Using the Weighted Wavelet Z-transform (WWZ) and Lomb-Scargle Periodogram (LSP) methods, we find tentative evidence for a month-scale QPO; however, its detection significance is limited by the small number of observed cycles. With a sufficiently long data set, the QPO may be detected with higher significance in the future. We further explored possible physical origins of this potential QPO and examined several models. We found that a curved-jet model can explain the observed behaviour.

</details>


### [87] [Unveiling SN 2022eyw: A Bright Member of the Type Iax Supernova Subclass](https://arxiv.org/abs/2512.23428)
*Hrishav Das,Devendra K. Sahu,Anirban Dutta,Mridweeka Singh,G. C. Anupama,Rishabh Singh Teja*

Main category: astro-ph.HE

TL;DR: SN 2022eyw is a bright Type Iax supernova with characteristics linked to a partial deflagration of a Chandrasekhar-mass CO white dwarf, supporting pure deflagration models as a viable explosion mechanism.


<details>
  <summary>Details</summary>
Motivation: To study the explosion mechanism and properties of luminous Type Iax supernovae using detailed photometric and spectroscopic observations.

Method: Comprehensive photometric and spectroscopic observations along with TARDIS spectral modeling were used to analyze SN 2022eyw's light curve, composition, and spectral evolution. Comparisons with deflagration models (N3-def and N5-def) were made.

Result: The supernova showed high luminosity, significant Ni-56 mass, and Fe-group element dominance with unburnt carbon traces. Spectral analysis indicated a partial deflagration of a Chandrasekhar-mass white dwarf, matching intermediate deflagration model predictions.

Conclusion: Observations confirm pure deflagration of a CO white dwarf as a valid mechanism for luminous Type Iax supernovae, bridging the gap between less and more energetic explosions.

Abstract: We present comprehensive photometric and spectroscopic observations of Supernova (SN) 2022eyw, a luminous member of the Type Iax SN subclass. SN 2022eyw reached a peak absolute magnitude of $M_g = -17.80\pm0.15$ mag and exhibited a rise time of $\sim$15 days, placing it among the brighter Iax events. The bolometric light curve indicates a synthesized $^{56}$Ni mass of $0.120\pm0.003~\text{M}_{\odot}$, with an estimated ejecta mass of $0.79\pm0.09~\text{M}_{\odot}$ and kinetic energy of $0.19\times10^{51}$ erg. The spectral evolution from -8 to +110 days past maximum reveals features characteristic of bright Type Iax Supernovae, including a transition from Fe III to Fe II dominance, moderate expansion velocities, and a lack of strong C III absorption. TARDIS spectral modelling of the early-phase spectra indicates a well-mixed ejecta dominated by Fe-group elements. In addition, traces of unburnt carbon are detected, pointing to incomplete burning as expected in pure deflagration models. Late-time spectral evolution shows a blend of permitted and forbidden lines. Comparison with deflagration models suggests that SN 2022eyw originated from a partial deflagration of a Chandrasekhar-mass white dwarf, with explosion properties intermediate between the N3-def and N5-def models. These observations support pure deflagration of a CO white dwarf as a viable explosion mechanism for its luminous members.

</details>


### [88] [Observations of the Fermi bubbles and the Galactic center excess with the DArk Matter Particle Explorer](https://arxiv.org/abs/2512.23458)
*F. Alemanno,Q. An,P. Azzarello,F. C. T. Barbato,P. Bernardini,X. J. Bi,H. Boutin,I. Cagnoli,M. S. Cai,E. Casilli,J. Chang,D. Y. Chen,J. L. Chen,Z. F. Chen,Z. X. Chen,P. Coppin,M. Y. Cui,T. S. Cui,I. De Mitri,F. de Palma,A. Di Giovanni,T. K. Dong,Z. X. Dong,G. Donvito,J. L. Duan,K. K. Duan,R. R. Fan,Y. Z. Fan,F. Fang,K. Fang,C. Q. Feng,L. Feng,S. Fogliacco,J. M. Frieden,P. Fusco,M. Gao,F. Gargano,E. Ghose,K. Gong,Y. Z. Gong,D. Y. Guo,J. H. Guo,S. X. Han,Y. M. Hu,G. S. Huang,X. Y. Huang,Y. Y. Huang,M. Ionica,L. Y. Jiang,W. Jiang,Y. Z. Jiang,J. Kong,A. Kotenko,D. Kyratzis,S. J. Lei,B. Li,M. B. Li,W. H. Li,W. L. Li,X. Li,X. Q. Li,Y. M. Liang,C. M. Liu,H. Liu,J. Liu,S. B. Liu,Y. Liu,F. Loparco,M. Ma,P. X. Ma,T. Ma,X. Y. Ma,G. Marsella,M. N. Mazziotta,D. Mo,Y. Nie,X. Y. Niu,A. Parenti,W. X. Peng,X. Y. Peng,C. Perrina,E. Putti-Garcia,R. Qiao,J. N. Rao,Y. Rong,R. Sarkar,P. Savina,A. Serpolla,Z. Shangguan,W. H. Shen,Z. Q. Shen,Z. T. Shen,L. Silveri,J. X. Song,H. Su,M. Su,H. R. Sun,Z. Y. Sun,A. Surdo,X. J. Teng,A. Tykhonov,G. F. Wang,J. Z. Wang,L. G. Wang,S. Wang,X. L. Wang,Y. F. Wang,D. M. Wei,J. J. Wei,Y. F. Wei,D. Wu,J. Wu,S. S. Wu,X. Wu,Z. Q. Xia,Z. Xiong,E. H. Xu,H. T. Xu,J. Xu,Z. H. Xu,Z. L. Xu,Z. Z. Xu,G. F. Xue,M. Y. Yan,H. B. Yang,P. Yang,Y. Q. Yang,H. J. Yao,Y. H. Yu,Q. Yuan,C. Yue,J. J. Zang,S. X. Zhang,W. Z. Zhang,Yan Zhang,Yi Zhang,Y. J. Zhang,Y. L. Zhang,Y. P. Zhang,Y. Q. Zhang,Z. Zhang,Z. Y. Zhang,C. Zhao,H. Y. Zhao,X. F. Zhao,C. Y. Zhou,X. Zhu,Y. Zhu*

Main category: astro-ph.HE

TL;DR: DAMPE detects Fermi bubbles at 26σ and a Galactic center GeV excess at 7σ, supporting dark matter annihilation interpretation.


<details>
  <summary>Details</summary>
Motivation: To independently confirm the existence of Fermi bubbles and Galactic center GeV excess observed by Fermi-LAT using DAMPE's unique capabilities.

Method: Analyzed 102 months of DAMPE data to survey gamma-rays above 2 GeV, comparing spectral and morphological properties with Fermi-LAT observations.

Result: Detected Fermi bubbles and Galactic center excess with high significance; spectra/morphology match Fermi-LAT, suggesting dark matter annihilation (50 GeV mass, 1e-26 cm^3/s annihilation cross-section).

Conclusion: DAMPE provides independent validation of these gamma-ray sources, strengthening dark matter interpretation and highlighting its role as a complementary space-borne detector.

Abstract: The DArk Matter Particle Explorer (DAMPE) is a space-borne high-energy particle detector that surveys the $γ$-ray sky above$\sim 2~\rm GeV$ with a peak acceptance of $\sim 0.2~\rm m^2\,sr$. With the 102 months of data collected by DAMPE, we show that the Fermi bubbles are detected at a significance of $\sim 26σ$ and identify a GeV excess in the direction of Galactic center at $\sim 7 σ$ confidence. Both spectra and morphology are consistent with those observed by Fermi-LAT and the GeV excess component can be interpreted by the dark matter annihilation with a mass of $\sim 50$ GeV and a velocity-averaged cross section of $\sim 10^{-26}~{\rm cm^{3}~s^{-1}}$ for the $χχ\rightarrow b\bar{b}$ channel. Our results thus provide the first independent detection of these two intriguing diffuse gamma-ray sources besides Fermi-LAT.

</details>


### [89] [Limits on dark matter existence in neutron stars from recent astrophysical observations and mass correlation analysis](https://arxiv.org/abs/2512.23577)
*Jing Fu Hu,Hang Lu,Bao Yuan Sun*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Dark matter admixed neutron stars (DANSs) serve as a specific astrophysical laboratory for probing the features of dark matter (DM) and have emerged as a promising candidate for interpreting recent astrophysical observations (e.g., by NICER and LIGO/Virgo). Accurately constraining the internal DM content of DANSs is therefore of critical importance. In this work, we construct the equations of state (EoS) for DANS matter by employing twelve nuclear matter (NM) models within the covariant density functional (CDF) theory and a self-interacting fermionic model for DM. Using these EoSs as input, we solve the two-fluid Tolman-Oppenheimer-Volkov (TOV) equations to systematically investigate the influence of DM on the global properties of neutron stars (NSs). By incorporating recent observational constraints on NS properties, the maximum DM mass fraction $f_χ^{\mathrm{max}}$ in DANSs is determined for each NM EoS model. Our analysis reveals a strong linear correlation (Pearson coefficient $r=0.98$) between $f_χ^{\mathrm{max}}$ and the maximum mass of a pure NS, $M_{\rm{NS}}^{\mathrm{max}}$, described by $f_χ^{\mathrm{max}} = 0.22 M_{\mathrm{NS}}^{\mathrm{max}} - 0.44$. Leveraging this correlation and the observed NS maximum mass distribution, $P(M_{\text{NS}}^{\max} \mid \text{EM})$, we derive the probability distribution function (PDF) for the maximum DM mass, $P(M_χ^{\max} \mid \text{EM})$, in DANSs. We find that at the 68\% confidence level, $M_χ^{\mathrm{max}}=0.150^{+0.070}_{-0.051}\ M_{\odot}$. This quantitative constraint on the DM mass provides a critical prior for interpreting potential observational signatures of DANSs, such as anomalous tidal deformabilities and distinctive gravitational-wave signals.

</details>


### [90] [Classification and Characteristics of Double-trigger Gamma-ray Bursts](https://arxiv.org/abs/2512.23660)
*Liang Li*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Over the past two decades, the \textit{Swift} and \textit{Fermi} missions have identified a rare class of ``double-trigger'' gamma-ray bursts (GRBs) that produce two independent trigger events. These events are characterized by a sufficiently long quiescent period during which the on-board trigger system can reset, resulting in the subsequent emission being recorded as a second independent event. Consistent sky localization confirms that both trigger events originated from the same astrophysical source. Here, we present a systematic classification and characteristics study of three such cases: GRB 091024A, GRB 110709B, and GRB 220627A. We investigate each trigger episode emission independently using standard classification diagnostics, including duration ($T_{90}$), hardness ratio, minimum variability timescale (MVT), spectral lag ($τ_{\rm lag}$), peak energy ($E_{\rm p}$), and energetics. We compare these properties with those of typical long GRBs (LGRBs) and with single-trigger LGRBs that exhibit extended quiescent periods. Our analysis reveals that all sub-bursts from the three double-trigger events consistently lie within the LGRB classification region. These results indicate that double-trigger GRBs are not a physically distinct subclass, but rather products of LGRB central engines that undergo extended dormancy and subsequent reactivation.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [91] [Space AI: Leveraging Artificial Intelligence for Space to Improve Life on Earth](https://arxiv.org/abs/2512.22399)
*Ziyang Wang*

Main category: astro-ph.IM

TL;DR: This paper proposes Space AI as a new interdisciplinary field combining AI and space technology, organizing its applications into four mission contexts: AI on Earth, in Orbit, in Deep Space, and for Multi-Planetary Life to enhance space exploration and operational resilience.


<details>
  <summary>Details</summary>
Motivation: AI's potential to enable autonomous and resilient operations in space under extreme conditions and limited human oversight, addressing challenges in mission planning, data processing, and resource management as Earth-based progress faces constraints.

Method: The authors consolidate historical and contemporary advancements in AI and space technology, proposing a systematic framework categorizing Space AI into four mission contexts with specific application areas for each.

Result: A structured framework for Space AI's application domains is established, highlighting how AI can drive advancements in space missions and cross-disciplinary innovations beneficial to both space exploration and terrestrial applications.

Conclusion: Space AI will enhance humanity's capacity for space exploration, fostering technological advancements in sensing, robotics, and trustworthy AI that can also yield significant societal benefits on Earth.

Abstract: Artificial Intelligence (AI) is transforming domains from healthcare and agriculture to finance and industry. As progress on Earth meets growing constraints, the next frontier is outer space, where AI can enable autonomous, resilient operations under extreme uncertainty and limited human oversight. This paper introduces Space AI as a unified interdisciplinary field at the intersection of artificial intelligence and space science and technology. We consolidate historical developments and contemporary progress, and propose a systematic framework that organises Space AI into four mission contexts: 1 AI on Earth, covering intelligent mission planning, spacecraft design optimisation, simulation, and ground-based data analytics; 2 AI in Orbit, focusing on satellite and station autonomy, space robotics, on-board/near-real-time data processing, communication optimisation, and orbital safety; (3) AI in Deep Space, enabling autonomous navigation, adaptive scientific discovery, resource mapping, and long-duration human-AI collaboration under communication constraints; and 4 AI for Multi-Planetary Life, supporting in-situ resource utilisation, habitat and infrastructure construction, life-support and ecological management, and resilient interplanetary networks. Ultimately, Space AI can accelerate humanity's capability to explore and operate in space, while translating advances in sensing, robotics, optimisation, and trustworthy AI into broad societal impact on Earth.

</details>


### [92] [Starkindler: An Uncertainty Aware Objective for Photometric Redshift Estimation](https://arxiv.org/abs/2512.22566)
*Raahul Singh,Ashutosh Pandey*

Main category: astro-ph.IM

TL;DR: Starkindler improves photometric redshift estimation by incorporating observational errors into the model's training objective, enhancing accuracy and calibration while providing interpretable uncertainty estimates.


<details>
  <summary>Details</summary>
Motivation: Existing ML methods for photometric redshift often ignore aleatoric uncertainties from observational data, leading to less accurate and less reliable uncertainty estimates.

Method: The paper introduces Starkindler, a new training objective that explicitly accounts for aleatoric uncertainty by integrating observational errors. A simple CNN is trained using SDSS data, differing from traditional methods that focus only on epistemic uncertainty.

Result: Starkindler achieves better accuracy, improved calibration, and reduced outlier rates compared to SDSS's existing photometric redshift estimates. Ablation studies show that excluding observational errors harms performance.

Conclusion: Starkindler effectively addresses aleatoric uncertainty, offering both better predictive performance and interpretable uncertainties, which is crucial for robust astronomical analysis.

Abstract: Photometric Redshift is critical for analyzing astronomical objects, but existing ML methods often overlook the aleatoric uncertainties inherent in observed data. We introduce Starkindler, a novel training objective that explicitly incorporates observational errors into the model's objective function, thereby directly accounting for aleatoric uncertainty. Unlike traditional probabilistic models that focus solely on epistemic uncertainty, Starkindler provides uncertainty estimates that are regularised by aleatoric uncertainty, and is designed to be more interpretable. We train a simple convolutional neural network (CNN) using data from Sloan Digital Sky Survey (SDSS) and compare against the Photometric redshift estimates provided by SDSS. We show improvements in accuracy, calibration and reduction in predicted outlier rate. We also conduct an ablation study which confirms that excluding observational errors significantly degrades model performance, underscoring the importance of accounting for aleatoric uncertainty. Our results suggest that Starkindler not only enhances predictive performance but also provides interpretable uncertainty estimates, making it a robust tool for astronomical data analysis.

</details>


### [93] [Dark matter direct detection: status, results and future plans](https://arxiv.org/abs/2512.23039)
*Laura Baudis*

Main category: astro-ph.IM

TL;DR: The paper reviews principles of direct dark matter detection, including experimental techniques, expected signals and backgrounds, and discusses current experiments searching for dark matter particles in the keV-TeV mass range along with future detector Sensitivities.


<details>
  <summary>Details</summary>
Motivation: The motivation is to understand the current state and future prospects of direct dark matter detection experiments, which aim to identify rare signals from galactic dark matter particles to confirm their existence and properties.

Method: The paper employs a review methodology, discussing established experimental techniques used in direct detection (e.g., cryogenic detectors, scintillation-based detectors), analyzing expected interaction signals versus background noise, and evaluating ongoing experiments' capabilities and upcoming detector improvements.

Result: The analysis highlights the current sensitivity limits of existing experiments, their challenges in distinguishing dark matter signals from backgrounds, and projections for future detectors showing improved sensitivity to detect particles across the keV-TeV mass range.

Conclusion: The paper concludes that while no confirmed dark matter detections exist, advancements in detector technology and experimental techniques are crucial for future discoveries, emphasizing the need for continued research and improved sensitivity in the field.

Abstract: Direct dark matter detection experiments search for rare signals induced by hypothetical, galactic dark matter particles in low-background detectors operated deep underground. I will briefly review the direct detection principles, the expected signals and backgrounds, and the main experimental techniques. I will then discuss the status of ongoing experiments aiming to discover new particles in the keV - TeV mass range, as well as future detectors and their sensitivity.

</details>


### [94] [Two birds with one stone: simultaneous realization of both Lunar Coordinate Time and lunar geoid time by a single orbital clock](https://arxiv.org/abs/2512.23098)
*Tian-Ning Yang,Ren-Fang Geng,Jing Zhang,Chong Yang,Yong Huang,Yi Xie*

Main category: astro-ph.IM

TL;DR: This paper proposes a 'time aligned orbit' around the Moon where an ideal clock's readings can match both Lunar Coordinate Time (O1) and selenoid proper time (O2) through a linear transformation, enabling synchronization between the two reference times. Numerical simulations show synchronization within 190 ns desynchronization after a year, with potential for improvement.


<details>
  <summary>Details</summary>
Motivation: To resolve the incompatibility between O1 (simpler but unsteered) and O2 (user-friendly but requiring coordinate rescaling), allowing simultaneous realization of both lunar reference times without compromising system simplicity or user convenience.

Method: Proposed a time aligned orbit at ~1.5 lunar radii, conducted numerical simulations accounting for orbital deviations, and assessed synchronization accuracy with and without topography corrections.

Result: Simulation showed 190 ns desynchronization/year (6E-15 frequency offset), which is 3.75% of topography-induced errors in O2. Improved estimates achieve 13 ns and 4E-16 with orbital corrections.

Conclusion: A single clock in the proposed orbit can realize both O1 and O2, offering scalability for other terrestrial planets, bridging the gap between the two lunar time standards.

Abstract: Context. Among options for definition of the lunar reference time, the option taking Lunar Coordinate Time (O1) has its simplicity but cannot be realized by any clock without steering, while another option adopting the lunar geoid (selenoid) proper time (O2) has its convenience for users on the lunar surface but would bring a new scaling of spatial coordinates and mass parameter of the Moon. Aims. We propose a ''time aligned orbit'' that the readings of an ideal clock in this orbit could equal to the selenoid proper time in O2 and these readings could be converted to Lunar Coordinate Time in O1 by a known linear transformation. Methods. We show that there exist the time aligned orbit around the Moon with its semi-major axis of about 1.5 lunar radius slightly depending on its inclination. We conduct a set of numerical simulations to assess to what extent a clock on these orbits could realize O2 in a more realistic lunar environment. Results. We find that the proper time in our simulations would desynchronize from the selenoid proper time up to 190 ns after a year with a frequency offset of 6E-15, which is solely 3.75% of the frequency difference in O2 caused by the lunar surface topography. These numbers might be further reduced to 13 ns and 4E-16, if we could account for the deviation of the mean orbits in our simulations from the nominal ones. Conclusions. One might simultaneously realize O1 and O2 by deployment of a single clock in the time aligned orbit. This approach also has its scalability for other terrestrial planets beyond the Earth-Moon system.

</details>


### [95] [Why Machine Learning Models Systematically Underestimate Extreme Values II: How to Fix It with LatentNN](https://arxiv.org/abs/2512.23138)
*Yuan-Sen Ting*

Main category: astro-ph.IM

TL;DR: LatentNN is introduced to correct attenuation bias in neural networks by jointly optimizing network parameters and latent inputs, improving accuracy in low signal-to-noise settings common in astronomical data.


<details>
  <summary>Details</summary>
Motivation: Measurement errors in astronomical data lead to attenuation bias, causing systematic underestimation in regression coefficients. Existing solutions for linear models needed extension to neural networks to handle complex, nonlinear relationships.

Method: LatentNN treats true inputs as latent variables, maximizing joint likelihood of inputs and outputs. It simultaneously estimates network parameters and latent values, addressing bias without prior assumptions about input distributions.

Result: Demonstrated bias reduction across diverse applications including stellar spectroscopy. Effective when measurement errors are less than half the intrinsic data range, particularly in low signal-to-noise scenarios with limited features.

Conclusion: LatentNN offers improved neural network inference for data with measurement errors, crucial for astronomical studies. It provides a framework to handle noisy data regimes where standard models fail significantly.

Abstract: Attenuation bias -- the systematic underestimation of regression coefficients due to measurement errors in input variables -- affects astronomical data-driven models. For linear regression, this problem was solved by treating the true input values as latent variables to be estimated alongside model parameters. In this paper, we show that neural networks suffer from the same attenuation bias and that the latent variable solution generalizes directly to neural networks. We introduce LatentNN, a method that jointly optimizes network parameters and latent input values by maximizing the joint likelihood of observing both inputs and outputs. We demonstrate the correction on one-dimensional regression, multivariate inputs with correlated features, and stellar spectroscopy applications. LatentNN reduces attenuation bias across a range of signal-to-noise ratios where standard neural networks show large bias. This provides a framework for improved neural network inference in the low signal-to-noise regime characteristic of astronomical data. This bias correction is most effective when measurement errors are less than roughly half the intrinsic data range; in the regime of very low signal-to-noise and few informative features. Code is available at https://github.com/tingyuansen/LatentNN.

</details>


### [96] [Lossless compression of simulated radio interferometric visibilities](https://arxiv.org/abs/2512.23490)
*A. R. Offringa,R. J. van Weeren*

Main category: astro-ph.IM

TL;DR: The paper introduces Sisco, a lossless compression method for forward-predicted model data in radio interferometry, achieving 24% of original data size on average. It uses polynomial extrapolation and Deflate compression.


<details>
  <summary>Details</summary>
Motivation: Existing lossy compression methods are problematic for noiseless model data in direction-dependent calibration, which can be an order of magnitude larger than observed data. A lossless solution is needed for storage efficiency without compromising calibration accuracy.

Method: Sisco decomposes complex visibility values, applies time/frequency polynomial extrapolation (linear/quadratic), groups bytes, and compresses residuals with Deflate. Integrates with Casacore storage manager for seamless workflow use.

Result: Sisco reduces model data to 24% on average, with 13-38% range based on data predictability. Pure noise data achieves 84%. Compression throughput is 534 MB/s, I/O bound. Potential for lossy extension discussed.

Conclusion: Sisco effectively reduces storage needs for model data, compatible with existing systems. Future work includes optimizing throughput and exploring lossy variants.

Abstract: Context. Processing radio interferometric data often requires storing forward-predicted model data. In direction-dependent calibration, these data may have a volume an order of magnitude larger than the original data. Existing lossy compression techniques work well for observed, noisy data, but cause issues in calibration when applied to forward-predicted model data. Aims. To reduce the volume of forward-predicted model data, we present a lossless compression method called Simulated Signal Compression (Sisco) for noiseless data that integrates seamlessly with existing workflows. We show that Sisco can be combined with baseline-dependent averaging for further size reduction. Methods. Sisco decomposes complex floating-point visibility values and uses polynomial extrapolation in time and frequency to predict values, groups bytes for efficient encoding, and compresses residuals using the Deflate algorithm. We evaluate Sisco on diverse LOFAR, MeerKAT, and MWA datasets with various extrapolation functions. Implemented as an open-source Casacore storage manager, it can directly be used by any observatory that makes use of this format. Results. We find that a combination of linear and quadratic prediction yields optimal compression, reducing noiseless forward-predicted model data to 24% of its original volume on average. Compression varies by dataset, ranging from 13% for smooth data to 38% for less predictable data. For pure noise data, compression achieves just a size of 84% due to the unpredictability of such data. With the current implementation, the achieved compression throughput is with 534 MB/s mostly dominated by I/O on our testing platform, but occupies the processor during compression or decompression. Finally, we discuss the extension to a lossy algorithm.

</details>


### [97] [Sidelobe Modification for an Offset Gregorian Reflector System using a Reconfigurable Intelligent Surface-Equipped Subreflector](https://arxiv.org/abs/2512.23530)
*S. W. Ellingson,A. J. Yip*

Main category: astro-ph.IM

TL;DR: This paper demonstrates that installing a reconfigurable intelligent surface (RIS) on the rim of the subreflector in an offset Gregorian reflector system can effectively reduce close-in sidelobes with minimal main lobe degradation, offering a compact and practical solution for radio astronomy to mitigate satellite interference.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address severe satellite interference in radio astronomy observations caused by sidelobes in offset Gregorian systems, improving upon previous RIS implementations by using a smaller RIS on the subreflector instead of the main reflector.

Method: The method involves placing a 1-bit phase-only RIS on the subreflector's rim, covering one-third of its surface. An unconstrained optimization algorithm adjusts RIS element states to create nulls in the second sidelobe peak without constraining the main lobe pattern.

Result: The RIS achieved a deep null in the second sidelobe peak with only a 0.2 dB main lobe directivity loss, using fewer elements than the previous main-reflector approach. It can be retrofitted into existing systems by replacing the subreflector.

Conclusion: The subreflector-mounted RIS provides an efficient, space-saving solution for sidelobe suppression in radio telescopes, better suited for practical implementation than prior methods due to reduced size and ease of integration.

Abstract: In past work, we described the use of a reconfigurable intelligent surface (RIS) mounted on the rim of an axisymmetric prime focus-fed reflector to create nulls in the close-in sidelobes. In this paper, we show that similar performance is possible in an offset Gregorian reflector system using a RIS on the rim of the subreflector. Applications include radio astronomy, where offset Gregorian reflectors are common and observations are subject to deleterious levels of interference from satellites entering through sidelobes. We show that an efficient RIS replacing the outer one-third of the subreflector surface, employing passive elements with 1-bit phase-only control, can create a null in the peak of the second sidelobe in the quiescent pattern. This is achieved using a simple unconstrained optimization algorithm to set the states of the RIS elements. The algorithm yields a deep null with just 0.2~dB reduction in main lobe directivity, despite lacking any constraints on main lobe pattern. Compared to our previous approach of mounting the RIS on the rim of the main reflector, the subreflector-based approach demonstrated in this paper requires a much smaller RIS and can implemented in existing systems by replacing the subreflector.

</details>


### [98] [Galaxy Zoo Evo: 1 million human-annotated images of galaxies](https://arxiv.org/abs/2512.23691)
*Mike Walmsley,Steven Bamford,Hugh Dickinson,Tobias Géron,Alexander J. Gordon,Annette M. N. Ferguson,Lucy Fortson,Sandor Kruk,Natalie Lines,Chris J. Lintott,Karen L. Masters,Robert G. Mann,James Pearson,Hayley Roberts,Anna M. M. Scaife,Stefan Schuldt,Brooke Simmons,Rebecca Smethurst,Josh Speagle,Kyle Willett*

Main category: astro-ph.IM

TL;DR: Galaxy Zoo Evo is a large labeled dataset with 104M crowdsourced labels for 823k galaxy images across four telescopes, designed to pretrain/finetune models for astronomy tasks like identifying strong lenses and analyzing Euclid telescope data. It serves as a benchmark for domain adaptation and uncertainty learning in astronomical computer vision.


<details>
  <summary>Details</summary>
Motivation: The motivation behind Galaxy Zoo Evo is to provide a comprehensive resource for training and evaluating foundation models in astronomy, addressing challenges like domain adaptation between terrestrial and astronomical images, and handling uncertainty from crowdsourced labels. This supports astronomers in managing the data deluge from new telescopes like Euclid.

Method: Galaxy Zoo Evo aggregates crowdsourced labels via fine-grained question-answer pairs (e.g., galaxy features, morphology, interactions) for millions of galaxy images. It includes both大规模预训练数据集和四个专项数据集（共计167k galaxies）用于下游任务如强引力透镜检测和欧几里得望远镜图像分析。

Result: The dataset enables pretraining/finetuning models for astronomical tasks and presents benchmarks for tasks like domain adaptation and learning under label uncertainty. Initial results are hinted but not detailed, positioning it as a critical resource for future astronomy research.

Conclusion: Galaxy Zoo Evo aims to accelerate astronomy research by providing essential foundation models capable of handling complex galaxy image analysis, which will be vital for interpreting data from upcoming large-scale surveys like Euclid's. It emphasizes community-driven data collection as key to advancing both AI and astrophysics.

Abstract: We introduce Galaxy Zoo Evo, a labeled dataset for building and evaluating foundation models on images of galaxies. GZ Evo includes 104M crowdsourced labels for 823k images from four telescopes. Each image is labeled with a series of fine-grained questions and answers (e.g. "featured galaxy, two spiral arms, tightly wound, merging with another galaxy"). These detailed labels are useful for pretraining or finetuning. We also include four smaller sets of labels (167k galaxies in total) for downstream tasks of specific interest to astronomers, including finding strong lenses and describing galaxies from the new space telescope Euclid. We hope GZ Evo will serve as a real-world benchmark for computer vision topics such as domain adaption (from terrestrial to astronomical, or between telescopes) or learning under uncertainty from crowdsourced labels. We also hope it will support a new generation of foundation models for astronomy; such models will be critical to future astronomers seeking to better understand our universe.

</details>
