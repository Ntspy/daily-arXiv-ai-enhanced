<div id=toc></div>

# Table of Contents

- [astro-ph.HE](#astro-ph.HE) [Total: 13]
- [astro-ph.IM](#astro-ph.IM) [Total: 4]
- [hep-ph](#hep-ph) [Total: 18]
- [gr-qc](#gr-qc) [Total: 6]


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [1] [Lagrangian versus Eulerian Methods for Toroidally-Magnetized Isothermal Disks](https://arxiv.org/abs/2512.05194)
*Yashvardhan Tomar,Philip F. Hopkins*

Main category: astro-ph.HE

TL;DR: The study compares Lagrangian and Eulerian methods in simulating toroidally-magnetized accretion disks, finding that Lagrangian methods maintain midplane toroidal flux better at low resolutions by resolving thin layers, suggesting physical differences, not resolution, explain divergent results with previous Eulerian studies.


<details>
  <summary>Details</summary>
Motivation: To investigate why Lagrangian simulations show sustained toroidal magnetic fields while Eulerian methods do not, by testing both methods on the same idealized problem.

Method: Re-running Guo et al. (2025) simulations using two Lagrangian methods (meshless finite-mass and finite-volume) and comparing results with Eulerian high/low resolution runs. Focus on flux evolution under varying thermal scale-length resolution.

Result: Lagrangian methods reproduce high-resolution Eulerian results and retain flux evolution down to low resolutions, whereas Eulerian methods exhibit no evolution at low resolution. The discrepancy links to Lagrangian capability to track thin midplane layers.

Conclusion: The sustained toroidal fields in Lagrangian multi-physics simulations aren't numerical artifacts but reflect physical differences from G25 conditions, requiring further investigation into underlying mechanisms.

Abstract: A number of simulations have seen the emergence of strongly-toroidally-magnetized accretion disks from interstellar medium inflows. Recently, Guo et al. 2025 (G25) studied an idealized test problem of toroidally-magnetized disks in isothermal ideal MHD with an Eulerian static-mesh method, and argued the midplane behavior changes qualitatively (with a significant loss of toroidal magnetic flux) when the the thermal scale-length is resolved ($Δx < H_{\rm thermal}$). We rerun the G25 test problem with two Lagrangian methods: meshless finite-mass, and meshless finite-volume. We show that Lagrangian methods reproduce the high-resolution ($Δx \ll H_{\rm thermal}$) Eulerian G25 results. At low resolution ($Δx \gg H_{\rm thermal}$), behaviors differ: Lagrangian methods still lose flux and evolve 'as close as possible' to the converged solution, while Eulerian methods show no evolution. We argue this difference in convergence behavior is related to the ability of Lagrangian codes to follow flows to an arbitrarily thin midplane layer, analogous to the well-studied difference in Jeans fragmentation problems. This and results from other higher-resolution simulations and different codes suggest that the sustained midplane toroidal fields seen in recent Lagrangian multi-scale, multi-physics simulations cannot be a numerical resolution effect, and some physical difference between those simulations and the G25 test problem explains their different behaviors.

</details>


### [2] [Two Step Localization Method for Electromagnetic Followup of LIGO-Virgo-KAGRA Gravitational-Wave Triggers](https://arxiv.org/abs/2512.05218)
*Daniel Skorohod,Ofek Birnholtz*

Main category: astro-ph.HE

TL;DR: The paper proposes a Two-Step Localization strategy using one wide-field auxiliary telescope and one narrow-field main telescope to reduce detection latency of EM counterparts to BNS mergers. Simulations show it outperforms uncoordinated methods, emphasizing the need for faster telescopes and better wide-field coverage.


<details>
  <summary>Details</summary>
Motivation: Current observational strategies for detecting EM counterparts to GW signals from BNS mergers are suboptimal. Rapid detection is crucial for understanding source properties and relativistic transients, necessitating improved, coordinated approaches.

Method: The Two-Step Localization strategy involves an auxiliary telescope with a wide field of view to detect early EM signals, which then triggers a main telescope with high resolution for follow-up. Performance is evaluated via simulations considering dynamic sky maps, telescope parameters, and SNR-weighted contours.

Result: The strategy reduces median detection latency compared to uncoordinated methods. Key improvements come from faster telescopes with higher slew rates and truly wide-field auxiliary telescopes rather than adding more telescopes.

Conclusion: Coordinated observational protocols like Two-Step Localization are effective. Future efforts should prioritize faster telescopes and enhanced wide-field coverage for optimal early-time discovery of EM counterparts.

Abstract: Rapid detection and follow-up of electromagnetic (EM) counterparts to gravitational wave (GW) signals from binary neutron star (BNS) mergers are essential for constraining source properties and probing the physics of relativistic transients. Observational strategies for these early EM searches are therefore critical, yet current practice remains suboptimal, motivating improved, coordination-aware approaches. We propose and evaluate the Two-Step Localization strategy, a coordinated observational protocol in which one wide-field auxiliary telescope and one narrow-field main telescope monitor the evolving GW sky localization in real time. The auxiliary telescope, by virtue of its large field of view, has a higher probability of detecting early EM emission. Upon registering a candidate signal, it triggers the main telescope to slew to the inferred location for prompt, high-resolution follow-up. We assess the performance of Two-Step Localization using large-scale simulations that incorporate dynamic sky-map updates, realistic telescope parameters, and signal-to-noise ratio (SNR)-weighted localization contours. For context, we compare Two-Step Localization to two benchmark strategies lacking coordination. Our results demonstrate that Two-Step Localization significantly reduces the median detection latency, highlighting the effectiveness of targeted cooperation in the early-time discovery of EM counterparts. Our results point to the most impactful next step: next-generation faster telescopes that deliver drastically higher slew rates and shorter scan times, reducing the number of required tiles; a deeper, truly wide-field auxiliary improves coverage more than simply adding more telescopes.

</details>


### [3] [Multiple outflows and delayed ejections revealed by early imaging of novae](https://arxiv.org/abs/2512.05220)
*Elias Aydi,John D. Monnier,Antoine Mérand,Gail H. Schaefer,Laura Chomiuk,Magdalena Otulakowska-Hypka,Jhih-Ling Fan,Kwan Lok Li,Kirill V. Sokolovsky,Ricardo Salinas,Michael Tucker,Benjamin Shappee,Richard Rudy,Kim L. Page,N. Paul M. Kuin,David A. H. Buckley,Peter Craig,Luca Izzo,Justin Linford,Brian D. Metzger,Koji Mukai,Marina Orio,Ken J. Shen,Jay Strader,Jennifer L. Sokoloski,Robert E. Williams,Montana N. Williams,Gesesew R. Habtie,Stefan Kraus,Narsireddy Anugu,Jean-Baptiste Le Bouquin,Sorabh Chhabra,Isabelle Codron,Tyler Gardner,Mayra Gutierrez,Noura Ibrahim,Cyprien Lanthermann,Benjamin R. Setterholm,Christopher Ashall,Jason T. Hinkle,Thomas de Jaeger,Anna V. Payne*

Main category: astro-ph.HE

TL;DR: Novae mass ejection mechanisms are revealed by observing two novae showing perpendicular outflows and delayed ejections contradicting previous assumptions.


<details>
  <summary>Details</summary>
Motivation: To determine the mechanisms of mass ejection in novae through multiwavelength observations and resolve discrepancies in theoretical models.

Method: Near-infrared interferometry combined with multiwavelength data of novae V1674 Her and V1405 Cas observed at different times post-eruption. For V1674 Her, observations occurred 2-3 days post-discovery, while V1405 Cas showed delayed envelope ejection 50+ days post-eruption.

Result: Detected two perpendicular outflows in V1674 Her causing γ-ray emission through shock interaction. V1405 Cas exhibited delayed mass ejection indicating a common-envelope phase, challenging simple ejection models.

Conclusion: Nova ejection mechanisms involve complex processes like multiple outflows and delayed ejections, not单一的impulsive or wind-driven models as previously thought.

Abstract: Novae are thermonuclear eruptions on accreting white dwarfs in interacting binaries. Although most of the accreted envelope is expelled, the mechanism -- impulsive ejection, multiple outflows or prolonged winds, or a common-envelope interaction -- remains uncertain. GeV $γ$-ray detections from $>20$ Galactic novae establish these eruptions as nearby laboratories for shock physics and particle acceleration, underscoring the need to determine how novae eject their envelopes. Here we report on near-infrared interferometry, supported with multiwavelength observations, of two $γ$-ray detected novae. The images of the very fast 2021 nova V1674~Her, taken just 2--3 days after discovery, reveal the presence of two perpendicular outflows. The interaction between these outflows likely drives the observed $γ$-ray emission. Conversely, the images of the very slow 2021 nova V1405~Cas suggest a delay in the ejection of the bulk of the accreted envelope of more than 50 days after the start of eruption, as the nova slowly rises to visible peak and during which the envelope engulfed the system in a common envelope phase. These unprecedented images offer direct observational evidence that the mechanisms driving mass ejection from the surfaces of accreting white dwarfs are not as simple as previously thought, revealing multiple outflows and delayed ejections.

</details>


### [4] [Absorption of strong electromagnetic waves in magnetized pair plasmas](https://arxiv.org/abs/2512.05281)
*Emanuele Sobacchi*

Main category: astro-ph.HE

TL;DR: The paper investigates synchrotron absorption of short electromagnetic pulses in cold magnetized pair plasmas, identifying a specific frequency range where absorption occurs. This frequency window generalizes the cyclotron resonance for strong pulses and impacts fast radio burst emission models.


<details>
  <summary>Details</summary>
Motivation: To understand the conditions under which electromagnetic pulses are absorbed in plasmas under magnetic fields, extending cyclotron resonance theory to high-intensity pulses and evaluating implications for astrophysical phenomena like fast radio bursts.

Method: The study analyzes the propagation of electromagnetic pulses in magnetized pair plasmas, deriving conditions for absorption (ω_B/a₀ < ω < a₀ω_B), and examines non-linear wave behavior in such plasmas compared to vacuum. Test particle motion in vacuum waves is studied to assess stochastic heating effects.

Result: Absorption occurs when the pulse frequency lies between ω_B/a₀ and a₀ω_B, representing a non-linear regime. This challenges assumptions about particle heating via synchrotron absorption, affecting models of fast radio burst emissions.

Conclusion: The identified frequency window generalizes cyclotron resonance for strong fields, alters plasma wave propagation, and suggests reevaluation of emission models requiring sustained source conditions in astrophysical contexts.

Abstract: We discuss synchrotron absorption of a short electromagnetic pulse that propagates in a cold magnetized pair plasma. We show that the pulse can be absorbed when $ω_{\rm B}/a_0< ω< a_0ω_{\rm B}$, where $a_0>1$ is the strength parameter of the pulse, and $ω$ and $ω_{\rm B}$ respectively are the frequency of the wave and the cyclotron frequency in the background magnetic field (all quantities are defined in the reference frame where the particles are at rest before being illuminated by the pulse). The condition $ω_{\rm B}/a_0< ω< a_0ω_{\rm B}$ is essentially a generalization of the cyclotron resonance to strong electromagnetic pulses with $a_0>1$. When $ω_{\rm B}/a_0< ω< a_0ω_{\rm B}$, the propagation of electromagnetic waves in a plasma can be very different with respect to the propagation in vacuum because the wave equation is strongly non-linear. Then it is unclear whether the particles are heated stochastically due to synchrotron absorption, as found by studying the motion of a test particle in the field of a vacuum electromagnetic wave. We discuss implications of our results for constraining emission models of fast radio bursts.

</details>


### [5] [Nuclear parameter inference with semi-agnostic priors](https://arxiv.org/abs/2512.05315)
*Lami Suleiman,Anthea F. Fantina,Francesca Gulminelli,Jocelyn Read*

Main category: astro-ph.HE

TL;DR: The study evaluates how neutron star mass and radius measurements can constrain nuclear parameters using semi-agnostic equation of state models, finding that some parameters are strongly correlated and that semi-agnostic methods improve accuracy compared to traditional models.


<details>
  <summary>Details</summary>
Motivation: To understand dense nuclear matter properties beyond lab capabilities, the paper explores how observational data from neutron stars improves constraints on nuclear parameters using advanced equation-of-state priors.

Method: Assessed correlations between nuclear parameters and pressure across densities; simulated observations for three nucleonic EoS models to test parameter recovery; compared semi-agnostic versus nucleonic meta-model approaches.

Result: Key parameters show strong correlations at high densities, causing inference challenges. Semi-agnostic priors outperform nucleonic models in accurately recovering true parameters by avoiding pollution from high-density parameterizations.

Conclusion: Semi-agnostic equation-of-state methods are superior for constraining nuclear parameters due to reduced contamination from high-density assumptions, though parameter degeneracies remain an issue needing further study.

Abstract: Radio pulsar timing, X-ray pulse profile modeling or gravitational-wave detections of binary mergers involving at least one neutron star offer the opportunity to elucidate the properties of dense and neutron rich matter in thermodynamic regimes inaccessible to nuclear laboratories. Such inference relies on building appropriate equation-of-state priors, such as the recently introduced semi-agnostic constructions that incorporate nuclear theory and experimental information available in low to intermediate density regimes, while offering the necessary flexibility at high density. In this paper, we assess how detections of mass, radius, and tidal deformability for low-mass ($\sim 1$M$_{\odot}$) or high-mass ($\sim 1.9$M$_{\odot}$) neutron stars would contribute to constraining nuclear empirical parameters in an inference based on semi-agnostic equation-of-state priors. We first assessed the correlation factors between nuclear empirical parameters and the zero-temperature and $β$-equilibrated pressure in different regimes of density. We then simulate observations for three nucleonic equations of state to test the recovery of the corresponding nuclear empirical parameters. We show that not all nuclear empirical parameters significantly correlate with the pressure and find a competition between them in the high-density regime that challenges their inference. We also find that using semi-agnostic constructions instead of assuming a nucleonic content up to the highest densities in the neutron-star core can help recover more accurately the true nuclear empirical parameters. Parameterizing the high-density regime of the equation of state with the nucleonic meta-model can pollute the inference of nuclear empirical parameters; semi-agnostic constructions are a solution to that. However, many nuclear matter empirical parameters contribute in a similar way to the building of baryonic pressure.

</details>


### [6] [A Persistently Active Fast Radio Burst source Embedded in an Expanding Supernova Remnant](https://arxiv.org/abs/2512.05448)
*Chen-Hui Niu,Di Li,Yuan-Pei Yang,Yuhao Zhu,Yongkun Zhang,Jia-heng Zhang,Zexin Du,Jumei Yao,Xiaoping Zheng,Pei Wang,Yi Feng,Bing Zhang,Weiwei Zhu,Wenfei Yu,Ji-an Jiang,Shi Dai,Chao-Wei Tsai,A. M. Chen,Yijun Hou,Jiarui Niu,Weiyang Wang,Chenchen Miao,Xinming Li,Junshuo Zhang*

Main category: astro-ph.HE

TL;DR: This paper identifies FRB 20190520B as the first known persistently active fast radio burst source over four years, revealing a significant and unprecedented decrease in its dispersion measure (DM) at 12.4 pc cm⁻³ yr⁻¹. These findings suggest the source exists within a dense, expanding ionized medium like a young supernova remnant.


<details>
  <summary>Details</summary>
Motivation: The rarity of persistent FRB sources and the need to understand DM variations, which provide clues about their environments, motivated this study.

Method: Long-term monitoring of FRB 20190520B using radio telescopes to track its DM changes over ~4 years, comparing results with pulsar data and theoretical models of supernova remnants.

Result: Observed DM decrease three times larger than previous FRB measurements and orders of magnitude greater than pulsars, with host galaxy contributing significantly to DM, pointing to a dense, expanding medium.

Conclusion: FRB 20190520B's environment is consistent with a young supernova remnant, offering insights into FRB origins and evolution in extreme astrophysical settings.

Abstract: Fast radio bursts (FRBs) remain one of the most puzzling astrophysical phenomena. While most FRBs are detected only once or sporadically, we present the identification of FRB 20190520B as the first persistently active source over a continuous span of ~ four years. This rare long-term activity enabled a detailed investigation of its dispersion measure (DM) evolution. We also report that FRB 20190520B exhibits a substantial decrease in DM at a global rate of minus 12.4 plus or minus 0.3 pc cm^-3 yr^-1, exceeding previous FRB DM variation measurements by a factor of three and surpassing those observed in pulsars by orders of magnitude. The magnitude and consistency of the DM evolution, along with a high host DM contribution, strongly indicate that the source resides in a dense, expanding ionized medium, likely a young supernova remnant (SNR).

</details>


### [7] [Search for UHE gamma photons in cosmic rays by studying the geomagnetic influence on air-shower muons](https://arxiv.org/abs/2512.05493)
*Animesh Basak,Meghamani Haldar,Kishor Chaudhury,Rajat K. Dey*

Main category: astro-ph.HE

TL;DR: The paper introduces a novel method using geomagnetic effects on muons to enhance discrimination between gamma rays and cosmic protons, achieving high efficiencies with minimal detector coverage.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of distinguishing gamma-ray signals from dominant cosmic-ray backgrounds in ultra-high-energy observations, enabling efficient detection with smaller detector arrays.

Method: Exploits geomagnetic-induced polar asymmetry in muon distributions from air showers. Transforms muon impact coordinates to the shower front plane, ignoring minor space attenuation. Uses observables d_max and N_mu;IQS^tr. from positive/negative muon zones.

Result: Achieved 93.2% and 98.6% gamma/proton discrimination efficiencies. Shows feasibility of using muon detectors covering ~1.4% of a square-km array.

Conclusion: Proposes implementation in current/future gamma-ray observatories due to effective discrimination and reduced detector area requirements.

Abstract: A major challenge in ground-based ultra-high-energy gamma-ray observations remains in discriminating sporadic gamma-ray signals from a huge background of cosmic-ray events. To achieve good discrimination power of gamma rays against protons, an unconventional approach is presented that exploits the geomagnetic influence on air shower muons in Monte Carlo shower events. A recognizable polar asymmetry in the positive and negative muon distributions is noticed after transforming the impact coordinates of each muon from the observer plane onto the shower front plane, plus a judicious ignoring of the minimal attenuation of muons in the space between the two planes. A couple of observables, $d_{\text{max}}$ and $N_{μ; \text{IQS}}^{\text{tr.}}$, can be extracted from the formation of two densely populated positive and negative muon zones in each shower. Both observables demonstrate excellent gamma/proton discrimination power, with efficiencies of $93.2\%$ and $98.6\%$. This analysis permitted the usage of muon detectors just covering a small area of $\simeq{1.4}\%$ of a square-km array for ultra-high-energy gamma-ray observations. It is expected that the present and future gamma-ray observatories will implement the current approach.

</details>


### [8] [Evolution of the Inner Accretion Flow in Swift J1727.8$-$1613 across Intermediate States: Insights from Broadband Spectral and Timing Analysis](https://arxiv.org/abs/2512.05544)
*Swadesh Chand,Andrzej A. Zdziarski,Gulab C. Dewangan,Pragati Sahu*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a comprehensive broadband spectral and variability study of the newly detected black hole X-ray binary Swift~J1727.8--1613 in the intermediate states during its 2023 outburst, using multi-mission observations from NICER, NuSTAR, AstroSat, and Insight-HXMT. The spectral data up to $78$ keV in the hard-intermediate state (HIMS) requires models with two Comptonizing regions. In contrast, models with a single Comptonizing region adequately describe the soft-intermediate states (SIMS), implying a significant evolution in the disk-corona geometry between the states. The hard X-ray tail above $100$ keV in the HIMS, detected with both AstroSat/CZTI and Insight-HXMT/HE, indicates that the electron population in the corona is not purely thermal but rather hybrid, with a power-law distribution above the thermal cutoff. While both the reflection modeling and disk continuum fitting favor a truncated disk geometry in the HIMS, the disk substantially moves close to the innermost stable circular orbit in the SIMS, accompanied by a significant rise in the disk temperature. This interpretation is further supported by the increase in the QPO frequency from $\sim1.3$ to $\sim6.6$ Hz. From joint modeling of the disk continuum and reflection component, we estimate a black hole mass of $10.5^{+7.7}_{-3.0}$, spin of $0.79^{+0.03}_{-0.13}$, and disk inclination angle of $42^\circ$-$50^\circ$, which match well with the previously reported spectro-polarimetric measurements. The inferred source distance of $\sim3.5$ kpc is consistent with the recent estimate based on optical spectroscopy. We find a weakly variable or stable disk and a highly variable Comptonized component.

</details>


### [9] [CTAO LST-1 observations of magnetar SGR 1935+2154: Deep limits on sub-second bursts and persistent tera-electronvolt emission](https://arxiv.org/abs/2512.05634)
*K. Abe,S. Abe,A. Abhishek,F. Acero,A. Aguasca-Cabot,I. Agudo,C. Alispach,D. Ambrosino,F. Ambrosino,L. A. Antonelli,C. Aramo,A. Arbet-Engels,C. Arcaro,T. T. H. Arnesen,K. Asano,P. Aubert,A. Baktash,M. Balbo,A. Bamba,A. Baquero Larriva,U. Barres de Almeida,J. A. Barrio,L. Barrios Jiménez,I. Batkovic,J. Baxter,J. Becerra González,E. Bernardini,J. Bernete,A. Berti,I. Bezshyiko,C. Bigongiari,E. Bissaldi,O. Blanch,G. Bonnoli,P. Bordas,G. Borkowski,G. Brunelli,A. Bulgarelli,M. Bunse,I. Burelli,L. Burmistrov,M. Cardillo,S. Caroff,A. Carosi,R. Carraro,M. S. Carrasco,F. Cassol,N. Castrejón,D. Cerasole,G. Ceribella,A. Cerviño Cortínez,Y. Chai,K. Cheng,A. Chiavassa,M. Chikawa,G. Chon,L. Chytka,G. M. Cicciari,A. Cifuentes,J. L. Contreras,J. Cortina,H. Costantini,M. Dalchenko,P. Da Vela,F. Dazzi,A. De Angelis,M. de Bony de Lavergne,R. Del Burgo,C. Delgado,J. Delgado Mengual,M. Dellaiera,D. della Volpe,B. De Lotto,L. Del Peral,R. de Menezes,G. De Palma,C. Díaz,A. Di Piano,F. Di Pierro,R. Di Tria,L. Di Venere,R. M. Dominik,D. Dominis Prester,A. Donini,D. Dorner,M. Doro,L. Eisenberger,D. Elsässer,G. Emery,J. Escudero,V. Fallah Ramazani,F. Ferrarotto,A. Fiasson,L. Foffano,F. Frías García-Lago,S. Fröse,Y. Fukazawa,S. Gallozzi,R. Garcia López,S. Garcia Soto,C. Gasbarra,D. Gasparrini,D. Geyer,J. Giesbrecht Paiva,N. Giglietto,F. Giordano,N. Godinovic,T. Gradetzke,R. Grau,D. Green,J. Green,S. Gunji,P. G"unther,J. Hackfeld,D. Hadasch,A. Hahn,M. Hashizume,T. Hassan,K. Hayashi,L. Heckmann,M. Heller,J. Herrera Llorente,K. Hirotani,D. Hoffmann,D. Horns,J. Houles,M. Hrabovsky,D. Hrupec,D. Hui,M. Iarlori,R. Imazawa,T. Inada,Y. Inome,S. Inoue,K. Ioka,M. Iori,T. Itokawa,A. Iuliano,J. Jahanvi,I. Jimenez Martinez,J. Jimenez Quiles,I. Jorge Rodrigo,J. Jurysek,M. Kagaya,O. Kalashev,V. Karas,H. Katagiri,D. Kerszberg,T. Kiyomot,Y. Kobayashi,K. Kohri,A. Kong,P. Kornecki,H. Kubo,J. Kushida,B. Lacave,M. Lainez,G. Lamanna,A. Lamastra,L. Lemoigne,M. Linhoff,S. Lombardi,F. Longo,R. López-Coto,M. López-Moya,A. López-Oramas,S. Loporchio,A. Lorini,J. Lozano Bahilo,F. Lucarelli,H. Luciani,P. L. Luque-Escamilla,P. Majumdar,M. Makariev,M. Mallamaci,D. Mandat,M. Manganaro,D. K. Maniadakis,G. Manicò,K. Mannheim,S. Marchesi,F. Marini,M. Mariotti,P. Marquez,G. Marsella,J. Martí,O. Martinez,G. Martínez,M. Martínez,A. Mas-Aguilar,M. Massa,G. Maurin,D. Mazin,J. Méndez-Gallego,S. Menon,E. Mestre Guillen,S. Micanovic,D. Miceli,T. Miener,J. M. Miranda,R. Mirzoyan,M. Mizote,T. Mizuno,M. Molero Gonzalez,E. Molina,T. Montaruli,A. Moralejo,D. Morcuende,A. Moreno Ramos,A. Morselli,V. Moya,H. Muraishi,S. Nagataki,T. Nakamori,A. Neronov,D. Nieto Castaño,M. Nievas Rosillo,L. Nikolic,K. Nishijima,K. Noda,D. Nosek,V. Novotny,S. Nozaki,M. Ohishi,Y. Ohtani,T. Oka,A. Okumura,R. Orito,L. Orsini,J. Otero-Santos,P. Ottanelli,M. Palatiello,G. Panebianco,D. Paneque,F. R. Pantaleo,R. Paoletti,J. M. Paredes,M. Pech,M. Pecimotika,M. Peresano,F. Pfeifle,E. Pietropaolo,M. Pihet,G. Pirola,C. Plard,F. Podobnik,M. Polo,E. Prandini,M. Prouza,S. Rainò,R. Rando,W. Rhode,M. Ribó,V. Rizi,G. Rodriguez Fernandez,M. D. Rodríguez Frías,P. Romano,A. Roy,A. Ruina,E. Ruiz-Velasco,T. Saito,S. Sakurai,D. A. Sanchez,H. Sano,T. Šarić,Y. Sato,F. G. Saturni,V. Savchenko,F. Schiavone,B. Schleicher,F. Schmuckermaier,J. L. Schubert,F. Schussler,T. Schweizer,M. Seglar Arroyo,T. Siegert,G. Silvestri,A. Simongini,J. Sitarek,V. Sliusar,A. Stamerra,J. Strišković,M. Strzys,Y. Suda,A. Sunny,H. Tajima,M. Takahashi,J. Takata,R. Takeishi,P. H. T. Tam,S. J. Tanaka,D. Tateishi,T. Tavernier,P. Temnikov,Y. Terada,K. Terauchi,T. Terzic,M. Teshima,M. Tluczykont,F. Tokanai,T. Tomura,D. F. Torres,F. Tramonti,P. Travnicek,G. Tripodo,A. Tutone,M. Vacula,J. van Scherpenberg,M. Vázquez Acosta,S. Ventura,S. Vercellone,G. Verna,I. Viale,A. Vigliano,C. F. Vigorito,E. Visentin,V. Vitale,V. Voitsekhovskyi,G. Voutsinas,I. Vovk,T. Vuillaume,R. Walter,L. Wan,M. Will,J. Wójtowicz,T. Yamamoto,R. Yamazaki,Y. Yao,P. K. H. Yeung,T. Yoshida,T. Yoshikoshi,W. Zhang,S. Mereghetti,N. Parmiggiani,C. Vignali,R. Zanin*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Galactic magnetar SGR 1935+2154 has exhibited prolific high-energy (HE) bursting activity in recent years. Investigating its potential tera-electronvolt counterpart could provide insights into the underlying mechanisms of magnetar emission and very high-energy (VHE) processes in extreme astrophysical environments. We aim to search for a possible tera-electronvolt counterpart to both its persistent and sub-second-scale burst emission. We analysed over 25 h of observations from the Large-Sized Telescope prototype (LST-1) of the Cherenkov Telescope Array Observatory (CTAO) during periods of HE activity from SGR 1935+2154 in 2021 and 2022 to search for persistent emission. For bursting emission, we selected and analysed nine 0.1 s time windows centred around known short X-ray bursts, targeting potential sub-second-scale tera-electronvolt counterparts in a low-photon-statistics regime. While no persistent or bursting emission was detected in our search, we establish upper limits for the tera-electronvolt emission of a short magnetar burst simultaneous to its soft gamma-ray flux. Specifically, for the brightest burst in our sample, the ratio between tera-electronvolt and X-ray flux is less than $10^{-3}$. The non-detection of either persistent or bursting tera-electronvolt emission from SGR 1935+2154 suggests that if such components exist, they may occur under specific conditions not covered by our observations. This aligns with theoretical predictions of VHE components in magnetar-powered fast radio bursts and the detection of MeV - GeV emission in giant magnetar flares. These findings underscore the potential of magnetars, fast radio bursts, and other fast transients as promising candidates for future observations in the low-photon-statistics regime with Imaging Atmospheric Cherenkov Telescopes, particularly with the CTAO.

</details>


### [10] [The X-ray/UV Connection in NGC 5548: A Rapidly Varying Corona](https://arxiv.org/abs/2512.05739)
*M. Papoutsis,I. E. Papadakis,C. Panagiotou,E. Kammoun,M. Dovciak*

Main category: astro-ph.HE

TL;DR: This paper challenges the standard X-ray reprocessing scenario by analyzing simultaneous X-ray, UV, and optical data of NGC 5548. The authors propose that X-ray reverberation from a dynamically evolving corona explains the observed variability within 2-5% accuracy, requiring rapid coronal changes on day-scale timescales.


<details>
  <summary>Details</summary>
Motivation: The observed weaker X-ray/UV correlation in AGN variability questions the traditional reprocessing model. The study aims to test an evolving X-ray corona as an alternative explanation using high-quality 2014 NGC 5548 data.

Method: Archival HST (UV) and Swift/XRT (X-ray) light curves from 2014 were analyzed. X-ray reverberation modeling incorporated time-varying corona height, photon index, and power to replicate observed UV/optical variability patterns.

Result: The model fits UV and optical variability within 2-5% accuracy when allowing dynamical corona changes. Best-fit parameters indicate coronal geometry and energetics must vary rapidly (days to weeks) to match observed timescales.

Conclusion: X-ray reverberation from a dynamically evolving corona successfully explains multi-band variability, suggesting coronal dynamics plays a critical role in AGN emission that wasn't accounted for in previous static models.

Abstract: Recent intensive monitoring campaigns of active galactic nuclei (AGN) have provided simultaneous X-ray, UV, and optical data of unprecedented quality. The observations reveal a strong correlation between the UV and optical variability, but a weaker correlation between the X-ray and UV bands, challenging the standard X-ray reprocessing scenario. We revisit the X-ray/UV connection in NGC 5548 by fitting archival 2014 HST and Swift/XRT light curves assuming X-ray reverberation from a dynamically evolving X-ray corona. Our results show that, as long as the corona height, photon index and power vary over time, X-ray reverberation can explain the observed UV and optical variability within 2% and 5%, respectively (on average). The evolution of the best-fit parameters suggests that fast changes in coronal geometry and energetics on a time scale of days are required to explain the observed variability.

</details>


### [11] [SRG/eROSITA-SDSS view on the relation between X-ray and UV emission for quasars](https://arxiv.org/abs/2512.05807)
*S. A. Prokhorenko,S. Yu. Sazonov,M. R. Gilfanov,S. A. Balashev,A. V. Meshcheryakov,A. V. Ivanchik,I. F. Bikmaev,R. A. Sunyaev*

Main category: astro-ph.HE

TL;DR: The study investigates the relationship between X-ray and UV luminosities of quasars using a large sample from eROSITA and SDSS data, confirming previous findings with improved methods accounting for selection effects and intrinsic scatter, revealing dominant X-ray luminosity scatter.


<details>
  <summary>Details</summary>
Motivation: To use quasars as standardizable candles for cosmological studies by establishing a precise L₂keV-L₂₅₀₀Å relation, addressing limitations in prior works.

Method: Analyzed 2414 quasars via cross-matched eROSITA and SDSS DR16Q catalogs, applying a new method considering flux limitations, variability, space density decline, and intrinsic scatter in both luminosities.

Result: Found a linear relation with slope γ=0.69±0.02 and normalization at L₂₅₀₀=30.5 (L₂keV=26.45±0.02), with X-ray intrinsic scatter (σ²=0.066) dominating over UV (σ²=0.001).

Conclusion: The method enhances accuracy in cosmological applications, highlights need to explain X-ray scatter dominance through accretion/observer orientation physics.

Abstract: Motivated by the idea of using quasars as standardizable candles for cosmology, we examine the relation between X-ray (at 2 keV, $L_{\rm 2keV}$) and ultraviolet (at 2500 Angstrom, $L_{\rm 2500}$) monochromatic luminosities of quasars using a sample of 2414 X-ray sources from the SRG/eROSITA all-sky survey cross-matched with the Sloan Digital Sky Survey data release 16 quasar catalogue (SDSS DR16Q), at redshifts between 0.5 and 2.5. These objects are bright both in X-rays and in the optical, so that the sample is characterized by nearly 100% statistical completeness. We have developed a new method for determining the $L_{\rm 2keV}-L_{\rm 2500}$ relation, which consistently takes into account (i) X-ray and UV flux limited object selection, (ii) X-ray and UV variability of quasars, and (iii) the decreasing space density of quasars with increasing luminosity. Assuming a linear relation between $l_{\rm X}\equiv\log(L_{\rm 2keV}/[{\rm erg\,s^{-1}\,Hz^{-1}}])$ and $l_{\rm UV}\equiv\log(L_{\rm 2500}/[{\rm erg\,s^{-1}\,Hz^{-1}}])$, we find the slope, $γ=0.69\pm0.02$ (hereafter all uncertainties are quoted at the 68% confidence level), and normalization, $l_{\rm X}=26.45\pm0.02$ at $l_{\rm UV}=30.5$, of the $L_{\rm 2keV}$ ($L_{\rm 2500}$) dependence. These values are not substantially different from the results of previous studies. A key novel aspect of our work is allowance for intrinsic scatter (which adds to the dispersion induced by quasar variability and flux measurement uncertainties) of the $L_{\rm 2keV}-L_{\rm 2500}$ relation in both variables, i.e. in X-ray and UV luminosity. The intrinsic X-ray scatter ($σ^2_{\rm intX}=0.066\pm0.005$) strongly dominates over the UV one ($σ^2_{\rm intUV}=0.001^{+0.003}_{-0.001}$). Further studies should seek to explain this behaviour in terms of accretion onto supermassive black holes and orientation of quasars with respect to the observer.

</details>


### [12] [Differentially rotating neutron stars with dark matter cores](https://arxiv.org/abs/2512.05898)
*Lorenzo Cipriani,Violetta Sagun,Kalin V. Staykov,Daniela D. Doneva,Stoytcho S. Yazadjiev*

Main category: astro-ph.HE

TL;DR: The paper explores how dark matter affects the structure and rotational dynamics of neutron star remnants from binary mergers by modeling two gravitationally coupled fluids: baryonic matter and a self-interacting dark matter bosonic condensate.


<details>
  <summary>Details</summary>
Motivation: To understand how dark matter accumulation influences neutron star structure, binary mergers, and the collapse dynamics of hypermassive remnants, particularly through its effect on differential rotation which delays collapse.

Method: Extended the RNS numerical code to simulate two gravitationally coupled fluids (realistic nuclear matter and self-interacting dark matter) in differential rotation, constructing equilibrium sequences using a representative rotation law.

Result: Provided foundational models to analyze dark matter's impact on global properties and rotational dynamics of neutron star merger remnants.

Conclusion: The framework establishes a method to study dark matter's role in neutron star systems, crucial for interpreting astrophysical observations and gravitational wave signals from mergers.

Abstract: Dark matter is expected to accumulate inside neutron stars, modifying the structure of isolated stars and influencing both the dynamics of binary mergers and the evolution of the resulting hypermassive remnants. Since differential rotation is the primary mechanism delaying the collapse of these remnants, understanding its behavior is crucial when assessing the impact of an embedded dark component. In this work, we extend the numerical code RNS to describe two gravitationally coupled fluids in differential rotation, with baryonic matter modeled by a realistic nuclear equation of state and dark matter represented as a self-interacting bosonic condensate. Within this framework, we construct equilibrium sequences for a representative differential rotation law, providing a basis to explore how dark matter may influence the global properties and rotational dynamics of binary neutron star remnants.

</details>


### [13] [Hadronic Emissions from the Microquasar V4641 Sgr, SS433, and its implications in the Diffuse Galactic Emission](https://arxiv.org/abs/2512.05839)
*Basanti Paul,Abhijit Roy,Jagdish C. Joshi,Debanjan Bose*

Main category: astro-ph.HE

TL;DR: Microquasars (MQs) can be Galactic PeVatrons, accelerating protons to PeV energies, as shown byTeV-PeV gamma-ray detections. The hadronic model explains observed data with hard proton spectra and predicts detectable neutrino fluxes from V4641 Sgr. A population of ~14 MQs contribute significantly to the diffuse very-high-energy emission, especially in the outer Galaxy.


<details>
  <summary>Details</summary>
Motivation: To investigate the hadronic origin of observed VHE/UHE gamma-rays from MQs like V4641 Sgr and SS433, confirm their role as Galactic PeVatrons, estimate required physical parameters, and assess their contribution to diffuse gamma-ray flux and neutrino signals.

Method: Developed a hadronic model where gamma-rays arise from proton-stellar wind interactions. Fitted model to observational data to constrain parameters such as jet power fraction, proton spectral index, maximum energy (~1-5 PeV), and jet Lorentz factor. Simulated neutrino fluxes and modeled Galactic MQ population contributions.

Result: Best-fit model parameters align with hard proton spectra (1.84-2.44). Estimated detectable neutrino fluxes from V4641 Sgr by next-gen telescopes. A synthetic MQ population (~14) needed to explain LHAASO data above 100 TeV; MQs dominate outer Galaxy TeV-PeV emission.

Conclusion: MQs are efficient PeV proton accelerators and significant Galactic PeVatron contributors. They represent key multimessenger sources, with detectable neutrinos and population-scale impacts on the diffuse gamma-ray sky.

Abstract: Microquasars (MQs) are Galactic binary systems, consisting of a star and a compact object, a neutron star or a stellar mass black hole, which accretes matter from its companion star and gives rise to relativistic jets. Recent detection of very-high-energy (VHE; $E \gtrsim 100,\text{GeV}$) and ultra-high-energy (UHE; $E \gtrsim 100,\text{TeV}$) gamma-rays by LHAASO, HAWC and HESS from the MQ V4641 Sgr and SS 433 suggests them as Galactic PeVatrons. In this work, we studied a hadronic origin of the observed TeV-PeV gamma-ray emission from these MQs. We considered the hadronic scenario where the gamma-rays are produced by the interaction of relativistic protons in the MQ jet with the stellar wind. We fitted our model with observed data and constrained physical parameters like the hadronic jet power fraction, the proton spectral index, the maximum proton energy and the jet bulk Lorentz factor. Our best-fit model shows hard proton spectra ($1.84-2.44$) and maximum proton energies between 1 and 5 PeV. We also estimated the all-flavor neutrino fluxes corresponding to the gamma-ray fluxes from the hadronic model and found that V4641 sgr can be detected by next-generation neutrino telescopes like KM3NeT-ARCA and TRIDENT. Furthermore, we modeled a synthetic population of Galactic MQs and estimated their contribution to the diffuse TeV-PeV gamma-ray flux. For the inner Galaxy PSR contribution dominates in the range 10-100 TeV, and above 100 TeV diffused cosmic ray interactions with the molecular clouds is most dominant. We find that a population $\sim 14$ MQs is required to explain the LHAASO data above 100 TeV. For the outer Galaxy, we show that MQs are the dominant class of sources, and we constrain their population $\sim$14. Our findings strongly suggest that MQs are efficient particle accelerators, contributing to Galactic PeVatrons and potential multimessenger sources in our Galaxy.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [14] [Ruminations Upon the Modeling of X-ray Foregrounds, Backgrounds and Faint Sources](https://arxiv.org/abs/2512.05405)
*Adam B. Mantz,Anthony M. Flores,Taweewat Somboonpanyakul,Steven W. Allen,R. Glenn Morris,Abigail Y. Pan,Haley R. Stueber*

Main category: astro-ph.IM

TL;DR: This paper presents a forward-modeling strategy to improve analysis of X-ray observations from Chandra and XMM-Newton telescopes, addressing foreground/background signals, systematic uncertainties, and instrumental miscalibrations. It shows significant benefits for high-redshift, low-surface-brightness galaxy clusters.


<details>
  <summary>Details</summary>
Motivation: The motivation is to maximize information extraction from faint, diffuse X-ray sources like galaxy clusters by addressing foreground/background contamination and instrumental artifacts. This is critical for current missions and future telescopes facing similar observational challenges.

Method: The method involves a forward-modeling approach that statistically accounts for Galactic soft X-ray emission, cosmic X-ray background, and instrument-specific backgrounds. It avoids data binning and allows for marginalization over systematic uncertainties through Bayesian frameworks. A correction for Chandra ACIS detector miscalibration is also introduced.

Result: Results show modest improvements for bright clusters but substantial gains for high-redshift, low-surface-brightness clusters. The time-dependent Chandra calibration correction improves data accuracy in archival galaxy cluster observations.

Conclusion: The approach enhances detection and measurement capabilities for faint X-ray sources, enabling more accurate cosmological studies and preparations for future X-ray missions. It underscores the importance of model-driven analysis over traditional methods for precision astronomy.

Abstract: With the goal of extracting as much information as possible from Chandra and XMM-Newton observations of faint, diffuse sources such as galaxy clusters, as well as those of future X-ray telescopes, we present a strategy for forward modeling all the foreground and background signals present in these data. This work leverages widespread efforts to understand the soft X-ray emission from the Galaxy, as well as the cosmic X-ray background and instrument-specific, particle-induced backgrounds. Statistically, a forward model of the foregrounds and backgrounds is preferable to alternatives because it requires no binning of the data, and allows straightforward marginalization over systematic uncertainties. We apply these methods to several galaxy clusters at intermediate-to-high redshifts, spanning a range of masses and morphologies, using Chandra and/or XMM-Newton data. Our results suggest a modest improvement even for relatively bright clusters at these redshifts, and more substantial advantages in the high-redshift, low-surface-brightness regime. We also discuss and provide a simple correction for a time-dependent miscalibration of the Chandra ACIS detectors identified in archival galaxy cluster data.

</details>


### [15] [Commissioning an Inexpensive Off-the-shelf Spectrograph for Radial-Velocity Studies](https://arxiv.org/abs/2512.05601)
*Lukas Stock,Andreas Schrimpf*

Main category: astro-ph.IM

TL;DR: The paper introduces a cost-effective setup for an off-the-shelf spectrograph capable of high stability and resolution, suitable for radial velocity measurements of binary stars and potentially detecting exoplanets.


<details>
  <summary>Details</summary>
Motivation: To provide an affordable yet reliable spectrograph option for astronomical观测, enabling radial velocity studies for binary stars and exoplanet detection without requiring expensive custom equipment.

Method: Utilizes commercially available components to assemble a spectrograph, optimizing for stability and resolution through careful calibration and setup.

Result: The setup achieves sufficient performance for radial velocity determinations, demonstrating feasibility for amateur or low-budget observatories to contribute to astrophysical research.

Conclusion: The method opens access to precision spectroscopy for smaller institutions, lowering barriers to participation in exoplanet and stellar dynamics research.

Abstract: We present a way to set up an inexpensive out of the shelf spectrograph at a local observatory. Stability and resolution of the spectrograph are high enough for radial velocity determination of binary stars or determination of stellar characteristics. Even some exoplanets might be detectable via the radial velocity method.

</details>


### [16] [Euclid Quick Data Release (Q1). From simulations to sky: Advancing machine-learning lens detection with real Euclid data](https://arxiv.org/abs/2512.05899)
*Euclid Collaboration,N. E. P. Lines,T. E. Collett,P. Holloway,K. Rojas,S. Schuldt,R. B. Metcalf,T. Li,A. Verma,G. Despali,F. Courbin,R. Gavazzi,C. Tortora,B. Clément,N. Aghanim,B. Altieri,L. Amendola,S. Andreon,N. Auricchio,C. Baccigalupi,M. Baldi,A. Balestra,S. Bardelli,P. Battaglia,A. Biviano,E. Branchini,M. Brescia,S. Camera,G. Cañas-Herrera,V. Capobianco,C. Carbone,J. Carretero,M. Castellano,G. Castignani,S. Cavuoti,A. Cimatti,C. Colodro-Conde,G. Congedo,C. J. Conselice,L. Conversi,Y. Copin,H. M. Courtois,M. Cropper,H. Degaudenzi,G. De Lucia,H. Dole,F. Dubath,X. Dupac,S. Dusini,A. Ealet,S. Escoffier,M. Farina,R. Farinelli,F. Faustini,S. Ferriol,F. Finelli,M. Frailis,E. Franceschi,M. Fumana,S. Galeotta,K. George,B. Gillis,C. Giocoli,P. Gómez-Alvarez,J. Gracia-Carpio,A. Grazian,F. Grupp,S. V. H. Haugan,W. Holmes,I. M. Hook,F. Hormuth,A. Hornstrup,K. Jahnke,M. Jhabvala,B. Joachimi,E. Keihänen,S. Kermiche,A. Kiessling,B. Kubik,M. Kümmel,M. Kunz,H. Kurki-Suonio,A. M. C. Le Brun,S. Ligori,P. B. Lilje,V. Lindholm,I. Lloro,G. Mainetti,D. Maino,E. Maiorano,O. Mansutti,S. Marcin,O. Marggraf,M. Martinelli,N. Martinet,F. Marulli,R. J. Massey,E. Medinaceli,S. Mei,M. Melchior,Y. Mellier,M. Meneghetti,E. Merlin,G. Meylan,A. Mora,M. Moresco,L. Moscardini,R. Nakajima,C. Neissner,S. -M. Niemi,J. W. Nightingale,C. Padilla,S. Paltani,F. Pasian,K. Pedersen,W. J. Percival,V. Pettorino,S. Pires,G. Polenta,M. Poncet,L. A. Popa,L. Pozzetti,F. Raison,A. Renzi,J. Rhodes,G. Riccio,E. Romelli,M. Roncarelli,C. Rosset,R. Saglia,Z. Sakr,A. G. Sánchez,D. Sapone,B. Sartoris,J. A. Schewtschenko,P. Schneider,T. Schrabback,A. Secroun,G. Seidel,S. Serrano,C. Sirignano,G. Sirri,L. Stanco,J. Steinwagner,P. Tallada-Crespí,A. N. Taylor,I. Tereno,N. Tessore,S. Toft,R. Toledo-Moreo,F. Torradeflot,I. Tutusaus,J. Valiviita,T. Vassallo,A. Veropalumbo,Y. Wang,J. Weller,A. Zacchei,G. Zamorani,F. M. Zerbi,E. Zucca,M. Ballardini,M. Bolzonella,E. Bozzo,C. Burigana,R. Cabanac,M. Calabrese,A. Cappi,T. Castro,J. A. Escartin Vigo,L. Gabarra,J. García-Bellido,V. Gautard,S. Hemmati,M. Huertas-Company,J. Macias-Perez,R. Maoli,J. Martín-Fleitas,M. Maturi,N. Mauri,P. Monaco,M. Pöntinen,C. Porciani,I. Risso,V. Scottez,M. Sereno,M. Tenti,M. Tucci,M. Viel,M. Wiesmann,Y. Akrami,I. T. Andika,G. Angora,S. Anselmi,M. Archidiacono,F. Atrio-Barandela,E. Aubourg,L. Bazzanini,D. Bertacca,M. Bethermin,F. Beutler,A. Blanchard,L. Blot,M. Bonici,S. Borgani,M. L. Brown,S. Bruton,A. Calabro,B. Camacho Quevedo,F. Caro,C. S. Carvalho,F. Cogato,S. Conseil,A. R. Cooray,O. Cucciati,S. Davini,F. De Paolis,G. Desprez,A. Díaz-Sánchez,S. Di Domizio,J. M. Diego,P. -A. Duc,V. Duret,M. Y. Elkhashab,A. Enia,Y. Fang,P. G. Ferreira,A. Finoguenov,A. Fontana,A. Franco,K. Ganga,T. Gasparetto,E. Gaztanaga,F. Giacomini,F. Gianotti,G. Gozaliasl,A. Gruppuso,M. Guidi,C. M. Gutierrez,A. Hall,H. Hildebrandt,J. Hjorth,J. J. E. Kajava,Y. Kang,V. Kansal,D. Karagiannis,K. Kiiveri,J. Kim,C. C. Kirkpatrick,S. Kruk,M. Lattanzi,L. Legrand,F. Lepori,G. Leroy,G. F. Lesci,J. Lesgourgues,T. I. Liaudat,M. Magliocchetti,A. Manjón-García,F. Mannucci,C. J. A. P. Martins,L. Maurin,M. Miluzio,A. Montoro,C. Moretti,G. Morgante,S. Nadathur,K. Naidoo,P. Natoli,S. Nesseris,D. Paoletti,F. Passalacqua,K. Paterson,L. Patrizii,A. Pisani,D. Potter,G. W. Pratt,S. Quai,M. Radovich,W. Roster,S. Sacquegna,M. Sahlén,D. B. Sanders,E. Sarpa,A. Schneider,D. Sciotti,E. Sellentin,L. C. Smith,J. G. Sorce,K. Tanidis,C. Tao,F. Tarsitano,G. Testera,R. Teyssier,S. Tosi,A. Troja,A. Venhola,D. Vergani,G. Vernardos,G. Verza,S. Vinciguerra,M. Walmsley,N. A. Walton,A. H. Wright*

Main category: astro-ph.IM

TL;DR: Combining simulated and real Euclid data improves machine learning performance for identifying gravitational lenses.


<details>
  <summary>Details</summary>
Motivation: To address the performance gap between machine learning models trained on simulations and their application to real observational data in lens discovery.

Method: Trained machine learning models on simulations only, then augmented with real Euclid lenses and diverse non-lenses from Q1 data, comparing performance metrics.

Result: Hybrid training increased real data completeness by 25-30% with 24% purity, showing that real data inclusion enhances performance. 20% improvement from real lenses and 5-10% from diverse non-lenses.

Conclusion: A hybrid approach integrating simulations and real data maximizes lens discovery efficiency, setting a methodology for future surveys like Euclid DR1 and LSST.

Abstract: In the era of large-scale surveys like Euclid, machine learning has become an essential tool for identifying rare yet scientifically valuable objects, such as strong gravitational lenses. However, supervised machine-learning approaches require large quantities of labelled examples to train on, and the limited number of known strong lenses has lead to a reliance on simulations for training. A well-known challenge is that machine-learning models trained on one data domain often underperform when applied to a different domain: in the context of lens finding, this means that strong performance on simulated lenses does not necessarily translate into equally good performance on real observations. In Euclid's Quick Data Release 1 (Q1), covering 63 deg2, 500 strong lens candidates were discovered through a synergy of machine learning, citizen science, and expert visual inspection. These discoveries now allow us to quantify this performance gap and investigate the impact of training on real data. We find that a network trained only on simulations recovers up to 92% of simulated lenses with 100% purity, but only achieves 50% completeness with 24% purity on real Euclid data. By augmenting training data with real Euclid lenses and non-lenses, completeness improves by 25-30% in terms of the expected yield of discoverable lenses in Euclid DR1 and the full Euclid Wide Survey. Roughly 20% of this improvement comes from the inclusion of real lenses in the training data, while 5-10% comes from exposure to a more diverse set of non-lenses and false-positives from Q1. We show that the most effective lens-finding strategy for real-world performance combines the diversity of simulations with the fidelity of real lenses. This hybrid approach establishes a clear methodology for maximising lens discoveries in future data releases from Euclid, and will likely also be applicable to other surveys such as LSST.

</details>


### [17] [Removing correlated noise stripes from the Nancy Grace Roman Space Telescope survey images](https://arxiv.org/abs/2512.05949)
*Katherine Laliotis,Christopher M. Hirata,Emily Macbeth,Kaili Cao*

Main category: astro-ph.IM

TL;DR: This paper introduces imDestripe, a Python tool designed to mitigate correlated read noise in Roman WFI images through the use of multiple roll angles and linear algebra, significantly reducing stripe noise and improving weak lensing measurements.


<details>
  <summary>Details</summary>
Motivation: Weak lensing requires high-precision measurements, but the Roman WFI's correlated read noise, especially 1/f noise causing horizontal banding, threatens accuracy even after standard corrections. imDestripe addresses this critical systematic bias.

Method: imDestripe employs Roman's varying telescope roll angles and linear algebra to model and subtract noise components. It uses real noise data from ground tests combined with simulated astronomical scenes for validation.

Result: Testing with hybrid simulations showed a 10-30x reduction in noise power spectra on large scales, effectively suppressing the banding artifact. This enhancement brings measurements closer to required precision levels.

Conclusion: imDestripe successfully reduces problematic noise, validating its role in future WFI pipeline integration. Further development will optimize its performance for upcoming missions relying on weak lensing precision.

Abstract: Weak gravitational lensing has emerged as a powerful tool for investigating the matter distribution in the Universe and how it has evolved over cosmic time. The Wide Field Instrument (WFI) on the Nancy Grace Roman Space Telescope (Roman) will deliver some of the highest precision measurements of weak lensing ever made. Since weak lensing is based on statistics of faint sources, it can be biased by even tiny instrument systematics, including correlated read noise. Previous works have shown the infrared detectors used in the Roman WFI show correlations in their noise fields at a level significant for weak lensing measurements, even after application of standard reference pixel corrections; of particular concern is 1/f noise, which appears as horizontal banding in the detector frame. In this paper, we present imDestripe: a new Python module utilizing the multiple roll angles in Roman's observing strategy and linear algebra techniques to remove correlated noise stripes from observed images. We test imDestripe in a hybrid simulation by combining real noise realizations (from darks taken during ground testing) with simulated images of the astronomical scene, and find that the power spectrum of the banding can be suppressed by factors of 10--30 on large scales. We briefly discuss plans for further development of imDestripe in the context of the WFI pipeline.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [18] [Radiative Semileptonic Decays of Beautiful Hadrons](https://arxiv.org/abs/2512.05186)
*Federico Cima,Michele Papucci*

Main category: hep-ph

TL;DR: The paper uses HQET to predict matrix elements for radiative semileptonic decays of beauty hadrons, focusing on specific transitions and showing that form factors are determined by non-radiative Isgur-Wise functions and magnetic dipole moments in certain kinematic regions.


<details>
  <summary>Details</summary>
Motivation: To provide theoretical predictions for future experiments at Belle II and LHCb by analyzing hadronic matrix elements relevant to radiative semileptonic decays, leveraging HQET's symmetries to reduce form factor complexity.

Method: Applied Heavy Quark Effective Theory (HQET) symmetries to constrain and determine the structure-dependent form factors in radiative semileptonic decay processes for Lambda(b) -> Lambda(c), Lambda(*)(c1), and B -> D(*), D** transitions. Analyzed both soft and sub-leading soft kinematic regions using non-radiative Isgur-Wise functions and magnetic dipole moments of heavy hadrons.

Result: All form factors in the specified decays are completely determined in the soft and sub-leading soft regions by known non-radiative quantities and magnetic moments. Higher-order correction structures were also outlined.

Conclusion: HQET provides a powerful framework for predicting decay observables with minimal form factors, aiding experimental precision at upcoming facilities like Belle II and LHCb. Future work should explore higher-order effects and experimental validation.

Abstract: We derive predictions for the hadronic matrix elements of radiative semileptonic decays of beautiful hadrons within Heavy Quark Effective Theory (HQET), relevant for future measurements at Belle II and LHCb. Our study considers Lambda(b) -> Lambda(c), Lambda(*)(c1) and B -> D(*), D** transitions. The symmetries of HQET highly constrain the number of structure-dependent form factors in all cases. In the soft and sub-leading soft regions, all the form factors are fully determined in terms of non-radiative Isgur-Wise functions and the magnetic dipole moments of the heavy hadrons. The structure of higher order corrections is also briefly discussed.

</details>


### [19] [Thermal Damping of Mass-Modulating Scalars](https://arxiv.org/abs/2512.05188)
*Abhishek Banerjee,Ngan H. Nguyen,Erwin H. Tanin*

Main category: hep-ph

TL;DR: This paper investigates the role of thermal damping effects on scalar field cosmological evolution, particularly in scenarios where the scalar field oscillates rapidly compared to the thermal bath's relaxation time. The authors derive general expressions for thermal damping rates for scalars coupled to neutrinos, gluons, and WIMPs, showing their significance in specific parameter regions. They also apply these findings to QCD axion models, highlighting cases where thermal damping dominates over Hubble damping. This work extends previous analyses by considering non-slow oscillations and demonstrates the necessity of accounting for thermal effects in cosmological scalar field dynamics.


<details>
  <summary>Details</summary>
Motivation: To address the neglected role of non-gravitational thermal damping in scalar field cosmology, which could be the dominant dissipative effect. Previous studies often overlooked scenarios where scalar field oscillations are rapid compared to thermalization rates, limiting the applicability of existing damping rate estimates.

Method: The authors derive approximate yet general formulas for thermal damping rates for scalar fields interacting with a primordial thermal bath. They consider three scenarios: linear coupling to neutrinos, quadratic coupling to gluons, and linear coupling to WIMPs. The approach includes extending earlier work to include non-slow oscillations (faster than thermal bath relaxation times). For QCD axions, they analyze the implications of their specific couplings.

Result: Thermal damping can dominate over Hubble damping in certain parameter spaces, especially when scalar oscillation frequencies are high. For example, neutrino-coupled scalars show significant thermal damping at early times, gluon-coupled scalars exhibit stronger damping during the quark-gluon plasma phase, and WIMP-coupled scalars have appreciable effects in high-coupling regions. QCD axions also show non-negligible thermal damping in specific phases of their evolution.

Conclusion: Thermal damping must be considered alongside Hubble damping in cosmological scalar field studies. The derived rates provide a tool to accurately model scalar field evolution in early universe scenarios, particularly when rapid oscillations occur. This challenges assumptions in prior models and opens new parameter regions for cosmological model exploration and observational testing.

Abstract: The cosmological evolution of a scalar field is shaped by Hubble damping. Any non-gravitational couplings of the scalar with the primordial thermal bath generically contribute additional damping. Although rarely considered, such thermal damping could be the dominant dissipative effect. We derive approximate but highly general thermal-damping rates of scalar fields that modulate the masses of thermally populated particles. We extend previous results to cover cases of particular phenomenological interest where the scalar background oscillates sinusoidally but not necessarily slowly compared to the thermalization rates of the primordial bath. Based on these results, we estimate the thermal damping of scalars coupled to neutrinos linearly, to gluons quadratically, and to WIMPs linearly, and demonstrate its importance in certain parameter space of these models. We also estimate the thermal damping rates in models of QCD axion.

</details>


### [20] [CoLoRFulNNLO for hadron collisions: regularizing initial-state double real emissions](https://arxiv.org/abs/2512.05192)
*Vittorio Del Duca,Gábor Somogyi,Francesco Tramontano*

Main category: hep-ph

TL;DR: The paper extends the CoLoRFulNNLO subtraction scheme for QCD calculations to color-singlet production in hadron collisions, providing explicit momentum mappings, double-real counterterms, and validations.


<details>
  <summary>Details</summary>
Motivation: The motivation is to enable precise predictions for color-singlet production processes in hadron collisions by extending subtraction schemes to handle necessary infrared-safety and computational efficiency.

Method: The method involves systematically deriving double-real counterterms from QCD matrix element infrared limits, ensuring analytic integrability. They constructed counter-events with minimized numbers to maintain the local and efficient CoLoRFulNNLO framework.

Result: They successfully implemented the counterterms in NNLOCAL Monte Carlo, validated through arbitrary-precision algebra, and provided representative results, confirming the scheme works for color-singlet processes.

Conclusion: The developed counterterms form a self-contained part of CoLoRFulNNLO, applicable to general hadronic processes, enabling accurate and efficient next-to-next-to-leading order calculations in QCD.

Abstract: We present the extension of the completely local subtraction scheme CoLoRFulNNLO to color-singlet production in hadron collisions. We provide explicit momentum mappings and the complete set of double-real counterterms required for this class of processes. The counterterms are systematically derived from the known infrared limit formulae of QCD matrix elements, and particular care has been taken to ensure their analytic integrability. The resulting construction involves a relatively small number of counter-events, preserving the locality and efficiency of the scheme. All formulae have been implemented within the publicly available NNLOCAL Monte Carlo program, and we explicitly validate all IR limits using arbitrary-precision computer algebra and present representative results. The counterterms presented here constitute a self-contained subset applicable to general hadronic processes within the CoLoRFulNNLO approach.

</details>


### [21] [Jet Charge with Global Event Shapes: Probing Quark Flavor Dynamics](https://arxiv.org/abs/2512.05199)
*Yang-Ting Chien,Sonny Mantry*

Main category: hep-ph

TL;DR: The paper proposes using jet charge measurements within the 1-Jettiness framework for quark flavor separation and studying hadronization in DIS processes, supported by a new factorization theorem and simulations targeting HERA and EIC applications.


<details>
  <summary>Details</summary>
Motivation: To advance understanding of quark flavor dynamics in nucleon structure and hadronization processes by introducing a novel observable (1-Jettiness jet charge) that enhances quark flavor separation and provides insights into final-state dynamics.

Method: The authors derive a factorization theorem for simultaneous measurements of τ₁ (1-Jettiness) and jet charge Q in the resummation region. They introduce a charged jet function to generalize standard jet functions, enabling extraction from N-jettiness and thrust data. Simulations demonstrate the observable's sensitivity to quark flavor and hadronization effects.

Result: The approach allows enhanced separation of initial-state polarized/unpolarized PDFs via τ₁-binned jet charge and probes final-state hadronization through Q-binned τ₁ distributions. Simulations validate the observable's potential for studying quark dynamics with existing HERA data and future EIC experiments.

Conclusion: The proposed 1-Jettiness jet charge observable is a powerful tool for disentangling quark flavor contributions in DIS processes and offers a pathway to constrain hadronization models, underscoring its utility in upcoming collider analyses.

Abstract: We propose measuring the jet electric charge of jet regions, defined within the framework of global event shapes, as a probe of quark flavor dynamics within the nucleon and the hadronization process. In particular, we consider a measurement of the jet region charge while simultaneously keeping track of the energy flow throughout the event, as characterized by the global event shape. As a concrete example, we focus on the measurement of the 1-Jettiness jet charge ($Q$), the jet charge of the jet region ($J$) defined within the framework of the 1-Jettiness global event shape ($τ_1$) for the Deep Inelastic Scattering (DIS) process, $e^- + p \to e^- + J + X$, with unpolarized or longitudinally polarized protons. The 1-Jettiness distribution, binned according to jet charge, allows for enhanced quark flavor separation of the initial state unpolarized or polarized PDFs. On the other hand, the jet charge distribution binned by 1-Jettiness can serve as a probe of quark flavor dynamics in the final state hadronization process. We derive a factorization theorem for simultaneous measurements of $τ_1$ and $Q$ in the resummation region, $τ_1 \ll P_{J_T}$, where $P_{J_T}$ denotes the transverse momentum of the jet region. The factorization theorem contains a new universal charged jet function, generalizing the standard jet function to include a jet charge measurement. Therefore these universal functions can be extracted from a global analysis of N-jettiness and thrust at $e^+e^-$ colliders. We provide simulation studies to demonstrate the sensitivity of the 1-Jettiness jet charge observable to quark flavor dynamics in nucleon structure and explore the possibility of probing the final state hadronization process. This observable is well-suited for applications in existing HERA data and the future Electron-Ion Collider (EIC).

</details>


### [22] [Illuminating sequential freeze-in dark matter with dark photon signal at the CERN SHiP experiment](https://arxiv.org/abs/2512.05380)
*Xinyue Yin,Sibo Zheng*

Main category: hep-ph

TL;DR: The paper analyzes sequential freeze-in dark matter through dark photon mediator signals, constraining parameters to specific ranges and highlighting model viability via SHiP experiment.


<details>
  <summary>Details</summary>
Motivation: To explore observable signatures of two-field freeze-in dark matter scenarios, particularly addressing limitations of single-field models in direct detection, collider, or fixed-target experiments.

Method: Examines dark photon mediator signals with masses from $10^{-2}$ to $10$ GeV, considering proton bremsstrahlung processes under vector meson/dipole dominance assumptions. Uses relic abundance and out-of-equilibrium conditions to constrain parameters.

Result: Determines dark charge $e'\sim 1.3\times 10^{-12}$, limits mixing parameter $\epsilon$ between $10^{-11}$ and $10^{-7.5}$, with SHiP excluding values ≥$10^{-8.5}$ (5 years) or $10^{-7.9}$ (15 years), leaving only $\epsilon\sim10^{-11}$ viable.

Conclusion: The narrow surviving parameter space necessitates alternative testing methods, emphasizing SHiP's role in constraining dark photon models and guiding future dark matter searches.

Abstract: Single-field freeze-in dark matter barely leaves observable footprints in dark matter direct detection, collider or fixed-target experiments, which can be altered in the two-field context. In this work, we consider sequential freeze-in dark matter through signals of dark photon mediator with a mass range of $m_{A'}\sim 10^{-2}-10$ GeV covered by the proposed SHiP experiment. We show that the dark charge is fixed to be $e'\sim 1.3\times 10^{-12}$ and the mixing parameter is restricted to $10^{-11}\leq ε< 10^{-8}-10^{-7.5}$, as a result of the out-of-equilibrium condition of dark photon and the observed relic abundance of dark matter. Within this $ε$ region, the 5(15)-year data of proton bremsstrahlung process for the dark photon, assuming vector meson (dipole) dominance, excludes $ε\geq 10^{-8.5} (10^{-7.9})$ at 90\% confidence level, implying only a narrow region of $ε$ close to $\sim 10^{-11}$ left for alternative tests.

</details>


### [23] [What can we learn from the radiative decays of the $D_{s1}(2460)$ meson?](https://arxiv.org/abs/2512.05476)
*Hai-Long Fu,Feng-Kun Guo,Christoph Hanhart,Alexey Nefediev*

Main category: hep-ph

TL;DR: The paper investigates radiative decay processes of D_{s1}(2460) mesons to study the nature of D^{*}_{s0}(2317) and D_{s1}(2460) mesons through their branching fraction ratios.


<details>
  <summary>Details</summary>
Motivation: To probe the internal structure and confirm the nature of the D^{*}_{s0}(2317) and D_{s1}(2460) mesons by analyzing their radiative decay branching ratios.

Method: The study examines specific radiative decay channels (D_{s1}(2460) → γD^{*}_{s0}(2317) and D_{s1}(2460) → γD^0K^+/γD^+K^0) and proposes that simultaneous experimental measurement or constraints on the ratio of their branching fractions can reveal meson properties.

Result: The analysis suggests that measuring these decay processes or their branching fraction ratios would provide insights into the nature of the mesons, potentially confirming their quark compositions or bound state characteristics.

Conclusion: Experimental constraints on the branching ratios of these radiative decays are crucial for understanding the nature of D^{*}_{s0}(2317) and D_{s1}(2460) mesons, emphasizing the need for future high-precision measurements in particle physics experiments.

Abstract: We study the radiative decays $D_{s1}(2460)\toγD^{*}_{s0}(2317)$ and $D_{s1}(2460)\to γD^0K^+/γD^+K^0$ and argue that their simultaneous experimental measurement, or at least a constraint on the ratio of the corresponding branching fractions, can allow one to probe the nature of the $D^{*}_{s0}(2317)$ and $D_{s1}(2460)$ mesons.

</details>


### [24] [Neutrino masses, $δ_\mathrm{PMNS}$, and $m_{ββ}$ in SO(10)](https://arxiv.org/abs/2512.05562)
*Shaikh Saad,Qaisar Shafi*

Main category: hep-ph

TL;DR: The paper investigates the leptonic sector of a supersymmetric SO(10) model with SUSY breaking up to 10 TeV, focusing on non-thermal leptogenesis. It predicts neutrino masses (m₁ ≈5 meV), right-handed neutrino masses (M₁≈10⁹ GeV, M₂,M₃≈10¹³ GeV), and CP phase δ_PMNS (≈235°, broadened to 100°-300°). Results align with JUNO's reactor neutrino data. Inflation parameters (mχ≈7×10⁹ GeV, TRH≈4×10⁶ GeV) are also estimated.


<details>
  <summary>Details</summary>
Motivation: To explain the observed baryon asymmetry via non-thermal leptogenesis in the context of SUSY SO(10) models, which is compatible with hybrid inflation scenarios. The work addresses the need for consistent predictions of neutrino parameters and cosmological constraints.

Method: Numerical and statistical analysis of the leptonic sector with non-thermal leptogenesis, incorporating hybrid inflation models. Uses parameter fits constrained by JUNO's latest reactor neutrino oscillation data (∆m²₁₂- sin²θ₁₂).

Result: Predicted neutrino masses (6 total: 3 SM, 3 RH), δ_PMNS range (100°-300°), m_ββ≈0.18 meV. Alignment with JUNO results (improving precision by 1.6x). Estimated inflaton mass and reheating temperature. Models show robustness under parameter variations.

Conclusion: Non-thermal leptogenesis in SUSY SO(10) successfully explains baryogenesis and predicts testable neutrino/early universe parameters. Future experiments like JUNO can further validate or constrain the model's predictions.

Abstract: We explore the leptonic sector of a recently proposed supersymmetric SO(10) model with supersymmetry breaking in the 3-10 TeV range. A new ingredient in this work is the requirement that the observed baryon asymmetry is explained via non-thermal leptogenesis, which can be realized in a large class of supersymmetric hybrid inflation models including SO(10). We provide estimates for the masses of the three Standard Model neutrinos (with the lightest mass $m_1\approx 5$ meV) as well as the three right-handed neutrinos ($M_1\approx 10^9$ GeV and $M_{2,3}\approx 10^{13}$ GeV). The best fit estimate for the leptonic CP violating parameter $δ_\mathrm{PMNS}\approx 235^\circ$, and the value of the neutrinoless double beta decay mass parameter $m_{ββ}\approx 0.18$ meV. A numerical analysis broadens the predicted range for $δ_\mathrm{PMNS}$ ($100^\circ$-$300^\circ$), but leaves largely intact the predictions for the six (light and heavy) neutrino masses and $m_{ββ}$. Our statistical analysis, which yields the likelihood-predicted ranges of the observables, is fully consistent with JUNO's newly released first measurement of reactor neutrino oscillations in the $Δm^2_{12}$-$\sin^2θ_{12}$ plane, with JUNO improving the precision by a factor of 1.6 relative to the combination of all previous measurements. The implementation of successful non-thermal leptogenesis allows us to provide estimates for the inflaton mass ($m_χ\approx 7\times 10^{9}$ GeV) and the reheating temperature ($T_\mathrm{RH}\approx 4\times 10^6$ GeV).

</details>


### [25] [Gauge-independent treatment of electroweak phase transition](https://arxiv.org/abs/2512.05565)
*Jie Liu,Renhui Qin,Ligong Bian*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We provide the first certificate of the gauge-independent bubble nucleation at the electroweak phase transition with the standard model effective field theory. Taking advantage of the thermal effective field theory framework, with the power counting $λ\sim g^3$, we rigorously demonstrate the gauge independence of the bubble nucleation rate up to two-loop order. Furthermore, we analyze the influence of relevant phase transition parameters on the gauge parameter and investigate its implications for gravitational waves generated by the electroweak phase transitions.

</details>


### [26] [The Dichotomous Nature of the $σ$ Meson and the Nucleon D-Term](https://arxiv.org/abs/2512.05583)
*Zanbin Xing,Khépani Raya,Yu-xin Liu,Lei Chang*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Employing a symmetry-preserving contact-interaction formulation of the Dyson-Schwinger equations in quantum chromodynamics (QCD), we examine the identity of the $σ$ meson and its implications for the gravitational structure of hadrons. In this framework, the scalar meson emerges as the chiral partner of the pion, with both states' properties tightly connected to the mechanisms of mass generation in QCD. We find that, above a critical coupling that triggers dynamical chiral symmetry breaking, the D-terms of the constituent quark, the pion, and $σ$ saturate at fixed values $D_{q,π,σ}=-1/3,-1,-7/3$. By examining the coupling strength evolution of the D-terms, this pattern follows naturally once a dual nature for the $σ$ meson is recognized: it behaves both as a quark-antiquark composite and as a dilaton arising from spontaneous scale symmetry breaking. This unified picture yields the prediction $D_N\sim -3$ for the nucleon D-term, consistent with contemporary lattice-QCD, continuum, and dispersive studies.

</details>


### [27] [A comprehensive study of $B$, $B_s$ and $B_c$ meson semitauonic modes in potential quark model](https://arxiv.org/abs/2512.05628)
*Sonali Patnaik*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this work, we derive the form factors and compute the branching fractions for the semitauonic decay modes, $B \to D^{(*)}\,τ\,ν_τ$, $B_s \to D_s^{(*)}\,τ\,ν_τ$, $B_c \to η_c\,(J/ψ)\,τ\,ν_τ$, and $B_c \to D^{(*)}\,τ\,ν_τ$ within the \emph{Relativistic Independent Quark (RIQ) Model}, emphasizing a quark potential model based analysis of these transitions. We outline the essential elements of the model, incorporating corrections from residual interactions and center-of-mass motion, and perform a comprehensive study of the form factors across the full physical kinematic range of $q^2$. The resulting predictions demonstrate consistency and good agreement with existing theoretical approaches and experimental measurements. Motivated by recent observations of polarization observables at LHCb and Belle, we further evaluate these quantities within our framework and find results compatible with Standard Model (SM) expectations. The predictions presented here serve as theoretical input in decay channels for which Lattice QCD results remain limited, offering guidance for future experimental and Lattice efforts. Thus, semileptonic $B$ decays continue to serve as precise and discerning probes of the fundamental mechanisms governing flavor transitions in the SM.

</details>


### [28] [Phenomenological studies of exclusive heavy-quarkonium electroproduction at NLO](https://arxiv.org/abs/2512.05629)
*Chris A. Flett*

Main category: hep-ph

TL;DR: The paper analyzes exclusive electroproduction of heavy vector mesons in ep collisions using NLO coefficient functions, compares results with HERA data, predicts EIC outcomes, and discusses the need for resummation in J/ψ production.


<details>
  <summary>Details</summary>
Motivation: To extend phenomenological studies of exclusive electroproduction relevant for HERA measurements and future EIC experiments, and to assess the importance of resumming logarithmically enhanced terms.

Method: Utilizes next-to-leading order (NLO) coefficient functions from previous work to calculate cross-sections, compares with experimental HERA data across various Q² and γ*p CM energies, and provides EIC predictions.

Result: Cross-section results align with HERA data across a broad Q² and energy range; predictions for EIC measurements are made; identifies necessity for resummation in J/ψ electroproduction at higher orders.

Conclusion: Resummation of logarithmically enhanced terms is essential for precise predictions in J/ψ electroproduction, highlighting the need for improved theoretical frameworks in upcoming EIC studies.

Abstract: Using the next-to-leading order (NLO) coefficient functions for exclusive electroproduction of heavy vector mesons derived in our previous work, we perform various phenomenological studies of exclusive electroproduction in $ep$ collisions relevant for both the existing measurements from HERA, and the forthcoming Electron-Ion collider (EIC). We compare our cross-section results to HERA data across a broad range of photon virtualities $Q^2$ and $γ^* p$ centre-of-mass energies, provide predictions for upcoming EIC measurements and conclude with a discussion on the necessity of resumming logarithmically enhanced contributions in $J/ψ$ electroproduction.

</details>


### [29] [Inelastic Majorana Dark Matter and Its Self-Interactions in a Gauged $U(1)_{L_μ- L_τ}$ Model](https://arxiv.org/abs/2512.05694)
*Kwei-Chou Yang*

Main category: hep-ph

TL;DR: The paper proposes an inelastic Majorana dark matter model under a gauged U(1)_{Lμ-Lτ} symmetry, addressing dark matter properties, (g-2)_μ anomaly, and small-scale cosmological issues through strong scalar couplings and Z' interactions.


<details>
  <summary>Details</summary>
Motivation: To explain the muon (g-2) discrepancy, resolve small-scale structure problems in cosmology, and account for dark matter's relic abundance while addressing potential Hubble tension and N_eff anomalies.

Method: Constructs a model with a complex scalar, fermions with small Dirac mass, and U(1)_{Lμ-Lτ} gauge symmetry. Exploits strong interactions between dark fermions/scalars to create Majorana eigenstates, uses Z' boson for inelastic DM self-interactions, and incorporates kinetic mixing with photon for observable effects.

Result: Predicts DM mass between 10 GeV- hundreds of GeV, scalar mass below 100 MeV. Annihilation via scalars determines relic density; Z' mediates thermal equilibrium. Self-interactions via scalar exchange mitigate cosmological issues. Model explains (g-2)_μ and offers pathways to test via direct detection and collider experiments.

Conclusion: The model successfully ties together DM phenomenology, muon anomalies, and cosmological problems through a unified framework, providing testable predictions for current/future experiments and observations.

Abstract: We develop an inelastic Majorana dark matter model gauged by $U(1)_{L_μ-L_τ}$ symmetry, featuring a complex scalar and fermions with a small Dirac mass. The model exhibits strong interactions between the dark fermion-antifermion pair and the scalar, with a large coupling generating a Majorana mass after symmetry breaking. The dark fermion splits into two nearly degenerate Majorana eigenstates, with the $U(1)_{L_μ-L_τ}$ gauge boson $Z^\prime$ interacting via inelastic axial vector currents. The lighter Majorana serves as dark matter (DM), while the heavier may also contribute. The model predicts DM masses ranging from about 10 GeV to hundreds of GeV, with the scalar favored below 100 MeV. Strong coupling causes DM particles to mainly annihilate into two scalars, which determines the relic abundance, while thermal equilibrium with the bath occurs through $Z^\prime$ interactions. Self-interacting DM particles scatter via ladder exchange of strongly coupled light scalars, helping resolve small-scale issues. The $Z^\prime$ interacts with the muon, affecting its magnetic moment and explaining the $(g-2)_μ$ discrepancy. Effects on experiments, $N_{\text{eff}}$, and the Hubble tension from kinetic mixing between $Z^\prime$ and the photon, originating from high-energy scales, are discussed. The model details and parameter constraints used in experiments are also covered.

</details>


### [30] [Machine Learning-Informed 3+1 Sterile Neutrino Global Fits using Posterior Density Estimation of Electron Disappearance Data](https://arxiv.org/abs/2512.05784)
*Joshua Villarreal,Julia Woodward,John Hardin,Janet Conrad*

Main category: hep-ph

TL;DR: The paper addresses the challenges in analyzing global oscillation data for sterile neutrinos, exploring simulation-based inference methods to tackle computational issues and provide Bayesian/frequentist interpretations.


<details>
  <summary>Details</summary>
Motivation: The motivation is to resolve discrepancies in neutrino experiments and determine if sterile neutrinos are viable solutions to observed anomalies, while addressing computational bottlenecks in global fits.

Method: The authors use posterior density estimation and machine-learning-based frequentist approaches to handle likelihood intractability and computational burdens in global fits of sterile neutrino data.

Result: Achieves a comprehensive analysis framework that allows both Bayesian and frequentist interpretations, aiding in evaluating sterile neutrino hypotheses against experimental data.

Conclusion: Simulation-based inference offers a promising path forward for reconciling global sterile neutrino data, highlighting the need for advanced statistical tools to address longstanding tensions in neutrino physics.

Abstract: Global analyses of particle physics data are integral for validating and scrutinizing published results of experiments. Global fits of anomalous oscillation data which search for one or more eV-scale sterile neutrinos are particularly challenging both to evaluate and to reconcile in the global picture. Fits (especially joint ones) to oscillation data suffer from significant computational burdens, such as likelihood intractability, making traditional Markov Chain-Monte Carlo all but impossible. Given evidence both supporting and challenging beyond Standard Model physics across neutrino experiments of various baselines, energies, and detection techniques, the global search for sterile neutrinos requires additional tools in order to determine whether sterile neutrinos remain a viable solution to unexplained anomalies. Furthermore, both a Bayesian and frequentist interpretation of sterile neutrino data is needed for a complete assessment of longstanding tensions in the field. Techniques from the machine learning subfield of simulation-based inference have a natural application to such a problem. In this contribution, we illustrate some of the outstanding questions of the global picture of light sterile neutrinos by focusing on experiments searching with the disappearance of electron (anti)neutrinos, and look to posterior density estimation strategies to craft answers, including comparisons to a machine-learning-based frequentist approach.

</details>


### [31] [Three-loop jet function for boosted top quarks](https://arxiv.org/abs/2512.05795)
*Alberto M. Clavero,Vicent Mateu,Maximilian Stahlhofen*

Main category: hep-ph

TL;DR: The paper presents a third-order calculation of the inclusive jet function for boosted heavy quarks using bHQET, contributing to N³LL' resummation and top quark mass calibration.


<details>
  <summary>Details</summary>
Motivation: The motivation is to improve the precision of top quark mass measurements at high-energy colliders by providing the necessary ingredients for resummed calculations, particularly in the resonance region of boosted top quark production.

Method: The method involves using boosted Heavy-Quark Effective Theory (bHQET) to compute the jet function at order α_s³. The analysis focuses on the regime where the jet invariant mass squared minus the mass squared is much smaller than the mass squared, ensuring consistency with non-Abelian exponentiation and renormalon calculus predictions.

Result: The results validate the cusp and non-cusp anomalous dimensions up to three loops, confirm the agreement of the n_ℓ² α_s³ contribution with renormalon predictions, and derive the relation between different jet-mass schemes. They also provide an estimate of the four-loop jet function's non-logarithmic part.

Conclusion: The study completes key ingredients for N³LL' resummed thrust distribution, enabling precise top quark mass calibration in Monte Carlo simulations and aiding future lepton collider experiments in determining top quark mass.

Abstract: We present the calculation of the inclusive jet function for highly energetic heavy quarks at order $\mathcal{O}(α_s^3)$ using boosted Heavy-Quark Effective Theory (bHQET). This jet function describes the effect of collinear radiation emitted by energetic heavy quarks on observables dependent on the jet invariant mass $M$. In particular, we focus on the regime $M^2 - m^2 \ll m^2$, which is relevant for boosted top quark production at high-energy colliders in the resonance region. Our results are consistent with non-Abelian exponentiation and reproduce the known cusp and non-cusp anomalous dimensions up to three loops. We also verify that the $n_\ell^2 α_s^3$ contribution, with $n_\ell$ denoting the number of light quark flavors, agrees with predictions from renormalon calculus. This calculation completes the list of ingredients required for the N$^3$LL$^\prime$ resummed (self-normalized) thrust distribution, an essential component for calibrating the top quark mass parameter in parton-shower Monte Carlo generators. It likewise contributes to the invariant-mass distribution of reconstructed top quarks, enabling precise mass determinations at future lepton colliders. Finally, we determine the relation between the pole and two short-distance jet-mass schemes at $\mathcal{O}(α_s^3)$ and provide an estimate of the non-logarithmic part of the four-loop jet function based on renormalon dominance.

</details>


### [32] [Dark matter implications from the XENONnT and LZ data](https://arxiv.org/abs/2512.05850)
*Haipeng An,Fei Gao,Jia Liu,Minghao Liu,Haoming Nie,Changlong Xu*

Main category: hep-ph

TL;DR: The paper explores whether the high-energy nuclear-recoil excess observed in recent liquid xenon experiments (XENONnT and LZ) originates from dark matter interactions beyond the standard elastic spin-independent WIMP model. Using the DIAMX framework, the authors performed combined likelihood fits to datasets with 7.3 tonne×year exposure. They find that velocity-dependent cross-sections or inelastic scattering interactions could explain the excess with up to 4σ significance. However, uncertainties in $^{124}$Xe DEC background modeling significantly affect the results. Future high-energy data from XENONnT and LZ extending up to 300 keV could decisively test the dark matter hypothesis, as DEC backgrounds are anticipated to be negligible there.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the unexplained high-energy nuclear-recoil excess detected in XENONnT and LZ experiments that deviates from predictions of standard elastic spin-independent WIMP scattering. The authors aim to identify if novel dark matter interaction mechanisms or background uncertainties could account for this anomaly.

Method: The method involves using the open-source DIAMX framework to perform combined profile-likelihood fits across multiple WIMP-search datasets with a total exposure of 7.3 tonne×year. They analyzed two interaction models: velocity-dependent cross-sections and inelastic (endo-/exothermic) scattering. Modeling uncertainties, particularly from $^{124}$Xe DEC background charge yields, were quantified through sensitivity studies.

Result: Key results include the ability of non-standard dark matter interactions to reproduce the excess up to 4σ significance. However, background modeling uncertainties (DEC charge yields) drastically shift significance estimates (1σ to 4σ). The authors emphasize the need for higher-energy data (up to 300 keV) to reduce background ambiguities.

Conclusion: The conclusion highlights the viability of certain dark matter interaction models to explain the signal, but stresses that precise interpretation depends on accurate background understanding. They advocate for extending analyses to forthcoming high-energy datasets from XENONnT and LZ to definitively distinguish dark matter signals from DEC backgrounds in the >200 keV range.

Abstract: We investigate a possible dark matter origin of the high-energy nuclear-recoil excess reported by recent liquid xenon experiments, including \textnormal{XENONnT} and \textnormal{LZ}, which cannot be explained by standard elastic spin-independent WIMP scattering. Using our unified \texttt{DIAMX} framework, built on openly available data and likelihood models, we perform the first combined profile-likelihood fits to multiple WIMP-search datasets with a total exposure of 7.3~tonne $\times$ year. We investigate that two broad classes of dark matter nucleon interactions, with velocity-dependent cross-section or inelastic (endo- and exothermic) scattering, can reproduce the observed high-energy recoil spectrum, reaching local significances up to $4σ$. We further quantify the impact of $^{124}$Xe double electron capture (DEC) backgrounds, finding that variations in the poorly known DEC charge yields can shift the inferred significances from below $1σ$ to $4σ$. We point out that extending the same analysis to \textnormal{XENONnT} and \textnormal{LZ} data with recoil energies up to 300\,keV, once available, will provide a powerful test of the dark matter interpretation, since the $^{124}$Xe DEC background is expected to be negligible in this high-energy range.

</details>


### [33] [Dijet bounds on third-generation four-quark operators](https://arxiv.org/abs/2512.05857)
*Maximilian Freiheit,Ulrich Haisch*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We use dijet measurements from the Large Hadron Collider to constrain ten third-generation four-quark operators in the Standard Model effective field theory. At tree level, only the five operators involving four bottom quarks are directly constrained, but renormalization group (RG) effects allow all ten operators to be probed. Our analysis includes the dominant leading-logarithmic RG contributions up to two-loop order. The resulting bounds for the first five operators are nominal stronger or comparable to current limits, while those for the remaining operators remain weak despite the inclusion of logarithmically enhanced corrections.

</details>


### [34] [Untangling the IBP Equations](https://arxiv.org/abs/2512.05923)
*Junhan W. Liu,Alexander Mitov*

Main category: hep-ph

TL;DR: The paper presents a new algorithm to diagonalize Integration-by-Parts (IBP) equations, enabling efficient reduction of loop integrals to master integrals and solving IBP identities analytically. It also introduces a triangular form of IBP equations for computational purposes, demonstrated on complex topologies.


<details>
  <summary>Details</summary>
Motivation: To address challenges in reducing loop integrals with high numerator powers to master integrals and solving IBP identities analytically, especially for multivariate Mellin representations and other recurrence relations.

Method: Development of an algorithm for diagonalizing IBP equations, which transforms them into a triangular form suitable for computer implementation. This method is applied to various complex Feynman diagram topologies.

Result: Successfully demonstrated efficient reduction of complicated loop integral topologies using the diagonalized IBP equations. The triangular form enables faster computation and analytic solutions for multivariate recurrence relations.

Conclusion: The algorithm provides a robust framework for handling IBP equations, advancing analytic computation in particle physics, particularly in contexts requiring multivariate Mellin representations and recurrence relation solutions.

Abstract: In this work, we present an algorithm for the diagonalization of the Integration-by-Parts (IBP) equations. Diagonalized IBP equations are indispensable for reducing loop integrals with high numerator powers to master integrals and for solving IBP identities in closed analytic form. A prime example is provided by multivariate Mellin representations of loop amplitudes and cross sections. The extension of these methods to other multivariate recurrence relations is also discussed. As a by-product of our diagonalization procedure, we show how the IBP equations can be cast into an efficient, fully triangular form that is well suited for computer implementation. Several complicated topologies have been computed.

</details>


### [35] [Strongly Coupled Quantum Forces](https://arxiv.org/abs/2512.05968)
*Yuval Grossman,Chinhsan Sieng,Xun-Jie Xu,Bingrong Yu*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum forces are long-range interactions originating from vacuum fluctuations of mediator fields. Such forces inevitably arise between ordinary matter particles whenever they couple to light mediator species. Conventional computations of quantum forces rely on evaluating one-loop Feynman diagrams of the relevant scattering processes. In this work, we introduce a novel framework to compute quantum forces. Instead of relying on perturbative scattering amplitudes, we directly evaluate the quantum fluctuations of the mediator field by solving its quantized equation of motion with appropriate boundary conditions. This approach remains valid beyond the Born approximation and thus applies to regimes of strong coupling between the mediator and matter fields. In the weak-coupling limit, our results reproduce the known expressions from the Feynman diagram approach. In the strong-coupling regime, the result is modified by a factor that can suppress or enhance the effect. In contrast to classical forces, quantum forces intrinsically violate the superposition principle. Our approach may therefore offer a useful tool for probing non-perturbative effects in the infrared regime.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [36] [Effective $f(Q)$ model emerging from $f(Q,T)$ under a special EOS limit in symmetric cosmology with Bayesian and ANN observational constraints](https://arxiv.org/abs/2512.05142)
*Anil Kumar Yadav,S. H. Shekh,N. Myrzakulov*

Main category: gr-qc

TL;DR: This paper presents an effective f(Q) model derived from f(Q,T) gravity under the condition ρ + p = 0, which aligns with the ΛCDM model's cosmic evolution. The study uses observational data and machine learning to constrain parameters, showing that the model addresses cosmological tensions and offers a competitive alternative to ΛCDM.


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore cosmological models beyond ΛCDM that can resolve persistent tensions like the Hubble constant (H₀) and σ₈ disputes, while maintaining observational consistency. The paper investigates how f(Q,T) gravity simplifies under specific conditions to produce viable dark energy scenarios.

Method: The authors derive f(Q) functional forms from f(Q,T) gravity under ρ + p = 0, leading to constraints on F(Q,T)H(t)=C. They apply Bayesian MCMC and an ANN emulator to constrain H₀, Ωₘ, and S₈ using CC, BAO, and Pantheon+ data. The ANN method reduces computational time while tightening parameter constraints.

Result: The f(Q) model reproduces observational trends from datasets, resolves H₀ and S₈ tensions, and provides an effective cosmological constant. The ANN approach shows superior efficiency in parameter estimation compared to traditional MCMC. The model is observationally consistent with ΛCDM but offers a distinct theoretical framework.

Conclusion: Effective nonmetricity-based dark energy models from f(Q,T) gravity are viable alternatives to ΛCDM, capable of addressing cosmological tensions. The study highlights the utility of machine learning techniques for efficient model testing. Future high-precision surveys are needed to differentiate between these models conclusively.

Abstract: In this work, we investigate the cosmological consequences of an effective $f(Q)$ model emerging from the more general $f(Q,T)$ gravity theory under the special equation-of-state condition $ρ+ p = 0$. Under this limit, the field equations yield the constraint $F(Q,T)H(t)=C$, implying that the function $F=f_Q$ becomes purely dependent on the nonmetricity scalar $Q$, and the background evolution mimics that of the standard $Λ$CDM model. We derive the resulting functional forms of $f(Q)$, obtain the corresponding effective cosmological constant, and analyze the physical nature of this reduction. To test the model against observations, we constrain the parameters $H_0$, $Ω_m$, and $S_8$ using cosmic chronometers (CC), baryon acoustic oscillations (BAO), and Pantheon+ SN Ia datasets. A comparative analysis is performed using both the conventional Bayesian Markov Chain Monte Carlo (MCMC) sampling and a machine-learning based Artificial Neural Network (ANN) emulator. We find that the ANN approach yields tighter posterior constraints while significantly reducing computational time. The model successfully reproduces the observational trends of each dataset and offers insights into the persistent $H_0$ and $S_8$ tensions. Our results indicate that effective nonmetricity-based dark energy scenarios derived from $f(Q,T)$ gravity provide a viable and observationally consistent alternative to $Λ$CDM, with future high-precision surveys expected to further distinguish between these frameworks.

</details>


### [37] [Images from disk and spherical accretions of Bardeen black hole surrounded by perfect fluid dark matter](https://arxiv.org/abs/2512.05147)
*Hui Zeng,Xi-Jing Wang,Yuan Meng*

Main category: gr-qc

TL;DR: The paper explores how Bardeen black holes surrounded by perfect fluid dark matter (PFDM) with varying parameters affect shadow, optical appearance, and accretion models. Key findings include competing effects of dark matter parameter |α| and magnetic charge g on black hole properties, constraints using EHT data favoring SgrA* over M87*, and parameter-dependent shadow imaging. These insights offer a method to distinguish black hole types and aid future dark matter studies.


<details>
  <summary>Details</summary>
Motivation: To understand the interplay between PFDM, magnetic charge, and black hole properties, and to leverage black hole shadows/images for dark matter parameter estimation and model differentiation.

Method: Analytically calculate black hole characteristics (horizon, photon sphere, impact parameter) under varying |α| and g; apply EHT data to constrain α; simulate black hole images across different accretion models.

Result: Increasing |α| enlarges r_h, r_ph, b_ph while reducing V_eff's peak; g has opposite effects on these parameters. EHT data from SgrA* gives tighter α constraints than M87*. Strong dependence of shadow size/brightness on α and accretion geometry, enabling PFDM-Bardeen hole differentiation.

Conclusion: Shadow observations and imaging can probe dark matter properties in black hole environments, offering experimental avenues for testing PFDM models. These results underscore the need for precision astrophysical measurements to explore quantum gravity effects and dark matter interactions.

Abstract: In this paper, we investigate the shadow and optical appearance of the Bardeen black hole surrounded by perfect fluid dark matter (PFDM) illuminated by various static accretions. First, we find that as the dark matter parameter $\left|α\right|$ increases, the fundamental characteristic quantities of the black hole, the event horizon $r_h$, the photon sphere radius $r_{ph}$, and the critical impact parameter $b_{ph}$ all increase, while the peak of the effective potential $V_{\text{eff}}$ decreases and shifts toward the direction of increasing $r$. In contrast, the magnetic charge parameter $g$ suppresses $r_h$, $r_{ph}$, and $b_{ph}$, while increases the peak of $V_{\text{eff}}$ and shifts it toward the direction of decreasing $r$. This indicates a competing effect between the dark matter parameter $\left|α\right|$ and the magnetic charge parameter $g$ on the fundamental properties of the black hole. Furthermore, we use the EHT observational data to constrain the dark matter parameters $α$ and find that the constraint range given by the supermassive black hole SgrA* is stricter than that of the black hole M87*. Finally, the black hole images are studied based on different accretion models, and it is found that both dark matter parameters $α$ and accretion models significantly influence the black hole images. For larger dark matter parameters $\left|α\right|$, the inner shadow or central faint illuminating region of the Bardeen black hole surrounded by PFDM is larger but the bright ring of the image is fainter. This provides a potential method for us to distinguish between classical Bardeen black holes and Bardeen black holes surrounded by PFDM. These preliminary results may provide some clues for future investigations of dark matter using black hole shadows and images.

</details>


### [38] [Black-hole ringdown with templates capturing spin precession: a critical re-analysis of GW190521](https://arxiv.org/abs/2512.05193)
*Chiara Anselmo,Costantino Pacilio,Davide Gerosa*

Main category: gr-qc

TL;DR: The paper presents a re-analysis of the gravitational wave event GW190521 using a precessing spin amplitude model in a ringdown simulation-based inference pipeline, showing that precession introduces systematic shifts in parameters but does not strongly indicate its presence, thus demonstrating the viability of precessing ringdown modeling.


<details>
  <summary>Details</summary>
Motivation: To critically re-examine GW190521, a contentious event with ambiguous interpretations, and evaluate the impact of spin precession on ringdown parameter estimation, leveraging a new amplitude model that incorporates spin precession.

Method: Implementing a precessing spin amplitude model within a simulation-based inference framework targeting ringdown signals. Conducted spin-aligned and precessing analyses at two distinct ringdown start times for GW190521's data.

Result: Precession causes measurable but modest shifts in inferred parameters and subdominant mode amplitudes. Ringdown-only analyses lack strong evidence for precession in GW190521. The approach validates the feasibility of precessing ringdown modeling with reduced waveform uncertainties.

Conclusion: The method establishes a pathway for detecting spin precession in gravitational-wave events through ringdown stages alone, minimizing waveform systematics and enhancing future analyses of compact binary coalescence signals.

Abstract: The ringdown phase of a binary black-hole merger provides a clean probe of strong-field gravity, as it can be modeled with minimal assumptions. The quasi--normal--mode frequencies encode the mass and spin of the Kerr black-hole remnant, while the mode excitation depends on the progenitor binary. In this paper, we implement a recently developed amplitude model that captures spin precession in a simulation-based inference pipeline that specifically targets ringdown signals. We present a critical re-analysis of GW190521 -- a short-duration, merger-dominated event with conflicting interpretations. Spin-aligned and precessing analyses at two ringdown start times show that precession induces modest but systematic shifts in inferred parameters and subdominant mode amplitudes, although such ringdown-only analyses provide no strong evidence for precession. Our results demonstrate the feasibility of physics-informed precessing ringdown modelling, paving the way for the identification of spin precession in gravitational-wave events using solely their ringdown stages, where waveform systematics are expected to be substantially less prominent.

</details>


### [39] [On the regularity of deformed extremal horizons](https://arxiv.org/abs/2512.05200)
*Francesco Di Filippo,Shinji Mukohyama,José M. M. Senovilla*

Main category: gr-qc

TL;DR: The paper investigates non-spherical extremal black holes, showing their horizons can remain regular despite some divergences. It confirms finite backreaction in perturbed extremal Reissner-Nordström AdS black holes and establishes geometric constraints for geodesic completeness.


<details>
  <summary>Details</summary>
Motivation: To address claims about extremal black holes amplifying new physics via horizon instabilities, and to assess viability of non-spherical extremal black holes.

Method: Analysis of scalar stress-energy tensor components for extremal Reissner-Nordström AdS black holes under perturbation. Study of geodesic completeness using geometric constraints.

Result: Some scalar stress-energy components diverge but backreaction remains finite. Geometric constraint ensures null geodesics cross horizons smoothly, supporting regular non-spherical spacetimes.

Conclusion: Non-spherical extremal black holes can maintain regular horizons, suggesting a broader class of such spacetimes viable for testing new physics effects.

Abstract: It has recently been argued that extremal black holes can act as amplifiers of new physics, due to horizon instabilities that enhance the effects of ultraviolet corrections. In this paper, we revisit some of these claims and investigate the viability of a class of non-spherical extremal black holes. In particular, we revisit the regularity of perturbed extremal Reissner--Nordström AdS black holes showing that, while some certain components of the scalar stress energy tensor diverge, the backreaction remains finite. We also study geodesic completeness, identifying a simple geometric constraint which, if satisfied, ensures that null geodesics cross the horizon smoothly. This analysis suggests the existence of a broad class of spacetimes with regular non-spherical horizons.

</details>


### [40] [Repetitive Penrose process in Kerr-de Sitter black holes](https://arxiv.org/abs/2512.05491)
*Ke Wang,Xiao-Xiong Zeng*

Main category: gr-qc

TL;DR: This paper explores the impact of the cosmological parameter on the repetitive Penrose process in Kerr-de Sitter black holes, finding higher energy returns and extraction capabilities compared to Kerr black holes, with outcomes dependent on the decay radius.


<details>
  <summary>Details</summary>
Motivation: Prior studies ([1-3]) showed that repetitive Penrose processes cannot fully extract energies from Kerr and RN black holes, suggesting a third-law-like limitation. The authors aim to extend this analysis to Kerr-dS black holes to understand cosmological effects and potential energy extraction efficiency.

Method: Analyzing the repetitive Penrose process in Kerr-dS black holes, quantifying effects of the cosmological constant on energy extraction metrics (EROI, EUE, single-extraction energy) across varying decay radii.

Result: Kerr-dS black holes exhibit stronger EROI and single-extraction energy with larger cosmological parameters. At lower decay radii, Kerr black holes have better EUE/energy extraction; at higher decay radii, Kerr-dS outperform due to process stopping conditions.

Conclusion: The cosmological parameter significantly enhances energy extraction efficiency in Kerr-dS black holes under certain conditions, suggesting new considerations for Penrose process applications beyond classical black hole models.

Abstract: Recently, references [1,2] found that the repetitive Penrose process cannot extract all the extractable rotational energy of a Kerr black hole, and reference [3] found that the repetitive electric Penrose process cannot extract all the electrical energy of a Reissner-Nordström (RN) black hole. This suggests that a law analogous to the third law of thermodynamics exists for the repetitive Penrose process. In this paper, we intend to study the repetitive Penrose process in the Kerr-de Sitter (Kerr-dS) black hole. We will explore influences of the cosmological parameter on the repetitive Penrose process. The results show that, in addition to a similar third law of thermodynamics, the Kerr-dS black hole yields a higher energy return on investment (EROI) and single-extraction energy capability compared to the Kerr black hole. Specifically, the larger the cosmological parameter, the stronger the EROI and the single-extraction energy capability. Furthermore, we also find that at a lower decay radius, the Kerr black hole exhibits a higher energy utilization efficiency (EUE) and more extracted energy after the repetitive Penrose process is completed. However, at a higher decay radius, the situation is reversed, i.e., the Kerr-dS black hole exhibits a higher EUE and more extracted energy, which is due to the existence of stopping condition of the iteration.

</details>


### [41] [Tidal Love numbers for regular black holes](https://arxiv.org/abs/2512.05767)
*Rui Wang,Qi-Long Shi,Wei Xiong,Peng-Cheng Li*

Main category: gr-qc

TL;DR: The paper explores Tidal Love numbers (TLNs) of regular black holes, showing they are nonzero and have model-dependent responses, indicating potential for testing new physics with gravitational waves.


<details>
  <summary>Details</summary>
Motivation: To investigate deviations from classical black holes' TLNs (which are zero) by studying regular black hole models, offering insights into quantum gravity and new physics through tidal interactions.

Method: Analytic calculations using Green's function and perturbative expansions for scalar, vector, and axial gravitational perturbations across three regular black hole models: Bardeen, sub-Planckian curvature, and asymptotically safe gravity BHs.

Result: TLNs are generically nonzero and exhibit scale-dependent behavior akin to renormalization-group running, reflecting internal structures like de Sitter cores. Higher-order terms show logarithmic dependencies, absent in classical BHs.

Conclusion: TLNs can serve as observational probes to distinguish regular black hole models via gravitational-wave observations, highlighting their utility in testing quantum gravity effects and alternative theories of gravity.

Abstract: Tidal Love numbers (TLNs) characterize the response of compact objects to external tidal fields and vanish for classical Schwarzschild and Kerr black holes in general relativity. Nonvanishing TLNs therefore provide a potential observational window into new physics. In this work, we present a unified and fully analytic study of the TLNs of three representative classes of regular black holes -- the Bardeen black hole,the black hole with sub-Planckian curvature, and the black hole arising in asymptotically safe gravity -- under scalar, vector, and axial gravitational perturbations. Employing a Green's function method combined with systematic perturbative expansions, we show that TLNs of regular black holes are generically nonzero and exhibit strong model and mode dependence. In many cases, higher-order corrections develop logarithmic scale dependence, closely resembling renormalization-group running in quantum field theory and revealing a scale-dependent tidal response absent in classical black holes. Our analysis demonstrates that the internal structure of regular black holes, including de Sitter or Minkowski cores and quantum-gravity-inspired modifications, leaves distinct fingerprints in their tidal properties. These results establish TLNs as promising probes for testing regular black hole models with future gravitational-wave observations.

</details>
