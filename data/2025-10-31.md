<div id=toc></div>

# Table of Contents

- [gr-qc](#gr-qc) [Total: 11]
- [hep-ph](#hep-ph) [Total: 23]
- [astro-ph.HE](#astro-ph.HE) [Total: 14]
- [astro-ph.IM](#astro-ph.IM) [Total: 9]


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [1] [Dark Energy Contaminated Black Hole Solution: A Drive Through the Thermodynamic Properties](https://arxiv.org/abs/2510.25815)
*Promila Biswas,Subhajit Pal,Sukanya Dutta,Ritabrata Biswas,Farook Rahaman*

Main category: gr-qc

TL;DR: The study explores how black hole mass evolves in different dark energy models using the Modified Chaplygin Gas cosmological framework. The mass growth is found to be sensitive to the dynamic properties of dark energy, showing varying behaviors like gentle slopes, steep slopes, and non-monotonic patterns which correlate with different models' pressure evolution and cosmic expansion effects.


<details>
  <summary>Details</summary>
Motivation: To probe the influence of dark energy's time-varying equation of state on black hole accretion dynamics, and to understand the interplay between local black hole growth and large-scale cosmic expansion driven by modified gravity models.

Method: The authors analyze the logarithmic mass ratio log10[M(z)/M0] across six dark energy models (Linear, Logarithmic, CPL, JBP, FSLL-II, BA). They model black hole mass evolution within a Modified Chaplygin Gas cosmology, examining redshift dependence of ω(z) and its impact on accretion rates through thermodynamic and gravitational interactions with the cosmic fluid.

Result: Key findings include distinct behavior patterns in mass ratio curves: smooth slopes for Linear/Logarithmic/CPL models (quasi-static accretion); steep slopes in JBP (rapid late-time variations); non-monotonic trends in FSLL-II/BA (transient accretion suppression/enhancement). These reflect dark energy's impact on cosmic pressure and horizon thermodynamics, showing black hole growth is sensitive to cosmic pressure dynamics.

Conclusion: Black hole accretion serves as a sensitive probe for dark energy's time-varying pressure and cosmic expansion effects. The study establishes a theoretical framework linking local strong-gravity phenomena (black hole growth) with global cosmological dynamics, offering observational diagnostics for distinguishing dark energy models through astrophysical accretion measurements.

Abstract: We investigate the evolution of black hole mass within a cosmological
background modeled by a Modified Chaplygin Gas (MCG) under various dark energy
equation of state parametrizations, including Linear, Logarithmic, CPL, JBP,
FSLL-II, and Barboza--Alcaniz (BA) models. The logarithmic mass ratio
$\log_{10}[M(z)/M_0]$ is found to be highly sensitive to the redshift-dependent
evolution of $\omega(z)$, with gentle slopes in Linear, Logarithmic, and CPL
models indicating quasi-static accretion, steep slopes in JBP corresponding to
rapid late-time variations, and non-monotonic behaviour in FSLL-II and BA
highlighting transient suppression or enhancement of accretion due to repulsive
dark energy effects. Peaks, minima, and amplitude offsets in the mass ratio
reflect the dynamic interplay between horizon thermodynamics, the evolving
pressure of the MCG, and cosmic expansion, illustrating how the black hole mass
growth is directly influenced by both the temporal evolution of dark energy and
the effective gravitational potential of the surrounding cosmic fluid. Our
results demonstrate that black hole accretion acts as a sensitive probe of the
time-dependent cosmic pressure landscape and provides physical insights into
the coupling between local strong gravity and global accelerated expansion.

</details>


### [2] [Birkhoff implies Quasi-topological](https://arxiv.org/abs/2510.25823)
*Pablo Bueno,Robie A. Hennigar,Ángel J. Murcia*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quasi-topological gravities (QTGs) are higher-curvature extensions of
Einstein gravity in $D\geq 5$ spacetime dimensions. Throughout the years,
different notions of QTGs constructed from analytic functions of polynomial
curvature invariants have been introduced in the literature. In this paper, we
show that all such definitions may be reduced to three distinct inequivalent
notions: type I QTGs, for which the field equations evaluated on a
single-function static and spherically symmetric ansatz are second order; type
II QTGs, whose field equations on general static and spherically symmetric
backgrounds are second order; and type III QTGs, for which the trace of the
field equations on a general background is second order. We show that type II
QTGs are a subset of type I QTGs and that type III QTGs are a subset of type II
QTGs modulo pure Weyl invariants. Moreover, we prove that type II QTGs possess
second-order equations on general spherical backgrounds. This allows us to
prove that any theory satisfying a Birkhoff theorem is a type II QTG, and that
the reverse implication also holds up to a zero-measure set of theories. For
every theory satisfying Birkhoff's theorem, the most general spherically
symmetric solution is a generalization of the Schwarzschild spacetime
characterized by a single function which satisfies an algebraic equation.

</details>


### [3] [Beyond general relativity: gravitational waves in non-minimally coupled theories](https://arxiv.org/abs/2510.25895)
*Stephon Alexander,Tatsuya Daniel,Tucker Manton*

Main category: gr-qc

TL;DR: The paper explores how non-minimal couplings between dark matter and curvature tensors affect gravitational wave (GW) observations by using a model-independent parameterization for GW strains and applying this to three specific models involving different field couplings.


<details>
  <summary>Details</summary>
Motivation: Non-minimal couplings modify GR solutions and can be probed via astrophysical observations. Dark matter's high density near binary black hole mergers provides a unique environment to study both dark matter properties and beyond-GR physics through GWs.

Method: The authors extended a parameterization for GW strains (left/right-handed) to include early-universe effects with slowly-varying matter fields. They analyzed three models: Kalb-Ramond dark matter with dimension-four operators, axion-dilaton-Chern-Simons-Gauss-Bonnet dimension-five operators, and a dimension-six coupling to a dark vector field.

Result: The study provides a framework to constrain non-minimal couplings using GW data, showing that different models produce distinct signatures detectable in gravitational wave observations, particularly in systems with high dark matter densities.

Conclusion: Observing GWs from binary black hole mergers in regions of high dark matter density can simultaneously probe dark matter interactions and gravitational theories beyond GR, offering a novel multi-messenger approach to fundamental physics.

Abstract: Non-minimal couplings between matter and curvature tensors arise in many
different contexts. Such couplings modify solutions of general relativity (GR)
and therefore can be probed in various astrophysical systems. A particularly
interesting scenario arises if dark matter experiences non-minimal couplings,
as dark matter densities are expected to spike in the vicinity of binary black
hole mergers. This gives a novel setting for simultaneously studying dark
matter and (beyond) GR physics via observations of gravitational waves (GWs).
In this work, we explore effects of various non-minimal couplings on GWs by
working with a model-independent parameterization for left- and right-handed GW
strains. We extend the parameterization proposed in
\cite{Jenks:2023pmk,Daniel:2024lev} to include early-universe effects, and we
write down the generic solution assuming slowly-varying matter fields. We then
systematically apply our results to three models: Kalb-Ramond dark matter with
dimension-four operators, axion-dilaton-Chern-Simons-Gauss-Bonnet
dimension-five operators, and dimension-six couplings to a (dark) vector field.

</details>


### [4] [Holographic Dark Energy from a Polynomial Expansion in the Hubble Parameter](https://arxiv.org/abs/2510.25928)
*Miguel Cruz,Joaquin Housset,Samuel Lepe,Joel Saavedra,Francisco Tello-Ortiz*

Main category: gr-qc

TL;DR: This paper introduces a generalized holographic dark energy (HDE) model using a polynomial expansion of the Hubble parameter up to H⁶ terms within a spatially flat FLRW universe. It explores cosmic evolution through Friedmann equations and investigates thermodynamic phase transitions, comparing results with the ΛCDM model.


<details>
  <summary>Details</summary>
Motivation: The motivation is to extend the standard holographic dark energy model by incorporating higher-order terms of the Hubble parameter to better understand cosmic acceleration and potential phase transitions, providing a more comprehensive framework than the ΛCDM model.

Method: The method involves formulating an HDE energy density with a polynomial expansion including H², H⁴, and H⁶ terms, deriving modified Friedmann equations for a matter-HDE FLRW universe, analyzing cosmic evolution, and examining P-V phase transitions thermodynamically.

Result: The analysis reveals possible thermodynamic phase transitions in the HDE model, offering insights into cosmic evolution dynamics. Comparisons with ΛCDM show differences in phase transition behavior and cosmic expansion profiles under varying parameter conditions.

Conclusion: The generalized HDE model provides a richer framework for cosmic evolution, highlighting non-trivial phase transitions absent in ΛCDM. It suggests that higher-order Hubble terms may reconcile observational data better and warrant further exploration in cosmological models.

Abstract: This work investigates a generalized holographic dark energy (HDE) model
defined by a polynomial expansion in the Hubble parameter, incorporating the
first three leading terms proportional to $H^{2}$, $H^{4}$, and $H^{6}$ through
a variable parameter in the expression for the energy density. The analysis is
developed within the framework of a spatially flat
Friedmann-Lema\^itre-Robertson-Walker (FLRW) Universe composed of
non-interacting matter and this HDE fluid. We derive the complete set of
Friedmann equations to study the cosmic evolution and subsequently examine the
system for the existence of thermodynamic $P-V$ type phase transitions.
Finally, a comprehensive comparison with the predictions of the standard
$\Lambda$CDM model is presented.

</details>


### [5] [Long-lived quasinormal modes, grey-body factors and absorption cross-section of the black hole immersed in the Hernquist galactic halo](https://arxiv.org/abs/2510.25969)
*B. C. Lütfüoğlu*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We analyze quasinormal modes, grey-body factors, and absorption
cross-sections of a massive scalar field in the background of a Schwarzschild
black hole surrounded by a Hernquist dark-matter halo. The quasinormal spectrum
is obtained through the higher-order WKB method and verified by time-domain
evolution, showing consistent results. The field mass increases the oscillation
frequency and reduces the damping rate, producing longer-lived modes, while
variations in the halo parameters lead to moderate shifts in the spectrum. The
grey-body factors reveal a suppression of low-frequency transmission and a
displacement of their main features toward higher frequencies, resulting in a
corresponding shift in the absorption cross-section.

</details>


### [6] [Spin effects on particle creation and evaporation in $f(R,T)$ gravity](https://arxiv.org/abs/2510.25973)
*A. A. Araújo Filho,N. Heidari,Francisco S. N. Lobo*

Main category: gr-qc

TL;DR: The paper explores how particle spin affects black hole processes in f(R,T) gravity, analyzing particle creation, greybody factors, absorption, and evaporation across scalar, vector, tensor, and spinorial modes.


<details>
  <summary>Details</summary>
Motivation: To understand the impact of modified electrodynamics in f(R,T) gravity on black hole physics, particularly focusing on spin-dependent effects on particle creation and evaporation.

Method: The study uses analytical and numerical methods: analytical expressions for greybody factors (with approximations for tensor and spinorial cases), numerical computation of absorption cross sections, and application of the Stefan-Boltzmann law to estimate evaporation lifetimes. Particle densities for massless bosons/fermions are determined through perturbations.

Result: Derived spin-dependent greybody factors, calculated absorption cross sections, estimated black hole evaporation lifetimes, and analyzed energy/particle emission rates. Also explored quasinormal mode-greynbody factor correspondence.

Conclusion: Spin significantly influences black hole processes in f(R,T) gravity, with distinct impacts across particle types. Findings highlight the necessity of considering spin effects in modified gravity models for accurate black hole dynamics.

Abstract: In this work, we study how the spin of particle modes influences particle
creation, greybody factors, absorption, and evaporation of a black hole within
the framework of modified electrodynamics in $f(R,T)$ gravity, recently
proposed in Ref. [1]. All spin sectors -- scalar, vector, tensor, and spinorial
-- are analyzed to obtain the corresponding features. For particle creation, we
consider massless bosonic and fermionic perturbations to determine the
respective particle densities. Analytical expressions for the greybody factors
are derived, with suitable approximations for the tensor and spinorial cases.
The absorption cross section is computed numerically, and using the
Stefan-Boltzmann law, we estimate the black hole evaporation lifetime. The
associated energy and particle emission rates are also discussed, along with
the correspondence between quasinormal modes and greybody factors.

</details>


### [7] [Mapping Anisotropies in the Stochastic Gravitational-Wave Background with space detector networks](https://arxiv.org/abs/2510.26359)
*Zhi-Yuan Li,Zheng-Cheng Liang,Cong-mao Zhang,Jian-dong Zhang,Yi-Ming Hu*

Main category: gr-qc

TL;DR: The paper presents a data analysis pipeline for joint space-based gravitational-wave detectors (TianQin, LISA, Taiji) to reconstruct the anisotropic stochastic gravitational-wave background's spatial distribution, achieving angular power spectrum reconstruction up to l=14.


<details>
  <summary>Details</summary>
Motivation: Enhance the capability to reconstruct and localize the anisotropic SGWB by combining the complementary viewing angles of multiple detectors, addressing the limitations of single-detector networks.

Method: Developed a data analysis pipeline using maximum likelihood estimation in pixel space, incorporating Gaussian stationary unpolarized point sources and random sky maps to model SGWB contributions.

Result: The TianQin+LISA+Taiji network can reconstruct the angular power spectrum up to l=14, enabling studies on galactic compact binaries and early Universe physics despite detector noise.

Conclusion: A multi-detector network improves SGWB spatial mapping, with the presented pipeline being the first dedicated tool for anisotropic analysis, offering critical insights into astrophysical and cosmological processes.

Abstract: Future space-based gravitational-wave detectors such as TianQin, LISA, and
Taiji are expected to conduct joint observations. Such a multi-detector network
will provide complementary viewing angles for the anisotropic stochastic
gravitational-wave background (SGWB), thereby significantly enhancing the
capability to reconstruct and localize its spatial distribution. In this paper,
we have established the first dedicated data analysis pipeline for the
anisotropic stochastic gravitational-wave background using a joint network of
TianQin, LISA, and Taiji. Our analysis incorporates both Gaussian, stationary,
and unpolarized point sources from diverse sky locations as well as a random
sky map. We have performed full-sky map reconstruction in pixel space using
maximum likelihood estimation to extract the angular distribution of the SGWB.
The results demonstrate that, when considering the detector noise, the
TianQin+LISA+Taiji detector network can reconstruct the angular power spectrum
of the stochastic background up to a maximum multipole moment of $l = 14 $,
which can provide valuable information for studies on the spatial distribution
of galactic compact binaries and physical imprints from the early Universe.

</details>


### [8] [Beyond GRMHD: A Robust Numerical Scheme for Extended, Non-Ideal General Relativistic Multifluid Simulations](https://arxiv.org/abs/2510.26019)
*Jonathan Gorard,James Juno,Ammar Hakim*

Main category: gr-qc

TL;DR: The paper introduces a general relativistic multifluid (GRMF) model that extends GRMHD by incorporating multiple fluid species and explicit electromagnetism, enabling simulations of extreme astrophysical environments with improved robustness and accuracy.


<details>
  <summary>Details</summary>
Motivation: The GRMHD model struggles with scenarios involving large Lorentz factors and high magnetizations due to reconstruction fragility, lack of non-ideal effects, and inability to model strong poloidal fields required for jet formation around black holes and neutron stars.

Method: The GRMF model uses multiple relativistic fluid species coupled via an explicit electromagnetic field, avoids issues with hyperbolicity and reconstruction by separating hydrodynamic and field equations, and derives the equations via Boltzmann-Vlasov moment equations.

Result: The numerical scheme demonstrates robustness in simulating extreme parameter regimes (high Lorentz factors, magnetizations) without sacrificing stability, validated against GRMHD benchmarks.

Conclusion: GRMF overcomes GRMHD's limitations by providing a more versatile framework for modeling non-ideal effects and extreme relativistic plasmas in strong gravitational fields near compact objects.

Abstract: The equations of general relativistic magnetohydrodynamics (GRMHD) have
become the standard mathematical framework for modeling high-energy plasmas in
curved spacetimes. However, the fragility of the primitive variable
reconstruction operation in GRMHD, as well as the difficulties in maintaining
strong hyperbolicity of the equations, sharply limit the applicability of the
GRMHD model in scenarios involving large Lorentz factors and high
magnetizations, such as around neutron stars. Non-ideal effects, such as
electron inertia and Hall terms, are also neglected, and the absence of an
explicitly evolved electric field precludes the self-consistent modeling of the
strong poloidal fields found around spinning black holes, which are known to be
crucial for jet formation. Here, we present a general relativistic multifluid
model which strictly generalizes the GRMHD equations, consisting of an
arbitrary number of relativistic fluid species interacting with a shared
electromagnetic field via an explicit coupling of their source terms, thus
allowing for the incorporation of non-ideal effects. We sketch how our model
may be derived from general relativistic kinetics (via moments of the
relativistic Boltzmann-Vlasov equation), as well as how GRMHD may be recovered
in the single-fluid limit as the mobility of charge carriers goes to infinity.
We present a numerical scheme for solving the general relativistic multifluid
equations, and validate it against the analogous scheme for the GRMHD
equations. Since the primitive variable reconstruction operation for our
multifluid model is purely hydrodynamic, and therefore independent of the
magnetic field, the resulting solver is highly robust, and able to simulate
significantly larger Lorentz factors and higher magnetizations (across both
black hole and neutron star spacetimes) than GRMHD without loss of either
accuracy or stability.

</details>


### [9] [Breaking Eternal Inflation: Empirical Viability of a Spontaneous Collapse Scenario](https://arxiv.org/abs/2510.26378)
*María Pía Piccirilli,Gabriel León,Rosa-Laura Lechuga-Solis,Daniel Sudarsky*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We revisit an inflationary scenario in which primordial inhomogeneities arise
from a quantum collapse, a stochastic mechanism described in the context of
quantum collapse theories in its continuous version and within semiclassical
gravity. The predictions of the model show a non-conventional scalar spectrum
governed by two new parameters in the collapse rate, whose aim is twofold: on
one side, to account for the primordial cosmic structure, and on the other to
explain the suppression amplitude associated with long-wavelength modes,
thereby eliminating the occurrence of eternal inflation. Furthermore, this
model can contribute to accounting for the lack of power anomaly in the low $l$
angular power spectra of the Cosmic Microwave Background (CMB). Using the
latest data from the Planck (2018) collaboration, we establish observational
constraints on the model parameters, which produce a characteristic low-$\ell$
suppression in the cosmic microwave background spectrum. We conclude that the
Planck data support the solution presented in the previous works, in other
words, that the model allows us to solve simultaneously the emergence of the
cosmic structure and, at the same time, avoid the eternal inflation scenario.

</details>


### [10] [The Penrose singularity theorem, MOTS stability, and horizon topology in weighted spacetimes](https://arxiv.org/abs/2510.26675)
*Eric Ling,Argam Ohanyan,Eric Woolgar*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We consider versions of the Penrose singularity theorem and the Hawking
horizon topology theorem in weighted spacetimes that contain weighted versions
of trapped surfaces, for arbitrary spacetime dimension and synthetic dimension.
We find that suitable generalizations of the unweighted theorems hold under a
weighted null energy condition. Our results also provide further evidence in
favour of a weighted scalar curvature that differs from the trace of the
weighted Ricci curvature. When the synthetic dimension is a positive integer,
these weighted curvatures have a natural interpretation in terms of warped
product metrics.

</details>


### [11] [Charged Rotating Black Hole and the First Law](https://arxiv.org/abs/2510.26772)
*S. D Campos*

Main category: gr-qc

TL;DR: The paper explores how charge influences the thermodynamic properties of black holes by extending existing frameworks with an analogy to charged rotating soap bubbles. It shows that charge contributes to angular momentum and entropy, validates the first law via the Gouy-Stodola theorem, and demonstrates that charge effects weaken at greater distances.


<details>
  <summary>Details</summary>
Motivation: To understand the role of charge in black hole thermodynamics, particularly its impact on entropy production and angular momentum, and to validate thermodynamic laws in charged systems.

Method: The authors use an analogy with charged rotating soap bubbles and apply the Gouy-Stodola theorem. They analyze the partition function from a distant observer's perspective to study charge effects.

Result: Charge contributes to total angular momentum and modifies the entropy-event horizon relationship. The first law of thermodynamics holds under these conditions, and charge effects diminish with distance.

Conclusion: The study reinforces the thermodynamic interpretation of black holes, clarifies charge's role in gravitational systems, and underscores the interplay between charge, rotation, and entropy.

Abstract: The thermodynamic properties of black holes have been extensively studied
through analogies with classical systems, revealing fundamental connections
between gravitation, entropy, and quantum mechanics. In this work, we extend
the thermodynamic framework of black holes by incorporating charge and
analyzing its role in entropy production. Using an analogy with charged
rotating soap bubbles, we demonstrate that charge contributes to the total
angular momentum and affects the entropy-event horizon relationship. By
applying the Gouy-Stodola theorem, we establish a consistent thermodynamic
formulation for charged black holes, showing that the first law of
thermodynamics remains valid in this context. Furthermore, we explore the
behavior of the partition function from the perspective of a distant observer,
revealing that charge effects diminish with increasing distance. These findings
reinforce the thermodynamic interpretation of black holes and provide insights
into the interplay between charge, rotation, and entropy in gravitational
systems.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [12] [Cavendish Tests of Millicharged Particles](https://arxiv.org/abs/2510.25825)
*Asher Berlin,Zachary Bogorad,Peter W. Graham,Harikrishnan Ramani*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A terrestrial population of room-temperature millicharged particles can arise
if they make up a dark matter subcomponent or if they are light enough to be
produced in cosmic ray air showers. In a companion paper, we showed that a
simple electrified shell acts as an efficient accumulator for such particles,
parametrically enhancing their local density by many orders of magnitude. Here
we demonstrate that Cavendish tests of Coulomb's Law, performed since the late
18th century, function as both quasistatic accumulators and detectors for this
overdensity. Reinterpretations of these past Cavendish tests thus provide some
of the strongest bounds on a terrestrial millicharge population. We also
propose surrounding a Cavendish test with an additional charged shell, which
significantly improves the sensitivity and can even enable detection of the
irreducible density of millicharged particles generated from cosmic rays. Using
decades-old technology, this can outperform future accelerator searches for
sub-GeV masses.

</details>


### [13] [Irreducible Bhabha background in the detection of muonium-antimuonium conversion](https://arxiv.org/abs/2510.25828)
*Mitrajyoti Ghosh,Kevin Liguori,Takemichi Okui,Kohsaku Tobioka*

Main category: hep-ph

TL;DR: The study evaluates a potential background in muonium-antimuonium conversion experiments, showing that Bhabha scattering could mimic signals for conversion rates below $10^{-18}$, but adding electron helicity measurements suppresses this to below $10^{-22}$.


<details>
  <summary>Details</summary>
Motivation: To assess and mitigate a background source (Bhabha scattering) that could fake antimuonium decay signals in experiments like MACS and MACE, ensuring accurate interpretation of muonium-antimuonium conversion probabilities.

Method: They calculated the scattering rate of Bhabha processes where $e^+$ and $e^-$ exchange energies, simulating how this mimics conversion events. They also modeled the impact of electron helicity measurements on reducing this background.

Result: The background exceeds the signal when conversion probabilities drop below $10^{-18}$ for MACE, but measuring electron helicity suppresses this background to below $10^{-22}$.

Conclusion: Helicity-based discrimination is essential for future high-sensitivity experiments targeting conversion rates below $10^{-22}$ to avoid false positives from Bhabha scattering.

Abstract: Experiments such as MACS and the proposed MACE study muonium-antimuonium
conversion by the energies of the final-state $e^\pm$. The $e^+$ and $e^-$ from
an antimuonium decay tend to be non-relativistic and relativistic,
respectively, and vice versa for muonium. However, these $e^\pm$ can exchange
their energies by hard Bhabha scattering, causing muonium to fake an
antimuonium decay signal. We compute the rate for this background and find
that, while negligible for MACE, it will become larger than the signal for
conversion probabilities less than $10^{-18}$. Measuring the helicity of the
$e^-$ will reduce this to $10^{-22}$.

</details>


### [14] [Electric Accumulation of Millicharged Particles](https://arxiv.org/abs/2510.25834)
*Asher Berlin,Zachary Bogorad,Peter W. Graham,Harikrishnan Ramani*

Main category: hep-ph

TL;DR: The paper proposes using electrified shells like Van de Graaff generators to accumulate millicharged particles, enhancing their density by 12 orders of magnitude, thereby improving detection sensitivity in experiments like Cavendish tests of Coulomb's law.


<details>
  <summary>Details</summary>
Motivation: To detect millicharged particles, which may exist as dark matter components or from cosmic ray showers, by leveraging their thermalization and accumulation in electrified environments, surpassing current accelerator search capabilities.

Method: Analyzing the thermalization of millicharged particles and modeling the efficiency of electrified shells in accumulating these particles. Applying this to Cavendish experiments to boost detection sensitivity.

Result: The electrified shell method parametrically increases particle density, enabling detection of millicharged particles with sensitivity surpassing future accelerator searches for sub-GeV masses.

Conclusion: This approach opens new parameter space exploration and offers a cost-effective alternative to accelerator-based experiments for studying millicharged particles.

Abstract: A terrestrial population of millicharged particles that interact
significantly with normal matter can arise if they make up a dark matter
subcomponent or if they are light enough to be produced in cosmic ray air
showers. Such particles thermalize to terrestrial temperatures through repeated
scatters with normal matter in Earth's environment. We show that a simple
electrified shell (e.g., a Van de Graaff generator) functions as an efficient
accumulator of such room-temperature millicharged particles, parametrically
enhancing their local density by as much as twelve orders of magnitude. This
can be used to boost the sensitivity of any detector housed in the shell's
interior, such as ion traps and tests of Coulomb's law. In a companion paper,
we apply this specifically to Cavendish tests of Coulomb's law, and show that a
well-established setup can probe a large region of unexplored parameter space,
with sensitivity to the irreducible density of millicharged particles generated
from cosmic rays that outperforms future accelerator searches for sub-GeV
masses.

</details>


### [15] [Determining (All) Dark Matter-Electron Scattering Rates From Material Properties](https://arxiv.org/abs/2510.25835)
*Yonit Hochberg,Majed Khalaf,Alessandro Lenoci,Rotem Ovadia*

Main category: hep-ph

TL;DR: The paper introduces a master formula linking dark matter-electron scattering rates to measurable material properties, extending beyond previous formalisms to include both spin-dependent and spin-independent interactions. It demonstrates new limits for light DM and highlights Praseodymium as a promising detector for sub-MeV DM.


<details>
  <summary>Details</summary>
Motivation: To generalize existing formalisms for dark matter interactions with electrons, enabling unified analysis of spin-dependent and spin-independent effects, and to explore novel targets for detecting sub-MeV dark matter.

Method: Derivation of a master formula connecting scattering rates to material properties (dielectric response, spin response functions), applying it to analyze existing data and propose Praseodymium as a detector due to its unique spin-dependent low-energy response.

Result: Shows spin-dependent dark matter rates depend solely on dielectric function, enabling new constraints; identifies Praseodymium's potential for sub-MeV DM detection via anisotropic spin response. Provides a framework for systematic target evaluation.

Conclusion: Advances dark matter detection strategies by unifying interaction analyses and introducing new material evaluation methods, enhancing prospects for discovering light/sub-MeV dark matter particles.

Abstract: We show that the scattering rate for any dark matter (DM) interaction with
electrons in any target is proportional to several measurable material
properties, encapsulated by a single master formula. This generalizes the
dielectric function formalism--developed for DM interactions that couple to
electron density--to any interaction, incorporating both spin-dependent and
spin-independent interactions simultaneously. This formalism links the full
many-body response of a target system to the DM probe in a clear and simple
form, providing a reliable event rate prediction from measurable material
quantities. We demonstrate the utility of our formalism by placing new limits
from existing data on a class of spin-dependent light DM interactions, as their
rates--contrary to common lore--are determined entirely by the dielectric
function. We further highlight a promising avenue for the detection of sub-MeV
DM using the rare earth metal Praseodymium, which exhibits a spin-dependent
anisotropic response down to the meV scale. Our results lay the groundwork for
a rapid systematic investigation of novel electron scattering targets going
beyond the classic spin-independent searches, enhancing the prospects for DM
detection.

</details>


### [16] [Deriving a parton shower for jet thermalization in QCD plasmas](https://arxiv.org/abs/2510.25837)
*Ismail Soudi,Adam Takacs*

Main category: hep-ph

TL;DR: The paper presents a novel parton-shower algorithm that accurately mimics linearized Effective Kinetic Theory (EKT) dynamics, addressing key limitations in current jet thermalization models by incorporating recoils, holes, quantum statistics, and merging processes.


<details>
  <summary>Details</summary>
Motivation: Existing jet quenching models rely on assumptions like rapid thermalization and simplified medium responses, while current Monte Carlo implementations of jet thermalization face challenges in treating recoils and particle merging. The motivation is to develop a first-principles approach that overcomes these limitations.

Method: The authors introduce a new parton-shower algorithm derived from linearized EKT to describe jet thermalization. This algorithm precisely incorporates recoils, hole effects, quantum statistics, and merging processes, bridging microscopic QCD understanding with practical simulations.

Result: The new algorithm provides a first-principles description of jet thermalization, overcoming previous challenges in MC implementations by exactly reproducing linearized EKT dynamics. This enables more accurate modeling of medium interactions in heavy-ion collisions.

Conclusion: The developed algorithm represents a step toward more precise, theory-grounded simulations of jet quenching, offering improved treatment of fundamental processes and paving the way for enhanced understanding of quark-gluon plasma dynamics.

Abstract: Jet quenching - the modification of high-energy jets in the quark-gluon
plasma - has been extensively studied through weakly coupled scattering
amplitudes embedded in parton-shower frameworks. These models, often combined
with bulk hydrodynamic evolution, successfully describe a wide range of
observables, though they typically rely on assumptions of rapid thermalization
and simplified treatments of medium response. Parallel to these developments,
jet thermalization has been investigated within the finite-temperature QCD
effective kinetic theory, which provides our best microscopic understanding of
equilibration in heavy-ion collisions. Early studies of linearized
perturbations have highlighted both the promise and the limitations of current
approaches, as existing MC implementations face challenges - particularly in
the treatment of recoils and particle merging. Building on this foundation, we
introduce a new parton-shower algorithm that exactly reproduces the dynamics of
the linearized EKT, enabling a first-principles description of jet
thermalization with proper inclusion of recoils, holes, quantum statistics, and
merging processes.

</details>


### [17] [A Mini Review of some Dark Matter/BSM Physics and a Bit More](https://arxiv.org/abs/2510.25877)
*Shmuel Nussinov*

Main category: hep-ph

TL;DR: The paper reviews various aspects of Dark Matter (DM) research, including cosmological foundations, Self-Interacting Dark Matter (SIDM) models, constraints on point-like DM particle masses, detection methods, and connections with beyond-Standard-Model (BSM) physics such as primordial black holes, neutrino sector extensions, ultra-light DM, and axions.


<details>
  <summary>Details</summary>
Motivation: To provide a comprehensive overview of current DM research topics, highlighting key theoretical frameworks, experimental constraints, and intersections with BSM physics.

Method: The paper employs a literature review approach, synthesizing existing studies in DM cosmology, particle physics models, and detection methodologies.

Result: Outlines potential directions for future research by identifying gaps in current understanding and emphasizing the importance of integrating cosmological observations with particle physics experiments.

Conclusion: Emphasizes the necessity of multidisciplinary approaches combining cosmology, particle physics, and experimental detection techniques to advance DM research and resolve unanswered questions.

Abstract: There is a vast literature on Dark Matter (DM) with many reviews of specific
topics only a small fraction of which will be mentioned. I start with a very
brief review of cosmology which underlies much of DM research and some relevant
General Relativity (GR). I next discuss Self Interacting Dark Matter (SIDM)
models and upper bounds on the mass M(X) of point-like, symmetric DM. This is
followed up by some general aspects of DM detection and directional and
temporal variations. I discuss DM models tied with BSM physics scenarios
including Primordial Black Holes, new physics in the neutrino sector,
ultra-light DM and axions.

</details>


### [18] [Precise predictions for joint polarisation fractions in WZ production at the LHC](https://arxiv.org/abs/2510.25898)
*Giovanni Pelliccioli,Rene Poncelet*

Main category: hep-ph

TL;DR: The authors achieved NNLO QCD + NLO EW precision for doubly polarized WZ production at the LHC in fully leptonic decays. They estimated missing QCD uncertainties using scale variations and a nuisance parameter approach, based on ATLAS Run-2 data setup.


<details>
  <summary>Details</summary>
Motivation: To attain higher precision in theoretical predictions for WZ production processes, which are crucial for testing Standard Model and searching for new physics at the LHC.

Method: Computed NNLO QCD and NLO EW corrections for doubly polarized WZ production. Used scale variations and theory-nuisance parameters to estimate higher-order uncertainties within ATLAS Run-2 fiducial experimental configuration.

Result: Provided precise cross-section predictions and uncertainty estimates for differential distributions and polarisation fractions in doubly polarised WZ production at the LHC.

Conclusion: The combined NNLO QCD+NLO EW calculation with uncertainty quantification provides a robust theoretical framework for analyzing ATLAS Run-2 data, enhancing precise SM tests and new physics sensitivity at the LHC.

Abstract: We achieve for the first time NNLO QCD + NLO EW accuracy for doubly polarised
WZ inclusive production at the LHC, in the case of fully leptonic decays.
Additionally, we provide estimates for missing higher-order uncertainties in
QCD associated with doubly polarised differential cross sections and joint
polarisation fractions, obtained both with standard scale variations and with a
theory-nuisance-parameter approach. The study is carried out in the fiducial
setup of a recent ATLAS analysis of Run-2 data.

</details>


### [19] [KM3-230213A and IceCube Neutrino Events from Metastable Dark Matter of Primordial Black Hole Origin](https://arxiv.org/abs/2510.26126)
*Prabhav Singh,Mansi Dhuria,Nathanael Varghese Job*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate a scenario in which the recently observed ultra-high-energy
neutrino event KM3-230213A, with a median energy of approximately 220 PeV, as
well as the high-energy neutrinos detected by IceCube Observatory, originate
from the decay of superheavy dark matter (DM) particles produced through
primordial black hole (PBH) evaporation. To establish this connection, we
derive constraints on the PBH abundance parameter $\beta$ as a function of the
initial PBH mass $M_{\mathrm{BH_0}}$ and DM mass $m_{\mathrm{DM}}$, by
considering the bound from the observed relic DM abundance. Using these
constraints, we compute the resulting neutrino flux and show that DM masses in
the PeV-EeV range can yield neutrinos of comparable energies, capable of
accounting for both the KM3-230213A and IceCube events while remaining
consistent with the relic abundance constraint. Interestingly, the scenario
remains viable over a broad region of parameter space while satisfying existing
cosmological and astrophysical bounds. Overall, our results demonstrate that
PBH evaporation followed by DM decay provides a consistent and natural
explanation for the observed ultra-high-energy neutrino events in the absence
of accompanying multimessenger signatures.

</details>


### [20] [Testing the type-II seesaw mechanism with gravitational waves](https://arxiv.org/abs/2510.26235)
*Yonghua Wang,Wei Chao*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Traditional seesaw mechanisms provide an elegant theoretical framework for
explaining the small yet non-zero masses of neutrinos. Nevertheless, they face
significant experimental challenges, primarily because the energy scale
associated with the seesaw mechanism is too high to be directly probed in
terrestrial experiments. In this paper, we explore the gravitational waves
(GWs) generated via graviton bremsstrahlung during the decay of seesaw
particles in the early Universe. Specifically, we compute the GW spectrum
resulting from the decay of the Higgs triplet within the type-II seesaw model.
Our results demonstrate that the resulting GW spectrum depends sensitively on
the mass of the Higgs triplet and its couplings to the Standard Model Higgs
doublet and the left-handed lepton doublet. The detection of such a
high-frequency GW background could offer a unique experimental window into the
seesaw mechanism and provide indirect evidence for its validity.

</details>


### [21] [MC-EKRT: Monte Carlo event generator with saturated minijet production for initializing 3+1 D fluid dynamics in high energy nuclear collisions](https://arxiv.org/abs/2510.26237)
*Harri Niemi,Jussi Auvinen,Kari J. Eskola,Henry Hirvonen,Yuuka Kanakubo,Mikko Kuha*

Main category: hep-ph

TL;DR: The paper introduces a new Monte Carlo implementation of the EKRT model for simulating QCD initial states in high-energy nuclear collisions, incorporating 3D event-by-event fluctuations and improved fluctuations in minijet production and saturation, while conserving energy-momentum and valence quark number.


<details>
  <summary>Details</summary>
Motivation: To address limitations in previous models regarding accurate representation of QCD initial states, particularly in terms of 3D spatial resolution, event-by-event fluctuations, and conservation laws, which are critical for understanding high-energy nuclear collision dynamics.

Method: A novel Monte Carlo method based on saturated and leading-order collinear factorization of the EKRT model. It includes 3D spatially dependent nuclear parton distributions, dynamical fluctuations in minijet production/saturation, and explicit conservation laws for energy-momentum and valence quark number.

Result: Provides a more realistic description of event-by-event initial states in heavy-ion collisions by incorporating detailed spatial fluctuations and improved conservation properties, which should enhance precision for comparing theoretical predictions with experimental data.

Conclusion: The developed framework offers significant advancements in modeling QCD initial states, providing a robust foundation for studying the quark-gluon plasma and related phenomena in high-energy nuclear physics experiments.

Abstract: We present a novel saturation and leading order collinear factorization based
Monte-Carlo implementation of the EKRT model for computing QCD matter initial
states in high-energy nuclear collisions. As new features the MC implementation
gives a full 3-dimensional initial state event-by-event, introduces new
event-by-event fluctuating spatially dependent nuclear parton distribution
functions, includes dynamical fluctuations in minijet production and
saturation, and accounts for the energy-momentum and valence-quark number
conservation.

</details>


### [22] [The signals of doomsday II: Cosmological signatures of late time $SU(3)_c$ symmetry breaking](https://arxiv.org/abs/2510.26267)
*Amartya Sengupta,Dejan Stojkovic,L. C. R. Wijewardhana*

Main category: hep-ph

TL;DR: The paper explores the potential future breaking of the SU(3)_c symmetry through cosmological observations, proposing a model with a new colored scalar field to study its observational signatures, such as photon and neutrino distributions from first-order phase transitions.


<details>
  <summary>Details</summary>
Motivation: To investigate whether the currently unbroken SU(3)_c and U(1)_{EM} symmetries might break in the future, which would have significant implications for the universe's structure and life as we know it.

Method: The model introduces a new colored scalar field with a potential supporting first-order phase transitions via true vacuum bubbles. The study calculates particle production due to vacuum mismatch, uses event generators for scalar/ gluon decays, and employs Pythia for hadronization to predict photon/neutrino distributions.

Result: The model predicts measurable photon and neutrino distributions as long-range signatures of SU(3)_c symmetry breaking, which could act as 'doomsday' signals if detected.

Conclusion: The observational prospects of detecting these signatures could provide evidence for future symmetry breaking events, though their occurrence remains uncertain without direct observation.

Abstract: The only two gauge symmetries which remain unbroken today are $SU(3)_c$ and
$U(1)_{EM}$. Both of them are crucial for our universe to appear the way it
does, and for our form of life to exist. Unless we are very special observers
living at the very end of the cosmological symmetry breaking chain, there is no
reason to believe that these two symmetries will remain unbroken in the future.
In this paper, we discuss cosmological observational signatures of the
$SU(3)_c$ symmetry breaking. We introduce a model with a new colored scalar
field whose potential supports the first order phase transition through
creation of the true vacuum bubbles. We then calculate particle production due
to vacuum mismatch and use the event generators to study the decays of the new
scalar field and massive gluons. We then use Pythia to hadronize the decay
products and get the distributions of produced photons and neutrinos as the
final result. They represent a long range signature which, if ever observed,
might be interpreted as the signals of the doomsday.

</details>


### [23] [Physical remnant of electroweak theta angles](https://arxiv.org/abs/2510.26281)
*James Brister,Bingwei Long,Longjie Ran,Muhammad Shahzad,Zheng Sun,Yingpei Zou*

Main category: hep-ph

TL;DR: The paper introduces a new theta angle in the Standard Model that is invariant under chiral rotations, distinct from the QCD theta angle and related to quantum electrodynamics, potentially observable in nontrivial spacetime topologies.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the presence of theta angles in the Standard Model beyond QCD and explore a chiral-invariant theta angle that could have observational implications.

Method: Analyzing the Standard Model's structure to identify a new theta angle unaffected by chiral rotations, linking it to QED and considering its behavior under topological spacetime conditions.

Result: Discovered a new theta angle invariant under chiral transformations, shown to align with the QED theta angle, which may be measurable in specific spacetime topologies.

Conclusion: This finding expands the Standard Model's parameter space, introduces a testable QED theta angle, and opens avenues for experimental detection in nontrivial topologies.

Abstract: In addition to the well-known quantum chromodynamical theta angle, we show
that the Standard Model has another theta angle which is invariant under
arbitrary chiral rotations of quarks and leptons. The new theta angle coincides
with the quantum electrodynamical theta angle which may be observable in a
nontrivial spacetime topology.

</details>


### [24] [Preparations for Quantum Computing in Hadron Physics](https://arxiv.org/abs/2510.26293)
*J. J. Gálvez-Viruet,F. J. Llanes-Estrada,M. Gómez-Rocha*

Main category: hep-ph

TL;DR: Quantum computing will revolutionize hadron physics by addressing challenges like sign problems in neutron-star matter, calculating fragmentation functions, quantum correlated Monte Carlo generation, entropy in jets, and Minkowski space time evolution, offering complementary solutions for excited hadron spectroscopy.


<details>
  <summary>Details</summary>
Motivation: To harness quantum computers' potential for ab-initio QCD-level hadron studies where classical methods fail, particularly in systems needing Minkowski time evolution or high chemical potentials, like neutron-star matter with sign problems.

Method: Explores applications such as solving lattice gauge theory sign issues via quantum computing, simulating quantum-correlated particle generation, and analyzing entropy production in jets, emphasizing complementary roles for complex systems like excited hadron spectroscopy.

Result: Highlights quantum computing's ability to tackle currently intractable QCD problems (sign problem, Minkowski evolution) while noting its role as a complementary tool for spectroscopy requiring large-scale computations.

Conclusion: Quantum computers will become essential in hadron physics over the next decade, enabling breakthroughs in dense matter, quantum correlations, and time-dependent processes, but will supplement rather than replace classical methods in some areas.

Abstract: Quantum computers are coming online and will quickly impact hadron physics
once certain fidelity, decoherence and memory thresholds are met, quite
possibly within a decade. We review a selected number of topics where ab-initio
QCD-level information about hadrons can be obtained with this computational
tool that is hard to come by from other methods. This includes high
baryon-density systems such as neutron-star matter (with a sign problem in
lattice gauge theory); fragmentation functions; Monte Carlo generation of
particles which accounts for quantum correlations in the final state; entropy
production in jets; and generally, any application where time evolution in
Minkowski space (as opposed to a Euclidean formulation) or where large chemical
potentials play an important dynamical role. For other problems, such as the
prediction of very highly excited hadron spectroscopy, they will not be a
unique, but a complementary tool.

</details>


### [25] [Study of neutrino spin oscillations in a gravitational field with a differential equations method](https://arxiv.org/abs/2510.26621)
*Mridupawan Deka,Maxim Dvornikov*

Main category: hep-ph

TL;DR: The paper investigates the consistency between the Ordinary Differential Equation (ODE) method and the integral Hamilton-Jacobi approach in studying neutrino spin oscillations during gravitational scattering by a rotating Kerr black hole.


<details>
  <summary>Details</summary>
Motivation: To compare and validate the two different methods (ODE vs. integral Hamilton-Jacobi) for analyzing neutrino oscillations in strong gravitational fields, ensuring accurate predictions in extreme astrophysical environments.

Method: The study applies the ODE solution method to model neutrino spin oscillations when neutrinos scatter off a Kerr black hole, contrasting it with the previously used integral solution of the Hamilton-Jacobi equation. They derive equations of motion and analyze discrepancies/concordance between methods.

Result: The ODE method aligns with the Hamilton-Jacobi integral approach under certain conditions, establishing their consistency. This validates both methods for future use in similar relativistic astrophysics contexts.

Conclusion: Both methods are consistent for describing neutrino spin oscillations in Kerr spacetime, providing reliability for theoretical models predicting particle behavior near rotating black holes.

Abstract: In this work, we employ Ordinary Differential Equation solution method to
study neutrino spin oscillations in the case when they are gravitationally
scattered off a rotating Kerr black hole. Previously, this problem involved the
integral solution of the Hamilton-Jacobi equation. We analyze the consistency
of these two methods.

</details>


### [26] [Electroweak corrections to doubly polarised WZ scattering at the LHC](https://arxiv.org/abs/2510.26462)
*Ansgar Denner,Robert Franken,Christoph Haitz,Daniele Lombardi,Giovanni Pelliccioli*

Main category: hep-ph

TL;DR: The paper calculates next-to-leading-order electroweak corrections for the vector-boson scattering (VBS) process involving leptonically decaying W and Z bosons with two jets at the LHC. It considers both polarized and unpolarized intermediate bosons, using the pole approximation and helicity state separation in amplitudes. Results are analyzed phenomenologically for 13.6 TeV LHC conditions, showing distinct patterns in polarisation states. This aids in characterizing the spin structure of VBS processes with full LHC data.


<details>
  <summary>Details</summary>
Motivation: To provide precise theoretical predictions for VBS processes necessary for understanding the spin structure and enhancing the analysis of LHC data, accounting for electroweak corrections which are crucial for high-precision physics at the LHC.

Method: The calculation employs next-to-leading-order electroweak corrections, considering polarized and unpolarized intermediate bosons. The pole approximation and helicity amplitude decomposition are used at both tree-level and one-loop levels. A phenomenological analysis is performed under realistic LHC conditions (13.6 TeV) to study differential and integrated cross-sections for various polarisation states.

Result: The study reveals different phenomenological patterns in cross-section distributions for different polarisation states of intermediate bosons. These results offer essential theoretical inputs for accurately interpreting LHC data and characterizing the spin structure of VBS processes.

Conclusion: The presented calculations are vital for precise theoretical modeling of VBS processes, enabling better Spin structure characterization with current LHC data. This work underscores the importance of including electroweak corrections for high-precision physics analyses at hadron colliders.

Abstract: We present a calculation of next-to-leading-order electroweak corrections to
the vector-boson scattering (VBS) process resulting in leptonically decaying W
and Z bosons in association with two jets at the LHC. The VBS process is
computed for both polarised and unpolarised intermediate bosons, exploiting the
pole approximation and the separation of helicity states in tree-level and
one-loop amplitudes. A phenomenological analysis is carried out for a realistic
fiducial setup at a 13.6 TeV LHC collision energy, highlighting different
patterns for the various polarisation states both at integrated and at
differential level. This study provides theoretical predictions that are
necessary to perform a sound characterisation of the spin structure of VBS
processes with full LHC data.

</details>


### [27] [An extraction of the Collins-Soper kernel from a joint analysis of experimental and lattice data](https://arxiv.org/abs/2510.26489)
*Artur Avkhadiev,Valerio Bertone,Chiara Bissolotti,Matteo Cerutti,Yang Fu,Simone Rodini,Phiala Shanahan,Michael Wagman,Yong Zhao*

Main category: hep-ph

TL;DR: The paper introduces a joint extraction method for the Collins-Soper kernel using both experimental and lattice QCD data in TMD analysis. By applying neural network parametrization and Bayesian reweighting, the inclusion of lattice data shifts the CSK central value by ~10% and reduces uncertainty by 40-50%, demonstrating lattice data's utility in enhancing TMD extractions.


<details>
  <summary>Details</summary>
Motivation: The motivation is to improve the accuracy and reliability of transverse-momentum-dependent distributions (TMDs) by incorporating lattice QCD data, which has been underutilized in prior TMD fits. This approach aims to reduce uncertainties and refine kernel extractions critical for high-energy physics analyses.

Method: The method involves a neural-network parametrization combined with Bayesian reweighting of existing TMD fits using lattice data. A joint fit to both lattice and experimental data is performed to extract the Collins-Soper kernel.

Result: Inclusion of lattice data shifts the central value of the CSK by approximately 10% and reduces its uncertainty by 40-50% compared to fits using only experimental data.

Conclusion: The study concludes that lattice QCD data significantly enhances the precision of TMD extractions, suggesting future analyses should prioritize integrating such data to achieve more accurate results.

Abstract: We present a first joint extraction of the Collins-Soper kernel (CSK)
combining experimental and lattice QCD data in the context of an analysis of
transverse-momentum-dependent distributions (TMDs). Based on a neural-network
parametrization, we perform a Bayesian reweighting of an existing fits of TMDs
using lattice data, as well as a joint TMD fit to lattice and experimental
data. We consistently find that the inclusion of lattice information shifts the
central value of the CSK by approximately 10% and reduces its uncertainty by
40-50%, highlighting the potential of lattice inputs to improve TMD
extractions.

</details>


### [28] [The $φp$ bound state in the unitary coupled-channel approximation](https://arxiv.org/abs/2510.26517)
*Bao-Xi Sun,Ying-Ying Fan,Qin-Qin Cao*

Main category: hep-ph

TL;DR: The ALICE Collaboration's study on phi meson-proton interactions reveals an intriguing two-pole structure in scattering amplitudes, indicating potential phi N resonance and bound states not yet recognized by PDG.


<details>
  <summary>Details</summary>
Motivation: To investigate the phi p scattering processes, clarify the roles of elastic vs inelastic interactions, and explore the implications of an attractive interaction between phi mesons and protons.

Method: Unitary coupled-channel approximation based on the Bethe-Salpeter equation was employed to compute scattering length parameters and analyze scattering amplitudes.

Result: Experimental scattering length data required incorporating an attractive interaction, leading to two poles in the scattering amplitude: a resonance (~1969-i283 MeV) and a bound state (~1949-i3 MeV), both not listed in PDG.

Conclusion: The observed phi N structures suggest new states requiring further experimental validation, highlighting the importance of the attractive phi N interaction in nuclear dynamics.

Abstract: The attractive interaction of the $\phi$ meson and the proton is reported by
the ALICE Collaboration, and the corresponding scattering length $f_0$ is given
as $Re(f_0)=0.85\pm0.34(stat)\pm0.14(syst)$ fm and
$Im(f_0)=0.16\pm0.10(stat)\pm0.09(syst)$ fm. The fact that the real part is
significant in contrast to the imaginary part indicates a dominating role of
the elastic scattering, whereas the inelastic process is less important. In
this work, such scattering processes are inspected on the basis of a unitary
coupled-channel approximation inspired by the Bethe-Salpeter equation. The
$\phi p$ scattering length is calculated and it is found that the experimental
value of the $\phi p$ scattering length can be obtained only if the attractive
interaction of the $\phi$ meson and the proton is taken into account. A
significant outcome of such an attractive interaction is a two-pole structure
in the scattering amplitude. One of the poles, located at $1969-i283$ MeV,
might be a resonance state of $\phi N$, while the other pole, located at
$1949-i3$ MeV, should be a bound state of $\phi N$. Both of these states do not
have counterparts in the data of the Particle Data Group(PDG).

</details>


### [29] [A New Probe for Long-Lived Particles at Higgs Factories: Displaced Photons in the Hadronic Calorimeter](https://arxiv.org/abs/2510.26649)
*Zhicheng Jiang,Hengne Li,Jin-Han Liang*

Main category: hep-ph

TL;DR: The paper introduces a new method to detect dark matter and long-lived particles (LLPs) by searching for displaced photons in the hadronic calorimeter at electron-positron colliders, overcoming background issues from standard mono-photon signatures.


<details>
  <summary>Details</summary>
Motivation: To address the overwhelming background from $e^+e^- 	o 
uar{
u}
uar{
u}ar{
u}
u$ processes at the $Z$-pole, which limits the effectiveness of conventional mono-photon signatures in dark matter/LLP searches.

Method: Proposes detecting displaced photons produced by LLP decays within the barrel section of the hadronic calorimeter, utilizing the detector's shielding to reduce background contamination.

Result: Demonstrates improved sensitivity to LLPs with decay lengths ranging from ~1 to $10^6$ meters, surpassing traditional search methods by up to an order of magnitude in benchmark models.

Conclusion: The novel calorimeter-based displaced photon signature offers a compelling background-free approach for LLP detection at future Higgs factories.

Abstract: The search for dark matter and other photon-portal long-lived particles
(LLPs) at electron-positron colliders often relies on the mono-photon
signature. At future Higgs factories operating at the $Z$-pole, this approach
faces a critical challenge: the irreducible background from $e^+e^- \to
\nu\bar{\nu}\gamma$ becomes overwhelming. We propose a novel strategy that
overcomes this limitation by searching for displaced photons from LLP decays
within the barrel of the hadronic calorimeter. This signature exploits the
architectural shielding of the detector to create a nearly background-free
environment. Our analysis demonstrates exceptional sensitivity to LLPs with
decay lengths from $\sim$1 to $10^6$ meters, improving upon conventional
searches by up to one order of magnitude for benchmark photon-portal models.

</details>


### [30] [QED corrections to bound-muon decays from an effective-field-theory framework](https://arxiv.org/abs/2510.26698)
*Duarte Fontes,Robert Szafron*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Bound-muon decays are a powerful probe of new physics, making precise
theoretical predictions for their spectra essential. While QED corrections
significantly affect the shape of the spectra, their calculation is extremely
challenging below the nuclear scale. By exploring the universality of modern
effective-field-theory techniques, we present a framework that systematically
computes those corrections across a broad class of bound-muon decays. As a key
application, we provide the most accurate predictions to date for the signal
and background spectra in muon conversion. We show that radiative corrections
modify the leading-order ratio of these spectra by $5\%$ with minimal energy
dependence, a result relevant for enhancing the discovery reach of upcoming
experiments. Our framework also represents a crucial step toward connecting
high-energy physics to low-energy observables, complementing recent progress
above the muon mass scale.

</details>


### [31] [Robust extraction of power corrections and nuclear dynamics from DIS at large $x$](https://arxiv.org/abs/2510.26729)
*Alberto Accardi,Matteo Cerutti*

Main category: hep-ph

TL;DR: The paper discusses updates to the CTEQ-JLab global PDF analysis (CJ22ht), incorporates full JLab 6 GeV datasets in a DIS database, presents preliminary CJ25 results with early JLab 12 GeV data, and explores future prospects for understanding nuclear/partonic dynamics in light nuclei.


<details>
  <summary>Details</summary>
Motivation: To improve precision in PDF determinations by addressing systematic uncertainties (HT/offshell corrections), integrating new experimental data, and evaluating how future measurements can uncover nuclear/partonic interactions in light nuclei.

Method: The CJ25 analysis uses a global PDF fitting framework incorporating HT correction systematics, offshell effects, and comprehensive DIS databases. It includes JLab 6/12 GeV data to constrain PDFs, particularly for light nuclei.

Result: CJ25 shows enhanced PDF precision with reduced uncertainties from updated datasets and correction implementations. Early JLab 12 GeV data highlight nontrivial nuclear effects, suggesting deeper insights into partonic structure.

Conclusion: Improved PDFs from CJ25 provide better constraints on nuclear dynamics. Future 12 GeV data will be critical for resolving remaining uncertainties and exploring novel aspects of light nucleus structure.

Abstract: We present recent updates from the CTEQ-JLab (CJ) global PDF analysis,
focusing on the interplay and implementation systematics of the HT and offshell
correction (CJ22ht). We also discuss preliminary results of the CJ25 global
analysis, showing the impact of the full JLab 6 GeV datasets, that we recently
collected in a comprehensive DIS database, and having a first look at early
JLab 12 GeV measurements. We finally offer a few thoughts on how future data
may help unraveling the nuclear and partonic dynamics in light nuclei.

</details>


### [32] [Vector dark matter with non-abelian kinetic mixing](https://arxiv.org/abs/2510.26765)
*Ana Luisa Foguel,Renata Zukanovich Funchal,Michele Frigerio*

Main category: hep-ph

TL;DR: The paper proposes a minimal model of dark matter based on a light hidden sector with vector boson dark matter and a dark photon mediator, coupled to the Standard Model via kinetic mixing. It explores mechanisms for generating the observed dark matter abundance and discusses experimental constraints on the model parameters.


<details>
  <summary>Details</summary>
Motivation: To address the dark matter puzzle with a minimal framework that includes light hidden sectors feebly coupled to the Standard Model through light mediators, ensuring naturalness and testability with current experiments.

Method: A model with vector dark matter (X±) and a dark photon (Z_D) of equal mass interacting via kinetic mixing with hypercharge. Computational predictions for relic density via freeze-out/in, analysis of 3-to-2 annihilations, and comparison with experimental/astrophysical constraints.

Result: Successful reproduction of observed dark matter abundance through various mechanisms, identification of viable parameter regions surviving current bounds, and prediction of distinct experimental signals linking dark photon and dark matter sectors.

Conclusion: The proposed model offers a viable and predictive framework explaining dark matter while remaining consistent with observations. Future collider and direct detection experiments could test key model predictions, especially involving dark photon interactions.

Abstract: An appealing framework for dark matter is provided by light hidden sectors,
below the electroweak scale, feebly coupled to the Standard Model via light
mediators. We consider a minimal, predictive model where both the dark matter
and the mediator are vector bosons, and have the same mass. The portal between
the dark sector and the Standard Model is provided by a kinetic mixing between
the dark gauge symmetry, $SU(2)_X$, and the hypercharge, $U(1)_Y$, induced by a
dimension-six operator. The dark-matter candidates, $X^\pm$, are charged under
a custodial symmetry and therefore stable, while the mediator is a massive dark
photon, $Z_D$, mixing with the photon and the $Z$. We show how the observed
dark-matter abundance can be reproduced via freeze-out or freeze-in, through
either the kinetic mixing or the dark gauge interaction. We also analyse dark
3-to-2 annihilations, that can become dominant in model variations with $Z_D$
heavier than $X^\pm$. We confront our relic-density predictions with current
and projected experimental, astrophysical and cosmological bounds on the model
parameter space, highlighting the correlation between the dark-photon and
dark-matter phenomenologies.

</details>


### [33] [Automated event generation for S-wave quarkonium and leptonium production in NRQCD and NRQED](https://arxiv.org/abs/2510.26773)
*Alice Colpani Serri,Chris A. Flett,Jean-Philippe Lansberg,Olivier Mattelaer,Hua-Sheng Shao,Lukas Simon*

Main category: hep-ph

TL;DR: Presents an extension to MadGraph5_aMC@NLO for automated S-wave quarkonium/leptonum production calculations in NRQCD/NRQED, validated with benchmarks and compatible with BSM/EFT scenarios.


<details>
  <summary>Details</summary>
Motivation: Enable automated leading-order cross section calculations for quarkonium/leptononium production using NRQCD/NRQED, addressing challenges in theoretical predictions due to subleading contributions.

Method: Framework extension integrating NRQCD/NRQED factorization, modified UFO interface for BSM/EFT, and compatibility with Monte Carlo generators for parton showering.

Result: Validated against benchmarks, shows robustness/flexibility; demonstrates necessity of careful theoretical consideration beyond simple coupling/velocity scaling.

Conclusion: Framework provides essential tool for phenomenological studies, emphasizing complexity of quarkonium processes requiring nuanced analysis beyond basic scaling arguments.

Abstract: We present an extension of the MadGraph5_aMC@NLO framework that enables the
automated calculation of leading-order cross sections for S-wave quarkonium and
leptonium production within the non-relativistic QCD (NRQCD) and
non-relativistic QED (NRQED) factorisation formalisms. The framework has been
validated against a variety of benchmark processes, demonstrating robustness
and flexibility for phenomenological studies. A key advantage of this
implementation is its seamless integration with existing MadGraph5_aMC@NLO
features, allowing computations not only within the Standard Model but also in
a wide range of Beyond the Standard Model or Effective Field Theory scenarios
via a modified Universal Feynman Output (UFO) interface. Furthermore, the
framework maintains compatibility with standard Monte Carlo event generators
for parton showering and hadronisation. Through numerous examples, we highlight
that theoretical studies of quarkonium processes require careful consideration:
the impact of subleading contributions is often difficult to predict using
simple counting arguments based solely on the hierarchy of couplings and
velocity-scaling rules.

</details>


### [34] [Determination of the initial condition for the Balitsky-Kovchegov equation with transformers](https://arxiv.org/abs/2510.26779)
*Meisen Gao,Zhong-Bo Kang,Jani Penttala,Ding Yu Shao*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In the high-energy limit of QCD, scattering off nucleons and nuclei can be
described in terms of Wilson-line correlators whose energy dependence is
perturbative. The energy dependence of the two-point correlator, called the
dipole amplitude, is governed by the Balitsky-Kovchegov (BK) equation. The
initial condition for the BK equation can be fitted to the experimental data,
which requires evolving the dipole amplitude for a large set of different
parameter values. In this work, we train a transformer model to learn the
energy dependence of the dipole amplitude, skipping the time-consuming
numerical evaluation of the BK equation. The transformer predicts the learned
dipole amplitude and the leading order inclusive deep inelastic scattering
cross section very accurately, allowing for efficient fitting of the initial
condition to the experimental data. Using this setup, we fit the initial
condition of the BK equation to the inclusive deep inelastic scattering data
from HERA and consider two different starting points $x_0$ for the evolution.
We find better agreement with the experimental data for a smaller $x_0$. This
work paves the way for future studies involving global fits of the dipole
amplitude at leading order and beyond.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [35] [Demystifying flux eruptions: Magnetic flux transport in magnetically arrested disks](https://arxiv.org/abs/2510.25842)
*Jonatan Jacquemin-Ide,Mitchell C. Begelman,Beverly Lowell,Matthew Liska,Jason Dexter,Alexander Tchekhovskoy*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Magnetically arrested disks (MADs) are a compelling model for explaining
variability in low-luminosity active galactic nuclei (AGN), including
horizon-scale outbursts like those observed in Sagittarius A*. MADs experience
powerful flux eruptions-episodic ejections of magnetic flux from the black hole
horizon-that may drive the observed luminosity variations. In this work, we
develop and validate a new formalism describing large-scale magnetic field
transport in general relativistic magnetohydrodynamic simulations of MADs with
geometrical thicknesses of $h/R=0.1$ and $h/R=0.3$. We introduce a net flux
transport velocity, $v_\Phi$, which accounts for both advective and diffusive
processes. We show that MADs maintain a statistical quasi-steady state where
advection and diffusion nearly balance. Flux eruptions appear as small
deviations from this equilibrium, with $v_\Phi/V_k\ll1$, where $V_k$ is the
local Keplerian velocity. Using this framework, we analytically derive a
recurrence timescale for flux eruptions, $t_{\rm rec}\sim1500\, r_g/c$. This
timescale closely matches simulation results. The smallness of $v_\Phi$
explains the long recurrence times of flux eruptions compared to other system
timescales. We also take a closer look at the diffusion of the magnetic field
by performing the first measurement of turbulent resistivity in MADs. We then
estimate the turbulent magnetic Prandtl number, defined as the ratio of
turbulent viscosity to turbulent resistivity. We find $\mathcal{P}_m\sim3$,
consistent with shearing-box simulations of magneto rotational
instability-driven turbulence. While flux eruptions excite large-scale
non-axisymmetric modes and locally enhance turbulent resistivity, magnetic
field diffusion is dominated by smaller-scale turbulent motions. These results
provide new insight into the nature of AGN variability and the fundamental
physics of magnetic field transport.

</details>


### [36] [25 Years of Groundbreaking Discoveries with Chandra](https://arxiv.org/abs/2510.25873)
*Patrick Slane,Ákos Bogdán,David Pooley*

Main category: astro-ph.HE

TL;DR: Chandra X-ray Observatory provides unique insights into high-energy astrophysical phenomena through its high-resolution X-ray imaging and spectroscopy, contributing significantly to understanding compact objects, supernovae, black hole jets, and exoplanet atmospheres.


<details>
  <summary>Details</summary>
Motivation: The motivation is to leverage Chandra's unmatched X-ray capabilities to study critical astrophysical processes and phenomena that are inaccessible to other observatories.

Method: The method involves utilizing Chandra's high angular resolution (0.5-10 keV band) for imaging and spectral analysis to observe compact objects, supernova remnants, active galactic nuclei jets, and exoplanetary systems subjected to stellar flares.

Result: Key results include breakthroughs in the role of compact objects in galaxy evolution, mechanisms of supernova explosions, environmental impacts of supermassive black hole jets, and atmospheric erosion in exoplanets due to stellar flares.

Conclusion: The conclusion highlights Chandra's enduring scientific value, underscoring its past achievements and promising future in advancing high-energy astrophysics despite the mission's longevity.

Abstract: The Chandra X-ray Observatory is a mainstay of modern observational
astrophysics. With the highest angular resolution of any X-ray facility, its
imaging and spectral capabilities in the 0.5-10 keV band have led to both
unique and complementary breakthroughs in nearly all areas of the field. Now
more than a quarter century into its mission, Chandra continues to provide
unique information on the contributions of compact objects to the evolution of
galaxies, the nature of supernova explosions, the impact of energetic jets from
supermassive black holes on their host environments, and the fate of exoplanet
atmospheres in systems rich with stellar flares. Here we provide a summary of
Chandra results - one that is embarrassingly incomplete, but representative of
both the exquisite past and promising future for Chandra's contributions to
high energy astrophysics and all of mainstream astronomy.

</details>


### [37] [Gravitational-Wave Constraints on Neutron-Star Pressure Anisotropy via Universal Relations](https://arxiv.org/abs/2510.26042)
*Victor Guedes,Siddarth Ajith,Shu Yan Lau,Kent Yagi*

Main category: astro-ph.HE

TL;DR: This paper analyzes how pressure anisotropy affects neutron star properties like tidal deformability and f-mode oscillations, showing that anisotropy-dependent universal relations allow constraints on anisotropy parameters using gravitational wave data from GW170817 and future detectors.


<details>
  <summary>Details</summary>
Motivation: To understand the impact of pressure anisotropy caused by phenomena like magnetism and superfluidity on neutron star properties and constrain anisotropy parameters using observational data.

Method: Applied a phenomenological quasi-local anisotropy model with a single parameter to compute tidal deformability and f-mode frequencies, then used GW170817 data and simulations in a statistical framework to constrain the anisotropy parameter.

Result: Found that the anisotropy parameter can be constrained to within order unity with current data, with future detectors showing similar bounds, and the results are insensitive to equation of state uncertainties.

Conclusion: Pressure anisotropy parameters in neutron stars can be statistically constrained using gravitational wave observations, offering insights into internal neutron star structures independent of EOS uncertainties.

Abstract: Neutron stars may exhibit pressure anisotropy arising from various physical
mechanisms, such as elasticity, magnetic fields, viscosity, and superfluidity.
We compute the tidal deformability and the $f$-mode oscillation frequency of
anisotropic neutron stars using a phenomenological quasi-local model
characterized by a single dimensionless anisotropy parameter. We find that
while the relation between the tidal deformability and the $f$-mode frequency
depends on the degree of anisotropy, it remains largely insensitive to
variations in the equation of state (the relation between radial pressure and
energy density) for a fixed anisotropy parameter, similar to the isotropic
case. Leveraging this anisotropy-dependent universal relation within a
statistical framework, we place constraints on the anisotropy parameter using
both the gravitational wave observation of GW170817 and simulated data for a
GW170817-like event observed by a future network of detectors. We find that the
anisotropy parameter can be constrained to order unity with current data, and
the bounds remain comparable with future detector sensitivities. Importantly,
these constraints are only weakly affected by uncertainties in the neutron-star
equation of state.

</details>


### [38] [Accretion rates of stellar-mass compact objects embedded in AGN discs](https://arxiv.org/abs/2510.26111)
*Cheng-Liang Jiao,Liying Zhu,Er-gang Zhao,Jia Zhang*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Stellar-mass compact objects (COs) embedded in active galactic nucleus (AGN)
discs are commonly assumed to accrete via Bondi or Bondi-Hoyle-Lyttleton (BHL)
prescriptions, neglecting gas angular momentum. We show that differential
rotation in AGN discs can impart non-negligible angular momentum, in which case
accretion proceeds through a viscous disc rather than Bondi/BHL flow. Our model
provides a new framework estimating the CO accretion rate as
$\dot{M}_\mathrm{CO} = \min\{\dot{M}_\mathrm{vis}, \dot{M}_\mathrm{BHL}\}$,
where the viscous rate $\dot{M}_\mathrm{vis}$ accounts for gas--CO relative
motion decomposed into a local gradient term (due to differential rotation) and
bulk motion (from differing orbital parameters). This rate can be expressed as
$\dot{M}_\mathrm{vis} = \alpha \xi
(r_\mathrm{H}/r_\mathrm{BHL})^3\dot{M}_\mathrm{BHL}$, where $\xi$ is a
coefficient of order unity. It can also be approximately scaled to the global
AGN accretion rate as $\dot{M}_\mathrm{vis} \propto \dot{M}_1$, with the
scaling coefficients in both forms determined by the specific dynamical
configuration. The accretion is viscosity-limited when $q > [\alpha
\xi(1+\mathcal{M}^2)^{3}/3]^{1/2} h^3$, where $q$ is the mass ratio between the
CO and the supermassive black hole, $\alpha$ the viscosity parameter,
$\mathcal{M}$ the Mach number of the bulk relative motion, and $h$ the aspect
ratio of the AGN disc. In thin AGN discs this condition is satisfied for most
stellar-mass or more massive COs. Our framework also naturally allows for the
inclusion of established outflow corrections, thereby enabling a more realistic
treatment of super-Eddington flows. Our formulation thus improves upon
Bondi/BHL prescriptions and offers a more physically motivated basis for
studying CO evolution in AGN environments.

</details>


### [39] [Evidence of cosmic-ray acceleration up to sub-PeV energies in the supernova remnant IC 443](https://arxiv.org/abs/2510.26112)
*Zhen Cao,F. Aharonian,Y. X. Bai,Y. W. Bao,D. Bastieri,X. J. Bi,Y. J. Bi,W. Bian,A. V. Bukevich,C. M. Cai,W. Y. Cao,Zhe Cao,J. Chang,J. F. Chang,A. M. Chen,E. S. Chen,G. H. Chen,H. X. Chen,Liang Chen,Long Chen,M. J. Chen,M. L. Chen,Q. H. Chen,S. Chen,S. H. Chen,S. Z. Chen,T. L. Chen,X. B. Chen,X. J. Chen,Y. Chen,N. Cheng,Y. D. Cheng,M. C. Chu,M. Y. Cui,S. W. Cui,X. H. Cui,Y. D. Cui,B. Z. Dai,H. L. Dai,Z. G. Dai,Danzengluobu,Y. X. Diao,X. Q. Dong,K. K. Duan,J. H. Fan,Y. Z. Fan,J. Fang,J. H. Fang,K. Fang,C. F. Feng,H. Feng,L. Feng,S. H. Feng,X. T. Feng,Y. Feng,Y. L. Feng,S. Gabici,B. Gao,C. D. Gao,Q. Gao,W. Gao,W. K. Gao,M. M. Ge,T. T. Ge,L. S. Geng,G. Giacinti,G. H. Gong,Q. B. Gou,M. H. Gu,F. L. Guo,J. Guo,X. L. Guo,Y. Q. Guo,Y. Y. Guo,Y. A. Han,O. A. Hannuksela,M. Hasan,H. H. He,H. N. He,J. Y. He,X. Y. He,Y. He,S. Hernández-Cadena,B. W. Hou,C. Hou,X. Hou,H. B. Hu,S. C. Hu,C. Huang,D. H. Huang,J. J. Huang,T. Q. Huang,W. J. Huang,X. T. Huang,X. Y. Huang,Y. Huang,Y. Y. Huang,X. L. Ji,H. Y. Jia,K. Jia,H. B. Jiang,K. Jiang,X. W. Jiang,Z. J. Jiang,M. Jin,S. Kaci,M. M. Kang,I. Karpikov,D. Khangulyan,D. Kuleshov,K. Kurinov,B. B. Li,Cheng Li,Cong Li,D. Li,F. Li,H. B. Li,H. C. Li,Jian Li,Jie Li,K. Li,L. Li,R. L. Li,S. D. Li,T. Y. Li,W. L. Li,X. R. Li,Xin Li,Y. Li,Y. Z. Li,Zhe Li,Zhuo Li,E. W. Liang,Y. F. Liang,S. J. Lin,B. Liu,C. Liu,D. Liu,D. B. Liu,H. Liu,H. D. Liu,J. Liu,J. L. Liu,J. R. Liu,M. Y. Liu,R. Y. Liu,S. M. Liu,W. Liu,X. Liu,Y. Liu,Y. Liu,Y. N. Liu,Y. Q. Lou,Q. Luo,Y. Luo,H. K. Lv,B. Q. Ma,L. L. Ma,X. H. Ma,J. R. Mao,Z. Min,W. Mitthumsiri,G. B. Mou,H. J. Mu,A. Neronov,K. C. Y. Ng,M. Y. Ni,L. Nie,L. J. Ou,P. Pattarakijwanich,Z. Y. Pei,J. C. Qi,M. Y. Qi,J. J. Qin,A. Raza,C. Y. Ren,D. Ruffolo,A. Sáiz,D. Semikoz,L. Shao,O. Shchegolev,Y. Z. Shen,X. D. Sheng,Z. D. Shi,F. W. Shu,H. C. Song,Yu. V. Stenkin,V. Stepanov,Y. Su,D. X. Sun,H. Sun,Q. N. Sun,X. N. Sun,Z. B. Sun,N. H. Tabasam,J. Takata,P. H. T. Tam,H. B. Tan,Q. W. Tang,R. Tang,Z. B. Tang,W. W. Tian,C. N. Tong,L. H. Wan,C. Wang,G. W. Wang,H. G. Wang,J. C. Wang,K. Wang,Kai Wang,Kai Wang,L. P. Wang,L. Y. Wang,L. Y. Wang,R. Wang,W. Wang,X. G. Wang,X. J. Wang,X. Y. Wang,Y. Wang,Y. D. Wang,Z. H. Wang,Z. X. Wang,Zheng Wang,D. M. Wei,J. J. Wei,Y. J. Wei,T. Wen,S. S. Weng,C. Y. Wu,H. R. Wu,Q. W. Wu,S. Wu,X. F. Wu,Y. S. Wu,S. Q. Xi,J. Xia,J. J. Xia,G. M. Xiang,D. X. Xiao,G. Xiao,Y. L. Xin,Y. Xing,D. R. Xiong,Z. Xiong,D. L. Xu,R. F. Xu,R. X. Xu,W. L. Xu,L. Xue,D. H. Yan,T. Yan,C. W. Yang,C. Y. Yang,F. F. Yang,L. L. Yang,M. J. Yang,R. Z. Yang,W. X. Yang,Z. H. Yang,Z. G. Yao,X. A. Ye,L. Q. Yin,N. Yin,X. H. You,Z. Y. You,Q. Yuan,H. Yue,H. D. Zeng,T. X. Zeng,W. Zeng,X. T. Zeng,M. Zha,B. B. Zhang,B. T. Zhang,C. Zhang,F. Zhang,H. Zhang,H. M. Zhang,H. Y. Zhang,J. L. Zhang,Li Zhang,P. F. Zhang,P. P. Zhang,R. Zhang,S. R. Zhang,S. S. Zhang,W. Y. Zhang,X. Zhang,X. P. Zhang,Yi Zhang,Yong Zhang,Z. P. Zhang,J. Zhao,L. Zhao,L. Z. Zhao,S. P. Zhao,X. H. Zhao,Z. H. Zhao,F. Zheng,W. J. Zhong,B. Zhou,H. Zhou,J. N. Zhou,M. Zhou,P. Zhou,R. Zhou,X. X. Zhou,X. X. Zhou,B. Y. Zhu,C. G. Zhu,F. R. Zhu,H. Zhu,K. J. Zhu,Y. C. Zou,X. Zuo*

Main category: astro-ph.HE

TL;DR: The study presents LHAASO observations of SNR IC 443, detecting gamma-ray emission from a point source (up to ~30 TeV with no cutoff) and an extended source. Hadronic models suggest proton acceleration up to ~300 TeV (sub-PeV), supporting SNRs as PeV cosmic ray accelerators.


<details>
  <summary>Details</summary>
Motivation: To address uncertainties in the maximum energy of particles accelerated by SNR shocks and clarify SNRs' role in producing CRs at PeV energies.

Method: Used LHAASO to observe high-energy gamma-rays from IC 443. Analyzed morphology and spectra, comparing with Fermi-LAT data. Evaluated hadronic/leptonic models for emission origins.

Result: Detected a point source matching Fermi-LAT's π⁰-decay signature and an extended source not seen by Fermi-LAT. Point source spectrum follows a power-law to ~30 TeV; hadronic model indicates protons up to 300 TeV. Extended source has dual model explanations.

Conclusion: SNRs like IC 443 can accelerate protons to sub-PeV energies, providing observational support for their role in cosmic ray acceleration up to PeV scales.

Abstract: Supernova remnants (SNRs) have been considered as the primary contributors to
cosmic rays (CRs) in our Galaxy. However, the maximum energy of particles that
can be accelerated by shocks of SNRs is uncertain observationally and
theoretically, and the role of contribution to CRs around PeV energies by SNRs
is unclear. In this study, we present observations of high-energy $\gamma$-ray
emission from the SNR IC 443 using the Large High Altitude Air Shower
Observatory (LHAASO). The morphological analysis reveals a pointlike source
whose location and spectrum are consistent with those of the Fermi-LAT-detected
compact source with $\pi^0$-decay signature, and a more extended source which
is consistent with a newly discovered source, previously unrecognized by
Fermi-LAT. The spectrum of the point source can be described by a power-law
function with an index of $\sim3.0$, extending beyond $\sim 30$ TeV without
apparent cutoff. Assuming a hadronic origin of the $\gamma$-ray emission, the
$95\%$ lower limit of accelerated protons reaches about 300 TeV. The extended
source might be coincident with IC 443, SNR G189.6+3.3 or the putative pulsar
wind nebula CXOU J061705.3+222127, and can be explained by either a hadronic or
leptonic model. The LHAASO results provide compelling evidence that CR protons
up to sub-PeV energies can be accelerated by the SNR.

</details>


### [40] [Direct Numerical Simulations of Oxygen-Flame-Driven Deflagration-to-Detonation Transition in Type Ia Supernovae](https://arxiv.org/abs/2510.26152)
*Xiaoyu Zhang,Lile Wang,Yang Gao,Yao Zhou*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present direct numerical simulations demonstrating
deflagration-to-detonation transition (DDT) driven by oxygen flames in Type Ia
supernova progenitors. Using the Castro hydrodynamics code coupled with the
``aprox13'' 13-isotope nuclear network, we simulate combustion in isolated fuel
regions where oxygen flames trail carbon flames. In a fiducial one-dimensional
run at $\rho_{0}=3.5\times10^{7}\ \mathrm{g\ cm^{-3}}$ we observe spontaneous
DDT of the oxygen flame via the Zel'dovich gradient mechanism when the
carbon-oxygen separation reaches $\sim 10\ \mathrm{km}$. The oxygen detonation
then captures the carbon flame and triggers a stable carbon detonation.
Systematic one-dimensional parameter scans show that successful carbon DDT
requires upstream densities in the range $(3.1$--$3.6)\times10^{7}\ \mathrm{g\
cm^{-3}}$ and a minimum carbon-flame thickness of $\gtrsim 20\ \mathrm{m}$.
Two-dimensional simulations confirm DDT and demonstrate that the
multidimensional cellular structure of the oxygen detonation can promote carbon
detonation at somewhat lower densities than in one dimension. These results
provide direct numerical evidence that oxygen-flame-driven DDT is physically
plausible in turbulent white-dwarf environments and underscore the importance
of multidimensional effects for Type Ia supernova explosion modeling.

</details>


### [41] [Multi-Faceted Emission Properties of PSR J2129+4119 Observed with FAST](https://arxiv.org/abs/2510.26209)
*Habtamu Menberu Tedila,Di Li,Pei Wang,Rai Yuen,Ziwei Wu,Shijun Dang,Jianping Yuan,Na Wang,Marilyn Cruces,Jun Shuo Zhang,Juntao Bai,De Zhao,FAST Collaboration*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a detailed single-pulse study of the long-period pulsar PSR
J2129+4119 using high-sensitivity FAST observations. Despite locating well
below the traditional death line, the pulsar exhibits sustained and multi-modal
emission behavior, including nulls, weak pulses, regular emission, and
occasional bright pulses. The nulling fraction is measured to be $8.13\% \pm
0.51\%$, with null durations typically under four pulse periods. Fluctuation
spectral analysis reveals both phase-modulated subpulse drifting and
intermittent beat-like modulation. At the same time, polarization profiles show
high linear polarization and stable polarization position angle (PPA) swings
consistent with a near-tangential sightline geometry. Quasi-periodic
microstructures are detected in 11.54\% of regular pulses, with a mean
periodicity and width of 4.57 ms and 4.30 ms, respectively. A well-defined
scintillation arc in the secondary spectrum confirms the presence of a
localized scattering screen. These results indicate that PSR J2129+4119 remains
magnetospherically active and coherently emitting despite its low energy loss
rate, offering key insights into pulsar emission physics near the death line.

</details>


### [42] [Rotation Measure Analysis of Shocks and Sloshing Fronts in a Galaxy Cluster Merger Simulation](https://arxiv.org/abs/2510.26218)
*Jia-Rou Liou,Alvina Y. L. On,H. -Y. Karen Yang,J. A. ZuHone*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent observations of the Fornax cluster show depolarization signatures on
megaparsec scales, which may be associated with shocks and/or sloshing motions
during cluster merger and/or in-fall. To investigate the possible reasons
behind the depolarization, we carry out analytical and full polarized radiative
transfer (PRT) calculations of radio point sources behind a merging galaxy
cluster simulated using the FLASH code. With uniform background light, we
analyzed the rotation measure (RM) morphology near the shock front and the
cluster center, where sloshing cold fronts appear. For the shock scenario, we
find a local RM enhancement by $\sim56\%$ behind the shock front on megaparsec
scales, arising from the compression of hot gas and magnetic field lines.
Behind the sloshing cold front, the cluster center shows decrement in RM
magnitude by $\sim23.3\%$, as a result of the cancellation effect of
randomly-oriented magnetic fields induced by sloshing-driven turbulence. We
find that beam depolarization increases behind shock fronts and across sloshing
cold fronts, indicating enhanced magnetic field fluctuations across the plane
of the sky in both scenarios. By fully accounting for all radiative transfer
coefficients in the PRT calculations, the uniform background light becomes more
depolarized near the cluster center, with the effect growing more pronounced as
background intensity decreases. This suggests that synchrotron emission and
Faraday rotation of the intracluster medium can significantly influence the
polarization of background sources.

</details>


### [43] [The $N_H$ Distribution of Hard X-ray Selected AGN in the NEP Field](https://arxiv.org/abs/2510.26554)
*Samantha Creech,Francesca Civano,Daniel R. Wik,Ross Silver,Xiurui Zhao,Rafael Ortiz III,Tonima Ananna,Normal A. Grogin,Rolf Jansen,Christopher N. A. Willmer,Rogier A. Windhorst*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: X-ray surveys are one of the most unbiased methods for detecting Compton
Thick (CT; $N_{{\mathrm{H}}} \geq 10^{24}$ cm$^{-2}$) AGN, which are thought to
comprise up to $60\%$ of AGN within $z \lesssim 1.0$. These CT AGN are often
difficult to detect with current instruments, but the X-ray data within the
JWST-North Ecliptic Pole (NEP) Time Domain Field (TDF) present a unique
opportunity to study faint and obscured AGN. The NEP contains the deepest
NuSTAR survey to date, and Zhao et al. (2024) detected 60 hard X-ray sources
from the combined exposure of NuSTAR's Cycle 5 and 6 observations. In this
work, we utilize the NuSTAR Cycle 5+6+8+9 data and simultaneous XMM-Newton
observations in order to perform the first spectroscopic analysis of the
60-source catalog. We present this analysis and measure the $N_{{\mathrm{H}}}$
distribution of the sample. We measure an observed CT fraction of
$0.13_{-0.04}^{+0.15}$ down to an observed $8-24$ keV flux of $6.0 \times
10^{-14}$ erg/s/cm$^{2}$, and we correct our analysis for absorption bias to
estimate an underlying CT fraction of $0.32_{-0.08}^{+0.23}$. The derived
obscuration distribution and CT fraction are consistent with population
synthesis models and previous surveys.

</details>


### [44] [A Star's Death by a Thousand Cuts: The Runaway Periodic Eruptions of AT2023uqm](https://arxiv.org/abs/2510.26561)
*Yibo Wang,Tingui Wang,Shifeng Huang,Jiazheng Zhu,Ning Jiang,Wenbin Lu,Rongfeng Shen,Shiyan Zhong,Dong Lai,Yi Yang,Xinwen Shu,Tianyu Xia,Di Luo,Jianwei Lyu,Thomas Brink,Alex Filippenko,Weikang Zheng,Minxuan Cai,Zelin Xu,Mingxin Wu,Xiaer Zhang,Weiyu Wu,Lulu Fan,Ji-an Jiang Xu Kong,Bin Li,Feng Lin,Ming Liang,Wentao Luo,Jinlong Tang,Zhen Wan,Hairen Wang,Jian Wang,Yongquan Xue,Dazhi Yao,Hongfei Zhang,Wen Zhao,Xianzhong Zheng,Qingfeng Zhu,Yingxi Zuo*

Main category: astro-ph.HE

TL;DR: The paper presents AT2023uqm as the second confirmed case of periodic flares from repeated partial tidal disruptions of a star by a supermassive black hole. Flares show an exponential energy increase, suggesting progressive stellar destruction. Observations support disruptions of low-mass or giant stars.


<details>
  <summary>Details</summary>
Motivation: To confirm the existence of repeated partial tidal disruption events (rpTDEs) and understand the mechanisms behind their periodic optical flares. Previous candidates lacked definitive proof, so this discovery provides critical insights into stellar disruption dynamics and black hole interactions.

Method: Analysis of multiwavelength observations and spectroscopic data of AT2023uqm's flares, comparing with ASASSN-14ko. Examined flare periodicity, energy escalation, and double-peaked structures to infer disruption mechanisms and stellar properties. Also considered orbital dynamics and mass fallback rates.

Result: Confirmed rpTDE periodicity in AT2023uqm with five flares showing exponential energy growth. Spectroscopic analysis of recent flares supports rpTDE interpretation. Double-peaked flare structures hint at dual collision events per orbit or varying mass fallback rates. The peak separation ratio suggests potential disruption of a giant star over a low-mass main-sequence star.

Conclusion: AT2023uqm is a pivotal case for studying rpTDEs, offering a framework to model stellar disruption processes. Future observations of mass-loss evolution will help distinguish between stellar types (giant vs. low-mass). This highlights the need for improved theoretical models and observational data to better understand tidal disruptions and supermassive black hole environments.

Abstract: Stars on bound orbits around a supermassive black hole may undergo repeated
partial tidal disruption events (rpTDEs), producing periodic flares. While
several candidates have been suggested, definitive confirmation of these events
remains elusive. We report the discovery of AT2023uqm, a nuclear transient that
has exhibited at least five periodic optical flares, making it only the second
confirmed case of periodicity after ASASSN-14ko. Uniquely, the flares from
AT2023uqm show a nearly exponential increase in energy--a "runaway" phenomenon
signaling the star's progressive destruction. This behavior is consistent with
rpTDEs of low-mass, main-sequence stars or evolved giant stars. Multiwavelength
observations and spectroscopic analysis of the two most recent flares reinforce
its interpretation as an rpTDE. Intriguingly, each flare displays a similar
double-peaked structure, potentially originating from a double-peaked mass
fallback rate or two discrete collisions per orbit. The extreme ratio of peak
separation to orbital period draws attention to the possibility of a giant star
being disrupted, which could be distinguished from a low-mass main-sequence
star by its future mass-loss evolution. Our analysis demonstrates the power of
rpTDEs to probe the properties of disrupted stars and the physical processes of
tidal disruption, though it is currently limited by our knowledge of these
events. AT2023uqm emerges as the most compelling rpTDE thus far, serving as a
crucial framework for modeling and understanding these phenomena.

</details>


### [45] [The second data release of the Indian Pulsar Timing Array: Investigating the Effect of Coronal Mass Ejection on PSR J1022+1001 and a Possible Mode Change of PSR J2145-0750](https://arxiv.org/abs/2510.26594)
*Shaswata Chowdhury,M. A. Krishnakumar,Manjari Bagchi,Bhal Chandra Joshi,Nobleson K.,Jibin Jose,Shantanu Desai,Manpreet Singh,Vaishnavi Vyasraj,Kuldeep Meena,Amarnath,Manoneeta Chakraborty,Shubham Kala,Debabrata Deb,Zenia Zuraiq,Arul Pandian B,Neelam Dhanda Batra,Churchil Dwivedi,Sushovan Mondal,Avinash Kumar Paladi,Kaustubh Rai,Abhimanyu Susobhanan,Adya Shukla,Aman Srivastava,Mayuresh Surnis,Hemanga Tahbildar,Keitaro Takahashi,Pratik Tarafdar,Prabu Thiagaraj,Kunjal Vara*

Main category: astro-ph.HE

TL;DR: The InPTA DR2 analyzed low-frequency data from 27 MSPs, detecting potential astrophysical outliers linked to a CME event and a pulsar mode change. This work advances understanding of plasma interactions and improves PTA modeling.


<details>
  <summary>Details</summary>
Motivation: To investigate astrophysical phenomena using low-frequency data from InPTA DR2, focusing on DM fluctuations that may indicate events like CMEs or pulsar mode changes, enhancing PTA accuracy.

Method: Analyzed DM time series of two MSPs (J1022+1001 and J2145-0750) at 300-500 MHz, identifying outliers. Confirmed a CME event in one and a potential mode change in the other.

Result: Detected a CME event in PSR J1022+1001 and a probable mode-changing event in PSR J2145-0750. Further analysis of DR2 data may yield more such events.

Conclusion: Such findings improve understanding of solar-pulsar plasma interactions and refine DM modeling, critical for high-precision PTA science and timing solutions.

Abstract: The Indian Pulsar Timing Array (InPTA) has recently published its second data
release (DR2), comprising the timing analysis of seven years of data on 27
millisecond pulsars (MSPs), observed simultaneously in the 300-500 MHz (band 3)
and 1260-1460 MHz (band 5), using the upgraded Giant Metrewave Radio Telescope
(uGMRT). The low-frequency data, particularly in band 3, is highly sensitive to
propagation effects such as dispersion measure (DM) fluctuations, which can be
imprints of some astrophysical phenomena (scientific outliers). Here, we
analyze the two outliers of possible astrophysical origin coming from the band
3 DM time series of two pulsars: PSR J1022+1001, with an ecliptic latitude of
-0.06 degree , and PSR J2145-0750, one of the brightest MSPs, with
multi-component profile morphology. Our study reveals compelling evidence for a
coronal mass ejection (CME) event traced in the data of PSR J1022+1001, and
reports evidence for a potential mode-changing event in PSR J2145-0750.
Extending the analyses presented here to the full sample of InPTA-DR2 pulsars
is expected to reveal additional CME events, and possible mode-changing events.
Such detections will not only improve our understanding of solar and pulsar
magnetospheric plasma interactions but will also enable more accurate modelling
of DM variations, leading to improved pulsar timing solutions, which are
crucial for high-precision Pulsar Timing Array (PTA) science.

</details>


### [46] [Tidal disruption events with SPH-EXA: resolving the return of the stream](https://arxiv.org/abs/2510.26663)
*Noah Kubli,Alessia Franchini,Eric R. Coughlin,C. J. Nixon,Sebastian Keller,Pedro R. Capelo,Lucio Mayer*

Main category: astro-ph.HE

TL;DR: The study challenges the prevailing view that significant kinetic energy dissipation occurs during pericentre passage in tidal disruption events, suggesting instead that debris circularization is primarily due to stream-stream collisions during self-intersection, based on high-resolution simulations showing diminishing in-plane spreading with increased resolution.


<details>
  <summary>Details</summary>
Motivation: To resolve the debate over the efficacy of shock-induced dissipation during TDEs by using high-resolution simulations to assess whether in-plane spreading (pre-self-intersection) leads to significant energy dissipation or if debris circularization is mainly caused by post-self-intersection interactions.

Method: High-resolution smoothed-particle hydrodynamics (SPH) simulations using SPH-EXA with up to 10^10 particles, incorporating relativistic effects, tracking debris from disruption until self-intersection. Comparing results across resolutions (10^8 to 10^10 particles) to isolate numerical effects.

Result: At lower resolutions (10^8 particles), significant in-plane spreading and dissipation were observed, but at higher resolutions (10^10), the stream width remained nearly unchanged post-pericenter, indicating minimal dissipation pre-self-intersection. This contradicts previous findings attributing major energy loss to shocks before stream collision.

Conclusion: The study concludes that earlier claims of substantial pre-self-intersection shocks driving circularization were likely artifacts of insufficient resolution. True debris circularization occurs predominantly through post-self-intersection stream interactions, redefining theoretical models of TDE energy dynamics.

Abstract: In a tidal disruption event (TDE), a star is disrupted by the tidal field of
a massive black hole, creating a debris stream that returns to the black hole,
forms an accretion flow, and powers a luminous flare. Over the last few
decades, several numerical studies have concluded that shock-induced
dissipation occurs as the stream returns to pericentre (i.e.,
pre-self-intersection), resulting in efficient circularisation of the debris.
However, the efficacy of these shocks is the subject of intense debate. We
present high-resolution simulations (up to 10^10 particles) of the disruption
of a solar-like star by a 10^6M_sun black hole with the new, GPU-based,
smoothed-particle hydrodynamics code SPH-EXA, including the relativistic
apsidal precession of the stellar debris orbits; our simulations run from
initial disruption to the moment of stream self-intersection. With 10^8
particles - corresponding to the highest-resolution SPH simulations of TDEs in
the pre-existing literature - we find significant, in-plane spreading of the
debris as the stream returns through pericenter, in line with previous works
that suggested this is a significant source of dissipation and luminous
emission. However, with increasing resolution this effect is dramatically
diminished, and with 10^10 particles there is effectively no change between the
incoming and the outgoing stream widths. Our results demonstrate that the
paradigm of significant dissipation of kinetic energy during pericentre passage
is incorrect, and instead it is likely that debris circularisation is mediated
by the originally proposed, stream-stream collision scenario.

</details>


### [47] [The 2024 July 16 Solar Event: A Challenge To The Coronal Mass Ejection Origin Of Long-Duration Gamma-Ray Flares](https://arxiv.org/abs/2510.26666)
*Alessandro Bruno,Melissa Pesce-Rollins,Silvia Dalla,Nicola Omodei,Ian G. Richardson,James M. Ryan*

Main category: astro-ph.HE

TL;DR: Analyzes a long-duration gamma-ray flare (LDGRF) from the July 16, 2024 solar eruption, finding that its multi-hour gamma-ray emission (up to >1 GeV) arises not from CME-driven shocks but likely from local particle acceleration in persistent coronal loops, challenging traditional acceleration mechanisms.


<details>
  <summary>Details</summary>
Motivation: To investigate the physical mechanisms producing the prolonged high-energy gamma-ray emission in LDGRFs and test whether fast CMEs and shock acceleration are necessary conditions for such events, given contradictory observations of weak CME/shock signatures in this case.

Method: Multi-spacecraft analysis combining Fermi/LAT gamma-ray data with observations of the associated CME, interplanetary shocks (type-II/III radio bursts), and solar energetic particles (SEPs). Contrasting event characteristics against expectations for shock-accelerated ion back-precipitation versus local trapped particle acceleration scenarios.

Result: The CME was slow (<600 km/s), its radio signatures were weak/short-lived, and SEPs were limited to <~30 MeV. Gamma-ray emission (persisting 7+ hours with >1 GeV photons) doesn’t align with typical shock acceleration scenarios requiring Minsky pion production. Giant coronal loops observed persisting throughout the event support local acceleration in closed magnetic structures.

Conclusion: LDGRFs can occur without fast CMEs/high-energy SEPs, indicating gamma-ray emission originates from trapped particles in persistent coronal loops rather than back-precipitating shock-accelerated ions. This challenges current paradigms linking LDGRFs to standard shock acceleration models.

Abstract: We present a multi-spacecraft analysis of the 2024 July 16 Long-Duration
Gamma-Ray Flare (LDGRF) detected by the Large Area Telescope on the Fermi
satellite. The measured >100 MeV $\gamma$-ray emission persisted for over seven
hours after the flare impulsive phase, and was characterized by photon energies
exceeding 1 GeV and a remarkably-hard parent-proton spectrum. In contrast, the
phenomena related to the coronal mass ejection (CME)-driven shock linked to
this eruption were modest, suggesting an inefficient proton acceleration
unlikely to achieve the energies well-above the 300 MeV pion-production
threshold to account for the observed $\gamma$-ray emission. Specifically, the
CME was relatively slow (~600 km/s) and the accompanying interplanetary
type-II/III radio bursts were faint and short-duration, unlike those typically
detected during large events. In particular, the type-II emission did not
extend to kHz frequencies and disappeared ~5.5 hours prior to the LDGRF end
time. Furthermore, the associated solar energetic particle (SEP) event was very
weak, short-duration, and limited to a few tens of MeV, even at magnetically
well-connected spacecraft. These findings demonstrate that a very-fast CME
resulting in a high-energy SEP event is not a necessary condition for the
occurrence of LDGRFs, challenging the idea that the high-energy $\gamma$-ray
emission is produced by the back-precipitation of shock-accelerated ions into
the solar surface. The alternative origin scenario based on local particle
trapping and acceleration in large-scale coronal loops is instead favored by
the observation of giant arch-like structures of hot plasma over the source
region persisting for the entire duration of this LDGRF.

</details>


### [48] [Compact Accretion Disks in the Aftermath of Tidal Disruption Events: Parameter Inference from Joint X-ray Spectra and UV/Optical Photometry Fitting](https://arxiv.org/abs/2510.26774)
*M. Guolo,A. Mummery,S. van Velzen,S. Gezari,M. Nicholl,Y. Yao,M. Karmen,Y. Ajay,T. Wevers,N. LeBaron,R. Chornock*

Main category: astro-ph.HE

TL;DR: The paper presents a multi-wavelength analysis of 14 tidal disruption events (TDEs), including an off-nuclear event in an ultra-compact dwarf galaxy. The study uses X-ray spectra and UV/optical data to model accretion disks, enabling precise black hole mass measurements. These masses align with galactic scaling relations and extend such correlations to intermediate-mass black holes. The findings highlight the superiority of accretion-based methods over earlier UV/optical emission models for inferring black hole properties.


<details>
  <summary>Details</summary>
Motivation: To improve the precision and physical basis of black hole mass measurements in TDEs, extending scaling relations into the intermediate-mass black hole regime and validating accretion disk models against observational data.

Method: The authors analyzed multi-wavelength data (X-ray spectra and UV/optical photometry) from 14 TDEs during their late-time plateau phases. They applied a fully relativistic accretion disk model to fit up to three epochs per source, recovering system properties like black hole mass. Comparisons were made with galactic and TDE-specific scaling relations, and different mass inference methods were evaluated.

Result: Accretion-based black hole masses spanned three orders of magnitude with high precision (68% CI < ±0.3 dex), consistent with galactic scaling relations. The data confirmed expected accretion relations (e.g., luminosity vs. Eddington ratio scaling), TDE-specific correlations (plateau luminosity and disk size vs. mass), and extended these to intermediate-mass black holes. Early-time UV/optical methods failed to recover host galaxy correlations.

Conclusion: Accretion disk modeling during TDE plateaus provides precise BH mass measurements and unifies multiple scaling relations across mass scales. This approach is superior to emission-based methods. The results open avenues for studying intermediate-mass black holes and refining TDE physics models.

Abstract: We present a multi-wavelength analysis of 14 tidal disruption events
(TDEs)-including an off-nuclear event associated with an ultra-compact dwarf
galaxy-selected for having available thermal X-ray spectra during their
late-time UV/optical plateau phase. We show that at these stages, the full
spectral energy distribution - X-ray spectra and UV/optical photometry - is
well described by a compact, yet standard accretion disk, the same disk which
powers the X-rays at all times. By fitting up to three three epochs per source
with a fully relativistic disk model, we show that many system properties can
be reliably recovered, including importantly the black hole mass
($M_{\bullet}$). These accretion-based $M_{\bullet}$ values, which in this
sample span nearly three orders of magnitude, are consistent with galactic
scaling relations but are significantly more precise (68\% credible interval $
< \pm 0.3$ dex) and physically motivated. Expected accretion scaling relations
(e.g., $L_{Bol}^{ disk} / L_{Edd} \propto T_p^4 \propto M_{\bullet}^{-1}$),
TDE-specific physics correlations ($L_{plat} \propto M_{\bullet}^{2/3}$ and
$R_{out}/r_g \propto M_{\bullet}^{-2/3}$) and black hole-host galaxy
correlations ($M_{\bullet}$-$M_{\star}$ and $M_{\bullet}$-$\sigma_{\star}$)
naturally emerge from the data and, for the first time, are self-consistently
extended into the intermediate-mass (IMBH, $M_{\bullet} < 10^{5}$) regime. We
discuss the implications of these results for TDE physics and modeling. We also
review and discuss different methods for $M_{\bullet}$ inference in TDEs, and
find that approaches based on physical models of the early-time UV/optical
emission are not able to recover (at a statistically significant level) black
hole-host galaxy scalings.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [49] [Pulsar Detection with Deep Learning](https://arxiv.org/abs/2510.25774)
*Manideep Pendyala*

Main category: astro-ph.IM

TL;DR: This paper presents a deep learning pipeline that combines array and image features from Astronomical data to classify pulsar candidates with an accuracy of 94%, addressing class imbalance through GAN-based augmentation.


<details>
  <summary>Details</summary>
Motivation: Pulsar candidate analysis is overwhelmed by the volume of data from modern radio telescopes, necessitating an automated method to filter false positives.

Method: The authors use a stacked architecture combining CNNs for image diagnostics (profile, time-phase, subbands-phase, DM curve) and ANNs for array data, fused via logistic regression, and implemented class balancing with GANs.

Result: The final model achieves 94% accuracy with balanced precision/recall, remaining lightweight enough for real-time use.

Conclusion: Deep learning techniques improve pulsar candidate classification by integrating both numeric and visual features, while GAN augmentation effectively addresses class imbalance, making it adaptable to future large-scale surveys.

Abstract: Pulsar surveys generate millions of candidates per run, overwhelming manual
inspection. This thesis builds a deep learning pipeline for radio pulsar
candidate selection that fuses array-derived features with image diagnostics.
From approximately 500 GB of Giant Metrewave Radio Telescope (GMRT) data, raw
voltages are converted to filterbanks (SIGPROC), then de-dispersed and folded
across trial dispersion measures (PRESTO) to produce approximately 32,000
candidates. Each candidate yields four diagnostics--summed profile, time vs.
phase, subbands vs. phase, and DM curve--represented as arrays and images. A
baseline stacked model (ANNs for arrays + CNNs for images with
logistic-regression fusion) reaches 68% accuracy. We then refine the CNN
architecture and training (regularization, learning-rate scheduling, max-norm
constraints) and mitigate class imbalance via targeted augmentation, including
a GAN-based generator for the minority class. The enhanced CNN attains 87%
accuracy; the final GAN+CNN system achieves 94% accuracy with balanced
precision and recall on a held-out test set, while remaining lightweight enough
for near--real-time triage. The results show that combining array and image
channels improves separability over image-only approaches, and that modest
generative augmentation substantially boosts minority (pulsar) recall. The
methods are survey-agnostic and extensible to forthcoming high-throughput
facilities.

</details>


### [50] [The Ray Tracing Sampler: Bayesian Sampling of Neural Networks for Everyone](https://arxiv.org/abs/2510.25824)
*Peter Behroozi*

Main category: astro-ph.IM

TL;DR: The paper introduces a Markov Chain Monte Carlo (MCMC) sampler using ray tracing to efficiently sample posterior distributions for large neural networks, demonstrating superior performance over traditional methods like HMC. It shows applicability up to GPT-2 scale on a single GPU.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of existing MCMC methods (e.g., HMC) in handling high-dimensional spaces with stochastic gradients and likelihood barriers, enabling efficient posterior sampling for large neural networks.

Method: Develops a ray tracing-based MCMC sampler that propagates rays at constant speed through parameter space, where refractive index corresponds to likelihood. This allows crossing likelihood barriers and improves resilience to gradient noise.

Result: Successfully sampled posterior distributions for neural networks up to 1.5B parameters on a single GPU. Demonstrated that traditional samplers (HMC, Metropolis, etc.) are special cases of this generalized framework.

Conclusion: Ray tracing provides a versatile and efficient alternative to existing samplers, particularly for large-scale Bayesian inference tasks, with open-source implementation available.

Abstract: We derive a Markov Chain Monte Carlo sampler based on following ray paths in
a medium where the refractive index $n(x)$ is a function of the desired
likelihood $\mathcal{L}(x)$. The sampling method propagates rays at constant
speed through parameter space, leading to orders of magnitude higher resilience
to heating for stochastic gradients as compared to Hamiltonian Monte Carlo
(HMC), as well as the ability to cross any likelihood barrier, including holes
in parameter space. Using the ray tracing method, we sample the posterior
distributions of neural network outputs for a variety of different
architectures, up to the 1.5 billion-parameter GPT-2 (Generative Pre-trained
Transformer 2) architecture, all on a single consumer-level GPU. We also show
that prior samplers including traditional HMC, microcanonical HMC, Metropolis,
Gibbs, and even Monte Carlo integration are special cases within a generalized
ray tracing framework, which can sample according to an arbitrary weighting
function. Public code and documentation for C, JAX, and PyTorch are available
at https://bitbucket.org/pbehroozi/ray-tracing-sampler/src

</details>


### [51] [Cosmological Simulations of Weakly Collisional Plasmas with Braginskii Viscosity in Galaxy Clusters](https://arxiv.org/abs/2510.25847)
*Tirso Marin-Gilabert,Ulrich P. Steinwandel,Milena Valentini,John A. ZuHone,Klaus Dolag*

Main category: astro-ph.IM

TL;DR: The paper describes the implementation of an anisotropic viscosity solver in the OpenGadget3 MHD framework, incorporating Braginskii viscosity along magnetic field lines and plasma-instability limiters. Validation tests and a cosmological simulation confirm its accuracy and efficiency.


<details>
  <summary>Details</summary>
Motivation: To model anisotropic viscous transport in weakly collisional plasmas, avoiding traditional subcycling and improving computational efficiency while maintaining physical consistency in astrophysical simulations.

Method: The solver uses Braginskii's formalism for anisotropic viscosity, with mirror and firehose instability-based limiters. Validated through standard tests (sound waves, Alfven waves, Kelvin-Helmholtz instability) and applied to a galaxy cluster simulation.

Result: Accurate reproduction of AREPO's results and stable performance in cosmological simulations, demonstrating robustness without subcycling. The implementation efficiently models plasma microphysics in large-scale systems.

Conclusion: The new solver provides a reliable, efficient method for studying anisotropic viscosity in magnetized astrophysical systems, suitable for both validation tests and complex cosmological scenarios.

Abstract: We present the implementation of an anisotropic viscosity solver within the
magnetohydrodynamics (MHD) framework of the TreeSPH code OpenGadget3. The
solver models anisotropic viscous transport along magnetic field lines
following the Braginskii formulation and includes physically motivated limiters
based on the mirror and firehose instability thresholds, which constrain the
viscous stress in weakly collisional plasmas. To validate the implementation,
we performed a suite of standard test problems -- including two variants of the
sound-wave test, circularly and linearly polarized Alfven waves, fast
magnetosonic wave, and the Kelvin-Helmholtz instability -- both with and
without the plasma-instability limiters. The results show excellent agreement
with the AREPO implementation of a similar anisotropic viscosity model (Berlok
et al. 2019), confirming the accuracy and robustness of our method. Our
formulation integrates seamlessly within the individual adaptive timestepping
framework of OpenGadget3, avoiding the need for subcycling. This provides
efficient and stable time integration while maintaining physical consistency.
Finally, we applied the new solver to a cosmological zoom-in simulation of a
galaxy cluster, demonstrating its capability to model anisotropic transport and
plasma microphysics in realistic large-scale environments. Our implementation
offers a versatile and computationally efficient tool for studying anisotropic
viscosity in magnetized astrophysical systems.

</details>


### [52] [A Natural Language Interface for Efficient Data Retrieval in SDSS](https://arxiv.org/abs/2510.25953)
*Prathamesh Tamhane*

Main category: astro-ph.IM

TL;DR: This paper presents an interface that translates natural language into SQL for SDSS databases, using a fine-tuned Phi-2 model to help non-experts access astronomical data without needing SQL knowledge.


<details>
  <summary>Details</summary>
Motivation: Non-experts struggle with querying SDSS databases due to the need for SQL knowledge and schema familiarity. The paper aims to lower this barrier by automating query translation.

Method: The authors fine-tuned Microsoft Phi-2 on natural language-SQL pairs derived from SDSS examples, then created an interface converting user natural language to executable SQL for SDSS SkyServer.

Result: The model generated syntactically valid and mostly semantically correct SQL queries for diverse astronomy requests, demonstrating that small models with careful fine-tuning can effectively handle domain-specific database interactions.

Conclusion: Small language models, when properly adapted, can provide accessible interfaces for scientific databases, empowering non-experts to utilize large datasets without SQL expertise.

Abstract: Modern astronomical surveys such as the Sloan Digital Sky Survey (SDSS)
provide extensive astronomical databases enabling researchers to access vast
amount of diverse data. However, retrieving data from archives requires
knowledge of query languages and familiarity with their schema, which presents
a barrier for non-experts. This work investigates the use of Microsoft Phi-2, a
compact yet powerful transformer-based language model, fine-tuned on natural
language--SQL pairs constructed from SDSS query examples. We develop an
interface that translates user queries in natural language into SQL commands
compatible with SDSS SkyServer. Preliminary evaluation shows that the
fine-tuned model produces syntactically valid and largely semantically correct
queries across a variety of astronomy-related requests. Our results show that
even small-scale models, when carefully fine-tuned, can provide effective
domain-specific natural language interfaces for large scientific databases.

</details>


### [53] [HS-ANET: Star Spectral Type Enhanced Astrometric Calibration for Hyper Spectral Space Imaging](https://arxiv.org/abs/2510.25987)
*Kevin Phan,William Mitchell,David Chaparro,Enrique De Alba,J. Zachary Gazak*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Traditional lost-in-space algorithms, such as those implemented in
astrometry.net, solve for spacecraft orientation by matching observed star
fields to celestial catalogs using geometric asterisms alone. In this work, we
propose a novel extension to astrometry.net that incorporates stellar spectral
type, which is derived from hyperspectral imagery, into the matching process.
By adding this spectral dimension to each star detection, we constrain the
search space and improve match specificity, enabling successful astrometric
solutions with significantly fewer stars. Our modified pipeline demonstrates
improved fit rates and reduced failure cases in cluttered or ambiguous star
fields, which is especially critical for autonomous space situational awareness
and traffic management. Our results suggest that modest spectral resolution,
when incorporated into existing geometric frameworks, can dramatically improve
robustness and efficiency in onboard star identification systems.

</details>


### [54] [A Triple-GEM Time Projection Chamber for Wide Field-of-View Hard X-ray Polarimetry: First Results](https://arxiv.org/abs/2510.26239)
*Davide Fiorina,Elisabetta Baracchini,Giorgio Dho,Paolo Soffitta,Samuele Torelli,David J. M. Marques,Enrico Costa,Sergio Fabiani,Fabio Muleri,Giovanni Mazzitelli,Atul Prajapati*

Main category: astro-ph.IM

TL;DR: The paper describes the development and testing of a large-volume, wide field-of-view TPC with triple-GEM and optical readout for X-ray polarimetry. Initial tests show promising results in detecting low-energy electrons with high angular resolution and modulation factors, suggesting potential for studying high-energy astrophysical events.


<details>
  <summary>Details</summary>
Motivation: The motivation is to extend X-ray polarimetry capabilities to higher energies, enabling the study of rapid transients like gamma-ray bursts and solar flares, which require sensitive detection of photon directionality and polarization.

Method: The method involves a TPC with triple-GEM amplification, sCMOS and PMT for optical readout, and a cylindrical active volume (radius 3.7 cm, height 5 cm). Electrons in the 10-60 keV range were tested for directionality and angular resolution.

Result: Results include full reconstruction of 10-60 keV electrons, 15° angular resolution, and modulation factors up to 0.9, demonstrating effective photoelectron tracking and high modulation.

Conclusion: The successful prototype testing implies that photoelectric-effect polarimetry can be extended to higher energies, enhancing the astrophysical applications of X-ray polarimetry in observing transient events.

Abstract: We report on the development of a large-volume, wide field-of-view time
projection chamber (TPC) for X-ray polarimetry, featuring a triple-GEM
amplification stage and optical readout. Originally developed within the CYGNO
program for directional dark matter searches, the system employs a scientific
CMOS (sCMOS) camera and a photomultiplier tube (PMT) to collect secondary
scintillation light produced during charge amplification. A prototype with a
cylindrical active volume (radius 3.7 cm, height 5 cm) was tested at the
INAF--IAPS calibration facility (Rome, Tor Vergata) to assess sensitivity to
low-energy electron directionality. We fully reconstruct electrons in the 10-60
keV range, obtain angular resolutions as good as 15{\deg}, and infer modulation
factors up to 0.9. These first results demonstrate robust photoelectron
tracking at tens of keV with strong modulation, indicating that
photoelectric-effect polarimetry can be extended to higher energies. This
capability is promising for rapid transients (GRBs, solar flares) and would
broaden the astrophysical reach of X-ray polarimetry.

</details>


### [55] [{\sc ampere}: A tool to fit heterogeneous observations consistently](https://arxiv.org/abs/2510.26333)
*P. Scicluna,S. Zeegers,J. P. Marshall,F. Kemper,S. Srinivasan T. E. Dharmawardena,L. Fanciullo,O. Morata,A. Trejo-Cruz*

Main category: astro-ph.IM

TL;DR: The paper introduces {	extsc{ampere}}, a method that employs modern inference techniques like flexible likelihood functions and likelihood-free inference to handle computationally expensive models in astronomy. It effectively performs Bayesian inference even with models missing certain observational features, demonstrates accurate parameter estimation, and highlights that past studies underestimated uncertainties.


<details>
  <summary>Details</summary>
Motivation: As astronomical data grows more complex and models become computationally expensive, there is a need for efficient inference methods that can handle models which may not capture all observational features (e.g., missing lines, incomplete PSFs). Existing approaches struggle with such scenarios, leading to underestimated uncertainties in parameter estimates.

Method: {	extsc{ampere}} uses flexible likelihood functions and likelihood-free inference to enable Bayesian analysis with costly models (e.g., hours of CPU time per run). It was tested on scenarios like inferring circumstellar dust mineralogy via Monte Carlo Radiative Transfer models, even when models lack full observational features.

Result: {	extsc{ampere}} accurately recovers input parameters across tested models. It shows that previous studies underestimated uncertainties in parameter estimation when using similarly limited models.

Conclusion: {	extsc{ampere}} is a versatile tool for Bayesian inference with expensive, incomplete models, offering reliable uncertainty quantification. It addresses limitations of past methods and is broadly applicable in astronomy for interpreting complex datasets.

Abstract: As astronomy advances and data becomes more complex, models and inference
also become more expensive and complex. In this paper we present {\sc ampere},
which aims to solve this problem using modern inference techniques such as
flexible likelihood functions and likelihood-free inference. {\sc ampere}\ can
be used to do Bayesian inference even with very expensive models (hours of CPU
time per model) that do not include all the features of the observations (e.g.
missing lines, incomplete descriptions of PSFs, etc). We demonstrate the power
of \ampere\ using a number of simple models, including inferring the posterior
mineralogy of circumstellar dust using a Monte Carlo Radiative Transfer model.
{\sc ampere}\ reproduces the input parameters well in all cases, and shows that
some past studies have tended to underestimate the uncertainties that should be
attached to the parameters. {\sc ampere}\ can be applied to a wide range of
problems, and is particularly well-suited to using expensive models to
interpret data.

</details>


### [56] [A summary of instruments proposed for observing pulsating variables from the Mt. Abu Observatory](https://arxiv.org/abs/2510.26507)
*Anwesh Kumar Mishra,Deekshya Roy Sarkar,Prachi Prajapati,Alka Singh,Prashanth K. Kasarla,Shashikiran Ganesh*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Pulsating variables play a significant role in shaping modern astronomy.
Presently it is an exciting era in observational study of variable stars owing
to surveys like OGLE and TESS. The vast number of sources being discovered by
these surveys is also creating opportunities for 1-2m class telescopes to
provide follow-up observations to characterize these. We present some initial
observations of type-II cepheids from the Mt. Abu observatory and highlight the
need for dedicated observing runs of pulsating variables. We also present
optical designs for several suggested instruments for the Mt. Abu observatory
that will contribute towards this goal. We present designs that are fairly
simple and yet take due benefit of the unique telescopes and facilities present
at the observatory.

</details>


### [57] [Stellar Spectroscopy Using Diffraction Grating, CMOS Monochrome Sensor, and Reflecting Telescopes](https://arxiv.org/abs/2510.26689)
*Abhinav Roy,Niti Singh*

Main category: astro-ph.IM

TL;DR: The paper presents a compact, low-cost stellar spectrometer designed for undergraduate education and public outreach, demonstrating that accessible equipment can capture meaningful spectra of bright stars.


<details>
  <summary>Details</summary>
Motivation: To enable affordable, hands-on astronomical instrumentation projects for students and public engagement by creating a simple yet effective spectrometer.

Method: Uses a 600 lines/mm diffraction grating, CMOS sensor, 3D-printed mount with reflecting telescopes, and a Python-based calibration pipeline using helium and Vega.

Result: Successfully captured spectra of bright stars (Vega, Sirius, etc.) across spectral types A-M, validating the spectrometer's effectiveness.

Conclusion: Low-cost instruments can achieve significant astronomical results, offering a practical platform for educational and outreach initiatives.

Abstract: We present the design and testing of a compact, low-cost stellar spectrometer
developed for undergraduate and outreach applications. The instrument employs a
600 lines/mm diffraction grating, a CMOS monochrome sensor, and a 3D-printed
mount integrated with reflecting telescopes. Calibration was performed using
helium emission sources in the laboratory and Vega as a spectrophotometric
standard, supported by a custom Python-based image-processing pipeline for
wavelength calibration and spectral stacking. The spectrometer successfully
recorded usable spectra of bright stars including Vega, Sirius, Procyon,
Capella, and Betelgeuse, covering spectral types A through M. The results
demonstrate that meaningful stellar spectroscopy can be achieved with
accessible, low-cost equipment, providing a practical framework for student-led
astronomical instrumentation projects.

</details>
