<div id=toc></div>

# Table of Contents

- [astro-ph.HE](#astro-ph.HE) [Total: 12]
- [astro-ph.IM](#astro-ph.IM) [Total: 35]
- [gr-qc](#gr-qc) [Total: 16]
- [hep-ph](#hep-ph) [Total: 20]


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [1] [Super-Eddington Chimneys: On the Cooling Evolution of Tidal Disruption Event Envelopes](https://arxiv.org/abs/2512.14810)
*Semih Tuna,Brian D. Metzger,Yan-Fei Jiang,Andrea Antoni*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The formation of a compact accretion disk following a tidal disruption event (TDE) requires that the shocked stellar debris cool efficiently as it settles toward the black hole. While recent simulations suggest that stream dissipation occurs rapidly, how the weakly bound debris subsequently loses its thermal energy to assemble a compact disk near the circularization radius remains uncertain. We investigate this cooling process using axisymmetric radiation-hydrodynamic simulations of quasi-hydrostatic 'TDE envelopes', initialized with the total mass, angular momentum, and binding energy expected from a complete stellar disruption. The envelopes, supported by radiation pressure on large scales and rotation near the circularization radius, evolve through a combination of radiative diffusion, turbulent mixing, and polar outflows. In our fiducial model, a quasi-steady state is achieved in which a polar outflow radiates and expels matter at several times the Eddington luminosity. This enables the envelope to cool and contract, forming a dense, rotationally supported ring near the circularization radius, but on a timescale roughly ten times shorter than the naive photon-diffusion timescale. Comparative models without radiation transport confirm that cooling, not purely adiabatic evolution, is essential to driving this rapid inflow. Nevertheless, across a range of envelope masses, the effective envelope cooling time scales only weakly with its optical depth, implying that advective and wind-driven energy transport dominate over diffusion. Our results demonstrate the cooling-induced contraction, even absent viscosity and associated black hole accretion, can produce luminosities and large photosphere radii consistent with early UV/optical TDE emission. However, more quantitative light-curve predictions must incorporate self-consistent formation and feeding of the envelope by fall-back accretion.

</details>


### [2] [Supermassive black-hole imaging with a self-consistent electron-temperature prescription](https://arxiv.org/abs/2512.14835)
*Alejandro Cruz-Osorio,Claudio Meringolo,Christian M. Fromm,Yosuke Mizuno,Sergio Servidio,Antonios Nathanail,Ziri Younsi,Luciano Rezzolla*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The recent 230 GHz observations by the Event Horizon Telescope have resolved the innermost structure of the M87 galaxy, revealing a ring-like feature consistent with thermal synchrotron emission from a magnetized torus surrounding a rotating supermassive black hole. Moreover, Global Millimeter VLBI Array observations at 86 GHz have revealed a larger-scale, edge-brightened jet with clear signatures of non-thermal emission. The theoretical modelling of these observations involves advanced general-relativistic magnetohydrodynamic simulations of magnetized accretion disks around rotating black holes, together with the associated synchrotron emission, which is normally treated with simplified expressions for the electron temperature and assuming a purely thermal distribution. However, an important non-thermal component is expected to be present, making the thermal-emission model not only an approximation, but also a source of degeneracy in the modelling. In view of this, we here present the first application of an ab-initio approach to the electron temperature derived from microscopic simulations of turbulent collisionless plasmas. The novel method, which has no tuneable coefficients and is fully specified by the thermodynamical and magnetic properties of the plasma, provides a better description of the jet morphology and width at 86 GHz, as well as of the broadband spectral emission. These findings highlight the importance of incorporating microscopic plasma physics in black-hole imaging and emphasise the crucial role of magnetic reconnection in electron heating and acceleration processes.

</details>


### [3] [A milli-Tidal Disruption Event Model for GRB$\;$250702B: Main Sequence Star Disrupted by an IMBH](https://arxiv.org/abs/2512.14847)
*Jonathan Granot,Hagai B. Perets,Ramandeep Gill,Paz Beniamini,Brendan O'Connor*

Main category: astro-ph.HE

TL;DR: The paper analyzes GRB 250702B, suggesting it arose from a tidal disruption event (TDE) by an intermediate-mass black hole (IMBH). The afterglow data supports a stratified interstellar medium density profile consistent with Bondi accretion. The inferred IMBH mass and velocity constraints align with a main-sequence star disruption, explaining the event's prolonged duration and energetics.


<details>
  <summary>Details</summary>
Motivation: To determine whether GRB 250702B is an ultra-long GRB or a TDE by an IMBH, focusing on the latter possibility to explain its extraordinary duration (~25 ks), distinct emission features, and radio/X-ray afterglow properties.

Method: Modeling the afterglow data to derive the external density profile (proportional to r^-1.6) and comparing it with Bondi accretion predictions. Calculated IMBH mass using density parameters and applied variability time constraints to limit the black hole's velocity.

Result: Derived a density profile exponent k=1.60±0.17, consistent with Bondi accretion. Estimated IMBH mass ~6.5×10^3 solar masses (dependent on ISM density and sound speed), with a velocity upper limit ~28 km/s. Concluded main-sequence star disruptions can explain the event, unlike white dwarfs.

Conclusion: GRB 250702B is plausibly a mTDE involving an IMBH. The gradual rise to the emission peak is attributed to accretion disk buildup from disrupted star material, enhancing jet power. Further observations are needed to conclusively confirm the IMBH and TDE origin.

Abstract: GRB$\;$250702B is the longest GRB recorded so far, with multiple gamma-ray emission episodes spread over a duration exceeding $25\;$ks and a weaker soft X-ray pre-peak $\sim1\;$day gradually rising emission. It is offset from its host galaxy center by $\sim5.7\;$kpc, and displays a long-lived afterglow emission in radio to X-ray. Its true nature is unclear, with the two leading candidate classes of objects being a peculiar type of ultra-long GRB and a tidal disruption event (TDE) by an intermediate mass black hole (IMBH). Here, we consider the latter, mTDE origin. We model the afterglow data, finding a stratified external density profile $\propto r^{-k}$ with $k=1.60\pm0.17$, consistent with Bondi accretion of the interstellar medium (of initial number density $n_{\rm ISM}=n_0\;{\rm cm^{-3}}$ and sound speed $c_s=c_{s,6}10^6\;{\rm cm\,s^{-1}}$) for which $n(r)\approx n_{\rm ISM}(r/R_{\rm B})^{-3/2}$ within the Bondi radius $R_{\rm B}$. Moreover, we use the implied density normalization to infer the IMBH mass within this model, finding $M_\bullet\approx\left(6.55^{+3.51}_{-2.29}\right)\times10^3\,n_0^{-2/3}\,c_{s,6}^{2}(1+\mathcal{M}^2)\;M_\odot$ where $\mathcal{M}\equiv v_{\rm BH}/c_s$ is the IMBH's Mach number relative to the ISM. Together with an upper limit on $M_\bullet<\frac{c^3}{G}\frac{t_{\rm MV}}{1+z} \lesssim5\times10^4\,M_\odot$ from the source-frame minimum variability time $t_{\rm MV,src}\!=\!\frac{t_{\rm MV}}{1+z}\!\approx\!0.5\;$s this implies $v_{\rm BH}\lesssim 28\,n_0^{1/3}\;{\rm km\;s^{-1}}$. We show that a mTDE of a main-sequence star (but not of a white dwarf) can explain the duration and energetics of GRB$\;$250702B. The gradual rise to the peak may be caused by gradual circularization and accretion disk buildup, leading to an increase in the jet's power and Lorentz factor.

</details>


### [4] [A Very Rich Bimodal Galaxy Cluster Merger: RXC J0032.1+1808](https://arxiv.org/abs/2512.14945)
*David Wittman,Rodrigo Stancioli,Faik Bouhrik,Reinout van Weeren,Andrea Botteon*

Main category: astro-ph.HE

TL;DR: This paper analyzes the merging galaxy cluster RXC J0032.1+1808 through X-ray, optical, and radio data, suggesting it underwent a merger ~400-560 Myr post-pericenter with a non-head-on trajectory and a viewing angle that compresses the subcluster separation.


<details>
  <summary>Details</summary>
Motivation: To understand the dynamic state and merger timeline of RXC J0032.1+1808 using multiwavelength observations and simulations.

Method: Analysis of archival XMM-Newton X-ray data (temperature/luminosity), galaxy redshift survey (line-of-sight velocities), and hydrodynamic simulations to model merger parameters (timing, angle, geometry).

Result: X-ray bimodality indicates merging; velocity difference of 76±364 km/s between subclusters; not a head-on merger; ~395-560 Myr post-pericenter; viewing angle reduces separation by ~2x.

Conclusion: RXC J0032 is a post-first-pericenter merger with specific geometric and temporal constraints, providing insights into cluster merger dynamics observed through multiwavelength methods.

Abstract: The galaxy cluster RXC J0032.1+1808 has been well-studied with optical imaging and gravitational lensing mass maps, both of which reveal an elongated morphology in the north-south direction. We find that its X-ray morphology is bimodal, suggesting that it is in the process of merging; combined with a previously reported detection of a radio relic, we suggest that the system is seen after first pericenter. We extract the global X-ray temperature and unabsorbed luminosity from archival XMM-Newton data, finding $T_X=8.5^{+1.1}_{-0.9}$ keV and $L_X=1.04 \pm 0.03 \times 10^{45}$ erg s$^{-1}$ at 90\% confidence in the $0.5$--$10.0$ keV energy range. We conduct a redshift survey of member galaxies and find that the line-of-sight relative velocity between the two subclusters is $76\pm364$ km/s. We use publicly available hydrodynamic simulations to show that it cannot be a head-on merger, that it is observed ${\approx}395$--560 Myr after pericenter, and that the viewing angle must be one that foreshortens the apparent subcluster separation by a factor ${\approx}2$.

</details>


### [5] [Future Space-based Gamma-ray Pulsar Timing Arrays](https://arxiv.org/abs/2512.14981)
*Matthew Kerr,Zorawar Wadiasingh,Adrien Laviron,Constantinos Kalapotharakos,Thankful Cromartie,Tyler Cohen*

Main category: astro-ph.HE

TL;DR: The Gamma-ray Pulsar Timing Array (GPTA) using GeV observations of millisecond pulsars (MSPs) offers potential to detect nHz gravitational waves with sensitivity rivaling or exceeding current radio PTAs, particularly in the 0.1-5 GeV range. Simulations suggest next-generation gamma-ray telescopes could detect thousands of MSPs, distinguishing bulge population formation scenarios and reducing plasma propagation effects.


<details>
  <summary>Details</summary>
Motivation: To evaluate GPTA's effectiveness for future gamma-ray observatories through simulating MSP populations and gamma-ray spectra, addressing limitations of radio PTAs like plasma propagation effects and data gaps.

Method: Simulated Galactic MSP populations, developed high-fidelity spectral prediction models validated against Fermi LAT data, and evaluated signal performance across instrument concepts across diverse energy ranges (0.1-5 GeV and Compton/MeV bands).

Result: Optimal GPTA performance occurs between 0.1-5 GeV; GeV-band instruments could detect 10³-10⁴ MSPs with GW sensitivity surpassing current radio PTAs. Compton/MeV concepts show lower signal-to-background ratios. The method can distinguish Galactic bulge MSP formation scenarios.

Conclusion: Next-generation gamma-ray timing arrays are critical for gravitational wave detection, complementary to radio PTAs, with capacity for high MSP discovery and bulge population analysis, necessitating future instrument development.

Abstract: Radio pulsar timing array (PTA) experiments using millisecond pulsars (MSPs) are beginning to detect nHz gravitational waves (GWs). MSPs are bright GeV gamma-ray emitters, and all-sky monitoring of about 100 MSPs with the Fermi Large Area Telescope (LAT) has enabled a gamma-ray Pulsar Timing Array. The GPTA provides a complementary view of nHz GWs because its MSP sample is different, and because the gamma-ray data are immune to plasma propagation effects, have minimal data gaps, and rely on homogeneous instrumentation. To assess GPTA performance for future gamma-ray observatories, we simulated the population of Galactic MSPs and developed a high-fidelity method to predict their gamma-ray spectra. This combination reproduces the properties of the LAT MSP sample, validating it for future population studies. We determined the expected signal from the simulated gamma-ray MSPs for instrument concepts with a wide range of capabilities. We found that the optimal GPTA energy range runs about 0.1 to 5 GeV, but we also examined Compton/MeV instruments. With the caveat that the MSP spectra models are extrapolated beyond observational constraints, we found low signal-to-background ratios, yielding few MSP detections. GeV-band concepts would detect 10$^3$ to 10$^4$ MSPs and achieve GW sensitivity on par with and surpassing the current generation of radio PTAs, reaching the GW self-noise regime. When considering two possible scenarios for the formation of MSPs in the Galactic bulge, the collective signal from which is a potential source of an excess GeV signal observed towards the Galactic center, we find that most of the concepts can both detect this bulge population and distinguish the production channel. In summary, the high discovery potential, strong GW performance, and tremendous synergy with radio PTAs all argue for the pursuit of next-generation gamma-ray pulsar timing.

</details>


### [6] [GRBs and Relativistic Transients in the 2040s](https://arxiv.org/abs/2512.15010)
*Nikhil Sarin,Andrew Levan,Nial Tanvir,Simone Scaringi,Fabio Ragosta,Andrea Melandri,Paul Groot,Paul O'Brien,Paul Lasky,Samaya Nissanke,Alexander Heger,Steve Schulze*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Relativistic transients such as gamma-ray bursts (GRBs), jetted tidal disruption events, luminous fast blue optical transients, and fast X-ray transients, represent the brightest explosions in the Universe and serve dual roles as laboratories for extreme physics and as cosmic lighthouses probing the earliest epochs of the Universe. The 2040s will bring transformative capabilities: wide-field optical surveys discovering tens of thousands of optical transients nightly, proposed high-energy missions like THESEUS providing 10-100x improved high-energy monitoring, and third-generation gravitational wave detectors identifying $\mathcal{O}(10^5)$ compact object mergers annually, many accompanied by relativistic jets. This industrial-scale discovery rate will enable population studies addressing fundamental questions such as jet launching mechanisms, nucleosynthesis, the first stars, and how progenitor environments shape these transients across cosmic time. However, realizing this science requires overcoming a critical bottleneck: these transients evolve on timescales of seconds to days, with their physics encoded in rapidly-changing multi-wavelength signatures demanding immediate spectroscopic characterization down to m ~ 25. Current facilities, optimized for classical/queue scheduling, do not provide the rapid, flexible, multi-target response necessary for industrial-scale follow-up. This white paper demonstrates that without a dedicated large-aperture (10-30 m effective collecting area) time-domain facility with robotic scheduling and optical-NIR spectroscopic capabilities, the transformative potential of relativistic transient science in the 2040s will be considerably limited.

</details>


### [7] [Irradiation-Driven Formation of Supersoft X-ray Sources Following Classical Novae](https://arxiv.org/abs/2512.15015)
*Weitao Zhao,Xiangcun Meng,Yingzhen Cui,Yunlang Guo*

Main category: astro-ph.HE

TL;DR: The paper proposes that irradiative feedback following a classical nova eruption can explain the formation of short-period supersoft X-ray sources (SSSs) by inducing stable mass transfer from low-mass companions, resolving a discrepancy in the standard model.


<details>
  <summary>Details</summary>
Motivation: The standard model of SSSs struggles to explain short-period systems because their low-mass donors theoretically cannot sustain high mass transfer rates required for persistent thermonuclear burning.

Method: Detailed binary evolution simulations using MESA to model irradiative feedback's effect on companion star expansion and mass transfer post-classical nova outburst.

Result: The simulations show sustained mass transfer rates sufficient for stable hydrogen burning for over 10^4 years, and predict transitions to recurrent nova outbursts when mass transfer drops.

Conclusion: This mechanism explains both short-period SSSs and short-period recurrent novae through irradiation-driven mass transfer dynamics.

Abstract: Supersoft X-ray sources (SSSs) are characterized by persistent thermonuclear burning on the surfaces of white dwarfs (WDs).The standard model requires high mass transfer rates of $\sim 10^{-7}\, {\rm M_{\odot}}\,yr^{-1}$ from massive companions, presenting a theoretical impediment to the observed short-period SSSs, whose orbital periods imply low-mass donors theoretically incapable of sustaining such accretion.To resolve this paradox,we propose and demonstrate through detailed simulations that irradiative feedback following a classical nova (CN) eruption provides a natural formation channel.Through detailed binary evolution simulations with MESA, we reveal that sustained WD irradiation initially from the outburst and subsequently from accretion luminosity triggers significant and stable expansion of the low mass companion.This,in turn,drives mass-transfer rates into the stable hydrogen-burning regime and sustains it beyond $10^4$ years after the initiation of hydrogen burning.This mechanism robustly explains the observed population of short-period SSSs. Moreover,when irradiation-driven mass transfer rate drops below the stable accretion rate,it may lead to the rapid accumulation of sufficient material on shorter time scales to trigger a recurrent nova outburst instead of SSS, thereby also offering an explanation for the origin of short-period recurrent novae.

</details>


### [8] [A Comprehensive Interpretation of Fermi-LAT Pulsars: Fundamental-Plane Death Border, Visibility Thresholds, and GeV-TeV Unification](https://arxiv.org/abs/2512.15065)
*Constantinos Kalapotharakos,Zorawar Wadiasingh,Alice K. Harding,Demosthenes Kazanas,Dimitrios Skiathas*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a framework that links equatorial-current-sheet (ECS) physics to catalog-lelvel phase-averaged gamma-ray pulsar properties. Guided by analytic scalings and 3D particle-in-cell (PIC) simulations, we show that the pulsar "Fundamental Plane" (relating gamma-ray luminosity, spectral cutoff energy, spin-down power $\dot{\cal{E}}$, and surface magnetic field) is bounded by two regimes: a radiation-reaction-limited branch and a potential-drop-limited branch. Their intersection defines a transition in $\dot{\cal{E}}$ that maps to a gamma-ray visibility threshold on the $P-\dot{P}$ diagram, above which detectability is set by distance and beaming, and below which both cutoff energy and efficiency decline rapidly. Placing ATNF pulsars and McGill magnetars onto these planes reproduces the observed Fermi occupancy, with millisecond pulsars (MSPs) on the observable side, young pulsars (YPs) straddling the threshold, and magnetars clustering at or just below it. At higher $\dot{\cal{E}}$, both MSPs and YPs depart from the maximal radiation-reaction-limited envelope at similar cutoff energies, suggesting that enhanced pair creation screens the accelerating electric field in the ECS. We interpret this behavior with a compactness-based criterion for optically thin $γγ$ pair feedback in or near the ECS and briefly note an extension to $γγ\rightarrowμ^\pm$ that could yield pulsed multi-TeV neutrinos in the most energetic systems. The framework predicts an MeV-bright, GeV-faint corridor below current Fermi sensitivity, a target for next-generation MeV missions. Finally, motivated by the recent HESSII detection of pulsed multi-TeV emission from Vela, we use PIC particle distributions with a simple seed-photon model to reproduce a multi-TeV inverse-Compton component alongside the GeV curvature emission, supporting a unified ECS-based GeV-TeV origin.

</details>


### [9] [Time Evolution of Optical Darkness in GRB Afterglow: The Case of GRB 240825A](https://arxiv.org/abs/2512.15162)
*Rui-Zhi Li,Jirong Mao,Yuan-Pei Yang,Bo-Ting Wang,Fei-Fan Song,Yu-Xin Xin,Jin-Ming Bai*

Main category: astro-ph.HE

TL;DR: This paper analyzes the early afterglow of GRB 240825A, showing its X-ray spectral evolution and optical darkness, indicating occurrence in a dust-obscured environment despite failing to meet optically dark burst criteria at later times.


<details>
  <summary>Details</summary>
Motivation: To explore the physical properties and environmental conditions of long-duration GRBs through detailed analysis of afterglow spectral features and their evolution.

Method: Time-resolved X-ray spectral analysis and calculation of optical darkness (β_OX) across multiple time intervals, alongside fitting X-ray-to-optical spectral energy distributions (SEDs) to derive extinction curves.

Result: β_OX showed a decrease followed by an increase, peaking lowest at ~1000s post-burst. Extinction curves suggest a dust-obscured environment, though the burst didn't qualify as optically dark at 11 hours.

Conclusion: GRB 240825A occurred in a dusty environment, with evolving optical properties indicating complex emission mechanisms and potential variations in obscuration over time.

Abstract: Long-duration gamma-ray bursts (GRBs) are believed to occur in star-forming regions. The multiwavelength follow-up observations of the early afterglow of GRB 240825A provided insights into the evolution of the optical-to-X-ray spectral feature of the afterglow. We comprehensively investigate the evolution of X-ray spectral properties through time-resolved spectral analysis and calculate optical darkness ($β_\mathrm{OX}$) to reveal the physical properties of the afterglow. The X-ray-to-optical SEDs of afterglow in different time intervals are fitted to derive the extinction curves. The $β_\mathrm{OX}$ exhibits a trend of decreasing and then increasing, reaching its minimum value at $\sim1000\mathrm{\,s}$ post-trigger. However, at 11 hours post-trigger, $β_\mathrm{OX}$ does not meet the criteria for an optically dark burst. The extinction curves in different time intervals indicate that GRB 240825A occurred in a dust-obscured environment.

</details>


### [10] [Magnetised turbulent plasmas as high-energy particle accelerators](https://arxiv.org/abs/2512.15239)
*M. Lemoine*

Main category: astro-ph.HE

TL;DR: The paper presents a theoretical model explaining particle acceleration in magnetised turbulent plasmas through a generalised Fermi framework, highlighting stochastic acceleration due to magnetic field bends and velocity compressions. It finds a spatially inhomogeneous acceleration with a broken power law distribution, positioning relativistic turbulence as an efficient particle accelerator.


<details>
  <summary>Details</summary>
Motivation: To understand recent kinetic simulation findings of particle acceleration in relativistic turbulence by framing them within a coherent theoretical model and exploring implications for astrophysical particle transport and energy spectra.

Method: Analytical modelling using a generalised Fermi acceleration framework combined with insights from fully kinetic numerical simulations of large-amplitude magnetised turbulence.

Result: Identifies key acceleration mechanisms via magnetic field line bends and velocity compressions, demonstrates spatial inhomogeneity in acceleration rates, and observes a broken power law distribution in acceleration probabilities.

Conclusion: Relativistic, large-amplitude turbulence serves as a powerful particle accelerator with significant consequences for understanding cosmic-ray energy spectra and transport mechanisms in astrophysical environments.

Abstract: This proceedings paper reports on the theoretical modelling of particle acceleration in magnetised turbulent plasmas. It briefly reviews some recent findings obtained from fully kinetic numerical simulations of large-amplitude, semi to fully relativistic turbulence. The paper then argues that these findings can be understood within the framework of a ``generalised Fermi'' picture of stochastic acceleration, which it summarises. The dominant contributions to acceleration appear to arise from particle interactions with sharp, dynamic bends of the magnetic field lines and regions of velocity compression. Interestingly, the acceleration rate is spatially inhomogeneous and its probability distribution follows a broken power law extending up to large values. This makes relativistic, large-amplitude turbulence an extreme particle accelerator. Some implications for particle transport and the shape of the particle energy spectrum in the presence of radiative losses and over long timescales are also discussed.

</details>


### [11] [Prospects on detection of the Fermi Bubbles with CTAO](https://arxiv.org/abs/2512.15316)
*Francesco Xotta,Nina Bavdaž,Christopher Eckner,Dmitry Malyshev,Judit Pérez-Romero,Gabrijela Zaharijas*

Main category: astro-ph.HE

TL;DR: The paper evaluates the Cherenkov Telescope Array Observatory (CTAO)'s ability to detect the Fermi Bubbles (FBs) using the alpha configuration in the South site, simulating observations with different strategies and models to estimate sensitivity.


<details>
  <summary>Details</summary>
Motivation: The mechanism behind the Fermi Bubbles' production is unclear, and existing upper limits from H.E.S.S. and HAWC necessitate more sensitive observations. CTAO's enhanced capabilities could provide critical insights into their origin, especially at low latitudes where the FBs' spectrum extends to 1 TeV.

Method: The authors simulated CTAO observations using gammapy, testing benchmark models of the FBs and interstellar emission with various survey strategies proposed by the CTAO consortium. They analyzed the sensitivity to detect the FBs under different configurations and observational approaches.

Result: The analysis estimates CTAO's sensitivity to detect the FBs, highlighting optimal observation strategies and demonstrating improved detection potential compared to current observatories like H.E.S.S. and HAWC.

Conclusion: CTAO's alpha configuration in the South site offers enhanced sensitivity to uncover the FBs' properties at low latitudes, aiding in resolving their origin by observing features like the high-energy spectrum extension beyond 100 GeV.

Abstract: In 2010, the Fermi Gamma-ray Space Telescope observed two gamma-ray emitting structures, the Fermi Bubbles (FBs), that extend up to 55° above and below the Galactic plane and that seem to emanate from the Galactic center region. Although the spectrum at latitudes |b| > 10° has a softening or a cutoff around 100 GeV, the one at the base of the FBs, |b| <10°, extends up to about 1 TeV without a significant cutoff in the Fermi LAT data. The mechanism behind the FBs production is currently under debate. More observations of the FBs at different energies are required to improve our understanding of their origin.
  Recently, H.E.S.S. and HAWC observatory have set upper limits on the FBs. In this work, we assess the sensitivity of the Cherenkov Telescope Array Observatory (CTAO) using the "alpha configuration" in the South site to detect the FBs and investigate the optimal strategies for their detection at low latitudes. We simulate the observations using the official CTAO science tool gammapy, considering several benchmark models for the FBs and the interstellar emission and test different observational strategies taking advantage of the proposed CTAO consortium surveys. We use these simulations to estimate the CTAO sensitivity to the FBs.

</details>


### [12] [Hadronic Clues in Quasars Caught by Fermi-LAT](https://arxiv.org/abs/2512.15609)
*Antonio Galván,Nissim Fraija,Edilberto Aguilar-Ruiz,Hermes León Vargas,Maria G. Dainotti,Jose Antonio de Diego*

Main category: astro-ph.HE

TL;DR: The study examines if hadronic processes can explain high-energy gamma-ray emission in quasars, finding a necessary hadronic contribution for Fermi-LAT data but insufficient correlation with IceCube neutrino observations.


<details>
  <summary>Details</summary>
Motivation: To challenge purely leptonic models and assess the role of hadronic mechanisms in quasar high-energy emission.

Method: Analyzing spectral energy distributions (SEDs) of FSRQs using multi-wavelength modeling that combines hadronic and leptonic components, comparing Fermi-LAT gamma-ray data with IceCube neutrino detections.

Result: Hadronic processes are necessary to explain Fermi-LAT gamma-ray spectra, but their contribution to IceCube-detected neutrino flux remains unconfirmed.

Conclusion: While hadronic models improve quasar SED explanations, the lack of strong neutrino signal correlation suggests further investigation into hadronic contributions and observational limitations.

Abstract: This work explores whether hadronic processes could be responsible for the high-energy emission seen in quasars identified by the Large Area Telescope (LAT) instrument aboard the Fermi satellite. In contrast to purely leptonic models, this work investigates whether hadronic mechanisms can explain the observed gamma-ray spectra by analyzing the spectral energy distributions (SEDs) of a chosen sample of FSRQs (Flat-Spectrum Radio Quasars). By incorporating both hadronic and leptonic components into their multi-wavelength modeling, we evaluate the model's feasibility to simultaneously describe the data collected by Fermi-LAT and neutrinos detected by IceCube. According to the results, a hadronic contribution would be required to explain the SED of quasars detected by Fermi-LAT. However, their contribution to the neutrino flux detected by IceCube remains understated.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [13] [The Galactic White Dwarf Population](https://arxiv.org/abs/2512.14763)
*Santiago Torres,Roberto Raddi,Alberto Rebassa-Mansergas,Leandro G. Althaus,Maria Camisassa,Tim Cunningham,Camila Damia Rincón,Aina Ferrer i Burjachs,Nicola Gentile Fusillo,Enrique García-Zamora,Anna F. Pala,Steven Parsons,Ingrid Pelisoli,Nicole Reindl,Snehalata Sahu,Alejandro Santos-García,Pier-Emmanuel Tremblay,Odette Toloza*

Main category: astro-ph.IM

TL;DR: The Gaia mission has advanced white dwarf studies by revealing new structures in the HR diagram, but unresolved questions remain regarding atmospheric composition and other parameters. Spectroscopic analysis using ESO facilities is crucial for determining white dwarf properties, which can help understand their evolution and the Galaxy's star formation history. Future surveys with advanced spectrographs will be essential to achieve complete spectral coverage.


<details>
  <summary>Details</summary>
Motivation: While Gaia revolutionized white dwarf census and HR diagram structures, it raised questions about atmospheric composition, magnetism, and evolutionary pathways. Detailed spectroscopic analysis is needed to interpret these findings and address gaps in understanding white dwarf physics and galactic history.

Method: Utilize current/future ESO spectroscopic facilities to obtain effective temperatures, surface gravities, and detailed spectral data. These parameters allow derivation of masses, cooling ages, and luminosities, enabling studies of spectral evolution, interior physics, and population characteristics.

Result: Accurate white dwarf parameters will improve mass distributions, luminosity functions, and constrain the initial-to-final mass relation. This data is critical for reconstructing the Galaxy's star formation history and probing the initial mass function.

Conclusion: Future multi-fiber spectrographs on large telescopes will provide comprehensive spectroscopic samples, ensuring spectral completeness and high-quality data across the HR diagram. This will resolve longstanding questions in white dwarf astrophysics and advance our knowledge of galactic evolution.

Abstract: The ESA Gaia mission has revolutionized our understanding of the white dwarf population, delivering an unprecedented census of these nearby remnants and revealing previously unseen structures in the Hertzsprung-Russell (HR) diagram. However, while Gaia has expanded the scope of white dwarf astrophysics, it has also exposed new questions related to atmospheric composition, spectral evolution, crystallization, magnetism, and merger-driven pathways. Many of these open problems are encoded in the detailed morphology of the Gaia HR diagram, where precise spectroscopic characterization is essential for interpreting the underlying physical processes. Spectroscopic characterization, obtainable with current and future ESO facilities, can provide the effective temperatures and surface gravities that are required to derive accurate white dwarf masses, cooling ages, and luminosities. These fundamental parameters not only enable studies of spectral evolution, interior physics, and the origin of magnetic and high-mass white dwarfs, but also guarantee the construction of robust mass distributions and luminosity functions, essential for constraining the initial-to-final mass relation, probing the initial mass function, and reconstructing the star formation history of the local Galaxy, among other applications. Looking toward the 2040s, future multi-fiber spectrographs operating in survey mode on 10--15 meter class telescopes will be able to collect a complete spectroscopic sample of white dwarf, enabling the detailed characterization of their population. Achieving spectroscopic completeness for the nearby Galactic population and securing high signal-to-noise, moderate-to-high resolution spectra across the HR diagram with ESO instrumentation will be critical steps toward resolving these longstanding questions in white dwarf astrophysics.

</details>


### [14] [Serendipitous and targeted mm/sub-mm transient searches with wide-FOV telescope](https://arxiv.org/abs/2512.14768)
*Karri Koljonen,Claudio Ricci,Thomas Stanke,Doug Johnstone,Atul Mohan,Francisco Montenegro-Montes,John Orlowski-Scherer*

Main category: astro-ph.IM

TL;DR: The mm/sub-mm wavelength range offers a promising frontier for studying transient and variable astrophysical phenomena. A new instrument combining wide field-of-view, high sensitivity, and multi-band capabilities could enable systematic surveys and rapid follow-up, addressing key science areas like young stellar objects, flaring stars, compact binaries, explosive events, and multi-messenger astronomy. Such observations would bridge the spectral gap between radio/optical/infrared and provide unique insights into obscured astrophysical processes, creating legacy datasets for future studies.


<details>
  <summary>Details</summary>
Motivation: The mm/sub-mm sky is under-explored despite its potential for discovering transient and variable phenomena. Existing instruments lack the necessary combination of wide field-of-view, high sensitivity, and rapid response capability required to systematically monitor these phenomena and respond to multi-messenger alerts. This spectral range uniquely accesses obscured environments and energetic processes not fully probed by other wavelengths.

Method: Propose deployment of a wide-field, high-sensitivity mm/sub-mm instrument with large aperture and degree-scale field of view. This would enable: 1) Regular Galactic Plane monitoring 2) Surveys targeting time-variable emission sources 3) Rapid-response follow-up for multi-messenger events (e.g., gravitational-wave triggers) 4) Multi-band observations to study energetic processes like jets, relativistic shocks, and accretion flows. Emphasis on rapid slewing capability and sensitivity across multiple bands.

Result: Expected outcomes include discovery of new variable sources, detailed characterization of astrophysical processes in obscured environments, and creation of large legacy datasets for population studies. Improved understanding of phenomena like young stellar object evolution, stellar flaring mechanisms, compact binary interactions, and explosive events' energetics.

Conclusion: Developing such an instrument would revolutionize time-domain mm/sub-mm astronomy, providing unparalleled observational capabilities that complement existing radio/optical facilities. The resulting long-term datasets will serve as critical resources for astrophysical research through the 2040s and beyond, driving advancements in our understanding of dynamic celestial processes and multi-messenger astrophysics.

Abstract: The millimeter/sub-millimeter (mm/sub-mm) sky remains a rich but under-explored frontier for transient and variable phenomena. A wide-field, high-sensitivity instrument with a large aperture and degree-scale field of view would open this regime, enabling both systematic survey monitoring and rapid-response follow-up. Key science opportunities include Galactic Plane monitoring and surveys to discover and characterize time-variable emission from young stellar objects, magnetically active and flaring stars, compact binaries, and explosive events, as well as prompt responses to multi-messenger alerts with large localization regions (e.g., gravitational-wave triggers). Multi-band capability, rapid slewing, and high sensitivity are essential to probe energetic processes such as jet launching, relativistic shocks and accretion flows in unprecedented detail. While long-term monitoring is well established at radio and optical/infrared wavelengths, mm/sub-mm observations uniquely bridge the spectral gap between these regimes, directly probing obscured environments that are inaccessible elsewhere. Large-scale monitoring programs will yield legacy datasets crucial for population studies through the 2040s and beyond.

</details>


### [15] [White Dwarfs in Wide Binary Systems as Reliable Age Calibrators](https://arxiv.org/abs/2512.14769)
*Alberto Rebassa-Mansergas,Roberto Raddi,Anna F. Pala,Alejandro Santos-García,Santiago Torres,Leandro Althaus,Diogo Belloni,Maria Camisassa,Tim Cunningham,Camila Damia Rincón,Aina Ferrer i Burjachs,Enrique García-Zamora,JJ Hermes,Adam Moss,Steven G. Parsons,Odette Toloza*

Main category: astro-ph.IM

TL;DR: The paper addresses uncertainties in stellar age estimation by focusing on massive white dwarfs in wide binaries, whose ages can be determined with higher precision due to negligible progenitor lifetimes, and outlines the instrumentation needed for their observations.


<details>
  <summary>Details</summary>
Motivation: To reduce uncertainties in age-dependent stellar relations by leveraging massive white dwarfs' simple cooling processes and minimal progenitor lifetimes, which allow more accurate age determinations.

Method: Analyzing a large sample of massive white dwarfs (>0.7 Msun) in wide binaries, requiring specialized instrumentation for observing faint objects and improving observational constraints on initial-to-final mass relations.

Result: Proposed instrumentation requirements for future observations to better characterize massive white dwarfs, thereby mitigating uncertainties in their age estimates.

Conclusion: Specialized observational tools are essential to exploit massive white dwarfs as precise cosmic clocks, improving our understanding of Milky Way and stellar evolution through accurate age determinations.

Abstract: Deriving precise stellar ages is a challenging task. Consequently, age-dependent relations - such as the age-metallicity and age-velocity dispersion relations of the Milky Way, or the age-rotation-activity relation of low-mass stars - are subject to potentially large uncertainties, despite the well-defined trends observed at the population level. White dwarfs, the most common stellar remnants, follow a relatively simple and well-understood cooling process. When found in wide binary systems with main-sequence companions, they can therefore provide the much-needed precise age estimates. The total age of such systems depends not only on the white dwarf cooling time but also on the lifetime of the main-sequence progenitor. Estimating this lifetime requires knowledge of the progenitor mass, which is typically inferred by adopting an initial-to-final mass relation. However, the observational constraints on this relation are still poorly defined, introducing a source of uncertainty in white dwarf age determinations. To mitigate this issue, we focus on a large sample of massive white dwarfs (>~0.7 Msun), for which the main-sequence progenitor lifetime is negligible. These white dwarfs are intrinsically faint and therefore require specialized facilities for adequate follow-up observations. In this white paper, we outline the instrumentation requirements needed to observe the forthcoming population of massive white dwarfs in our Galaxy.

</details>


### [16] [The Emergence of Prebiotic Chemistry in the ISM](https://arxiv.org/abs/2512.14772)
*Izaskun Jimenez-Serra,Giuliana Cosentino,Francisco Montenegro-Montes,Laura Colzi,Victor M. Rivilla,Miguel Sanz-Novo,Marta Rey-Montejo,David San Andres,Sergio Martin,Shaoshan Zeng,Amelie Godard Palluet,Miguel A. Requena-Torres,German Molpeceres,Pamela Klassen,Doug Johnston,Francesco Fontani,Silvia Spezzano,Elena Redaelli,Juris Kalvans,Yuri Aikawa,Belen Tercero,Pablo de Vicente,Serena Viti,Emilio J. Cocinero,Aran Insausti*

Main category: astro-ph.IM

TL;DR: The paper explores the potential formation of complex organic molecules, including amino acids, sugars, and RNA/DNA nucleobases, in the interstellar medium using a next-generation single-dish telescope. This research could reveal whether these molecules, essential for life, originated in space and were delivered to Earth.


<details>
  <summary>Details</summary>
Motivation: To investigate whether complex organic molecules necessary for life can form in the interstellar medium and were possibly delivered to Earth via celestial bodies like comets and meteorites.

Method: Utilizing a large-area single-dish telescope with high sensitivity, wide field-of-view, and multi-band instruments to observe and analyze the chemical complexity in the ISM across galaxies.

Result: The study aims to determine the presence of life-building molecules (amino acids, sugars, nucleobases) in space, potentially showing their extraterrestrial origin.

Conclusion: If found, these molecules would suggest that the ingredients for life are abundant in the universe, possibly seeding Earth and other planets, thus supporting panspermia theories.

Abstract: Contrary to popular belief, the interstellar medium (ISM) is not empty; it is filled with atoms, dust particles, and molecules. Some of these molecules may have been the very building blocks of life that, delivered to Earth via comets and meteorites, could have given rise to Life itself. A large-area single-dish telescope with superb sensitivity, field-of-view and multi-band instruments will allow us to explore the limits of chemical complexity in the interstellar medium, across our Galaxy and in external galaxies, determining whether amino acids, sugars, or RNA/DNA nucleobases can form in space.

</details>


### [17] [The Future of Evolved Planetary Systems](https://arxiv.org/abs/2512.14774)
*Roberto Raddi,Anna F. Pala,Alberto Rebassa-Mansergas,Boris T. Gänsicke,Lientur Celedon,Tim Cunningham,Camila Damia Rincón,Aina Ferrer i Burjachs,Enrique García-Zamora,Nicola Pietro Gentile Fusillo,Joaquim Meza,Evelyn Puebla,Pablo Rodríguez-Gil,Snehalata Sahu,Alejandro Santos-García,Odette Toloza,Santiago Torres,Pier-Emmanuel Tremblay,Jan van Roestel,Murat Uzundag,Dimitri Veras,Jamie Williams*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Understanding the formation, evolution, and chemical diversity of exoplanets are now central areas of astrophysics research. White dwarfs provide a uniquely sensitive laboratory for studying the end stages of planetary-system evolution and for probing the bulk composition of both rocky and volatile-rich exoplanetary material. In the 2030s new facilities will transform our ability to carry out \textit{``industrial-scale''} astrophysics, leading to fundamental results and new challenges for the next decade. By combining the volume of data surveyed by the ESA {\em Gaia} mission and Vera C. Rubin Observatory with the next-generation of spectroscopic facilities, the European Southern Observatory (ESO) community will be in a position to obtain an unbiased census of evolved planetary systems, constrain the composition of thousands of disrupted planetesimals, and connect these signatures to Galactic populations and stellar birth environments. Thus, it is now the time for assessing those challenges and preparing for the future. This white paper outlines key science opportunities arising in the next decade and the technological requirements of future ESO facilities in enabling transformative discoveries in the 2040s. These future facilities will have to combine a number of features that are crucial for studying evolved planetary systems at white dwarfs, such as broad optical to near-infrared coverage, a high sensitivity at blue wavelengths, multi-resolution capability, massive multi-plexing, and time-domain reactivity.

</details>


### [18] [Sub-millimeter wavelength protostellar accretion rate monitoring with AtLAST](https://arxiv.org/abs/2512.14777)
*Thomas Stanke,Verena Wolf,Bringfried Stecklum,Doug Johnstone,Jochen Eislöffel,Gregory J. Herczeg,S. Tom Megeath,Karri I. I. Koljonen*

Main category: astro-ph.IM

TL;DR: The paper argues that a large ground-based sub-millimeter single-dish telescope with a wide field of view is essential to monitor accretion luminosity variations in a large sample of protostars over decades, which is necessary to determine whether protostellar accretion occurs in major bursts or steadily.


<details>
  <summary>Details</summary>
Motivation: The motivation is to resolve the question of how protostars accrete mass during their formation. Direct study of early protostellar accretion processes is hindered by high extinction, and long-term monitoring of accretion luminosity variations is needed to distinguish between bursty vs. steady accretion scenarios.

Method: The paper proposes that a dedicated sub-millimeter observational facility with wide field of view and large collecting area is required. Such a telescope would enable decade-scale photometric monitoring of a statistically significant sample of protostars to track changes in their sub-mm emission linked to accretion luminosity.

Result: No observational results are presented here since this is a proposal for required observational infrastructure. The expected outcome would be time-series data showing accretion luminosity variations over decades.

Conclusion: The conclusion is that existing facilities lack the necessary sensitivity and survey speed to perform this critical monitoring, necessitating the development of a new generation sub-millimeter telescope with specific characteristics to advance our understanding of protostellar evolution.

Abstract: How a star forms is a fundamental question in astrophysics. In the earliest stages of protostellar evolution high extinction prevents a direct study of the accretion processes and their temporal evolution. Monitoring the variations of the accretion luminosity in a large protostar sample over decades is needed to reveal how protostars accrete -- in major bursts or in a quasi-steady fashion. We here argue that a large ground based sub-millimeter single-dish facility with a wide FoV is required to fulfill this task.

</details>


### [19] [Why the Northern Hemisphere Needs a 30-40m Telescope and the Science at Stake: Shaping Galaxies and Their Stars with Stellar Population Gradients, IMF Variations and Environmental Drivers in Cluster Early-Type Galaxies](https://arxiv.org/abs/2512.14780)
*A. Vazdekis,P. Sánchez-Blázquez,A. Ferré-Mateu,I. Martín-Navarro,M. A. Beasley,J. A. L. Aguerri,A. Camps-Fariña,A. de Lorenzo-Cáceres,E. Eftekhari,J. Falcón-Barroso,I. Ferreras,F. La Barbera,R. García-Benito,R. M. González Delgado,M. Longhetti,C. Maraston,I. Pérez,F. Pinna,V. Quilis,R. F. Peletier,S. F. Sánchez-Sánchez,A. Sansom,L. Scholz-Díaz,C. Spiniello,D. Thomas,E. Villaver*

Main category: astro-ph.IM

TL;DR: This white paper argues that a 30m-class telescope is essential for studying early-type galaxies (ETGs) through high-resolution, spatially resolved spectroscopy to understand their formation history, environmental influences, and connections to high-redshift progenitors.


<details>
  <summary>Details</summary>
Motivation: The paper's motivation is to address the need for advanced observational capabilities to disentangle the formation mechanisms of ETGs, including star formation, accretion, mergers, and feedback, which are encoded in stellar populations, chemical abundances, IMF variations, and structural features at large radii.

Method: The proposed method involves using a 30m-class telescope to obtain high-signal-to-noise U-band to near-IR spectroscopy with sufficient spatial resolution (~kpc scales) at large galactic radii. Observations will target nearby clusters (Virgo, Perseus, Coma) to study ETGs across diverse environments and evolutionary stages.

Result: Expected results include detailed maps of stellar population gradients, IMF variations, 3D galaxy structures, and identification of compact/relic systems. These will constrain ETG formation models and link them to high-redshift galaxies.

Conclusion: A 30m-class telescope is indispensable for resolving critical unresolved questions about ETG evolution and their environmental dependencies. The proposed observations will transform our understanding of galaxy formation and connectivity across cosmic time.

Abstract: This white paper highlights how stellar population gradients, chemical abundance patterns, stellar initial mass function (IMF) variations, and structural signatures in early-type galaxies (ETGs), measured at faint and large galactocentric radii, out to $\sim4R_e$, provide powerful diagnostics of their formation and evolutionary histories. These observables encode the combined effects of early dissipative star formation, subsequent accretion and mergers, and internal feedback processes. Achieving such measurements requires high-signal-to-noise, spatially resolved U-band--optical--near-IR spectroscopy at large radii, with enough spatial resolution to study the variation of these properties on $\sim$kpc scales. These capabilities can only be delivered by a 30\,m-class telescope. Disentangling these internal processes from environmental influences further demands observations of galaxies across clusters spanning a wide range of evolutionary stages and local environments. The nearby Virgo, Perseus, and Coma clusters, without any comparable nearby counterparts in the Southern Hemisphere, offer ideal laboratories for this work. Such observations will place stringent constraints on the formation mechanism of ETGs, connecting local cluster ETGs to their high-redshift progenitors. This white paper outlines several key science cases enabled by such a facility: (1) mapping stellar population gradients across environments; (2) tracing IMF variations as a function of evolutionary stage and environment; (3) reconstructing the three-dimensional structure of galaxies through deep integral-field spectroscopy and imaging; and (4) identifying and studying compact and relic systems as progenitors of present-day ETGs.

</details>


### [20] [Why the Northern Hemisphere Needs a 30-40 m Telescope and the Science at Stake: Cosmology and High-z Universe](https://arxiv.org/abs/2512.14781)
*Pablo G. Pérez-González,Roberto Maiolino,Pascal A. Oesch,Alvio Renzini,Tommaso Treu,Cristina Ramos Almeida,Sandra Faber,Luis Colina,Almudena Alonso-Herrero,Santiago Arribas,Guillermo Barro,Helmut Dannerbauer,Mark Dickinson,Mauro Giavalisco,Marc Huertas-Company,Göran Östlin,Giulia Rodighiero,Patricia Sánchez-Blázquez,Elisa Toloba*

Main category: astro-ph.IM

TL;DR: The construction of a 30-40 meter-class telescope in the Northern Hemisphere, akin to ELT/TMT, is crucial for comprehensive Astrophysics, Cosmology, and Physics research, enabling synergistic studies with space observatories like JWST and addressing key questions about the Universe's composition and early structures.


<details>
  <summary>Details</summary>
Motivation: To address unresolved questions in Astrophysics and Cosmology, such as the Universe's composition, formation of first stars/supermassive black holes, and to complement data from full-sky space telescopes (JWST, Euclid, Roman). A Northern ELT/TMT would provide essential observing capabilities not fully met by existing facilities.

Method: Deploy a 30-40 meter Northern Hemisphere telescope with advanced instrumentation to maximize multiplexing, observational diversity, rapid-response capability, and statistical power needed for analyzing transient events and follow-up studies of space observatory discoveries.

Result: Enhanced capacity to study rare/transient phenomena, accelerate progress in understanding fundamental Physics through multi-messenger/time-domain astronomy, and achieve synergies with space-based missions.

Conclusion: A Northern ELT/TMT is indispensable for maintaining scientific leadership and maximizing the value of current/future space telescope investments, ensuring holistic exploration of cosmic phenomena.

Abstract: Full sky coverage with 30-40 meter-class telescopes is essential to answer fundamental questions in Astrophysics, Cosmology, and Physics, such as the composition of the Universe and the formation of the first stars and supermassive black holes. An ELT/TMT-like telescope in the Northern Hemisphere is a fundamental and necessary facility to provide multiplexing of observing power, diversity of instrumentation, rapid response, and statistical power required to address the questions and the problems, current and future, unveiled by full sky observatories such as JWST, Euclid, or Roman space telescopes. The Northern ELT/TMT will expedite the study of unique, extreme, rare, transient, and/or high-energy events which will give the most information about fundamental Physics problems in the era of multi-messenger and time-domain Astronomy.

</details>


### [21] [Why the Northern Hemisphere Needs a 30-40 m Telescope and the Science at Stake. How do Planetary Systems Form?](https://arxiv.org/abs/2512.14782)
*I. Mendigutía,N. Huélamo,I. Jiménez-Serra,E. Villaver,O. Balsalobre-Ruza,D. Barrado,M. Benisty,A. Boccaletti,H. Bouy,G. Chauvin,G. Cugno,R. Fedriani,M. Fernández,A. Fuente,S. Haffert,M. Kama,J. Lillo-Box,G. Meeus,N. Miret-Roig,B. Montesinos,M. Osorio,R. D. Oudmaijer,A. F. Placinta-Mitrea,D. Pollacco,I. Rebollido,M. Reggiani,A. Ribas,P. Rivière-Marichalar,A. Sicilia-Aguilar,C. Toci,R. van Boekel,N. van der Marel,M. Vioque,E. Whelan,A. Zurlo*

Main category: astro-ph.IM

TL;DR: The paper argues that a large northern hemisphere telescope is essential to complement the ELT's southern coverage, enabling comprehensive census of forming planets in key star-forming regions and maintaining Europe's leadership in planet-formation studies.


<details>
  <summary>Details</summary>
Motivation: Current facilities have insufficient coverage of northern star-forming regions; without a northern telescope, Europe cannot fully study planet formation processes observable only in the northern sky, risking exclusion from key discoveries.

Method: Advocates for a 30-40m class telescope in the northern hemisphere to achieve diffraction-limited imaging necessary for detecting protoplanets and disks, emphasizing synergy with ngVLA and Gaia for comprehensive studies.

Result: Such a telescope would allow complete sky coverage, enabling statistical analyses of forming planets, better understanding of disk-planet interactions, and leveraging northern facilities' capabilities.

Conclusion: Building a northern giant telescope is critical for Europe to remain a leader in planet formation research, ensuring it can fully explore the necessary parameter space and work with global observatories to advance the field.

Abstract: The detection and characterization of protoplanets in protoplanetary disks around young stars is emerging as a transformative field that will redefine our understanding of how planetary systems form. While current facilities have revealed the diversity of mature exoplanets and the complex structures of disks, we still lack the crucial observational link between them: a statistically meaningful census of planets caught in the act of formation. This white paper argues that such a breakthrough requires access to the nearest and most informative star-forming regions, roughly half of which are poorly accessible or entirely unreachable from Cerro Armazones. Although the ELT alone will strongly impact our knowledge of planet formation, its location prevents Europe from fully exploiting the necessary parameter space. A 30-40 m telescope in the northern hemisphere is therefore essential for obtaining diffraction-limited imaging of protoplanets and disks across the entire sky, enabling robust demographics, exploiting synergies with ngVLA, Gaia, and other facilities covering the north, and ensuring that Europe remains at the forefront of the planet-formation revolution in the coming decades.

</details>


### [22] [Why the Northern Hemisphere Needs a 30-40m Telescope and the Science at Stake: Ultra-Low-Mass Dwarf Galaxies Across the Boreal Cosmic Web](https://arxiv.org/abs/2512.14783)
*J. Alfonso L. Aguerri,Jesús Falcón-Barroso,María Argudo-Fernández,Yago Ascasibar,Marc Balcells,Bahar Bidaran,Virginia Cuomo,David Fernández-Arenas,Anna Ferré-Mateu,Rubén García-Benito,Rosa María González Delgado,Marcella Longhetti,Pavel Mancera-Piña,Antonino Marasco,Lorenzo Morelli,Reynier F. Peletier,Isabel Pérez Martín,Francesca Pinna,Daniel Rosa González,Marc Sarzi,Alexandre Vazdekis,Marc Verheijen,Pedro Villalba González,Anne-Marie Weijmans,Stefano Zarattini*

Main category: astro-ph.IM

TL;DR: The paper proposes using a large northern telescope with advanced spectroscopic tools to study faint dwarf galaxies across various environments, aiming to understand galaxy formation and fundamental physics through their star formation, chemistry, and dynamics.


<details>
  <summary>Details</summary>
Motivation: Current studies lack detailed spectroscopic data on the faintest dwarf galaxies, especially in different environments. This gap hinders understanding of how feedback, reionization, and environment affect the lowest-mass galaxies.

Method: A deep survey of the Coma Cluster and targeted observations in diverse environments (clusters, groups, filaments, low-density regions) using a 30-40m telescope with a multiplexed optical integral-field spectrograph to map star formation histories, chemical enrichment, and kinematics.

Result: The study will produce unprecedented data on dwarf galaxies, enabling tests of models related to dark matter physics, early-Universe feedback, and environmental quenching.

Conclusion: Such observations will elevate dwarf galaxies to precision probes for both galaxy formation mechanisms and fundamental physics, filling critical gaps in our knowledge of ultra-low mass systems.

Abstract: Dwarf galaxies dominate the galaxy population in the nearby Universe and occupy the regime where feedback, reionization, and environment exert their strongest influence on galaxy formation. Despite their importance, detailed spectroscopic constraints on the faintest dwarfs are currently limited to a handful of systems in the Local Volume, leaving the role of large-scale environment essentially unexplored at ultra-low stellar masses. A northern 30-40m class telescope equipped with a multiplexed optical integral-field spectrograph will enable a systematic, spatially resolved spectroscopic census of dwarf galaxies with $M_\star \sim 10^{5}-10^{7} M_\odot$ across a wide range of environments. A deep survey of the Coma Cluster, combined with targeted observations of dwarfs in clusters, groups, filaments, and low-density regions, will map star formation histories, chemical enrichment, and internal kinematics at unprecedented depth. This program will directly test models of dark-matter physics, early-Universe feedback, and environmental quenching in the lowest-mass galaxies, establishing dwarf galaxies as precision probes of both galaxy formation and fundamental physics.

</details>


### [23] [Why the Northern Hemisphere Needs a 30-40 m Telescope and the Science at Stake: A Low Surface Brightness Science Case](https://arxiv.org/abs/2512.14784)
*Mireia Montes,Ignacio Trujillo,David Martínez Delgado,Borja Anguiano,Magda Arnaboldi,Michael A. Beasley,Fernando Buitrago,Michele Cantiello,Andrés del Pino,Amandine Doliva-Dolinsky,Helena Domínguez-Sánchez,Mauro D'Onofrio,Pierre-Alain Duc,Katja Fahrion,Anna Ferré-Mateu,Carme Gallart,Nina Hatch,Enrica Iodice,Yolanda Jiménez-Teja,Francine Marleau,Chris Mihos,Nicola Napolitano,Agnieszka Pollo,Javier Román,Joanna Sakowska,Jorge Sánchez Almeida,Patricia Sánchez-Blázquez,Marilena Spavone,Guillaume Thomas,Eva Villaver*

Main category: astro-ph.IM

TL;DR: The paper advocates for the necessity of a large (30-40m) telescope in the Northern Hemisphere to study faint, low surface brightness galaxies, which are key to understanding galaxy evolution and dark matter but are underexplored due to observational limitations.


<details>
  <summary>Details</summary>
Motivation: Current models of galaxy evolution and dark matter are biased by focusing on bright, easily observable objects. Observing LSB galaxies, which are critical for completing our astrophysical understanding, requires overcoming the observational limitations that make these faint structures hard to detect.

Method: Proposing the construction of a 30-40m class telescope with advanced capabilities like adaptive optics to achieve the sensitivity and spatial resolution needed to probe LSB regimes, particularly in the Northern Hemisphere to access important galactic structures and environments.

Result: Such a telescope would enable transformative science in studying LSB galaxies, revealing insights into galaxy evolution, hierarchical formation processes, and the properties of dark matter that current facilities cannot achieve.

Conclusion: A next-generation telescope with these specifications is indispensable for advancing astrophysics by addressing observational biases and exploring the underobserved LSB Universe.

Abstract: The Extragalactic Low Surface Brightness (LSB, $μ_V\gtrsim 27$ mag/arcsec$^2$) Universe represents a crucial, yet largely unseen, frontier in modern astrophysics. This faint realm holds the keys to completing our understanding of galaxy evolution, hierarchical assembly, and even the fundamental nature of dark matter. Our current theoretical models are inherently incomplete, largely mirroring the properties of the brightest, most easily observed objects. To overcome this critical bias and unlock the secrets of this realm, a transformative leap in observational capability is required. A 30 to 40m class telescope, leveraging unprecedented sensitivity and spatial resolution, especially with adaptive optics, is the essential tool to fundamentally probe these faint, low-density stellar regimes. This white paper details the transformative LSB science that such a facility, strategically positioned in the Northern Hemisphere (NH) to access crucial nearby structures and rich environments, can achieve.

</details>


### [24] [Why the Northern Hemisphere Needs a 30-40m Telescope and the Science at Stake: from Interstellar Visitors to Planetary Defence](https://arxiv.org/abs/2512.14785)
*J. de León,N. Pinilla-Alonso,P. Tanga,D. Souami,Z. Gray,A. Alvarez-Candal,B. Carry,R. de la Fuente Marcos,A. Delsanti,F. La Forgia,A. Migliorini,T. Müller,A. Penttilä,M. Popescu,C. Snodgrass,D. Oszkiewicz,C. Opitom,A. Campo-Bagatin,J. Licandro,R. Hueso,M. Lazzarin,S. Fornasier,R. Brunetto,J. A. de Abol Brasón,J. de Cos Juez,J. DeMartini,A. Donaldson,R. Dorsey,R. Duffard,J. Fernández Díaz,F. García de Leániz,R. Hevia Díaz,J. M. Gómez-Limón,O. Groussin,S. Iglesias Álvarez,T. Kohout,M. Kretlow,T. Le Pivert-Jolivet,M. Montero-Vega,N. Morales,K. Muinonen,J. L. Ortiz,G. P. Prodan,J. L. Rizos,J. E. Robinson,S. Rodríguez Cabo,J. Rodríguez Rodríguez,A. Rozek,P. Santos-Sanz,E. Tatsumi,F. Tinaut-Ruano,E. Villaver*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Small Solar system Objects (SSOs) preserve the physical, chemical, and dynamical signatures of the Sun's protoplanetary disk. Upcoming surveys will discover vast numbers of new objects, yet their scientific value will depend on follow-up observations requiring far greater sensitivity and resolution than those currently available. A 30-m class telescope like the Extremely Large Telescope (ELT) will be transformative, but its Southern location will leave significant regions of the sky poorly covered or even non accessible. A Northern 30-40m telescope is therefore essential to achieve full-sky coverage and fully exploit the small body discoveries of the 2030-2050 era, in particular for targets of opportunity or unexpected discoveries, like those of interstellar objects and potentially hazardous asteroids, as well as for distant trans-Neptunian objects and space mission targets.

</details>


### [25] [Why the Northern Hemisphere Needs a 30-40 m Telescope and the Science at Stake: Mapping formation pathways of nuclear star clusters across galaxies](https://arxiv.org/abs/2512.14786)
*Francesca Pinna,Isabel Pérez,Anna Ferré-Mateu,Begoña García Lorenzo,Alessandra Mastrobuono Battisti,Abbas Askar,Michael Beasley,Bahar Bidaran,Ana L. Chies-Santos,Sébastien Comerón,Kristen C. Dage,Adriana de Lorenzo-Cáceres,Katja Fahrion,Jesús Falcón Barroso,Anja Feldmeier-Krause,Emma Fernández Alvar,Nils Hoyer,Rubén García Benito,Rosa M. Gonzalez Delgado,Ignacio Martín Navarro,Cristina Ramos Almeida,Patricia Sánchez Blázquez,Rubén Sánchez Janssen,Alexandre Vazdekis*

Main category: astro-ph.IM

TL;DR: A 30-m-class Northern telescope is proposed to conduct the first comprehensive survey of nuclear star clusters (NSCs), enabling spatially resolved studies of their properties and their connection with central massive black holes.


<details>
  <summary>Details</summary>
Motivation: Current limitations in telescope resolution and sample size hinder understanding of NSC formation and their relationship with black holes. Most known NSCs are in the Northern Hemisphere, necessitating a large Northern telescope for a systematic survey.

Method: Use the high-resolution instruments of a 30-m-class telescope to spatially resolve NSCs beyond the local 5 Mpc volume, collecting spectroscopic data to study dynamical and star-formation histories and measure black hole masses.

Result: The survey would provide the first unbiased dataset on NSC properties across a large sample, revealing formation pathways and connections with central black holes.

Conclusion: Such a survey is critical to advance knowledge of galaxy evolution and the interplay between NSCs and massive black holes, achievable only with next-generation Northern telescopic facilities.

Abstract: Nuclear star clusters (NSCs) are dense, compact stellar systems only a few parsecs across, located at galaxy centers. Their small sizes make them difficult to resolve spatially. NSCs often coexist with massive black holes, and both trace the dynamical state and evolution of their host galaxies. Dense stellar environments such as NSCs are also ideal sites for forming intermediate-mass black holes (IMBHs). To date, spatially resolved NSC properties, crucial for reconstructing dynamical and star-formation histories, have only been obtained for galaxies within 5 Mpc, using the highest-resolution instruments on the current class of very large telescopes. This severely limits spectroscopic studies, and a systematic, unbiased survey has never been accomplished. Because the vast majority of known NSCs are located in the Northern Hemisphere, only a 30-m-class telescope in the North can provide the statistical power needed to study their physical properties and measure the mass of coexisting central black holes. We propose leveraging the capabilities of a 30-m-class Northern telescope to obtain the first comprehensive, spatially resolved survey of NSCs, finally allowing us to unveil their formation pathways and their yet unknown connection with central massive black holes.

</details>


### [26] [Science Enabled by a 30-Meter-Class Telescope in the Northern Hemisphere: Massive Stars at Low Metallicity](https://arxiv.org/abs/2512.14787)
*Miriam Garcia,Artemio Herrero,Ignacio Negueruela,Norberto Castro,Sara R. Berlanas,Miguel Cerviño,Gonzalo Holgado,Jorge Iglesias-Páramo,Carolina Kehrig,Jesús Maíz Apellániz,J. Miguel Mas-Hesse,Francisco Najarro,Sergio Simón-Díaz,José M. Vílchez*

Main category: astro-ph.IM

TL;DR: The paper emphasizes the importance of studying massive stars under early Universe conditions to improve our understanding of high-redshift galaxies and transient phenomena, as current models have significant uncertainties when extrapolated beyond well-tested environments.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the limitations of current models of massive stars, which are based on observations in the Milky Way and nearby galaxies but need to be extrapolated to the extreme conditions of the early Universe. This is crucial for accurate interpretations of distant galaxies and transient events observed with new telescopes.

Method: The paper likely discusses advancing observational techniques and expanding model testing to environments more representative of the early Universe, leveraging next-generation telescopes to study massive stars in such conditions.

Result: Anticipated results include refined models of massive star populations and their effects (ionizing fluxes, element dispersion) under early Universe conditions, leading to more accurate interpretations of high-redshift observations.

Conclusion: The conclusion stresses that extending massive star studies to early Universe-like environments is essential for progressing our knowledge of the distant Universe, achievable through next-generation telescope capabilities.

Abstract: Massive stars are at the core of our observations of the Universe up to the reionization epoch, both through their intense ionizing fluxes and through the energetic end products that release fresh elements into the interstellar medium. Our interpretation of very high redshift galaxies and transient phenomena depends on knowledge derived from massive star populations in the Milky Way and nearby galaxies, with characteristics that only remotely resemble the conditions in the early Universe. However, the models supporting these interpretations have been tested in a narrow range of environments and carry significant uncertainties when extrapolated. Advancing in our understanding of the Universe beyond the Local Volume therefore requires extending massive star studies to conditions representative of the early Universe. The next generation of telescopes has the potential to accomplish this goal.

</details>


### [27] [Why the Northern Hemisphere Needs a 30-40 m Telescope and the Science at Stake: Resolved Stellar Populations Studies in M31 and its Satellites](https://arxiv.org/abs/2512.14788)
*C. Gallart,E. Fernández-Alvar,A. B. A. Queiroz,A. Aparicio,B. Anguiano,G. Battaglia,M. Beasley,T. Bensby,G. Bono,V. Braga,L. Carigi,L. Casamiquela,S. Cassisi,C. Chiappini,V. P. Debattista,A. del Pino,I. Escala,A. M. N. Ferguson,G. Fiorentino,K. M. Gilbert,P. Guhathakurta,R. Ibata,E. N. Kirby,K. Kuijken,S. Larsen,D. Martínez-Delgado,C. Martínez-Vázquez,D. Massari,I. Minchev,M. Monelli,J. F. Navarro,M. Ness,S. Okamoto,K. Olsen,S. Ortolani,P. A. Palicio,I. Pérez,F. Pinna,A. Prieto,J. Read,A. Recio-Blanco,M. Rejkuba,A. Renzini,R. M. Rich,T. Ruiz-Lara,M. Schultheis,M. Tantalo,G. F. Thomas,A. Vazdekis,E. Villaver,M. Zoccali*

Main category: astro-ph.IM

TL;DR: A proposed 30 m optical/IR telescope in the Northern Hemisphere would revolutionize studies of M31 and its satellites, enabling detailed observations comparable to those done for the Milky Way, thus addressing whether the MW's evolution is representative of other galaxies.


<details>
  <summary>Details</summary>
Motivation: To investigate the formation and evolution of M31 and its satellite system at a level of detail comparable to the Milky Way studies achieved by missions like Gaia and HST, in order to determine how representative the MW's characteristics are in the broader galaxy formation context.

Method: Equipping a 30 m-class telescope with diffraction-limited imaging and high-resolution multi-object spectroscopy to study faint stellar populations in M31 and its satellites.

Result: Such a telescope would provide unprecedented detailed data on M31's disk, halo, bulge, and satellite system, allowing tests of galaxy evolution models beyond the Milky Way.

Conclusion: Comprehensive resolved stellar studies of M31 are feasible with this telescope, which would fill critical gaps in understanding galaxy evolution by comparing M31 and the MW as benchmarks.

Abstract: A 30 m class optical/near-IR telescope in the Northern Hemisphere, equipped for diffraction-limited imaging and high-resolution, multi-object spectroscopy of faint stars, would enable a transformational investigation of the formation and evolution of M31 and its satellite system - on par with what Gaia, the HST, and other major photometric and spectroscopic facilities have achieved for the Milky Way (MW) and its satellites. The unprecedented detail obtained for our home system has reshaped our understanding of the assembly of the MW disk, halo, and bulge, and that of its satellites, which now serve as a benchmark for galaxy formation and evolution models. Extending this level of insight to the M31 system - that of the nearest massive spiral and the only one for which such a comprehensive, resolved stellar population study is feasible - will allow us to address a fundamental question: how representative is the MW and its satellite system within the broader context of galaxy evolution?

</details>


### [28] [White Dwarf Binaries: Probes of Future Astrophysics](https://arxiv.org/abs/2512.14800)
*Anna F. Pala,Roberto Raddi,Alberto Rebassa-Mansergas,Boris T. Gänsicke,Richard I. Anderson,Diogo Belloni,Avraham Binnenfeld,Elmé Breedt,David Buckley,Tim Cunningham,Alessandro Ederoclite,Ana Escorza,Valeriya Korol,Thomas Kupfer,Domitilla de Martino,Jaroslav Merc,Joaquin Meza,Steven Parsons,Ingrid Pelisoli,Nicole Reindl,Pablo Rodríguez-Gil,Alejandro Santos-García,Simone Scaringi,Paula Szkody,Odette Toloza,Santiago Torres,Murat Uzundag,Monica Zorotovic*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: White dwarf binaries are fundamental astrophysical probes. They represent ideal laboratories to test the models of binary evolution, which also apply to the sources of gravitational waves, whose detection led to the award of the 2017 Nobel Prize in Physics. Moreover, their final fate is intimately linked to Type Ia Supernovae (SNe Ia), i.e. the thermonuclear explosion of a white dwarf following the interaction with a companion star, which have become the fundamental yardsticks on cosmological distance scales and led to the discovery of dark energy and the award of the 2011 Nobel Prize in Physics. Finally, white dwarf binaries play a crucial role in influencing star formation and chemical evolution of the Galaxy by injecting energy into, and enriching, the interstellar medium with material ejected during nova eruptions and SN Ia explosions. In the next decade, the advent of the Large Synoptic Survey Telescope (LSST) at the Vera Rubin Observatory will lead to the discovery of hundreds of thousands of white dwarf binaries. Nonetheless, the intrinsic faintness of the majority of these systems will prevent their spectroscopic characterisation with the instruments available in the 2030s. Hence ESO's Expanding Horizons call is timely for planning a future transformative facility, capable of delivering phase-resolved spectroscopic observations of faint white dwarf binaries, which are key to advancing our understanding of stellar and Galactic evolution and cosmology.

</details>


### [29] [Why the Northern Hemisphere Needs a 30-40 m Telescope and the Science at Stake: Galactic Archaeology from the Northern Sky](https://arxiv.org/abs/2512.14789)
*Borja Anguiano,David Valls-Gabaud,Guillaume F. Thomas,David Martínez Delgado,Alberto M. Martínez-García,Andrés del Pino,Ivan Minchev,Patricia Sanchez-Blazquez,Carme Gallart,Teresa Antoja*

Main category: astro-ph.IM

TL;DR: The paper argues that a northern 30-meter-class telescope with advanced spectroscopic capabilities is essential to address unresolved questions about the Milky Way's formation and dark matter structure by observing faint stars in distant and low-surface-brightness structures.


<details>
  <summary>Details</summary>
Motivation: Key unresolved questions include the detailed reconstruction of the Galaxy's assembly from its earliest building blocks and testing dark matter granularity through the stellar halo and outer disk, especially in the Galactic anticenter. Existing and upcoming facilities will not be sufficient to study faint main-sequence stars in low-surface-brightness regions.

Method: Proposes a 30-meter-class telescope in the northern hemisphere equipped with wide-field, highly multiplexed, high-resolution spectroscopic instruments to conduct: (i) a Northern Halo Deep Survey of 10^5-10^6 faint stars out to 150-200 kpc, (ii) chemodynamical mapping of streams to detect dark matter subhalo perturbations, and (iii) tomographic studies of the anticenter and outer disk.

Result: Such a facility would enable all-sky Milky Way archaeology when combined with the Southern ELT, providing transformative insights into Galactic structure and dark matter properties through unprecedented stellar surveys.

Conclusion: A northern 30-meter telescope is critical to achieving comprehensive Milky Way studies and stringent dark matter tests, complementing existing/southern facilities to ensure all-sky coverage for next-generation astronomy.

Abstract: By the 2040s--50s, facilities such as \emph{Gaia}, WEAVE, 4MOST, Rubin, \emph{Euclid}, \emph{Roman}, and the ESO ELT will have transformed our global view of the Milky Way. Yet key questions will remain incompletely resolved: a detailed reconstruction of the Galaxy's assembly from its earliest building blocks, and robust tests of dark matter granularity using the fine structure of the stellar halo and outer disk -- particularly in the Galactic anticenter. Addressing these questions requires high-resolution spectroscopy of faint main-sequence stars (typically 1--2 mag below the turnoff) and turnoff stars ($r \sim 21$--23) in low-surface-brightness structures: halo streams and shells, ultra-faint dwarf galaxies, the warped and flared outer disk, and anticenter substructures. We argue that addressing this science case requires a 30\,m-class telescope in the northern hemisphere, equipped with wide-field, highly multiplexed, high-resolution spectroscopic capabilities. Such a facility would enable (i) a Northern Halo Deep Survey of $\sim 10^{5}$--$10^{6}$ faint main-sequence and turnoff stars out to $\sim 150$--200\,kpc, (ii) chemodynamical mapping of dozens of streams to measure perturbations from dark matter subhalos, and (iii) tomographic studies of the anticenter and outer disk to disentangle perturbed disk material from accreted debris. A northern 30\,m telescope would provide the essential complement to ESO's southern ELT, enabling genuinely all-sky Milky Way archaeology and delivering stringent constraints on the small-scale structure of dark matter.

</details>


### [30] [Dynamical binary interactions in the 2040s](https://arxiv.org/abs/2512.14802)
*Nadejda Blagorodnova,Ondřej Pejcha,Tomek Kamiński,Yongzhi Cai,Kishalay De,Nancy Elias-Rosa,Jim Fuller,Hongwei Ge,David Jones,Stephen Justham,Viraj Karambelkar,Jakub Klencki,Elena Mason,Brian Metzger,Andrea Pastorello,Andrea Reguitti Friedrich Röpke,Steven Shore,Giorgio Valerin*

Main category: astro-ph.IM

TL;DR: The paper highlights the importance of dynamically interacting binaries in diverse astrophysical phenomena and emphasizes the need for advanced observational techniques to study luminous red novae, which can provide insights into the physics of these interactions.


<details>
  <summary>Details</summary>
Motivation: To address unresolved questions about the physics and frequencies of binary interaction stages like common envelope evolution or stellar mergers, which are crucial for understanding phenomena such as blue stragglers and gamma-ray bursts.

Method: Proposes using multi-wavelength observations (spectroscopy, photometry), linear spectropolarimetry, and interferometry of luminous red novae, combined with next-generation instruments offering improved angular resolution, spectral resolution, and sensitivity.

Result: A tenfold increase in transient event identifications and enhanced observational capabilities will enable unprecedented insights into the dynamics of binary interactions and their evolutionary pathways.

Conclusion: Future observational advancements are critical to resolving long-standing problems in binary interaction physics and will be essential as gravitational wave data grows, providing comprehensive data to refine theoretical models.

Abstract: Dynamical binary interactions such as common envelope (CE) evolution or stellar mergers are a critical phase in the formation of a wide variety of binary phenomena, ranging from blue stragglers to type I supernovae (of all flavours, a, b and c), $γ$-ray bursts to bipolar planetary nebulae, Thorne-Zytkow objects to X-ray binaries. In 2040s, the urgency of resolving long-standing questions regarding the physics behind the dynamical interaction stages and the absolute and relative frequencies of binary evolutionary pathways will only increase owing to rapidly expanding population statistics of gravitational wave events. Here, we argue that multi-wavelength observations (spectroscopy and photometry), linear spectropolarimetry, and interferometry of a large number of Luminous Red Novae, a particular class of transients associated with dynamical binary interactions, will provide unprecedented details about the underlying interaction physics. A breakthrough will be achieved by a tenfold or larger increase in identifications of transient-type events from interacting binaries and their follow-up with instrumentation that provides at least 10 times better angular resolution, 100 times better spectral resolution, and $\sim$100 times higher sensitivity than 2030s facilities.

</details>


### [31] [Why the Northern Hemisphere Needs a 30-40 m Telescope and the Science at Stake: Northern Local Star-forming Dwarf Galaxies. Analogues of the First Galaxies and Probes of the Cosmic Metallicity Scale](https://arxiv.org/abs/2512.14790)
*C. Esteban,J. M. Vilchez,J. García-Rojas,R. Amorín,K. Z. Arellano-Córdova,L. Carigi,F. Cullen,O. V. Egorov,S. R. Flury,J. Iglesias-Páramo,C. Kehrig,K. Kreckel,J. E. Méndez-Delgado,E. Pérez-Montero,F. F. Rosales-Ortega,D. Scholte,T. M. Stanton,E. Villaver*

Main category: astro-ph.IM

TL;DR: The study proposes using deep spectra of local star-forming dwarf galaxies to better understand their chemical composition and ionization sources, challenging current models and potentially revising galactic chemical evolution theories.


<details>
  <summary>Details</summary>
Motivation: To address the lack of observational data on heavy element lines and inhomogeneities in ionized gas properties, and to explain the origin of high-ionization lines unaccounted for by current stellar models.

Method: Obtain very deep spectra for a selected sample of local star-forming dwarf galaxies to measure key emission lines and analyze their electron temperature, density, and chemical abundances.

Result: Expected to provide constraints on ionization sources, chemical abundances, and reveal whether Population III stars or non-conventional ionizing sources exist, which could revise the metallicity scale for galaxy evolution studies.

Conclusion: Such observations could transform our understanding of metal-poor galaxies' properties and their role in cosmic chemical evolution, necessitating updated models and assumptions.

Abstract: Star-forming dwarf galaxies in the local Universe, especially extremely metal-poor ones, can be considered analogous to early galaxies of the Epoch of Reionization (z >= 6). Currently available telescopes cannot adequately detect and measure heavy element recombination lines and certain faint collisionally excited lines, which are essential for exploring the effects and biases that potential inhomogeneities in electron temperature and density of the ionized gas may have on determining the chemical composition of these galaxies. On the other hand, the origin of very high-ionization lines (e.g. He II, [Ne V], C IV]) measured in the spectra of an important fraction of these objects remains unknown and a challenge to current stellar models, suggesting the presence of Population III-like stars and/or the existence of non-conventional ionizing sources. Obtaining very deep spectra for a selected sample of local star-forming dwarf galaxies would provide unprecedented constraints on their nature, ionization and true chemical abundances, and could change the metallicity scale we assume to understand the chemical evolution of galaxies over cosmic time.

</details>


### [32] [Luminous Fast Blue Optical Transients in the 2040s](https://arxiv.org/abs/2512.14832)
*A. A. Chrimes,N. Sarin,D. Coppejans,P. J. Groot,A. Inkenhaag,P. G. Jonker,T. L. Killestein,D. A. Perley,M. Pursiainen*

Main category: astro-ph.IM

TL;DR: This paper discusses the need for advanced observational capabilities by 2040 to better understand Luminous Fast Blue Optical Transients (LFBOTs), which are poorly understood but crucial for insights into black hole evolution and transient astrophysics.


<details>
  <summary>Details</summary>
Motivation: LFBOTs are mysterious extragalactic events whose origins are uncertain. Studying them can advance knowledge of black hole formation, central engine physics, and transient-host galaxy interactions. Current surveys miss most LFBOTs or lack efficient follow-up methods.

Method: The paper does not describe a specific method but outlines required observational capabilities for future surveys to maximize LFBOT discovery and study efficiency by 2040.

Result: N/A (This is a white paper proposing future observational strategies rather than presenting new results).

Conclusion: Future surveys must improve detection rates and follow-up efficiency for LFBOTs to fully explore their astrophysical implications and address their origins.

Abstract: Luminous Fast Blue Optical Transients (LFBOTs) are a class of extragalactic transient of uncertain origin. Several hypotheses have been put forward which could feasibly be consistent with the sample number of events discovered thus far, including tidal disruption events around intermediate mass black holes, failed supernovae and mergers of stars with black holes. Whatever their origin, it is clear that better understanding LFBOTs will provide unique insight into the black hole formation/growth, central engine physics and transient-host galaxy interactions - themes which are expected to drive research in transient astronomy over the coming decades. The vast majority of LFBOTs are missed by current photometric surveys, or not efficiently selected for detailed follow-up. This white paper outlines the observing capabilities required on a 2040 timescale to maximise the discovery potential from these enigmatic events.

</details>


### [33] [Why the Northern Hemisphere Needs a 30-40 m Telescope and the Science at Stake: Key Targets of Opportunity on Gas and Ice Giants and their satellites](https://arxiv.org/abs/2512.14791)
*Ricardo Hueso,Leigh N. Fletcher,Damya Souami,Thierry Fouchet,Tristan Guillot,Olivier Mousis,Patrick G. J. Irwin,Michael Roman,Arrate Antuñano,Athena Coustenis,Julia de León,Sonia Fornasier,Emmanuel Lellouch,Alice Lucchetti,Noemí Pinilla-Alonso,Don Pollacco,Agustín Sánchez-Lavega,Daniel Toledo*

Main category: astro-ph.IM

TL;DR: A 30-meter class telescope in the Northern Hemisphere with ELT-complementary instruments is proposed to ensure timely observations of time-critical phenomena in outer planets and their satellites, addressing observational limitations posed by the ELT's southern location.


<details>
  <summary>Details</summary>
Motivation: The ELT's location limits timely observations of high-value northern targets. Major outer planets like Uranus, Neptune, Jupiter, and Saturn have varying Northern Hemisphere observational windows (2055 for Uranus, 2027-2117 for Neptune, cyclical 10/30-year periods for Jupiter/Saturn), necessitating northern-based large telescopes for capturing unpredictable events.

Method: Analyzes declination-based observability cycles of outer planets, evaluates ELT's southern hemisphere observational bias, proposes a 30m telescope in the north with specialized instruments to complement ELT's capabilities for time-sensitive observations.

Result: Highlights importance of northern hemisphere infrastruture for capturing transient events in outer planets, establishes rationale for coordinated telescope networks.

Conclusion: Northern 30m telescope with complementary instruments is critical to maximize scientific return from unpredictable phenomena in gas giants and their satellites, balancing ELT's southern observational coverage.

Abstract: The Extremely Large Telescope (ELT) will transform our knowledge of the outer planets and their satellite systems; however the visibility of unique targets of opportunity with high scientific value will be reduced for northern objects. Uranus' declination favors observations from the Northern Hemisphere until 2055, and Neptune will be favored from the Northern Hemisphere from 2027 for the next 90 years. Jupiter and Saturn experience cycles of better observability from either hemisphere on cycles of 10 and 30 years. These planets and their satellite systems often offer unique opportunities for discovery through time-critical observations. We argue that a 30-m class size telescope in the Northern Hemisphere with complementary scientific instrumentation to that on the ELT will secure the possibility of observing high-impact unpredictable phenomena in these systems.

</details>


### [34] [Why the northern hemisphere needs a 30-40 m telescope and the science at stake: Massive stars in spiral galaxies](https://arxiv.org/abs/2512.14799)
*J. Maíz Apellániz,S. Simón-Díaz,A. Herrero,S. R. Berlanas,J. M. Mas Hesse,I. Negueruela,G. Holgado,M. García*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This document discusses the three main lines expected to dominate massive-star research in the 2040s, namely: (1) The role of metallicity in stellar evolution, especially in determining the end products such as gravitational-wave progenitors. (2) The initial mass function from the most massive stars to substellar objects. (3) The role of the environment in the different modes of star formation from compact star clusters to born-this-way associations and from massive clusters to small stellar groups. More specifically, we present the contributions to such science that would be enabled by a 30~m type telescope in the northern hemisphere studying spiral galaxies. Those can be grouped in three: our own Galaxy, the Milky Way; the other two spiral galaxies in the Local Group, M31 and M33; and other galaxies within 25 Mpc, such as M101, M51, and NGC~6946. This work is based on the fact that, as of today, no construction of a 30~m telescope has yet started in the northern hemisphere, so even in the best case scenario of such a hypothetical telescope, its full operation would not start until the late 2030s or early 2040s. It makes no assumptions about its location but supposes an instrumentation development similar to that of ELT.

</details>


### [35] [Finding New Debris Discs at Sub-millimetre Wavelengths](https://arxiv.org/abs/2512.14803)
*Mark Booth,Patricia Luppe,Sebastian Marino,Joshua B. Lovell,Jonathan P. Marshall,Gaspard Duchêne,Isabel Rebollido,Mark C. Wyatt,Riouhei Nakatani,Aya E. Higuchi,Miguel Chavez-Dagostino,Hiroshi Kobayashi*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Debris discs reveal the architectures and dynamical histories of planetary systems. Sub-millimetre observations trace large dust grains within debris discs, revealing their bulk properties. Debris discs have so far only been detected around ~20% of stars, representing the bright end of the population. A new facility is required to reach fainter discs, overcoming the confusion limit, with multiwavelength capabilities for characterisation, sensitivity to large-scale emission for nearby targets and a large field of view for surveying distant populations. All of this is made possible with the Atacama Large Aperture Submillimetre Telescope (AtLAST).

</details>


### [36] [Characterisation of the Bedretto Underground Site for Fundamental Physics Experiments](https://arxiv.org/abs/2512.14815)
*Björn Penning,Nicolas Angelides,Laura Baudis,Harvey Birch,Abigail Flowers,Florian Jörg,Alexander Kavner,Marcelle Soares-Santos,Aravind Sreekala,Johannes Wütrich,Guandi Zhao,Chiara Capelli,John Clinton,Jose Cuenca García,Paolo Crivelli,Domenico Giardini,Evangelos-Leonidas Gkougkousis,Yacine Haddad,Marian Hetrich,Rebecca Hochleutner,Luisa Hötzsch,Philippe Jetzer,Ben Kilminster,Boris Korzh,Frederick Massin,Knut Dundas Morå,Margherita Noia,Francesco Piastra,Christian Regenfus,Federico Sanchez,Steven Schramm,Francesco Riva,Serhan Tufanli,Michele Weber,Stefan Wiemer,Mathilde Wimez*

Main category: astro-ph.IM

TL;DR: The Bedretto tunnel in Switzerland is analyzed as a potential deep underground laboratory site, showing it has extremely low cosmic muon flux, radiation levels, and very low magnetic and seismic noise, making it suitable for advanced physics experiments.


<details>
  <summary>Details</summary>
Motivation: To evaluate the environmental conditions of the Bedretto tunnel for its potential as a new underground lab, capable of hosting sensitive experiments like rare-event searches and gravitational-wave detection.

Method: Measured cosmic muon, gamma-ray, neutron fluxes, radon concentration, magnetic-field spectrum, and seismic backgrounds at the site with over 1400m overburden.

Result: Muon flux reduced by six orders of magnitude, effective depth equivalent to 4000m water. Gamma/neutron levels align with local geology, indicating needed shielding. Magnetic/seismic noise meets next-gen detector requirements.

Conclusion: Bedretto tunnel emerges as a highly competitive, accessible site for fundamental physics experiments requiring ultra-low background and stability.

Abstract: Underground laboratories provide the ultra-low background and low-vibration environments essential for rare-event searches, gravitational-wave detection, and quantum-sensing technologies. We report a comprehensive environmental characterisation of the Bedretto tunnel in Ticino, Switzerland, a site offering horizontal access, excellent infrastructure, and the potential to be be Europe's second-deepest and quietest underground laboratory. At the prospective physics site, located beneath an overburden exceeding 1400 m, we measure the cosmic-muon, gamma-ray, and neutron fluxes, as well as the radon concentration, magnetic-field spectrum, and seismic backgrounds. The muon flux is suppressed by six orders of magnitude relative to the surface, consistent with an effective depth of about 4000 metre water equivalent, gamma-ray and neutron measurements reflect the local geology and guide shielding requirements for future particle and nuclear physics experiments. Magnetic and seismic noise levels are found to be exceptionally low, meeting or exceeding the criteria for next-generation atom-interferometric gravitational-wave detectors. These results establish the site as a highly competitive, accessible deep-underground location for fundamental-physics experiments.

</details>


### [37] [Exploiting tidal asteroseismology in binary populations from combined space photometry and time-resolved high-resolution spectroscopy](https://arxiv.org/abs/2512.14816)
*Ema Šipková,Alex Kemp,Dario Fritzewski,Andrew Tkachenko,Dominic M. Bowman,Conny Aerts,Jasmine Vrancken*

Main category: astro-ph.IM

TL;DR: The paper highlights the need for a specialized multi-fibre spectrograph to enable large-scale, high-resolution spectroscopic observations of pulsating stars in binary systems, which are crucial for advancing asteroseismic modeling and understanding binary stellar evolution.


<details>
  <summary>Details</summary>
Motivation: The lack of large-scale multi-epoch high-resolution spectroscopy limits constraints on stellar parameters and tidal physics in binary systems. Existing space-based photometry has identified many such systems, but complementary spectroscopic data at scale is missing.

Method: Proposes development of a dedicated multi-fibre spectrograph (30–200 fibres) with high resolution (R≥50,000), high S/N (≥300), and limiting magnitude ~15 to enable population-level analysis of pulsating binaries. This would allow phase-resolved spectroscopy to track pulsation variability (minutes) and orbital motion (days/years).

Result: Such a spectrograph would provide precise, model-independent constraints on binary star properties, enabling tests of asteroseismic models and improving our understanding of stellar and binary physics through large-scale data.

Conclusion: Implementing this spectroscopic capability is essential to unlock the full potential of space-based photometry data and address key questions in binary evolution and tidal physics at a population level.

Abstract: Space-based photometry has substantially increased the number of pulsating stars found in binary systems by more than four orders of magnitude. Combined with high-resolution spectroscopy, high-precision photometry offers model-independent constraints on stellar parameters and internal processes. The advent of space-based photometric surveys has given us access to populations of tidally perturbed pulsators, which offer a unique and demanding set of constraints on tidal physics and stellar interiors. However, we lack the ability to undertake multi-epoch, high-resolution spectroscopy at large scale. The ability to obtain phase-resolved, high-resolution spectra would allow us to place precise, model-independent constraints on the stellar properties of pulsators in binary systems that will truly test our close binary asteroseismic modelling techniques, leading to much-needed constraints on fundamental stellar and binary physics. The need to properly cover the large parameter-space of binary stars demands a large-scale, population-level analysis in order to understand the complex landscape of binary stellar evolution. To enable this population-level analysis, we need a dedicated multi-fibre spectrograph (30--200 fibres) with high spectral resolution ($R\geq 50000$), high signal-to-noise ratio ($\mathrm{S/N\geq 300}$), and a limiting magnitude of approximately 15. Such a spectrograph would be capable of efficiently resolving the pulsation variability on the order of minutes and orbit motion on the order of days to years for many targets.

</details>


### [38] [Skykatana: a scalable framework to construct sky masks for the Vera Rubin Observatory and large astronomical surveys](https://arxiv.org/abs/2512.14848)
*Claudio Lopez,Emilio Donoso,Mariano Javier de L. Dominguez Romero*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Modern wide-field surveys require robust spatial masks to excise bright-star halos, bleed trails, poor-quality regions, and user-defined geometry at scale. We present Skykatana, an open source pipeline that builds and combines boolean HEALPix/HEALSparse maps into science-ready masks and engineered for low-memory operation. Skykatana can efficiently construct, visualize multi-order coverage maps and generate random points in high-resolution masks over half of the celestial sphere with very limited resources and leveraging the hierarchical partition of data the HATS/LSDB framework. We demonstrate two end-to-end applications: (1) a Subaru HSC-WISE composite mask; and (2) Rubin star masks generated on demand in the Rubin Science Platform by querying HATS/LSDB Gaia data and assigning radii from empirical fits to Rubin DP1 data. We release full bright-star masks for various regions of the Rubin footprint and describe performance and scaling. The code, documentation, and examples are publicly available at https://github.com/samotracio/skykatana, and the LSST masks can be obtained from https://osf.io/r5vw6

</details>


### [39] [Development of a Custom kV-amplitude, pressure-tolerant Radio-Frequency transmitter](https://arxiv.org/abs/2512.14866)
*Christian Hornhuber,Mohammad Ful Hossain Seikh,Mark Stockham,Scott Voigt,Rob Young,Alisa Nozdrina,Sanyukta Agarwal,Shoukat Ali,Kenny Couberly,Dave Besson*

Main category: astro-ph.IM

TL;DR: The paper presents a custom RF calibration transmitter designed for UHEN detection in Antarctic ice, validated at 1740m depth with strong signal recovery at 5km distance.


<details>
  <summary>Details</summary>
Motivation: Accurate calibration of RF receivers is critical for determining neutrino energy and direction, necessitating a robust transmitter capable of deep-ice operation.

Method: Developed a kiloVolt-scale pulser (IDL) driving a high-pressure SPUNK antenna, deployed in a South Pole borehole to 1740m depth, measuring signal performance at 5km range.

Result: Successfully achieved high Signal-to-Noise ratio signals at 5km distance, validating the transmitter's performance under extreme conditions.

Conclusion: The transmitter enables precise calibration, advancing the capability to detect and characterize ultra-high energy neutrinos in ice-based experiments.

Abstract: Current experiments seeking first-ever observation of Ultra-High Energy Neutrinos (UHEN) typically utilize radio frequency (RF) receiver antennas deployed in cold, radio-transparent polar ice, to measure the coherent RF signals resulting from neutrino interactions with ice molecules. Accurate calibration of the receiver response, sampling the full range of possible neutrino geometries, is necessary to estimate the energy and incoming direction of the incident neutrino. Herein, we detail the design and performance of a custom radio-frequency calibration transmitter, consisting of a battery-powered, kiloVolt-scale signal generator (`IDL' pulser) driving an antenna (South Pole UNiversity of Kansas antenna, or `SPUNK') capable of operating at pressures of 200 atmospheres. Performance was validated by lowering the transmitter into a borehole at the South Pole to a depth of 1740 m, yielding high Signal-to-Noise ratio signals at a distance of 5 km from the source.

</details>


### [40] [AMKID -- a large KID-based camera at the APEX telescope](https://arxiv.org/abs/2512.14905)
*N. Reyes,A. Weiss,S. J. C. Yates,A. M. Baryshev,I. C. mara-Mayorga,S. Dabironezare A. Endo,L. Ferrari,A. Görlitz,G. Grutzeck,R. Güsten,C. Heiter,S. Heyminck,S. Hochgürtel,H. Hoevers,S. Jorquera,A. Kovàcs,D. Koopmans,C. König,N. Llombart,K. M. Menten,V. Murugesan,M. Ridder,A. Schmitz,D. J. Thoen,A. J. van der Linden,L. Wang,O. Yurduseven,J. J. A. Baselmans,B. Klein*

Main category: astro-ph.IM

TL;DR: The AMKID camera on the APEX telescope, with its dual-band capability, large field-of-view, and high pixel count, achieves sensitivities of 25 mJy per hour for mapping a square degree, advancing sub-millimeter astronomy in studies of star/planet formation and galaxy evolution.


<details>
  <summary>Details</summary>
Motivation: To overcome the technical challenge of slow mapping speeds for detecting faint sub-millimeter emissions, which is crucial for studying circumstellar disks, planet formation, and galaxy evolution at cosmological distances.

Method: The AMKID camera uses kinetic inductance detectors (KIDs) with dual-color (350 GHz and 850 GHz) simultaneous observation, a 15.3'x15.3' field-of-view, and a large number of detectors (13,952 at high frequency; 3,520 at low frequency). The low-frequency array (LFA) was commissioned and tested for performance.

Result: The LFA achieved detector sensitivity of 2.2 mK√s and diffraction-limited beam sizes (17.0'') with on-sky measurements showing 70-90 mJy√s per detector under good atmospheric conditions (PWV <1.0 mm). The LFA regularly reaches 25 mJy mapping sensitivity for a square degree in an hour.

Conclusion: AMKID's capabilities enable breakthrough astronomical studies by providing high sensitivity, wide field, and efficient mapping, positioning APEX to explore new frontiers in star/planet formation and galaxy evolution research.

Abstract: The thermal emission at sub-millimeter wavelengths carries unique information in many astronomical applications ranging from disks and planet formation around young stars, to galaxy evolution studies at cosmological distances. Advancing on the mapping speed to detect this faint emission in ground-based astronomy has been a technical challenge for decades. The APEX Microwave Kinetic Inductance Detector (AMKID) camera was designed to accomplish this task. The instrument is a wide field-of-view camera based on kinetic inductance detectors. It is installed on the 12~meter APEX telescope in Chile at 5.100~meters above see level. The instrument operates dual color, covering simultaneously the 350~GHz and 850~GHz atmospheric windows. It has a large field-of-view of 15.3'x15.3', and an unprecedented number of pixels: 13.952~detectors in the high frequency band and 3.520~detectors in the low frequency band. Here we present a complete description of the instrument design and construction together with results of the successful low frequency array (LFA) commissioning campaign executed during the last year. The LFA performance is in good agreement with design parameters, with detector sensitivity of 2.2~mK$\sqrt{s}$ and diffraction limited beam sizes of 17.0''. On-sky measurements demonstrate a sensitivity of 70-90~mJy$\sqrt{s}$ per detector when operating under good atmospheric conditions (PWV below 1.0mm). With this performance the LFA regularly achieve a mapping sensitivity of 25~mJy when mapping a square degree in an hour.
  AMKID on APEX with its dual color observing capabilities, high sensitivity, large field-of-view and high angular resolution holds the promise to open a new range of science with the APEX telescope.

</details>


### [41] [The use of astronomical data for satellite tracking](https://arxiv.org/abs/2512.15122)
*Rositsa Miteva,Nikola Antonov,Adrian Sonka*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The study explored the usage of astronomical observations for the identification and tracking of artificial satellites. Spacecraft streaks on astronomical images are a growing issue for the astronomical community. The increasing number of satellites in the future will only worsen the situation for ground-based optical and radio observations of cosmic objects. In addition, the spacecraft passages often lead to the discarding of the obtained data. In this analysis, we propose an estimation of the usefulness of dedicated astronomical observation for spacecraft monitoring, identification, and deduction of orbital parameters. We use astronomical data from the Astronomical Observatory Meshtitsa (Bulgaria) and the https://www.tycho-tracker.com/ software for the streak analysis. The results are compared with well-known satellite databases, such as https://celestrak.org/. The findings are discussed in the framework of space weather research.

</details>


### [42] [Expanding stellar horizons with polarized light](https://arxiv.org/abs/2512.15170)
*J. Vandersnickt,R. Ochoa Armenta,V. Vanlaer,A. David-Uraz,C. Aerts,S. B. Das,J. -C. Bouret,D. M. Bowman,L. Bugnet,V. Khalack,J. Labadie-Bartz,S. Mathis,Y. Nazé,C. Neiner,P. Petit,V. Petit,K. Thomson-Paressant,T. Van Doorsselaere,M. Vanrespaille*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The polarization of light is a critically under-utilized, rich source of information in astronomy. For stars in particular, surface magnetism polarization that can be detected and measured with spectro-polarimetry. Many questions about these surface fields remain unanswered due to a lack of dedicated instruments capable of probing weak and strong surface magnetic fields for the entire mass range of stars, from M-dwarfs (and even substellar objects) to massive O-type stars at different evolutionary stages and metallicities. These questions range from the origin of these fields to their true incidence rate throughout the stellar population and the dependence on metallicity. Magnetic fields, although currently often excluded from stellar evolution models, play an important role in stellar evolution. Connecting the surface fields to internal fields through asteroseismology will instigate a new era of understanding stellar evolution and the transport of angular momentum and chemical elements throughout stellar interiors, also impacting our understanding of star-planet interactions and stellar remnants. Polarimetry is also an under-utilized tool to observationally constrain the mode identification of nonradial oscillations, which lies at the basis of accurate asteroseismic parameter estimation at percentage-level for stellar radii, masses, ages, internal rotation, and magnetic field strengths. Combining strong constraints on mode identification and surface magnetic properties through the acquisition of time-resolved, high-resolution and high-signal-to-noise (S/N) spectro-polarimetry and spectroscopy promises to bring leaps forward in our understanding of stellar structure, particularly when combined with long-term space photometric data from past, current, and future missions.

</details>


### [43] [A Characterization of JWST MIRI Detector Persistence and Implications for High-Contrast Imaging](https://arxiv.org/abs/2512.15477)
*Alisha Vasan,Mary Anne Limbach,Andrew Vanderburg,Rachel Bowens-Rubin,Kevin B. Stevenson*

Main category: astro-ph.IM

TL;DR: The study analyzes flux deficit persistence in the JWST MIRI detector following a saturation event from a bright nearby star, finding it decays exponentially with a half-life estimate. It highlights risks for high-contrast imaging in terms of false exoplanet signals and PSF subtraction issues, and suggests mitigation strategies.


<details>
  <summary>Details</summary>
Motivation: To characterize the timescales and impacts of flux deficit persistence at 21 μm on MIRI's imaging, particularly relevant for high-contrast observations where such persistence could mimic exoplanets or degrade image analysis.

Method: Analyzed MIRI F2100W observations of IRAS 21500+5903 saturation effects at two post-event epochs (11.6 min & 1.39 hrs); applied Bayesian exponential decay modeling to quantify persistence decay timescale.

Result: Measured initial 1.69±0.10% flux deficit persistence decreasing to ≤10% of initial level in ~5.16 hours; identified risks of false positives in exoplanet surveys and PSF subtraction challenges in high-contrast imaging.

Conclusion: MIRI's flux deficit persistence requires mitigation strategies in observation planning to avoid contaminated detections; recommends avoiding observing targets within ~5.2hr timescale of bright sources for critical contrast applications.

Abstract: The JWST MIRI detector exhibits a flux deficit persistence, but its timescales and impacts remain largely uncharacterized, particularly at the longest imaging wavelengths. In this study, we analyze full-field MIRI imager observations at 21 $μ$m (F2100W) to quantify detector persistence following a saturation event by a bright (K = 5.65 mag) nearby (8.12 $\pm$ 0.04 pc) mid M-dwarf star, IRAS 21500+5903. Unlike typical persistence that appears as excess flux, this effect presents as a flux deficit in pixels previously illuminated by the saturating or near saturating source. We measure persistence at two post-saturation epochs: shortly after saturation (11.6 minutes) and an hour later (1.39 hours). Immediately after the saturation event, we detect a persistence level of $1.69 \pm 0.10$%. By fitting a Bayesian exponential decay model to the two epochs, we estimate that persistence decreases to one-tenth of its initial value after $5.16^{+1.49}_{-0.94}$ hours. We examine the implications of persistence for MIRI high-contrast imaging using the imager (not coronagraphy). Specifically, we discuss how MIRI detector persistence can produce false-positive exoplanet signals in direct imaging surveys, as well as degrade PSF subtraction, particularly at small inner working angles. We also outline mitigation strategies to avoid these impacts in future observations.

</details>


### [44] [Spectroscopic Alerts for the Time-Domain Era](https://arxiv.org/abs/2512.15555)
*Alejandra Melo,Paula Sanchez-Saez,Valentin D. Ivanov,Richard I. Anderson,Amelia Bayo,Avraham Binnenfeld,Sofia Bisero,Dragana Ilić,Andjelka B. Kovačević,Fatemeh Zahra Majidi,Jaroslav Merc,Anna Pala,Swayamtrupta Panda,Sarath Satheesh-Sheeba,Fabian Schüssler,Susanna D. Vergani*

Main category: astro-ph.IM

TL;DR: The paper introduces 'spectroscopic alerts' to address the gap between the vast number of photometric alerts from next-gen surveys and limited spectroscopic follow-up capacity. This system would trigger real-time notifications for significant spectral changes, transforming spectroscopy into a discovery tool.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the即将来临的天文学观测革命，其中大视场、高频率巡天项目如LSST, Roman, Euclid等会产生海量光变警报，但理解可变现象和瞬现事件往往需要光谱学信息来揭示电离状态、运动学和吸积等细节。然而光谱随机动态观测能力受限，每年只能跟进约十万量级的光谱，远低于预计十亿级别的光变警报数量。光谱及时警报系统能补足这一差距。

Method: The method involves developing a real-time spectral monitoring system that can detect significant spectral changes and issue alerts. This requires a wide-field, highly multiplexed spectroscopic facility capable of handling large volumes of data and providing immediate spectral analysis. The infrastructure must support continuous operation and rapid data processing to enable timely alerts.

Result: The proposed system aims to enable spectroscopy to act as a discovery channel by providing real-time spectral alerts, significantly enhancing the scientific yield of time-domain and multi-messenger astronomy in the 2040s. Key science cases include studying transients,变量天体, active galactic nuclei, and多信使天文 events.

Conclusion: The conclusion emphasizes the necessity of spectroscopic alerts systems for future astronomy, highlighting its potential torevolutionize the way spectroscopic data is used from solely follow-up to a proactive discovery tool. It calls for the development of appropriate instrumentation and operational strategies to meet the demands of upcoming surveys.

Abstract: Time-domain astronomy is entering an era of unprecedented discovery driven by wide-field, high-cadence surveys such as LSST, Roman, Euclid, SKA, and PLATO. While some of these facilities will generate enormous photometric alert streams, the physical interpretation of variability and transients often requires spectroscopy, which encodes changes in ionisation state, kinematics, and accretion that are inaccessible to photometry alone. A critical gap is therefore emerging: next-generation surveys may produce up to $\sim10^9$ alerts per year, whereas global spectroscopic follow-up is limited to only $\sim10^4$--$10^5$ transient spectra annually. We present the concept of spectroscopic alerts: real-time notifications triggered by significant spectral evolution, enabling spectroscopy to act as a discovery channel rather than solely as follow-up. We outline the key science cases enabled by this capability and describe the instrumental and operational requirements of a wide-field, highly multiplexed spectroscopic facility capable of delivering real-time spectral discovery for 2040s time-domain and multi-messenger astronomy.

</details>


### [45] [Benchmarking Dimensionality Reduction Methods for High-Dimensional ALMA Image Cubes](https://arxiv.org/abs/2512.15615)
*Haley N. Scolati,Ryan A. Loomis,Anthony J. Remijan,Kin Long Kelvin Lee*

Main category: astro-ph.IM

TL;DR: The study evaluates various dimensionality reduction techniques (linear and nonlinear) on high-dimensional astronomical data cubes, focusing on feature preservation, computational scalability, and performance trade-offs using ALMA data, aiming to guide users and prepare for future upgrades.


<details>
  <summary>Details</summary>
Motivation: To address the challenges in analyzing large, complex astronomical datasets, the study aims to compare different dimensionality reduction methods to determine their effectiveness in preserving important features while reducing computational demands, especially as new observatory upgrades approach.

Method: The authors use publicly available ALMA data from diverse sources and setups to benchmark dimensionality reduction methods. They assess performance metrics such as computational cost, reconstruction accuracy, and scalability across linear (PCA) and nonlinear (convolutional autoencoders) approaches.

Result: The study identifies the strengths and weaknesses of each method in terms of feature preservation and computational efficiency, providing recommendations for their application and scalability for observatory-level data processing.

Conclusion: The research highlights the importance of selecting appropriate dimensionality reduction techniques for astronomical data based on specific needs, guiding future data analysis strategies and enabling efficient processing as observational data volumes increase with upgrades like the ALMA Wideband Sensitivity Upgrade.

Abstract: High-dimensional astronomical data cubes provide a wealth of spectral and structural information that can be used to study astrophysical and chemical processes. The complexity and sheer size of these datasets pose significant challenges in their efficient analysis, visualization, and interpretation. In specific astronomical use cases, a number of dimensionality reduction techniques, including traditional linear (e.g. principal component analysis) and modern nonlinear methods (e.g. convolutional autoencoders) have been used to tackle this high-dimensional problem. In this study, we assess the strengths, weaknesses, and nuances of various methods in their ability to capture and preserve astronomically-relevant features at lower dimensions. We provide recommendations to guide users in identifying and incorporating these treatments to their data, and provide insights into the computational scalability of these methods for observatory level data processing. This benchmark study uses publicly available archival ALMA data from a diverse sampling of source morphologies and observing setups to assess the performance and trade-offs between computational cost, image reconstruction accuracy, and scalability. Finally, we discuss the generalizability of these techniques in regard to data segmentation and labeling algorithms and how they can be exploited for advanced data product generation and streamlined archival analysis as we prepare to enter the era of the ALMA Wideband Sensitivity Upgrade.

</details>


### [46] [Towards ALMA2040: An update from the European community and invitation to contribute](https://arxiv.org/abs/2512.15652)
*Stefano Facchini,Jacqueline Hodge,Jes Jørgensen,Eva Schinnerer,Gie Han Tan,Tom Bakx,Andrey Baryshev,Maite Beltran,Leindert Boogaard,Roberto Decarli,María Díaz Trigo,Jan Forbrich,Peter Huggard,Elizabeth Humphreys,Violette Impellizeri,Karri Koljonen,Kuo Liu,Luca Matrà,Miguel Pereira Santella,Arianna Piccialli,Gergö Popping,Miguel Querejeta,Miriam Rengel,Francesca Rizzo,Lucie Rowland,Hannah Stacey,Wouter Vlemmings,Catherine Walsh,Sven Wedemeyer,Martina Wiedner*

Main category: astro-ph.IM

TL;DR: ALMA2040 aims to define a next-gen sub-mm facility by 2040, leveraging ALMA's legacy and emerging technologies while addressing future scientific goals from upcoming telescopes.


<details>
  <summary>Details</summary>
Motivation: The need for advanced (sub-)mm capabilities beyond ALMA's current infrastructure to address key science questions in the 2040s Era with new facilities like JWST and SKA.

Method: Community-driven process including workshops, white papers, and developing a reference design for ALMA2040 based on synthesized science requirements.

Result: Framework established for ALMA2040 initiative with clear roadmap toward technical and scientific goals, inviting global collaboration.

Conclusion: The initiative emphasizes sustained community engagement to ensure the next-gen facility maximizes scientific impact in the evolving astronomical landscape post-2040.

Abstract: Over the last 15 years, the Atacama Large Millimeter/submillimeter Array (ALMA) has revolutionized astrophysics by providing unprecedented resolution and sensitivity in observing the cold universe, including the formation of stars, planets, and galaxies. With groundbreaking discoveries ranging from the first detailed images of protoplanetary disks to the kinematics of galaxies in the Epoch of Reionization, ALMA has showcased the vast discovery potential of the (sub-)mm wavelength regime. However, in another 15 years from now--in the 2040s--the science landscape will have changed dramatically as new major observational facilities will have started their operations or have come towards advanced maturity in their scientific outcome (e.g., JWST, Rubin Observatory, ELT, Euclid, Gaia, Plato, Ariel, Roman Space Telescope, SPHEREx, LiteBIRD, LISA, SKA and others). At the same time, ALMA's current Wideband Sensitivity Upgrade will have been in place for ~10 years, and ALMA itself will have been operational for 30 years. To fully exploit this era, the community needs a next-generation facility operating at (sub-)mm wavelengths with capabilities far beyond those possible within ALMA's current infrastructure.
  To this end, ALMA2040 is a community-driven initiative to define the key scientific questions of the 2040s and translate them into a technical vision for a next-generation transformational (sub-)millimeter facility. Our goal with this document is to summarize the current status of the effort, synthesize outcomes from the 2025 workshops, outline next steps toward a reference design concept, and invite broad participation from the global mm/sub-mm community to help shape this future facility.
  In the following we provide details on the process and scope. We invite everyone who wishes to join the effort and/or contribute to the dedicated White Papers planned for 2026.

</details>


### [47] [Searching potential astronomical sites in Ethiopia](https://arxiv.org/abs/2512.15669)
*SS Akalu,N. Suleiman,GM. Kumssa,ST. Belay,E. Alemayehu,M. Getnet,M. Povic,SH. Negu,B. Belata,J. Tamrat*

Main category: astro-ph.IM

TL;DR: This paper identifies 21 potential sites in Ethiopia for an optical observatory by evaluating 367 mountain locations using criteria like altitude, light pollution, cloud cover, humidity, and wind conditions, applying multi-criteria statistical analysis.


<details>
  <summary>Details</summary>
Motivation: To expand Ethiopia's astronomical infrastructure beyond existing sites (Entoto and Lalibela) and promote sustainable astronomy, dark sky preservation, and astrotourism in the region.

Method: Evaluated 367 mountains using six criteria (altitude, light pollution, cloud cover, humidity, wind speed/direction) via multi-criteria statistical analysis (MCSA) to shortlist 21 sites.

Result: 21 high-potential sites identified and mapped for further study on astronomical seeing conditions.

Conclusion: Study supports protecting these sites and advancing Ethiopia's astronomical capabilities through astrotourism and regional collaboration.

Abstract: This work aims to choose potential astronomical sites that can be candidates for a new astronomical optical observatory in Ethiopia, in addition to the Entoto Observatory and Lalibela sites. For our primary investigation, the six basic criteria, namely the altitude of the mountains, artificial light pollution, cloud coverage, humidity, wind speed, and wind direction, are taken into account. Consequently, using the multi-criteria statistical analysis (MCSA) techniques, 21 high-potential places are selected and presented for further investigation out of 367 mountains. Those selected mountains are mapped and presented to study the future of the astronomical seeing effect. This study may contribute to the protection of those potential astronomical sites and their dark skies and the development of astrotourism for the sustainable development of modern astronomy in Ethiopia and in the East African region.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [48] [Achromatic, spin-odd Kerr EVPA as a null Frenet--Serret torsion integral on the photon ring](https://arxiv.org/abs/2512.14773)
*M. Baran Ökten*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We compute the achromatic gravitational imprint that Kerr spacetime leaves on linear polarization at the photon ring. Recasting parallel transport in a null Frenet--Serret frame yields a single scalar evolution law for the electric-vector position angle. On the observer's screen, the Kerr-minus-Schwarzschild pattern on the direct critical curve is nonzero, strictly odd under spin reversal after a half-turn azimuth relabelling, and tightly confined to a thin annulus. Using backward-shot, Carter-separated geodesics with midpoint RK2 transport, we achieve second-order convergence and degree-scale amplitudes that grow monotonically with spin and inclination (RMS $\simeq 0.5$--$2^\circ$ for $a/M\gtrsim 0.8$, $i\gtrsim 60^\circ$). Three independent constructions -- Frenet--Serret line integral, explicit Levi--Civita transport of the polarization vector, and the phase of the Walker--Penrose constant -- agree ray by ray. We then define a parity-odd ring estimator that is intrinsically achromatic after standard wavelength-squared regression, symmetry-protected against common even-parity systematics, and compressed into low azimuthal modes. This yields a minimal two-parameter template (spin and inclination) for mm/sub-mm polarimetry of horizon-scale rings in sources such as M87$^\ast$ and Sgr~A$^\ast$. The pipeline enables either a detection of the strong-field parallel-transport phase induced by frame dragging or informative upper limits.

</details>


### [49] [Analytical model of the photon ring with finite thickness](https://arxiv.org/abs/2512.14775)
*S. V. Chernov*

Main category: gr-qc

TL;DR: The paper presents an analytical model of a thick asymmetric Gaussian ring, calculating its visibility function in two perpendicular directions for baselines up to six times the Earth's diameter.


<details>
  <summary>Details</summary>
Motivation: To develop an accurate analytical model for thick asymmetric Gaussian rings to better understand their visibility functions at large baseline lengths, which is crucial for applications in radio astronomy or interferometry.

Method: The authors derive an analytical framework to compute visibility functions in two perpendicular directions. They likely employ mathematical modeling and simulations to validate the model's performance across varying baseline lengths up to 6 Earth diameters.

Result: The model successfully quantifies visibility variations for the specified ring structure across the range of baselines. Results may include parameters like signal attenuation, interference patterns, or resolution limits under the modeled conditions.

Conclusion: The derived model provides a reliable tool for analyzing asymmetric Gaussian rings in radio astronomy or interferometric systems, enabling precise predictions and optimizations for observational setups involving extended structures.

Abstract: An analytical model of a thick asymmetric Gaussian ring is presented for which the visibility function is calculated in two perpendicular directions for baselines up to 6 of the Earth's diameter.

</details>


### [50] [Gravitational decoupling and regular hairy black holes: Geodesic stability, quasinormal modes, and thermodynamic properties](https://arxiv.org/abs/2512.14920)
*R. C. de Paiva,K. S. Alves,R. T. Cavalcanti,R. da Rocha*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The stability of geodesic orbits around a regular hairy black hole, in the gravitational decoupling setup, is investigated by employing Lyapunov exponents, which quantify the divergence rate of nearby trajectories in dynamical systems. Both timelike and null geodesics are addressed, probing the effect of the hair parameter on orbital stability. Deviations from the Schwarzschild solution have a significant influence on orbit stability, potentially providing observational signatures. Quasinormal modes of regular hairy black holes are calculated, and their thermodynamic properties are discussed. Both the Rényi and the Bekenstein-Hawking entropies are reported, deepening our understanding of gravitational dynamics in the strong-field regime, contributing to ongoing approaches to modified gravity.

</details>


### [51] [$\ell$-Boson stars in anti-de Sitter spacetime](https://arxiv.org/abs/2512.14921)
*Miguel Megevand*

Main category: gr-qc

TL;DR: The paper explores the properties of 
ℓ-boson stars in anti-de Sitter spacetimes with a negative cosmological constant.


<details>
  <summary>Details</summary>
Motivation: Extend the study of ℓ-boson stars to asymptotically anti-de Sitter spacetimes to understand their behavior in curved backgrounds.

Method: Generalizing previous work on ℓ-boson stars by incorporating a negative cosmological constant and analyzing their properties while maintaining spherical symmetry.

Result: Successful construction and analysis of ℓ-boson stars in AdS spacetime, revealing how angular momentum and cosmological constant parameters influence their properties.

Conclusion: ℓ-boson stars in AdS spacetime provide a rich platform for studying gravitational effects and scalar field dynamics in curved spacetimes.

Abstract: In previous work, we introduced the $\ell$-boson stars, a generalization of standard boson stars, which are parameterized by an angular momentum number $\ell$, while still preserving the spacetime's spherical symmetry. In this article, we present and study the properties of $\ell$-boson stars in spacetimes with a negative cosmological constant, such that they are asymptotically anti-de Sitter.

</details>


### [52] [Axions, Black Holes and the Detection of Gravitons: from Astrophysics to Cosmology](https://arxiv.org/abs/2512.14951)
*Nick E. Mavromatos,Panagiotis Dorlis,Sarben Sarkar,Sotirios-Neilos Vlachos*

Main category: gr-qc

TL;DR: The paper explores how spin-polarized entangled squeezed graviton states emerge from superradiant axionic clouds around rotating black holes. It combines GR and gravitational Chern-Simons (gCS) interactions to estimate squeezing parameters, discusses detectability via LIGO/Virgo for constraining axion cloud lifetimes, and outlines indirect cosmological implications like inflationary GW patterns and resolving cosmic tensions.


<details>
  <summary>Details</summary>
Motivation: To investigate novel mechanisms for detecting quantum gravitational effects using axion-gravity interactions near black holes, leveraging both classical GR and quantum gCS terms. Aims to bridge theoretical predictions with observational constraints using existing and future gravitational wave detectors, and explore cosmological consequences of these quantum gravitational phenomena.

Method: Analyzed axion-gravity dynamics in rotating black hole spacetimes using a weak-quantum-gravity framework. Derived entangled squeezed graviton states contributions from GR and gCS interactions. Estimated squeezing parameters and discussed their observational implications for axion cloud lifetimes via LIGO/Virgo data. Explored cosmological model where gCS term condensation drives running vacuum inflation.

Result: Established theoretical framework linking axionic clouds to detectable squeezed gravitons. Demonstrated LIGO/Virgo data can impose upper bounds on squeezing parameters and axion cloud lifetimes. Proposed cosmological consequences include distinct GW patterns from post-inflationary eras and mitigation of cosmic tensions through gCS-induced dynamics.

Conclusion: Provides a dual detection pathway (direct GW interferometry and indirect cosmological observations) for quantum gravity effects tied to axions. Highlights urgent need for collaborative analyses between astrophysical observations and cosmological models to fully exploit this mechanism’s potential in testing quantum gravity and resolving cosmological puzzles.

Abstract: We review a novel scenario for the emergence of spin-polarisation entangled squeezed graviton states from superradiant axionic clouds in the neighborhood of astrophysical rotating black holes (BHs). The entangled squeezed graviton states are produced by both, conventional General-Relativity (GR) type axion-gravity interactions, and gravitational Chern-Simons (gCS) anomalous terms coupled to axions, which are non-trivial in the presence of rotating BHs. The two kinds of terms have different-symmetry contributions to the entangled squeezed states. The squeezing parameter is estimated in a weak-quantum-gravity framework. Some phenomenology with respect to current and future interferometric detection devices is discussed. Importantly, current data from LIGO/Virgo Experiments can impose upper-bound constraints on the value of the squeezing parameter and, thus, on the lifetime of the axionic clouds. In addition to the above rather direct-detection possibility of squeezed gravitons, there is also the possibility of indirect detection of quantum gravitons in Cosmology, given that chiral quantum gravitational-wave (GW) perturbations in the primordial Universe may imply condensation of gCS terms. This, in turn, leads to inflation of running vacuum type, with in principle observable patterns in the profile of the GW produced during the post-inflationary early radiation era, as well as the potential of alleviating cosmic tensions in the current era.

</details>


### [53] [Cosmological Models with Symmetric Teleparallel Gravity and its Extension](https://arxiv.org/abs/2512.15096)
*S. A. Narawade*

Main category: gr-qc

TL;DR: This thesis explores $f(Q)$ gravity as an alternative to the ΛCDM model to explain late-time cosmic acceleration, addressing issues like dark matter and dark energy discrepancies through modified gravity, and uses observational data and statistical methods to constrain its parameters.


<details>
  <summary>Details</summary>
Motivation: To address shortcomings of the ΛCDM model, such as the mysterious nature of dark matter/dark energy and observational discrepancies, by investigating modified gravity theories like $f(Q)$ gravity which could dynamically explain cosmic acceleration without a cosmological constant.

Method: Analyzes $f(Q)$ gravity through observational data from Type Ia Supernovae, Hubble parameter measurements, and other cosmological datasets using statistical tools like MCMC to constrain model parameters and compare with ΛCDM.

Result: Provides parameter constraints for $f(Q)$ gravity and evaluates its viability against ΛCDM model using observational evidence.

Conclusion: Demonstrates that $f(Q)$ gravity offers a compelling alternative to ΛCDM by resolving some of its theoretical issues while fitting observational data, though further testing is needed.

Abstract: This thesis investigates late-time cosmic acceleration using modified gravity theories with a focus on $f(Q)$ gravity, as an alternative to the $Λ$CDM model. The standard cosmological model attributes the acceleration to a cosmological constant, but it faces issues like the unexplained nature of dark matter and dark energy and discrepancies with certain observations. Modified gravity including $f(Q)$ gravity, offers a potential solution by incorporating dynamic dark energy or changes to gravitational interactions, avoiding the need for a constant cosmological term. Also, thesis evaluates the viability of $f(Q)$ gravity by analyzing observational data from Type Ia Supernovae, Hubble parameter measurements and other cosmological datasets. Using statistical tools like Markov Chain Monte Carlo (MCMC) analysis, this work constrains the parameters of $f(Q)$ gravity and compares it to the $Λ$CDM model.....

</details>


### [54] [Strong lensing cosmography using binary-black-hole mergers: Prospects for the near future](https://arxiv.org/abs/2512.15168)
*Koustav N. Maity,Souvik Jana,Tejaswi Venumadhav,Ankur Barsode,Parameswaran Ajith*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A small fraction of gravitational-wave (GW) signals from binary black holes (BBHs) will be gravitationally lensed by intervening galaxies and galaxy clusters. Strong lensing will produce multiple identical copies of the GW signal arriving at different times. Jana et al.~\cite{Jana_2023} recently proposed a method to constrain cosmological parameters using strongly lensed GW events detected by next-generation (XG) detectors. The idea is that the number of strongly lensed GW events and the distribution of their lensing time delays encode imprints of the cosmological parameters. From the observed number of lensed GW events (tens of thousands) and their time delay distribution, this method can provide a new probe of cosmology, obtaining information at intermediate redshifts. In this work, we explore the possibility of doing lensing cosmography using upcoming observations of the upgraded LIGO-Virgo-KAGRA (LVK) network. This requires incorporating the detector network selection effects in the analysis, which was neglected earlier. We expect dozens of lensed GW events to be detected by upgraded LVK detectors, potentially enabling modest constraints on cosmological parameters. Even with relatively modest numbers of lensed detections, we demonstrate the potential of lensing cosmography. For XG detectors, our revised forecasts are consistent with with the earlier forecasts that neglected the selection effects.

</details>


### [55] [Multiple mountains on a pulsar: implications for gravitational waves and the spin-down rate](https://arxiv.org/abs/2512.15200)
*Paritosh Verma,Sudip Bhattacharyya*

Main category: gr-qc

TL;DR: This paper analyzes the gravitational wave emission from a neutron star with multiple crustal mountains using Brans-Dicke theory, calculating strain, power, torque, and spin-down rates. It extends previous models by considering irregular mountain distributions and includes scalar polarization effects not accounted for in general relativity.


<details>
  <summary>Details</summary>
Motivation: To explore gravitational wave signals from realistic neutron star structures (with multiple mountains) and assess the impact of Brans-Dicke gravity's scalar polarization on detectability and astrophysical insights.

Method: 1. Models multiple crustal deformations as specified mountain distributions. 2. Applies Brans-Dicke theory to calculate gravitational wave parameters (strain, power, torque). 3. Derives spin-down rates considering both tensor and scalar polarization contributions. 4. Compares results with general relativity limits.

Result: Shows enhanced gravitational wave emission in Brans-Dicke theory due to scalar dipole contributions, providing new observational signatures. Establishes modified relationships between spin-down rates andmountain parameters compared to GR predictions.

Conclusion: Multiple mountains significantly affect gravitational wave characteristics under alternative gravity theories. These findings improve models for pulsar observations and gravitational wave detection strategies, emphasizing the importance of considering non-uniform deformities and scalar polarizations.

Abstract: A pulsar, i.e., a spinning neutron star, with a deformation could emit gravitational waves continuously. Such continuous waves, which have not been detected yet, will be very useful to study gravitational physics and to probe the extreme physics of neutron stars. While typically such waves from a pulsar are estimated considering an overall stellar ellipticity, there can be multiple irregularities or mountains in the stellar crust that the gravity of the star cannot smooth. In this paper, we consider this realistic situation and compute the strain, power, torque and the pulsar spin-down rate due to multiple mountains supported by the stellar crust. Here, we consider astronomically motivated mountain distributions and use the Brans-Dicke theory of gravity which has three polarization states: two tensors dominated by the time-varying quadrupole moment and one scalar dominated by the time-varying dipole moment. We also give the limiting results for general relativity.

</details>


### [56] [A bigravity model from noncommutative geometry](https://arxiv.org/abs/2512.15234)
*Marco de Cesare,Mairi Sakellariadou,Araceli Soler Oficial*

Main category: gr-qc

TL;DR: This paper explores noncommutative gravity through a twist-deformation approach, introducing additional gravitational degrees of freedom and a larger gauge group. It compares the resulting theory to bigravity and examines cosmological solutions split into two distinct branches with different dynamical properties.


<details>
  <summary>Details</summary>
Motivation: To extend general relativity by incorporating noncommutative spacetime geometries and explore their implications through a modified gravitational framework that preserves extra degrees of freedom even in the commutative limit.

Method: The authors use a twist-deformation of spacetime's differential geometry with a first-order dynamical formulation. They introduce a GL(2,C) gauge connection and two tetrads, allowing interactions similar to ghost-free bigravity, and perform a Hamiltonian analysis of cosmological solutions.

Result: The theory's commutative limit yields an effective action with preserved extra degrees of freedom. Cosmological solutions branch into two: one with constant spatial curvature and another with enhanced gauge freedom and additional first-class constraints.

Conclusion: Noncommutative gravity provides a natural extension to GR with unique features, offering a playground for testing modifications. The findings highlight potential connections to bigravity theories and open avenues for studying cosmological implications through the identified branches.

Abstract: Noncommutative gravity, based on a twist-deformation of the differential geometry of spacetime and a first-order formulation of the dynamics, requires additional gravitational degrees of freedom as well as an enlargement of the gauge group of Lorentz transformations of the tetrad frame. As such, it offers a theoretical playground to build fundamentally motivated extension to general relativity. The dynamical degrees of freedom include a ${\rm GL}(2,\mathbb{C})$ gauge connection and two independent tetrads. The theory allows for interaction terms between the two tetrads, whose structure displays some similarities with ghost-free bigravity. The extra gravitational degrees of freedom survive in the commutative limit. We show the effective action obtained in this limit, discuss its symmetries, and compare it with other bigravity theories. The dynamics of homogeneous and isotropic cosmological solutions split into two branches. One is characterized by a constant and purely spatial curvature two-form. The other displays a richer gauge freedom, and the Hamiltonian analysis of the dynamics reveals three extra first-class constraints in addition to the generator of time reparametrizations.

</details>


### [57] [The Missing Massive Sector: Massive Boson Stars -- Stability and GW Emission in Head-on Mergers](https://arxiv.org/abs/2512.15242)
*Bo-Xuan Ge*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate quartically self-interacting massive boson stars by constructing equilibrium sequences and performing dynamical evolutions. The mass curve $M(|φ_c|)$ along these sequences develops multiple extrema, yet stability changes only at the first maximum; configurations beyond it become highly compact and collapse under numerically induced perturbations, with near-critical models displaying a short-lived double-dive behaviour. Head-on collisions of equal-mass stars yield three distinct outcomes - boson star remnants, black hole formation at contact, and collapse of each star to a black hole prior to contact. The associated gravitational-wave energies reflect the competition between increasing compactness and decreasing tidal deformability, and at large self-interaction strengths the collapse-before-contact branch exhibits a pronounced non-monotonic structure. The simulations reported here constitute a substantial catalogue of initial conditions and waveforms, providing a natural basis for neural-network techniques aimed at improving boson star initial data and constructing surrogate models capable of rapidly predicting gravitational-wave signals across an extended parameter space.

</details>


### [58] [Spontaneous wave function collapse from non-local gravitational self-energy](https://arxiv.org/abs/2512.15393)
*Kimet Jusufi,Douglas Singleton,Francisco S. N. Lobo*

Main category: gr-qc

TL;DR: The paper integrates non-local gravitational self-energy from string-inspired T-duality into the Schrödinger-Newton equation, showing that linear superposition becomes unstable when gravity is considered. This instability leads to spontaneous wave function collapse, driven by a conflict between the equivalence principle and quantum superposition. Calculations also reveal mass-dependent collapse times via gravitational phase shifts in different frames.


<details>
  <summary>Details</summary>
Motivation: To address the stability of quantum superposition in the presence of gravitational effects and explore the implications of non-locality from T-duality on semiclassical gravity.

Method: Modifying the Schrödinger-Newton equation by incorporating non-local gravitational self-energy derived from T-duality principles. Analyzing wave function behavior in inertial vs. freely-falling frames to compute gravitational phase shifts and collapse times.

Result: Linear superposition becomes unstable under gravity, leading to collapse proportional to inverse mass. Phase shifts produce model-independent collapse times and global phase changes in wave functions across reference frames.

Conclusion: Gravity introduces unavoidable instabilities in quantum superpositions due to the tension between the equivalence principle and superposition, implying spontaneous collapse intrinsic to semiclassical gravity.

Abstract: We incorporate non-local gravitational self-energy, motivated by string-inspired T-duality, into the Schrödinger-Newton equation. In this framework spacetime has an intrinsic non-locality, rendering the standard linear superposition principle only an approximation valid in the absence of gravitational effects. We then invert the logic by assuming the validity of linear superposition and demonstrate that such superpositions inevitably become unstable once gravity is included. The resulting wave-function collapse arises from a fundamental tension between the equivalence principle and the quantum superposition principle in a semiclassical spacetime background. We further show that wave functions computed in inertial and freely falling frames differ by a gravitationally induced phase shift containing linear and cubic time contributions along with a constant global term. These corrections produce a global phase change and lead to a spontaneous, model-independent collapse time inversely proportional to the mass of the system.

</details>


### [59] [Stefan-Boltzmann Law and Thermal Casimir Effect in Neutron Star Spacetime via Thermo Field Dynamics](https://arxiv.org/abs/2512.15610)
*Klecio E. L. de Farias,Marcos A. Anacleto,Rafael A. Batista,Iver Brevik,Francisco A. Brito,Eduardo Passos,Amilcar R. Queiroz,Lázaro L. Sales*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the thermal Casimir effect for a massless scalar field in the curved spacetime of a neutron star within the Thermo Field Dynamics (TFD) formalism. Starting from the renormalized energy-momentum tensor, we generalize the Stefan-Boltzmann law to include gravitational redshift and curvature corrections governed by the Tolman-Oppenheimer-Volkoff (TOV) metric. Finite temperature and spatial compactification are introduced simultaneously, allowing a unified and consistent treatment of both vacuum and thermal contributions inside and outside the star. Analytical expressions are derived for the high- and low-temperature limits, showing explicitly how curvature and redshift modify the characteristic $T^4$ dependence of thermal radiation. The results reveal that strong gravity significantly alters the local energy density and pressure, demonstrating the nontrivial interplay between quantum vacuum fluctuations and compact astrophysical geometries. A polytropic model is considered to perform numerical analyses, highlighting the influence of the spacetime background on vacuum fluctuations.

</details>


### [60] [Observational constraints on the spin/anisotropy of the CCOs of Cassiopeia A, Vela Jr. and G347.3-0.5 and a single surviving continuous gravitational wave candidate](https://arxiv.org/abs/2512.15672)
*Jing Ming,Maria Alessandra Papa,Heinz-Bernd Eggenstein,Bernd Machenschalk,J. Martins,B. Steltner,B. McGloughlin,V. Dergachev,R. Prix,M. Bensch*

Main category: gr-qc

TL;DR: The paper presents a comprehensive search for continuous gravitational waves from three neutron stars in supernova remnants using Einstein@Home volunteers' computing power, setting stringent constraints on parameters like ellipticity and crustal anisotropy, with one surviving candidate from G347.3.


<details>
  <summary>Details</summary>
Motivation: To explore gravitational-wave signals from neutron stars to understand their structure and emission mechanisms, particularly focusing on parameters like equatorial ellipticity and crustal anisotropy, which are crucial for astrophysical models.

Method: A multi-stage search using distributed computing via Einstein@Home to analyze data, followed by follow-up analysis of top candidates with independent datasets, applying advanced filtering and constraint calculations.

Result: The study set the most stringent constraints to date on gravitational-wave amplitudes, ellipticity (≤4×10⁻⁷ for spin periods <2 ms), and crustal anisotropy (≤5×10⁻³ for 1.3-100 ms periods). One candidate from G347.3 required further scrutiny but lacked accessible new data.

Conclusion: The methodology significantly advances gravitational-wave detection capabilities for neutron stars, with potential for refining astrophysical models. The unresolved G347.3 candidate highlights the need for improved data access and future observations.

Abstract: We carry out the deepest and broadest search for continuous gravitational-wave signals with frequencies between 20-1500 Hz, from three neutron stars at the center of the supernova remnants Cassiopeia A, Vela Jr., and G347.3-0.5. This search was made possible by the computing power shared by thousands of Einstein@Home volunteers. After the initial Einstein@Home search, we perform a multi-stage follow-up of the most promising $\approx$ 45 million signal candidates. In the last stages, we use independent data to further investigate the remaining candidates from the previous stages. We set the most stringent constraints to date on the gravitational-wave amplitude, equatorial ellipticity, r-mode saturation amplitude, and -- for the first time -- the neutron-star crustal anisotropy. For spin periods lower than 2 ms we constrain the ellipticity to be smaller than $4\times 10^{-7}$ for all targets. We exclude the crustal anisotropy to be smaller than $5\times 10^{-3}$ for spin periods between 1.3-100 ms. Only one candidate -- from the low frequency G347.3 search -- survives all follow-ups. We illustrate properties of this candidate. Investigations on new data will aid in clarifying its nature. Such ``new" data exists and would be optimal for this purpose, but they are not publicly accessible at the time of writing.

</details>


### [61] [An introduction to nonlinear fiber optics and optical analogues to gravitational phenomena](https://arxiv.org/abs/2512.15695)
*Dimitrios Kranas,Andleeb Zahra,Friedrich König*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The optical fiber is a revolutionary technology of the past century. It enables us to manipulate single modes in nonlinear interactions with precision at the quantum level without involved setups. This setting is useful in the field of analogue gravity (AG), where gravitational phenomena are investigated in accessible analogue lab setups. These lecture notes provide an account of this AG framework and applications. Although light in nonlinear dielectrics is discussed in textbooks, the involved modelling often includes many assumptions that are directed at optical communications, some of which are rarely detailed. Here, we provide a self-contained and sufficiently detailed description of the propagation of light in fibers, with a minimal set of assumptions, which is relevant in the context of AG. Starting with the structure of a step-index fiber, we derive linear-optics propagating modes and show that the transverse electric field of the fundamental mode is well approximated as linearly polarized and of a Gaussian profile. We then incorporate a cubic nonlinearity and derive a general wave envelope propagation equation. With further simplifying assumptions, we arrive at the famous nonlinear Schrödinger equation, which governs fundamental effects in nonlinear fibers, such as solitons. As a first application in AG, we show how intense light in the medium creates an effective background spacetime for probe light akin to the propagation of a scalar field in a black hole spacetime. We introduce optical horizons and particle production in this effective spacetime, giving rise to the optical Hawking effect. Furthermore, we discuss two related light emission mechanisms. Finally, we present a second optical analogue model for the oscillations of black holes, the quasinormal modes, which are important in the program of black hole spectroscopy.

</details>


### [62] [Physical Effects of Gravitational Waves at Second Order](https://arxiv.org/abs/2512.15704)
*Guillem Domènech,Shi Pi,Ao Wang*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: There is currently no rigorous definition of gravitational wave strain at second order in cosmological perturbation theory. The usual association of gravitational waves with transverse and traceless fluctuations of the metric on spatial hypersurfaces becomes ambiguous at second order, as it inherently depends on the spacetime slicing. While this poses no practical issues in linearized gravity, it presents a fundamental problem for secondary gravitational waves, especially notorious for gravitational waves induced by primordial fluctuations. We compute, for the first time, the physical effects of gravitational waves at second order, as measured by geodesic observers that emit and receive electromagnetic signals, thereby settling the debate on gauge ambiguities. We find that the measured gravitational wave strain coincides with the transverse-traceless components in the Newton gauge.

</details>


### [63] [The $μ$-deformed Einstein field equations with $μ$-dependent effective cosmological constant](https://arxiv.org/abs/2511.17790)
*O. P. Mykhailiv,Yu. A. Mishchenko,A. M. Gavrilik*

Main category: gr-qc

TL;DR: The paper addresses the cosmological constant problem by deriving μ-deformed Einstein equations from a modified Bose gas model and Verlinde's approach, showing that varying μ reduces the cosmological constant to realistic values and links to dark matter.


<details>
  <summary>Details</summary>
Motivation: To tackle the cosmological constant problem by exploring deformation parameters in thermodynamic models, offering a pathway to adjust the cosmological constant to observed values.

Method: Derivation of μ-deformed Einstein field equations using a generalized thermodynamic framework based on a μ-deformed Bose gas model, leveraging Verlinde's approach to connect thermodynamics and gravity.

Result: Varying the μ parameter significantly reduces the cosmological constant to realistic levels, suggesting a solution to the CC problem and hinting at connections to dark matter phenomena.

Conclusion: The μ-deformation provides a viable framework to address the cosmological constant issue, with potential implications for understanding dark matter through parameter adjustments in the model.

Abstract: In this paper, we derive the $μ$-deformed Einstein field equations from the generalized thermodynamic functions of the $μ$-deformed analog of Bose gas model, applying the (adapted) Verlinde's approach. The basic role of deformation parameter is shown: it provides the possibility to vary the value of the cosmological constant. Due to this, we suggest an interesting treatment of the cosmological constant (CC) problem within the framework of $μ$-deformation. Namely, viewing the derived $μ$-deformed CC as an effective one and varying the parameter $μ$ appropriately, we gain the possibility to drastically reduce the CC, so as to get for it the realistic value. The relation to dark matter is of importance.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [64] [Implications of Flavor Symmetries for Baryon Number Violation](https://arxiv.org/abs/2512.14813)
*Arnau Bas i Beneito,Ajdin Palavrić,Andrea Sainaghi*

Main category: hep-ph

TL;DR: This paper systematically classifies dimension-six baryon-number-violating (BNV) SMEFT operators under different flavor symmetry assumptions, explores their phenomenology, and finds that proton decay constraints allow BNV scales up to multi-TeV in certain scenarios. It also examines UV completions showing potential limitations of the EFT approach.


<details>
  <summary>Details</summary>
Motivation: Baryon number violation signals new physics beyond the Standard Model, particularly through proton decay. The study aims to understand how flavor structure influences BNP effects and test the applicability of EFT in describing underlying dynamics.

Method: Systematic classification of dimension-6 BNV SMEFT operators across various flavor symmetries, analysis of phenomenological consequences (including neutrino masses and proton decay rates), and identification of UV completions (e.g., models with leptoquarks or vector-like fermions).

Result: Some flavor scenarios permit BNV scales near multi-TeV due to suppressed proton decay rates linked to tiny neutrino masses. UV completion studies reveal cases where EFT predictions differ significantly from full theory calculations, indicating EFT limitations.

Conclusion: Flavor structures play a critical role in determining BNV phenomenology and allowed energy scales. EFT analysis must be complemented with UV model considerations to properly capture dynamics beyond their validity range.

Abstract: In the Standard Model, baryon number is an accidental symmetry, whose violation would constitute unambiguous evidence of new physics, with proton decay providing its most prominent experimental signature. At the same time, the peculiar structure of flavor can serve as a guiding principle for exploring possible new-physics effects. In this work, we present a systematic classification of dimension-six baryon-number-violating (BNV) SMEFT operators across several flavor-symmetry assumptions and analyze the resulting phenomenology. Interestingly, in certain flavor scenarios the non-trivial interplay with tiny neutrino masses leads to proton-decay constraints compatible with BNV scales in the multi-TeV range. Finally, we complement the EFT analysis by identifying one-particle UV completions of the BNV operators, revealing scenarios in which the leading-order EFT description may not fully account for their underlying dynamics.

</details>


### [65] [Symmetric Dicke States as Optimal Probes for Wave-Like Dark Matter](https://arxiv.org/abs/2512.14821)
*Ping He,Jing Shu,Bin Xu,Jincheng Xu*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We identify symmetric Dicke states as the optimal quantum probes for distributed sensing of wave-like dark-matter fields. Within an ensemble-averaged quantum-metrological framework that incorporates the field's random phases and finite coherence, they maximize the Fisher information for short-baseline arrays with $N_d$ sensors and realize a robust $N_d^2$ enhancement. They also retain this collective advantage under amplitude-damping noise, whereas GHZ-type probes are highly fragile and rapidly lose their sensitivity once such noise is included. For two sensors at separations comparable to the dark-matter coherence length, the optimal entangled state acquires an additional spatial-correlation phase and outperforms both Dicke and independent probes. Our framework applies broadly to stochastic bosonic fields, including gravitational waves, and can be implemented with superconducting qubits, atomic ensembles, and NV centers.

</details>


### [66] [Higgs-Pair Production via Gluon Fusion: Top-Yukawa- and light-quark-induced electroweak Corrections](https://arxiv.org/abs/2512.14823)
*Arunima Bhattacharya,Francisco Campanario,Sauro Carlotti,Jamie Chang,Javier Mazzitelli,Margarete Mühlleitner,Jonathan Ronca,Michael Spira*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Gluon fusion, $gg\to HH$, is the dominant Higgs-pair production process at the Large Hadron Collider (LHC) and provides the first direct access to the trilinear Higgs self-interaction. The process is loop-induced, with the main contribution emerging from top-quark loops within the Standard Model. In the past, the QCD corrections have been calculated and found to increase the cross section significantly. With the anticipated accuracies achievable at the high-luminosity LHC (HL--LHC), the theoretical uncertainties will be of increased relevance to compete with the experimental precision at the level of less than 30\%. In this work, we take the next steps towards the determination of the complete electroweak corrections at next-to-leading order by calculating the full top-Yukawa and light-quark induced corrections. These corrections modify the cross section moderately in the kinematical regimes of interest.

</details>


### [67] [Towards First Detection of the Solar MSW Transition With JUNO](https://arxiv.org/abs/2512.14824)
*Obada Nairat,John F. Beacom,Kevin J. Kelly,Shirley Weishi Li*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Matter-induced neutrino flavor mixing (the Mikheyev-Smirnov-Wolfenstein, or MSW, effect) is a central prediction of the neutrino mixing framework, but it has not been conclusively observed. Direct observation of the energy-dependent MSW transition in the solar electron-neutrino survival probability would solve this, but backgrounds have been prohibitive. We show that our new technique for suppressing muon-induced spallation backgrounds will allow JUNO to measure the MSW transition at $>$4$σ$ significance in 10 years. This would strongly support upcoming multi-\$1B next-generation long-baseline experiments and their goals in cementing the neutrino mixing framework.

</details>


### [68] [Opening the Parameter Space of sub-GeV Inelastic Dark Matter through Parity Violation](https://arxiv.org/abs/2512.14828)
*Giovani Dalla Valle Garcia,Juan Herrero-García,Joel Jones-Pérez,Javier Silva-Malpartida*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Sub-GeV dark matter (DM) has emerged as a particularly compelling target in light of the persistent null results from conventional DM searches. While s-wave annihilating DM candidates with masses below the GeV are strongly constrained by indirect-detection bounds, inelastic scenarios can naturally evade these limits. In this work, we show that parity violation can play an important role in inelastic DM models featuring long-lived excited states by inducing small diagonal couplings that significantly relax experimental constraints. A precise determination of the excited-state abundance is essential for assessing the phenomenology of such models. To this end, we solve the integrated Boltzmann equation, fully accounting for up- and down-scattering with electrons and positrons as well as dark-sector conversion processes. Using the resulting abundance, we update the viable parameter space in light of the most recent experimental constraints and demonstrate that parity-violating interactions can reopen broad regions of parameter space that would otherwise be excluded. Moreover, the forthcoming LDMX experiment will probe a significant portion of the parameter space. The framework developed in this work can be readily applied to other exothermic sub-GeV DM scenarios.

</details>


### [69] [Renormalization of U(1) Gauge Boson Kinetic Mixing](https://arxiv.org/abs/2512.14836)
*Felix Forner,Felix Tellander*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum field theories containing fields with the same quantum numbers allow for mixed kinetic terms in the Lagrangian, leading to off-diagonal elements in the tree-level two-point function. After removing the mixing by a field rotation, the off-diagonal UV divergences cannot be subtracted by a counterterm, still one can show that the theory is renormalizable. We study kinetic mixing of $U(1)$ gauge bosons in an extension of QED with a massive "dark" photon at one-loop order. In general covariant $R_ξ$-gauge, the gauge-fixing function naively obstructs the removal of tree-level mixing but we show that these off-diagonal gauge-dependent contributions cancel. We compare two renormalization schemes: one with and one without kinetic mixing, and relate them via a scale-dependent field transformation, showing that the schemes are equivalent.

</details>


### [70] [Compact Stars as Portals to Extra-Dimensional Dark Matter](https://arxiv.org/abs/2512.14837)
*Raghuveer Garani,Chris Kouvaris,Michel H. G. Tytgat,Jérôme Vandecasteele*

Main category: hep-ph

TL;DR: The paper explores how fermionic dark matter in extra dimensions could collapse neutron stars into black holes, with implications for dark matter mass and extra dimension size constraints.


<details>
  <summary>Details</summary>
Motivation: To understand the impact of extra dimensions on dark matter behavior within neutron stars and derive constraints on dark matter mass and extra dimensional parameters.

Method: Analyzes hydrostatic configurations of asymmetric dark matter in higher-dimensional scenarios, modeling gravitational collapse into extra-dimensional black holes and their accretion processes.

Result: Dark matter above ~10 TeV with more than two extra dimensions (size ~fm) may already be excluded, unlike 3D case requiring masses ~1e5 TeV for similar limits.

Conclusion: Extra dimensions significantly lower the mass threshold for dark matter-induced neutron star collapse, providing stringent constraints on particle physics models with large extra dimensions.

Abstract: We investigate hydrostatic configurations of asymmetric dark matter (DM) spheres in scenarios where fermionic DM can propagate into extra spatial dimensions, while Standard Model fields remain confined to ordinary three dimensions. As the number of extra dimensions increases, the effective equation of state for non-relativistic matter softens, making even modest DM accumulation inside neutron stars susceptible to gravitational collapse into extra-dimensional black holes. These black holes are longer lived than their $3$ dimensional counterparts and can accrete enough material to consume an entire neutron star, ultimately producing solar-mass black holes. For geometric cross sections, DM with masses above $\mathcal{O}(10\,{\rm TeV})$ may already be excluded for more than two extra dimensions of size ${\mathcal{O}(\rm fm})$ -- sharply contrasting with the standard $3$ dimensional case, where comparable limits only appear for masses $\gtrsim 10^{5}$ TeV at typical halo densities of $0.3\, \rm{GeV/cm^3}$.

</details>


### [71] [Non-Thermal Production of Sexaquark Dark Matter](https://arxiv.org/abs/2512.14838)
*Marianne Moore,Stefano Profumo*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Standard thermal freeze-out scenarios with QCD-scale interaction rates predict a $uuddss$ sexaquark relic abundance many orders of magnitude below the observed dark matter density, representing a key challenge for sexaquark dark matter models. Additionally, if the maximum post-inflationary temperature never exceeds the QCD confinement scale, the usual thermal/chemical-equilibrium production of the sexaquark near ${T \sim T_{\rm QCD} \simeq 150 \text{-} 170~\mathrm{MeV}}$ never occurs. In this work we show that non-thermal mechanisms can naturally overcome this obstacle. Using late-decaying reheatons as a representative case (while noting the broader applicability), we demonstrate that the final abundance is determined by two quantities: the branching fraction into strange-quark-rich matter and the coalescence probability into sexaquarks during the matter-dominated or early radiation-dominated epoch. We provide compact expressions and benchmark calculations for reheating temperatures $T_R \in [10, 100]~\mathrm{MeV}$ and reheaton masses above the QCD confinement scale. Unlike the predictive but unsuccessful thermal scenario, non-thermal production is sensitive to injection microphysics, coalescence efficiency, and residual entropy dilution. We delineate the viable parameter space, evaluate collider and precision constraints on representative reheaton models, and derive indirect detection bounds on residual antisexaquark populations. Our results establish non-thermal production as a viable pathway to sexaquark dark matter and highlight broader implications for non-equilibrium mechanisms in the early universe.

</details>


### [72] [Beyond $\boldsymbol{SU(N)}$: $\boldsymbol{U(3) \times U(2)}$ as the underlying symmetry of the strong and electroweak interactions](https://arxiv.org/abs/2512.14839)
*Antonio Herrero-Brocal,Javier Perez-Soler,Avelino Vicente*

Main category: hep-ph

TL;DR: The paper explores extending the gauge principle by promoting all SU(N) symmetries to U(N), focusing on a U(3)×U(2) model. This approach explains Standard Model features like charge quantization, predicts hypercharge assignments, requires right-handed neutrinos, and introduces a B-L symmetry, leading to neutrino masses.


<details>
  <summary>Details</summary>
Motivation: To address unresolved questions in the Standard Model (e.g., ad hoc features like charge quantization and hypercharge assignments) and explore a stricter adherence to the gauge principle by eliminating ungauged global U(1) symmetries.

Method: Proposes a model based on local U(3)×U(2) invariance, promoting all SU(N) symmetries to U(N), ensuring no global U(1) redundancies remain ungauged.

Result: The model uniquely predicts Standard Model hypercharge assignments, necessitates right-handed neutrinos, and introduces a B-L symmetry, leading to non-zero neutrino masses without fine-tuning. It also provides a natural framework for the Standard Model's structure.

Conclusion: U(3)×U(2) symmetry may underpin the strong and electroweak interactions, offering a more consistent gauge principle interpretation and new directions for particle physics model building.

Abstract: The gauge principle is a cornerstone of particle-physics model building. Nevertheless, many constructions leave certain global $U(1)$ redundancies ungauged. In this work, we take the gauge principle to its logical extreme by promoting all $SU(N)$ symmetries to $U(N)$. We focus on a model based on local $U(3)\times U(2)$ invariance. This framework accounts for several otherwise ad hoc features of the Standard Model, including charge quantization and the observed hypercharge assignments, which emerge here as unique predictions. Furthermore, the internal consistency of the model requires the introduction of right-handed neutrinos and implies the presence of an additional $U(1)$ factor that can be identified with $B-L$, thereby naturally yielding non-zero neutrino masses. In light of these findings, we hypothesize that $U(3)\times U(2)$ constitutes the underlying symmetry of the strong and electroweak interactions. More importantly, our approach opens up novel avenues for model building, driven by this extended interpretation of the gauge principle.

</details>


### [73] [$i$-incidental $N$-naturalness](https://arxiv.org/abs/2512.14841)
*Brian Batell,Akshay Ghalsasi,Wenjie Huang,Matthew Low*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: $N$-naturalness is a novel solution to the electroweak hierarchy problem which posits $N$ copies of the Standard Model with varying Higgs mass-squared parameters. Reheating proceeds through a "reheaton" particle that deposits most of its energy density into the Standard Model and small but potentially measurable fractions into the other copies. Typically the sector with the lightest negative Higgs mass-squared is identified as the Standard Model. We demonstrate that $N$-naturalness admits a broader class of realizations in which the Standard Model is identified with a heavier sector, rather than being restricted to the lightest. This is made possible by resonant mixing between the reheaton and the Higgs, which generically causes one sector to be preferentially reheated and to acquire the largest share of the energy density, singling it out as the Standard Model. We demonstrate that this scenario is consistent with current cosmological bounds on new relativistic degrees of freedom and overclosure constraints from heavy stable relics, while future cosmic microwave background and high redshift surveys will probe significant portions of the remaining parameter space. Furthermore, we highlight the possibility of a novel stochastic gravitational wave spectrum from the many cosmological first order QCD phase transitions occurring across the other sectors.

</details>


### [74] [Three-dimensional imaging of hadrons with hard exclusive reactions: advances in experiment, theory, phenomenology, and lattice QCD](https://arxiv.org/abs/2512.15064)
*M. Boër,A. Camsonne,M. Constantinou,H. S. Jo,K. Joo,K. Semenov-Tian-Shansky,H. -D. Son,P. Sznajder,C. Van Hulse,J. Wagner,A. Afanasev,J. S. Alvarado,S. Bhattacharya,D. Biswas,Xu Cao,H. -M. Choi,K. Cichy,N. Crnković,W. Hamdi,M. Hoballah,G. M. Huber,P. T. P. Hutauruk,A. Jentsch,C. -R. Ji,H. -Ch. Kim,B. Kriesten,Huey-Wen Lin,P. -J. Lin V. Martínez-Fernández,M. Mazouz,Z. -E. Meziani,M. Nefedov,K. Passek-K.,B. Pire,P. Rossi,O. Teryaev,A. W. Thomas,N. Tomida*

Main category: hep-ph

TL;DR: The paper discusses advancements in Generalized Parton Distributions (GPDs) for studying hadron structure, including their interpretation in impact parameter space for 3D imaging, connections to QCD energy-momentum tensor for spin and pressure analysis, and recent quark pressure profile extractions from DVCS data. It highlights lattice QCD progress and future experimental initiatives.


<details>
  <summary>Details</summary>
Motivation: To explore hadron structure at a deeper level using GPDs, providing insights into momentum distributions, spatial configurations, and fundamental properties like spin and pressure, while setting a roadmap for future research through upcoming experiments.

Method: The paper reviews theoretical developments in GPD framework, impact parameter space analysis, QCD energy-momentum tensor connections, lattice QCD simulations, and evaluates DVCS experimental data to extract quark pressure profiles.

Result: GPDs enable tomographic imaging of hadrons and measurement of quark pressure inside protons. Lattice QCD confirms theoretical predictions, while future experiments promise refined structural insights.

Conclusion: GPDs remain vital for probing hadron structure, with ongoing and planned experiments (e.g., Jefferson Lab upgrades, EIC, LHC) offering transformative opportunities to map hadron dynamics and validate QCD predictions.

Abstract: Generalized Parton Distributions (GPDs) have emerged as a powerful framework for exploring the internal structure of hadrons in terms of their partonic constituents. Over the past three decades, the field has witnessed significant theoretical and experimental advancements. The interpretation of GPDs in impact parameter space offers a vivid three-dimensional visualization of hadron structure, correlating longitudinal momentum and transverse spatial distributions, thereby enabling tomographic imaging of hadrons. Furthermore, the link between GPDs and the matrix elements of the QCD energy-momentum tensor provides access to fundamental properties of hadrons, including spin decomposition and internal pressure distributions. Notably, recent analyses of Deeply Virtual Compton Scattering (DVCS) data have enabled the empirical extraction of the quark pressure profile inside the proton. This white paper presents an overview of recent developments in GPD theory and phenomenology, as well as progress in lattice QCD studies. It outlines the prospects for advancing our understanding of hadron structure through the next generation of dedicated experiments, including the extension of the Jefferson Lab 12~GeV program (and its potential 22~GeV upgrade), J-PARC, COMPASS/AMBER, LHC ultra-peripheral collisions, and the future electron-ion colliders EIC and EicC.

</details>


### [75] [Crossover or First-Order: Impacts of Regularization](https://arxiv.org/abs/2512.15094)
*Xin-Peng Li,Hao-Ran Zhang,Zhu-Fang Cui,Thomas Klähn*

Main category: hep-ph

TL;DR: The study investigates the impact of regularization schemes on the phase transitions in hot, dense nuclear matter, revealing strong dependencies on both scheme and parameters.


<details>
  <summary>Details</summary>
Motivation: To address the ongoing debate over reliable treatments of the equation of state in hot, dense nuclear matter due to the nonperturbative nature of strong interactions.

Method: Employed symmetry-preserving vector⊗vector contact interaction models under noncovariant and covariant regularization schemes at nonzero temperature or quark chemical potential.

Result: Numerical results demonstrate that the phase transition's nature is highly sensitive to the chosen regularization scheme and parameter settings.

Conclusion: The choice of regularization method and its parameters critically influence the predicted phase transition behavior, highlighting the need for careful selection and validation in theoretical models.

Abstract: The equation of state of hot, dense nuclear matter plays a fundamental role in many areas. However, owing to the nonperturbative nature of strong interactions, a reliable treatment is still under debate. We use a symmetry-preserving treatment of a vector\,$\otimes$\,vector contact interaction to study related issues at nonzero temperature or quark chemical potential, and carefully compare a noncovariant and a covariant regularization scheme. The numerical results show that the character of the phase transition depends sensitively on the regularization scheme and parameter choices.

</details>


### [76] [The domain of soft hadrons in transverse momentum space in high energy collisions](https://arxiv.org/abs/2512.15178)
*Jun Song,Hai-hong Li,Feng-lan Shao*

Main category: hep-ph

TL;DR: The paper identifies two critical transverse momentum points, $p_0$ and $p_1$, in hadronic spectra from high-energy collisions, classifying hadron production into soft, transition, and hard regions. It correlates $p_0$ with hadron species, collision parameters, and observes differences between mesons and baryons linked to quark combination mechanisms.


<details>
  <summary>Details</summary>
Motivation: To understand the underlying mechanisms of hadron production in high-energy collisions by analyzing the transverse momentum distributions and identifying characteristic points in their spectra.

Method: Systematic analysis of experimental data on $p_{T}$ spectra of various hadrons (kaons, K*, φ, protons, Λ, Ξ, Ω) in pp, p-Pb, and heavy-ion collisions at RHIC and LHC. The second derivative of the log-spectra, $[\ln f(p_T)]''$, is used to determine $p_0$ (zero crossing) and $p_1$ (maximum) points, classifying the regions dominated by soft physics, transition, and hard jets.

Result: Observed dependence of $p_0$ and $p_1$ on particle species, collision energy, centrality, and multiplicity. Distinct $p_0$-$\langle p_T \rangle$ correlations for mesons vs. baryons, suggesting quark combination effects. $p_0$ sensitivity to soft hadron production properties across collision systems.

Conclusion: $p_0$ and $p_1$ are robust indicators of hadron production dynamics, revealing phase-space partitioning between soft and hard processes. The $p_0$-$\langle p_T \rangle$ disparity between mesons and baryons supports quark hadronization models. These observables are valuable tools for studying soft-hard interplay in high-energy collisions.

Abstract: By studying experimental data for invariant transverse momentum distribution $f(p_{T})$ of hadrons in high energy $pp$, $p$A and AA collisions, we find two characteristic $p_{T}$ points relating to the behavior of $\left[\ln f(p_{T})\right]^{''}$, i.e., the second derivative of the logarithm of hadronic $p_{T}$ spectrum with respect to $p_{T}$. One point is $p_{0}$ at which $\left[\ln f(p_{T})\right]^{''}$ is zero and another point is $p_{1}$ at which $\left[\ln f(p_{T})\right]^{''}$ reaches maximum. \bz{The hadronic distribution can be classified into three kinetic regions, i.e., soft region $0<p_{T}<p_{0}$ dominated by hadrons from soft parton system, hard region $p_{T}>p_{1}$ dominated by hadrons from high energy partonic jet, and the transition region $p_{0}<p_{T}<p_{1}$ of above two sources of hadron production.} Using rich data of hadronic $p_{T}$ spectra at RHIC and LHC, we carry out a systematical analysis for $p_{0}$ and $p_{1}$ of kaon, $K^{*}$, $φ$ and baryons such as $p$, $Λ$, $Ξ$, $Ω$ in $pp$, $p$-Pb and heavy-ion collisions, and show their dependence on hadron species, collision energy, collision centrality and/or charged-particle multiplicity. We also study the correlation between $p_{0}$ of hadrons and their average transverse momentum $\left\langle p_{T}\right\rangle $, and find a difference between $p_{0}$-$\left\langle p_{T}\right\rangle $ correlation of baryons and that of mesons which can be understood by quark combination mechanism at hadronization. The systematic comparison for $p_{0}$-$\left\langle p_{T}\right\rangle $ correlation of kaon, $φ$, $p$ and $Λ$ in $pp$, $p$-Pb, Pb-Pb and Au+Au collisions at RHIC and LHC energies indicates that $p_{0}$ is a sensitive physical quantity of reflecting the production property of soft hadrons in high energy collisions.

</details>


### [77] [Axion-like Particle Search with a Light-Shining-Through-Walls Setup at a $γ$-$γ$ Collider](https://arxiv.org/abs/2512.15192)
*Zi-Yao Yan,Jie Feng*

Main category: hep-ph

TL;DR: The paper proposes a new method using high-intensity gamma-ray beams from a gamma-gamma collider to improve sensitivity in搜寻 axion-like particles (ALPs) via the light-shining-through-walls (LSW) technique. The setup enhances coupling sensitivity by an order of magnitude without added experimental complexity.


<details>
  <summary>Details</summary>
Motivation: The motivation is to overcome limitations of conventional LSW experiments by leveraging existing high-intensity gamma-ray sources, enabling more sensitive searches for axion-like particles in a practical and infrastructure-compatible manner.

Method: The method involves using inverse Compton scattering at a gamma-gamma collider to produce a collimated gamma beam for ALP production, followed by a regeneration region. An upstream magnetic region further enhances sensitivity by improving ALP regeneration efficiency.

Result: With one year of operation and conservative assumptions, the method achieves a sensitivity of $g_{aγγ} ≈ 3.82 × 10^{-5} GeV^{-1}$ for ALP masses below 0.1 eV, surpassing previous LSW limits by up to an order of magnitude.

Conclusion: This approach significantly advances ALP detection capabilities through efficient use of existing facilities, offering a promising path for future particle physics experiments without requiring new complex infrastructure.

Abstract: In this work, we have explored a practical extension of the conventional light-shining-through-walls technique by making direct use of the high-intensity $γ$-ray beam available at a $γ$-$γ$ collider. The energetic and highly collimated photon flux produced via inverse Compton scattering naturally provides an efficient ALP production stage, while the addition of a regeneration region downstream enables a complete LSW configuration without introducing new experimental complexities. This approach therefore represents an experimentally simple and infrastructure-compatible method for enhancing laboratory sensitivity to axion-like particles. Under conservative assumptions, we find that one year of operation can probe ALP-photon couplings down to $g_{aγγ}\simeq 3.82\times 10^{-5} \,\mathrm{GeV^{-1}}$ for $m_a\lesssim 0.1 \,\mathrm{eV}$ when an additional magnetic region is included upstream of the beam dump, improving upon previous laboratory LSW limits by up to an order of magnitude.

</details>


### [78] [Selected decays of $B_{s}$ meson in covariant confined quark model](https://arxiv.org/abs/2512.15321)
*Stanislav Dubnička,Anna Zuzana Dubničková,Mikhail A. Ivanov,Andrej Liptaj*

Main category: hep-ph

TL;DR: This paper analyzes various $B_{s}$ meson decays using a covariant confined quark model, finding good agreement for some modes but discrepancies in others, suggesting potential issues with factorization and long-distance effects.


<details>
  <summary>Details</summary>
Motivation: The motivation is to broadly test the Standard Model's understanding of $B_{s}$ meson decay dynamics through multiple channels and identify discrepancies implying beyond-factorization effects.

Method: The authors use the covariant confined quark model to compute decay amplitudes, analyzing hadronic and semileptonic $B_{s}^0$ decays with different spins and diagram topologies.

Result: Agreement with data is good (semileptonic), acceptable (some hadronic), marginal (others), and poor for $φightarrow \\

Conclusion: Discrepancies in certain decays like $B_{s}^{0}\to D_{s}^{-}π^{+}$ suggest naive factorization breaks down, requiring inclusion of long-distance effects for accurate predictions.

Abstract: We present a study of various $B_{s}$ meson decays, including hadronic and semileptonic final states with different spins and diagram topologies. The covariant confined quark model is employed to describe hadronic effects, and our analysis serves as a broad test of the current understanding of the underlying dynamics within the Standard Model. The level of agreement with experimental data varies across channels: it is good for the semileptonic decays $B_{s}^{0}\to D_{s}^{-}μ^{+}ν_μ$ and $B_{s}^{0}\to K^{-}μ^{+}ν_μ$; acceptable for the hadronic modes $B_{s}^{0}\to D_{s}^{-}D^{+}$ and $B_{s}^{0}\to K^{-}π^{+}$; marginal for $B_{s}^{0}\to D_{s}^{-}π^{+}$, $B_{s}^{0}\to D_{s}^{-}ρ^{+}$, and $B_{s}^{0}\toφ\,J/ψ$; and significantly discrepant for $B_{s}^{0}\toφ\,\overline{D^{0}}$ and $B_{s}^{0}\toφ\,η_{c}$. We argue that the observed inconsistencies may arise from the breakdown of naive factorization and unaccounted long-distance effects. In particular, the channels $B_{s}^{0}\to D_{s}^{-}π^{+}$ and $B_{s}^{0}\to D_{s}^{-}ρ^{+}$ are theoretically among the cleanest nonleptonic decays, yet they exhibit persistent discrepancies also reported by other theoretical groups.

</details>


### [79] [Statistical repulsion on hyperons in two-color dense QCD](https://arxiv.org/abs/2512.15434)
*Masato Nagatsuka,Toru Kojo*

Main category: hep-ph

TL;DR: The paper explores the formation of hyperons in baryonic matter under two-color QCD by introducing heavy quark doublets. It finds that hyperon onset density is delayed due to Pauli blocking suppression of diquark correlations.


<details>
  <summary>Details</summary>
Motivation: To study hyperon appearance in dense baryonic matter and understand deviations from simple hadronic expectations within two-color QCD, avoiding the lattice sign problem with an even quark flavor setup.

Method: Constructed a QC$_2$D model with light-light, light-heavy, and heavy-heavy diquark interactions via Yukawa couplings. Analyzed phase transitions at increasing quark chemical potential.

Result: Light diquarks condense first at densities explainable by hadronic models. Hyperon onset occurs significantly later than hadronic predictions due to repulsion from occupied light quarks blocking diquark correlations.

Conclusion: Hyperon formation is delayed in dense matter due to Pauli blocking's suppression of attractive interactions, suggesting non-trivial quark dynamics beyond hadronic composition. Implications for three-color QCD (real-world QCD) are noted.

Abstract: We investigate the onset of hyperons in baryonic (diquark) matter in two-color QCD (QC$_2$D) by introducing heavy quark doublets that emulate strange quarks. An even number of flavors is required to avoid the sign problem in lattice Monte Carlo simulations. To explore QC$_2$D matter containing both light and heavy quarks, we construct a model in which quarks interact with light-light, light-heavy (hyperonic), and heavy-heavy diquarks via Yukawa couplings. As the quark chemical potential increases, the light diquarks condense first and form baryonic matter, and this onset density can be understood in hadronic terms. In contrast, the onset density of hyperons is substantially higher than that estimated from the hadronic sector of the model. This shift reflects an effective repulsion among baryons induced by the pre-occupied light quarks. The Pauli blocking of light quarks suppresses the attractive diquark correlations responsible, in vacuum, for making hyperons lighter than the sum of the constituent light and heavy quark masses. Implications for three-color QCD are also briefly discussed.

</details>


### [80] [The effective running quark mass from the variational solution of the 4dimensional Bethe-Salpeter equation for charmonium](https://arxiv.org/abs/2512.15571)
*V. Sauli*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The scale dependence of the modulus of the effective charm quark mass is determined from measured values of leptonic decay constants and vector charmonium masses. Unlike nonrelativistic approximations, the Poincaré-invariant framework based on the full four-dimensional (4D) Bethe-Salpeter equation does not support a single-valued constituent quark mass approximation. To overcome the obstacles of low accuracy associated with standard methods, the variational method is used to solve the full 4D Bethe-Salpeter equations. This method achieves precise agreement with the experiment while avoiding unphysical abnormal states. The quark mass must slide to provide almost unique values for the charm running mass at the scale of individual charmonium states, achieving precise agreement with the experiment on one hand and avoiding unphysical abnormal states on the other.

</details>


### [81] [Resonant Type-II + Type-I Hybrid Leptogenesis in SO(10) with Triplet--Neutrino Mass Degeneracy $M_T \simeq M_{N_3}$](https://arxiv.org/abs/2512.15654)
*Gayatri Ghosh*

Main category: hep-ph

TL;DR: This paper proposes a new mechanism called hybrid resonant leptogenesis within renormalizable SO(10) grand unified theories. It leverages interference between type-I and type-II seesaw processes, enabled by a near-mass-degenerate scalar triplet and heaviest right-handed neutrino. This interference generates a physical CP-violating phase leading to resonant enhancement of baryon asymmetry at moderate masses (~10^11 GeV) without requiring extreme parameters.


<details>
  <summary>Details</summary>
Motivation: The central problem of explaining the Universe's observed baryon asymmetry drives this research. Existing mechanisms often require unnatural conditions like extreme Yukawa hierarchies or fine-tuning, which this work aims to avoid by proposing a novel interference-based approach in SO(10) GUTs.

Method: Examines a quasi-degenerate regime in SO(10) models where scalar triplet mass M_T ≈ heaviest right-handed neutrino mass M_{N3}. Analyzes interference effects between type-I and type-II decay amplitudes, deriving the physical CP phase φ_HR = arg(μf Yν†). Calculates baryon asymmetry enhancement via resonant leptogenesis under these conditions.

Result: Demonstrates that the observed baryon asymmetry Y_B ~8.7×10^-11 can be naturally achieved with masses ~10^11 GeV, moderate washout effects, and order-1 phases. Avoids the need for extreme Yukawa couplings or parameter tuning.

Conclusion: This hybrid resonant leptogenesis mechanism provides a predictive, testable framework. Its predictions correlate with observable phenomena like lepton-flavour violation and electric dipole moments, making it experimentally verifiable.

Abstract: The origin of the baryon asymmetry of the Universe remains one of the central open problems in particle physics and cosmology. We identify a new regime of \emph{hybrid resonant leptogenesis} in renormalizable SO(10) grand unified theories, where a quasi-degeneracy between the scalar triplet and the heaviest right-handed neutrino, \( M_T \simeq M_{N_3}, \) induces an unavoidable interference between type-I and type-II decay amplitudes. This interference gives rise to a physical CP-violating phase, \( φ_{\rm HR} = \arg(μf Y_ν^\dagger), \) which cannot be removed by field redefinitions and leads to a resonant enhancement of the baryon asymmetry without extreme Yukawa hierarchies or tuning. We show that the observed asymmetry, \( Y_B \simeq 8.7 \times 10^{-11}, \) is naturally reproduced for masses around \(10^{11}\,\mathrm{GeV}\), moderate washout, and \(\mathcal{O}(1)\) phases. The mechanism is predictive and testable, with correlated implications for lepton-flavour violation and electric dipole moments.

</details>


### [82] [An Extra-Dimensional Axion in a 5D Warped Orbifold GUT](https://arxiv.org/abs/2512.15666)
*Gongjun Choi,Tony Gherghetta*

Main category: hep-ph

TL;DR: The paper explores the QCD axion within a 5D warped U(1) gauge field in a grand unified theory (GUT), showing that warped geometries allow smaller axion decay constants (f_a) than flat extra dimensions while maintaining gauge unification. It establishes that the conventional QCD axion window (10^9 to 10^12 GeV) is viable when the AdS curvature approaches the Planck scale. This framework, linking 5D GUTs to string theory compactifications, offers dual geometric and holographic insights into the axion mechanism.


<details>
  <summary>Details</summary>
Motivation: To determine viable ranges for the QCD axion decay constant (f_a) in a 5D warped GUT context, addressing limitations of flat extra dimensions and ensuring compatibility with perturbative gauge unification while allowing for a QCD axion in the standard observational window.

Method: Analyzes the behavior of the 5th component of a bulk U(1) gauge field in a 5D warped geometry, contrasting logarithmic running of gauge couplings (vs. rapid running in flat geometries). Considers holographic interpretations of CFT renormalization to derive bounds on f_a, ensuring consistency with both warped GUT unification and axion phenomenology.

Result: Found that warped geometries allow the conventional QCD axion window (10^9–10^12 GeV) without sacrificing perturbativity, provided the AdS curvature is near the Planck scale. Established lower bounds on f_a from bulk contributions. Demonstrated compatibility with string-theoretic warped flux compactifications.

Conclusion: 5D warped orbifold GUTs naturally accommodate high-quality QCD axions within grand unification, offering a geometric and holographic framework that bridges particle physics models and string theory compactifications.

Abstract: We study the QCD axion arising from the 5th component of a bulk $U(1)$ gauge field in a five-dimensional warped grand unified theory, and determine the viable range of the axion decay constant $f_a$. Unlike flat extra dimensions, where gauge couplings run quickly above the Kaluza--Klein (KK) scale, the logarithmic running in warped geometries permits substantially smaller $f_a$ while preserving perturbative gauge coupling unification. However, bulk tree-level contributions to the gauge coupling -- interpreted holographically as CFT renormalization -- place a lower bound on $f_a$. We find that the conventional QCD axion window $10^{9}\,\mathrm{GeV} \lesssim f_a \lesssim 10^{12}\,\mathrm{GeV}$ is readily compatible without losing perturbativity, provided the AdS curvature is near the Planck scale. Thus, the 5D warped orbifold GUT naturally accommodates a high-quality QCD axion in a grand unified theory that provides an effective description of string-theoretic warped flux compactifications, admitting complementary geometric and holographic descriptions of the axion.

</details>


### [83] [Fermionic Electroweak Two-Loop Corrections to Drell-Yan and Related Processes](https://arxiv.org/abs/2512.15700)
*Ayres Freitas,E. Jackson Wallace*

Main category: hep-ph

TL;DR: The paper presents a complete calculation of NNLO electroweak fermionic corrections to fermion-pair production processes using semi-numerical techniques involving dispersion relations and Feynman parameters. NNLO corrections modify NLO cross-sections by ~1%.


<details>
  <summary>Details</summary>
Motivation: To improve precision in fermion-pair production calculations by including the next-to-next-to-leading order (NNLO) electroweak fermionic corrections (closed fermion loops), which are essential for accurate cross-section predictions in high-energy physics experiments.

Method: Semi-numerical approach using dispersion relations for fermion sub-loops in two-loop box and vertex diagrams, along with Feynman parameters for vertex diagrams with fermionic triangle sub-loops. UV and IR divergences were managed with subtraction terms.

Result: Numerical results for cross-sections of e+e−→μ+μ−/uū/d d̄ at various energies and differential distributions show NNLO corrections adjust NLO results by approximately 1%.

Conclusion: The inclusion of NNLO fermionic corrections is crucial for enhancing precision in electroweak calculations, with corrections at the ~1% level offering significant improvements for experimental data interpretation.

Abstract: We perform a complete calculation of the next-to-next-to-leading order (NNLO) electroweak fermionic corrections to fermion-pair production processes, where "fermionic" refers to contributions with closed fermion loops. We did this via a semi-numerical technique that used dispersion relations for the fermion sub-loop in two-loop box and vertex diagrams and dispersion relations and Feynman parameters for vertex diagrams with fermionic triangle sub-loops. UV and IR divergences are treated with suitable subtraction terms. We present numerical results for the cross-sections of $e^+e^-\to μ^+μ^-/u\bar{u}/d\bar{d}$ and differential distributions at representative center-of-mass energies. The NNLO corrections are found to modify the NLO cross-section on the order of 1%.

</details>
