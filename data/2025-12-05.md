<div id=toc></div>

# Table of Contents

- [gr-qc](#gr-qc) [Total: 27]
- [astro-ph.IM](#astro-ph.IM) [Total: 10]
- [hep-ph](#hep-ph) [Total: 25]
- [astro-ph.HE](#astro-ph.HE) [Total: 13]


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [1] [Cosmological Implications and Stability of $f\mathbb{(Q,T)}$ Gravity with Pilgrim Dark Energy Model](https://arxiv.org/abs/2512.04127)
*M. Sharif,Iqra Ibrar*

Main category: gr-qc

TL;DR: The paper proposes a pilgrim dark energy model within f(Q,T) gravity theory, using a non-interacting matter model and power-law scale factor. It successfully replicates cosmological epochs, derives key parameters like equation of state and stability, confirming observational data.


<details>
  <summary>Details</summary>
Motivation: To explore dark energy dynamics in modified gravity theories (f(Q,T)) and explain cosmic evolution phases without interaction between matter and dark energy.

Method: Constructed pilgrim dark energy framework in f(Q,T) gravity under non-interacting matter model. Derived equations of state, phase planes, and stability via squared speed of sound analysis using power-law scale factor.

Result: Model shows pilgrim dark energy parameter with increasing/decreasing trends. Equation of state enters phantom regime, stable via sound speed. Phase planes indicate freezing region (ω-ω' plane) and Chaplygin gas-like behavior (r-s plane). Matches observational data.

Conclusion: The f(Q,T) pilgrim dark energy model effectively describes cosmic evolution across epochs, supports phantom era dynamics, and aligns with current observations, offering a viable framework for understanding dark energy behavior.

Abstract: This manuscript endeavors to construct a pilgrim dark energy framework within the $f\mathbb{(Q,T)}$ gravity theory, employing a correspondence approach aligned with a non-interacting model that incorporates pressureless matter alongside a power-law scale factor. Here $\mathbb{Q}$ and $\mathbb{T}$ represent the non-metricity and trace of the energy-momentum tensor, respectively. This extended modified gravity framework accurately replicates various epochs in the cosmological history. The $f\mathbb{(Q,T)}$ gravity models are utilized to derive the equation of state parameter, phase planes and squared speed of sound. The analysis reveals that the reconstructed model exhibits an increasing or decreasing trend with the pilgrim dark energy parameter. The equation of state parameter characterizes the phantom regime, while the squared speed of sound parameter provides a stable framework for examining the ongoing cosmic evolution. The $ω_{DE}-ω'_{DE}$ plane trajectories reveal the freezing region, while the $r-s$ phase plane shows the Chaplygin gas model. It is important to highlight that our findings align with the most recent observational data.

</details>


### [2] [Proof the Spacetime Penrose Inequality](https://arxiv.org/abs/2512.04137)
*Da Xu*

Main category: gr-qc

TL;DR: The paper proves the Spacetime Penrose Inequality unconditionally, demonstrating that for asymptotically flat initial data sets with the Dominant Energy Condition, the ADM mass is bounded below by the square root of the trapped surface area over 16π, with equality only for Schwarzschild. The proof uses a novel combination of the generalized Jang equation and the p-harmonic level set method.


<details>
  <summary>Details</summary>
Motivation: To resolve Penrose's 1973 conjecture, a major open problem in mathematical relativity, by establishing the lower bound for ADM mass in line with the Cosmic Censorship hypothesis and geometrical considerations.

Method: Combines the generalized Jang equation with the p-harmonic level set method. Key steps include proving Fredholm solvability in weighted Sobolev spaces, validating Jang-conformal metrics with distributional curvature, verifying mean curvature jump positivity, and justifying double limits with explicit bounds.

Result: Unconditional proof of the Spacetime Penrose Inequality valid for any trapped surface, regardless of its stability or topology. Equality condition precisely characterizes the Schwarzschild spacetime.

Conclusion: This resolves the long-standing Penrose conjecture, advancing the understanding of mass inequalities in general relativity and the role of trapped surfaces in spacetime geometry.

Abstract: We prove the Spacetime Penrose Inequality: for any asymptotically flat initial data set satisfying the Dominant Energy Condition, the ADM mass is bounded below by the square root of the trapped surface area divided by 16 pi, with equality only for Schwarzschild. Unlike previous partial results, our proof is unconditional and holds for any trapped surface regardless of stability or topology.
  The proof combines the generalized Jang equation with the p-harmonic level set method. We establish Fredholm solvability in weighted Sobolev spaces, verify that Jang-conformal metrics with distributional curvature satisfy all required analytic hypotheses, prove mean curvature jump positivity for stable horizons, and justify the double limit with explicit bounds.
  This resolves Penrose's 1973 conjecture, a central open problem in mathematical relativity for over fifty years.

</details>


### [3] [Popcorn EMRIs: Transient Gravitational Wave Signals and Their Analysis in Schwartz Space](https://arxiv.org/abs/2512.04167)
*Pau Amaro Seoane,Kostas Tzanavaris*

Main category: gr-qc

TL;DR: The paper introduces 'popcorn EMRIs,' extreme-mass ratio inspirals with long orbital periods that produce transient gravitational wave bursts. Using a steady-state model and analytical methods, it estimates a burst rate of 5-44 per year in the Milky Way and establishes a mathematical framework for analyzing these signals.


<details>
  <summary>Details</summary>
Motivation: To study gravitational wave signals from EMRIs with orbital periods longer than observational timescales, understand their population in a Milky Way-like galaxy, and develop accurate analysis methods for their transient bursts.

Method: A steady-state analytical model based on the continuity equation in phase space, linked to the Fokker-Planck equation for stellar relaxation. The study uses a one-year observation baseline and employs standard smoothing techniques to define the Fourier transform of transient signals without windowing.

Result: Estimated observable burst rate of 5-44 events/year, confirmation of low duty cycle (~1e-4), high detectability of bursts from the Galactic Center, and a mathematically rigorous framework for transient signal analysis.

Conclusion: Popcorn EMRIs are viable transients for gravitational wave observatories, requiring specific analytical methods to preserve signal integrity. The developed framework validates direct Fourier transform usage and highlights the need for proper mathematical treatments in detecting these isolated events.

Abstract: We investigate extreme-mass ratio inspirals (EMRIs) with orbital periods exceeding the observational timescale of mHz gravitational wave observatories. In their early, highly eccentric phases, these systems generate transient gravitational wave bursts during pericentre passages, separated by long quiescent intervals; we designate these signals ``popcorn EMRIs.'' We utilize a steady-state analytical model based on the continuity equation in phase space to estimate the population in a Milky Way-like galaxy. The normalization of this model is linked to the solution of the Fokker-Planck equation describing stellar relaxation. Adopting a conservative one-year observation baseline ($P>1$ year), we estimate the steady-state population of popcorn EMRIs. We forecast an observable burst rate of 5 to 44 events per year. The low duty cycle ($\sim 10^{-4}$) confirms their manifestation as isolated transients. Individual bursts from the Galactic Centre exhibit high detectability. Analyzing these intrinsically transient signals demands a rigorous mathematical framework, as standard windowing techniques distort burst morphology. We establish an analytical foundation using standard smoothing techniques commonly used in real analysis. This yields the mathematically correct definition for the Fourier transform of transient signals, justifying the use of the direct Fourier transform without ad hoc windowing and ensuring the integrity of spectral analysis.

</details>


### [4] [Asymmetric excitation of left- vs right-handed photons in accelerating waveguides](https://arxiv.org/abs/2512.04188)
*Adrian del Rio*

Main category: gr-qc

TL;DR: The paper demonstrates that electromagnetic duality symmetry leads to a conserved polarization Q in classical settings, but when quantized under accelerated waveguide conditions, non-inertial observers detect a breaking of this symmetry through photon-pair excitations and spectral asymmetry between helicity modes, even in flat spacetime.


<details>
  <summary>Details</summary>
Motivation: To explore how classical electromagnetic duality symmetry behaves under quantization in non-inertial frames, specifically in accelerating waveguides, to reveal quantum effects that break classical conservation laws in flat spacetime.

Method: Quantum field theory analysis of Maxwell's equations in an accelerating cylindrical waveguide with duality-preserving boundaries. Calculating expectation values of the polarization operator Q for inertial vs. co-moving observers, considering frame-dragging effects.

Result: Non-conservation of ⟨Q⟩ for accelerated observers due to spectral asymmetry between right/left photons in vacuum. Photodetectors in rotating waveguides observe imbalanced helicity modes, proving quantum symmetry breaking in flat spacetime with non-inertial frames.

Conclusion: Classical duality symmetry's conservation fails in quantum theory under acceleration even without curved spacetime, offering a testable prediction in analogue gravity systems to validate relativistic quantum effects.

Abstract: The electromagnetic duality symmetry of Maxwell's equations in vacuum implies that the circular polarization $Q$ of classical electromagnetic waves is conserved. In quantum field theory, the normal-ordered operator $\hat Q$ represents the difference between the number operators of right- and left-handed photons. Previous studies have shown that its expectation value is not conserved for observers propagating in a gravitational field. Here, we show that this Noether symmetry can also be realized in empty waveguides with duality-preserving boundary conditions, and we quantize the source-free Maxwell theory inside a long, cylindrical waveguide undergoing both linear and rotational acceleration from rest. In the vacuum $|0\rangle$ associated to inertial observers, we find that the expectation value $\langle 0| \hat Q |0\rangle $ fails to be conserved for observers co-moving with the waveguide. In particular, frame-dragging effects induce a spectral asymmetry between the right- and left-handed field modes at late times. As a consequence, accelerated detectors co-moving with the rotating waveguide can detect photon-pair excitations from the quantum vacuum, exhibiting an imbalance between opposite helicity modes. This is a relativistic quantum effect, which shows that the classical conservation law associated with duality symmetry is broken in the quantum theory even in flat spacetime, provided we work with non-inertial systems. Our analysis provides a concrete proof of concept for testing this effect in analogue gravity platforms.

</details>


### [5] [Phase mixing and the Vlasov equation in cosmology](https://arxiv.org/abs/2512.04214)
*Martin Taylor,Renato Velozo Ruiz*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We consider the Vlasov equation on slowly expanding isotropic homogeneous tori, described by the Friedmann--Lemaître--Robertson--Walker cosmological spacetimes. For expansion rate $t^q$, with $0< q<\frac{1}{2}$ (excluding certain exceptional values), we show that the spatial density decays at the rate $t^{-6q}$ and that, when the spatial average is removed, the density decays at an enhanced rate due to a phase mixing effect. This enhancement is polynomial for Sobolev initial data and super-polynomial, but sub-exponential, for real analytic initial data. We further show that, when the expansion rate is the borderline $t^{\frac{1}{2}}$ -- the rate which describes a radiation filled universe -- a degenerate phase mixing effect results in a logarithmic enhancement for Sobolev initial data and a super-logarithmic enhancement (in fact, a gain of $\exp(-μ(\log t)^ε)$ for some $μ,ε>0$) for analytic initial data. The proof is based on a collection of commuting vector fields, and certain combinatorial properties of an associated collection of differential operators. The vector fields are not explicit, but are shown to have good properties when $t$ is large with respect to the momentum support of the solution. A physical space dyadic localisation is employed to treat non-compactly supported (in particular, non-trivial real analytic) but suitably decaying solutions.

</details>


### [6] [(Pre)-Inflationary Dynamics with Starobinsky Potential in Noncommutative Effective LQC](https://arxiv.org/abs/2512.04230)
*Luis Rey Díaz-Barrón,Abraham Espinoza-García,Sinuhé Pérez-Payán,José Socorro*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this work, we investigate the (pre)-inflationary dynamics of a flat, homogeneous, and isotropic universe governed by the Starobinsky potential within the framework of noncommutative effective loop quantum cosmology. The field equations are solved numerically for various initial conditions and different values of the noncommutative parameter. We analyze the background dynamics for three representative regimes -- the extreme kinetic-energy domination, kinetic-energy domination, and potential-energy domination. A complementary analysis is performed from the viewpoint of dynamical systems, highlighting the qualitative features of the scalar field evolution. Finally, a discussion comparing our results with previous studies employing the chaotic (quadratic) potential in the same formalism is presented.

</details>


### [7] [Spectral lines of dirty wormholes](https://arxiv.org/abs/2512.04274)
*Leonardo K. S. Furuta,Renan B. Magalhães,Haroldo C. D. Lima Junior,Luís C. B. Crispino*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Astrophysical objects like black holes are usually surrounded by matter in the form of accretion disks or jets of matter. These astrophysical scenarios are expected to introduce novel phenomenology in the scattering of particles and fields. Wormholes are viable candidates for exotic compact objects that can mimic some black hole properties. Hence, it is natural to wonder what would happen if the central astrophysical object were a wormhole, instead of a black hole. We investigate the astrophysical environment effect on the absorption of a massless scalar field by a dirty wormhole surrounded by a thick shell of matter. We study null geodesics around these dirty wormholes and analyze under which conditions new pairs of light rings can appear. The presence of new stable light rings allows new quasibound states in the spacetime, apart from the ones trapped near the throat. Thus, the astrophysical environment can introduce deviations in the absorption bands. Remarkably, although heavy and dense distributions of matter are considered surrounding the wormhole, the position of most of the spectral lines in the absorption bands is preserved, indicating that the astrophysical environment cannot hide some fingerprints of the central object.

</details>


### [8] [Cosmological implications of Bumblebee theory on an FLRW background](https://arxiv.org/abs/2512.04349)
*Manuel Gonzalez-Espinoza,Grigorios Panotopoulos,Francisco Tello-Ortiz*

Main category: gr-qc

TL;DR: The paper explores cosmological implications of the Bumblebee model at the background level. Utilizing dynamical system techniques, it analyzes phase-space, critical points, stability, and compares with supernovae data to determine the best-fit parameter. Graphical representations of deceleration parameter, dark energy equation of state, statefinders, and Universe age are provided, alongside a comparison with Λ-CDM model.


<details>
  <summary>Details</summary>
Motivation: To investigate the cosmological validity and behavior of the Bumblebee model by analyzing its dynamical properties and comparing it with observational data and the Λ-CDM model.

Method: Dynamical system analysis applied to the Bumblebee model's phase-space, critical point evaluation, parameter fitting using supernovae data, and graphical representation of cosmological quantities like deceleration parameter and statefinders.

Result: Determines the best-fit parameter value of the Bumblebee model, demonstrates its cosmological behavior through critical points stability analysis, and provides graphical comparisons with observational data and the Λ-CDM model.

Conclusion: The Bumblebee model effectively describes cosmological observations with its derived parameter, showing consistency with supernovae data and offering a viable alternative or complementary framework to the Λ-CDM model.

Abstract: We investigate some cosmological implications at background level of the Bumblebee model. The phase-space, the critical points and their stability are analyzed in detail applying well-established dynamical system techniques. What is more, upon comparison to available supernovae data, the best fit numerical value of the unique free parameter of the model is determined. We show graphically all the cosmological quantities of interest versus red-shift, such as the deceleration parameter, dark energy equation of state parameter, etc. The statefinders and the age of the Universe are also computed. Finally, a comparison to the $Λ$-CDM model is made as well.

</details>


### [9] [Linear stability of nonrelativistic Proca stars](https://arxiv.org/abs/2512.04376)
*Emmanuel Chávez Nambo,Galo Diaz-Andrade,Alberto Diez-Tejedor,Edgar Preciado-Govea,Armando A. Roque,Olivier Sarbach*

Main category: gr-qc

TL;DR: The paper investigates the linear stability of nonrelativistic Proca stars under general perturbations, finding the ground state and certain excited states to be mode-stable, with implications for spin-1 ultralight dark matter.


<details>
  <summary>Details</summary>
Motivation: To determine the stability of Proca star solutions under perturbations and explore their potential role in dark matter models.

Method: Combination of analytic techniques and numerical simulations to analyze stability through linear perturbation analysis.

Result: Confirmed mode-stability of the ground state and identified multiple mode-stable excited states, including different polarizations and multi-frequency states without spin-spin self-interaction.

Conclusion: The findings suggest that stable excited states of Proca stars could be viable candidates in spin-1 ultralight dark matter scenarios.

Abstract: We study the linear stability of nonrelativistic Proca stars under generic perturbations. Using a combination of analytic and numerical methods, we demonstrate that, as expected, the ground state is always mode-stable. Additionally, we identify several mode-stable spherically symmetric excited states, including stationary states of constant and radial polarization, as well as multi-frequency states in case that the spin-spin selfinteraction vanishes. The existence of stable excited states may have implications for spin-$1$ ultralight dark matter models.

</details>


### [10] [Hairy black holes via gravitational decoupling: light rings, absorption and spectral lines](https://arxiv.org/abs/2512.04377)
*Gabriel P. Ribeiro,Renan B. Magalhães,Luís C. B. Crispino*

Main category: gr-qc

TL;DR: The paper examines how massless scalar waves are absorbed by three types of hairy black holes created via gravitational decoupling, under different energy conditions. It finds that under the weak energy condition, quasibound states emerge, causing Breit-Wigner-like resonances linked to light rings—structures typically found in exotic compact objects like wormholes. The study shows how deformation parameters from the decoupling method affect these light rings and absorption spectra, with results matching established approximations.


<details>
  <summary>Details</summary>
Motivation: To understand the impact of gravitational decoupling on hairy black hole properties (absorption spectra and light rings) under various energy conditions, exploring connections between quasibound states and spacetime structures analogous to exotic objects.

Method: Numerical analysis of scalar wave absorption by three hairy black hole configurations derived via gravitational decoupling. The study calculates absorption spectra, identifies quasibound states under different energy conditions (weak, strong, dominant), and examines light ring formation linked to these states using deformation parameters.

Result: Quasibound states and Breit-Wigner resonances are observed in absorption spectra under weak energy conditions, correlated with novel light rings in hairy black holes. Gravitational decoupling parameters significantly shape these light rings and absorption profiles, with findings confirming theoretical approximations.

Conclusion: Gravitational decoupling introduces exotic spacetime features (light rings) in hairy black holes, bridging properties of black holes and horizonless objects. The method's parameters provide a versatile tool for studying absorption phenomena and energy condition effects on black hole dynamics.

Abstract: We investigate the absorption of massless scalar waves by three distinct hairy black hole solutions obtained through the gravitational decoupling method, considering the weak, the strong or the dominant energy conditions. Remarkably, in certain configurations of hairy black holes associated with the fulfillment of the weak energy condition, quasibound states may appear, resulting in Breit-Wigner-like resonances in their absorption profile. These quasibound states (and consequently the spectral lines in the absorption spectrum) can be related to stable light rings in the spacetime, a structure often associated with horizonless exotic compact objects, such as wormholes. We investigate how the gravitational decoupling method introduces novel light ring structures in hairy black holes and influences the absorption spectra through its deformation parameters. Our numerical results show excellent agreement with well-known approximations.

</details>


### [11] [On angular dependent response to gravitational-wave signals for time-delay interferometry combinations](https://arxiv.org/abs/2512.04473)
*Pan-Pan Wang,Hao-Kang Chen,Wei-Liang Qian,Rui Luo,Jing Zhou,Wei-Sheng Huang,Yu-Jie Tan,Cheng-Gang Shao*

Main category: gr-qc

TL;DR: This study examines the angular dependence of space-based gravitational wave detectors' sensitivity using TDI combinations, categorizing response functions into seven types at low frequencies and analyzing their zenithal dependence post-detection to improve GW source localization.


<details>
  <summary>Details</summary>
Motivation: The motivation is to optimize GW detection by tailoring TDI combinations to specific sources once their location is known, enhancing sensitivity beyond standard angle-averaged analyses.

Method: The method involves evaluating angular dependence of detector response functions for various TDI combinations, classifying these into seven categories at low frequencies, and averaging out the azimuthal angle to study zenithal dependence.

Result: Response functions were categorized into seven types; their zenithal dependences were analyzed, revealing how orientation affects sensitivity, enabling post-detection refinement of TDI for better source characterization.

Conclusion: The findings offer practical insights for space-borne detectors to improve localization and signal analysis by leveraging source-specific TDI combinations post-detection.

Abstract: Space-based gravitational wave (GW) detectors are designed for wave sources in the millihertz band with different locations and orientations.
  Time-delay interferometry (TDI) technique is an indispensable ingredient in space-borne GW detection that effectively suppresses the laser phase noise.
  The abundant TDI solutions derived in the literature also feature distinct angular-dependent sensitivities.
  Because a GW source's angular location is unknown prior to the signals' detection, a solid-angle average is often performed when analyzing the sensitivity function of a given TDI combination.
  The present study explores the angular dependence of the detector's sensitivity.
  This detail is relevant, because once the initial detection is achieved, the source's location can be extracted and used to provide information on a refined TDI combination tailored for the specific GW source.
  As the TDI technique is a post-processing algorithm, such a procedure can be implemented in practice.
  We evaluate the angular dependence of the detector's response function to the GW signals for different TDI combinations as a function of the orientation angles.
  Moreover, we classify the response functions into seven categories at the low-frequency limit, leveraging the characteristics of the underlying geometrical TDI combinations.
  By further averaging out the azimuthal angle $φ_D$ in the detector's plane, the main features of the resulting response functions and their zenithal dependence with respect to the GW source are scrutinized.
  The findings presented in this work provide pertinent insights for ongoing space-borne detector programs.

</details>


### [12] [Thermodynamic geometric analysis of D-dimensional RN black hole](https://arxiv.org/abs/2512.04478)
*Wen-Xiang Chen*

Main category: gr-qc

TL;DR: The study explores the thermodynamics and Ruppeiner geometry of D-dimensional RN black holes, showing that in canonical ensembles, the curvature scalar diverges at critical points for phase transitions when D > 4. In grand-canonical ensembles, the geometry becomes flat, with a connection to Euclidean path integrals via inverse temperature.


<details>
  <summary>Details</summary>
Motivation: To investigate how thermodynamic curvature (Ruppeiner geometry) relates to phase transitions in higher-dimensional RN black holes across different ensembles and to establish a link with Euclidean quantum gravity methods.

Method: Analysis of Ruppeiner curvature scalar in fixed-charge (canonical) and variable-charge (grand-canonical) ensembles for D-dimensional RN black holes. Comparison of thermodynamic metrics with Euclidean path integral periodicity.

Result: In canonical ensembles, R diverges at critical points for D > 4, signaling phase transitions. Grand-canonical ensembles yield flat Ruppeiner geometry. The inverse temperature bridges thermodynamic geometry and Euclidean action approach.

Conclusion: Ruppeiner geometry captures phase transition features only in specific ensembles (canonical), while its flatness in others (grand-canonical) reflects different thermodynamic behaviors. The Euclidean time period's role emphasizes geometric-thermodynamic interplay in quantum gravity contexts.

Abstract: This paper studies the thermodynamics and Ruppeiner geometry of D-dimensional RN black holes. We analyze the thermodynamic curvature scalar $R$ in various thermodynamic ensembles. It is found that in an ensemble of fixed charge (canonical ensemble), the Ruppeiner curvature is curved and diverges at a critical point, indicating the existence of a phase transition for $D > 4$. In contrast, when all extensive variables are allowed to fluctuate (for example, in a grand-canonical ensemble or with pressure fixed), the Ruppeiner geometry can appear flat. We also demonstrate that the thermodynamic geometric metric has a one-to-one correspondence with the periodicity of the Euclidean path integral method. In particular, the inverse temperature (the Euclidean time period) serves as a bridge connecting the thermodynamic geometry and the Euclidean action approach.

</details>


### [13] [General SIGW source for reheating dynamics](https://arxiv.org/abs/2512.04482)
*M. Laine,S. Procacci*

Main category: gr-qc

TL;DR: The paper derives a source term for scalar-induced gravitational waves during reheating, allowing the energy component to transition smoothly from inflaton to radiation, with gauge invariance verified up to second order.


<details>
  <summary>Details</summary>
Motivation: To accurately model gravitational wave production during reheating phases in cosmology where energy dominance shifts from inflaton field to radiation, ensuring gauge invariance to avoid unphysical results.

Method: Derive scalar-induced gravitational wave source terms in an arbitrary gauge, considering smooth energy transitions through reheating epochs. Validate gauge invariance at the second-order perturbation level.

Result: A general source term for SIGW applicable during reheating, accommodating transitions through possible matter domination periods, with confirmed gauge invariance up to second order.

Conclusion: The derived framework provides robust calculations of SIGW spectra in diverse post-inflationary scenarios, enhancing precision in early universe cosmology studies involving gravitational wave signals.

Abstract: Working in an arbitrary gauge, we derive the source term for scalar-induced gravitational waves (SIGW) valid during a general reheating epoch. Specifically, the dominant energy component is allowed to transition smoothly from an inflaton field to a radiation fluid, possibly via a period of matter domination. Gauge invariance is verified up to second order.

</details>


### [14] [Searching for binary black hole mergers with deep learning in Advanced LIGO's third observing run](https://arxiv.org/abs/2512.04516)
*Damon Beveridge,Alistair McLeod,Linqing Wen,Weichangfeng Guo,Andreas Wicenec*

Main category: gr-qc

TL;DR: The paper presents a hybrid search pipeline combining matched filtering and deep learning to detect gravitational waves from compact binary coalescences, demonstrating comparable sensitivity for high chirp mass signals and identifying new candidates, including one potential intermediate-mass black hole system.


<details>
  <summary>Details</summary>
Motivation: To improve gravitational wave detection by combining traditional methods (matched filtering) with deep learning, addressing limitations in sensitivity for lower chirp mass signals and expanding the population of identified candidates.

Method: A hybrid pipeline first applies matched filtering to identify candidates, followed by deep learning to enhance detection. Targeted injection studies benchmark its performance, and an offline search of LVK's third observing run data was conducted.

Result: The hybrid method matches existing pipelines for signals with chirp mass >25 M⊙ but underperforms below this threshold at lower network SNR. It recovered 31 known LVK candidates and found two new ones, including one with a probable intermediate-mass black hole.

Conclusion: The hybrid approach is effective for high-mass systems and identifies unique candidates, suggesting value in combining traditional/ML methods for gravitational wave astronomy. Further optimization is needed for lower mass signals.

Abstract: The detection of gravitational waves from compact binary coalescences has provided significant insights into our Universe, and the discovery of new and unique gravitational wave candidates from independent searches remains an ongoing field of research. In this work, we built a hybrid search pipeline that combines matched filtering and deep learning to identify stellar-mass binary black hole candidates from detector strain data. We first present results from a targeted injection study to benchmark the sensitivity of our method and compare it with existing search pipelines. We demonstrate that our hybrid approach has comparable sensitivity for injections with a source-frame chirp mass greater than 25$\,$M$_{\odot}$, and below this threshold our sensitivity drops off for signals with a network SNR less than 15. We also observe that our search method can identify a significant population of unique candidates. Furthermore, we conduct an offline search for gravitational wave candidates in the third observing run of the LIGO-Virgo-KAGRA Collaboration (LVK), yielding 31 candidates previously reported by the LVK with a probability of astrophysical origin $p_{\rm astro}\geq0.5$. We identify two other candidates: one previously reported only in a search conducted by the Institute for Advanced Study, and one previously unreported promising new candidate with a $p_{\rm astro}$ of 0.63. This unique candidate has a high chirp mass and a high probability that the primary black hole is an intermediate-mass black hole.

</details>


### [15] [From Source Properties to Strong-Field Tests: a multipronged analysis of GW250114 with an effective one-body model for generic orbits](https://arxiv.org/abs/2512.04593)
*Koustav Chandra,Rossella Gamba,Danilo Chiaramello*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a detailed analysis of GW250114, the loudest gravitational-wave signal observed to date, using a waveform model capable of describing binary black holes in generic (eccentric and precessing) orbits. Our analysis builds on LIGO-Virgo-KAGRA (LVK)'s results, finding that the source is consistent at a probability of $\geq 96\%$ with the merger of two first-generation, nearly equal-mass, low-spin black holes, forming a remnant within the pair-instability mass gap. The signal's high signal-to-noise ratio ($\gtrsim 75$) enables the detection of the subdominant $(4,\pm4)$ multipoles, whose presence we confirm with higher evidence than previously reported by the LVK. Restricting the analysis even to post-peak data yields $\log_{10}B\gtrsim 1$ in favor of models including the $(4,\pm4)$ mode, demonstrating that this contribution remains detectable well into the post-merger phase. We further perform three independent tests of general relativity, complementary to those performed by the LVK: a modified residual analysis confirms that our semi-analytical model fully describes the signal without detectable discrepancies; a subdominant mode test finds that the amplitude of the $(4,\pm4)$ multipoles agrees with general-relativistic expectations; and a parameterised analysis of the plunge-merger-ringdown regime recovers the GR expectation within the 50\% credible region for the remnant mass and spin, and within the 90\% interval for the $(2,\pm2)$ peak amplitude. Collectively, these results reinforce GW250114 as a landmark event for a precision test of gravity.

</details>


### [16] [Charged Regular Black Holes From Quasi-topological Gravities in $D\ge 5$](https://arxiv.org/abs/2512.04604)
*Chen-Hao Hao,Jiliang Jing,Jieci Wang*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The investigation of gravity in higher-dimensional spacetime has transitioned from a mathematical curiosity to a fundamental framework in theoretical physics, catalyzed by the dimensional requirements of String theory and M-theory. In this paper, we explicitly construct a spherically symmetric charged black hole solution in $D \ge 5$ dimensions within a gravity theory featuring an infinite tower of higher-curvature corrections. For a given mass and electric charge, the model admits a unique static spherically symmetric solution. We demonstrate that, with an appropriate choice of coupling coefficients $α_n$, the central singularity is progressively mitigated as the correction order increases, ultimately resolving into a globally regular spacetime in the limit of infinite-order corrections. Furthermore, the criteria for the existence of extremal black holes are determined.

</details>


### [17] [Mode interactions in scalar field cosmology](https://arxiv.org/abs/2512.04607)
*Spiros Cotsakis,Ignatios Antoniadis*

Main category: gr-qc

TL;DR: The paper analyzes the dynamics of spatially homogeneous universes near the massless transition s=1, where the Einstein-scalar system has a codimension-two Hopf-steady-state organizing centre. The study reveals that slow-roll parameters and cosmological observables emerge universally from the unfolding variables, offering a potential-independent mechanism for early inflation.


<details>
  <summary>Details</summary>
Motivation: To understand the universal properties of inflationary dynamics near the quadratic model and provide a framework independent of specific scalar field potentials, explaining the near scale-invariance of primordial perturbations.

Method: Reduction to the centre manifold capturing two slow geometric modes (Hopf amplitude r and Hubble mode z). Derived relationships between unfolding parameters (μ₁, μ₂) and cosmological observables (spectral tilt, tensor-to-scalar ratio) through geometric unfolding of the organizing centre.

Result: Showed that slow-roll parameters ε and η directly arise from r² and z. Demonstrated that key cosmological observables are universal functions of (r,z), independent of potential choice. Classified perturbations via μ parameters as tilt/curvature deformations of potentials.

Conclusion: Near scale-invariance of primordial perturbations is a structural feature of the system's organizing centre, providing a potential-independent mechanism for slow-roll inflation. This geometric framework unifies classification of inflationary models.

Abstract: We study the dynamics of spatially homogeneous Friedmann--Robertson--Walker universes filled with a massive scalar field in a neighbourhood of the massless transition $s=1$. At this point the Einstein--scalar system exhibits a codimension--two Hopf--steady--state organising centre whose versal unfolding describes all small deformations of the quadratic model. After reduction to the centre manifold, the dynamics is governed by two slow geometric modes $(r,z)$: the Hopf amplitude $r$, measuring the kinetic departure from de Sitter, and the slowly drifting Hubble mode $z$. We show that the standard slow--roll parameters follow directly from these unfolding variables, $ε\sim\tfrac32 r^{2}$ and $η\sim z$, so that the spectral tilt, tensor--to--scalar ratio, and scalar amplitude arise as universal functions of $(r,z)$, independently of the choice of potential. The two unfolding parameters $(μ_{1},μ_{2})$ classify all perturbations of the quadratic model and can be interpreted physically as controlling the tilt and curvature deformations of generic polynomial inflationary potentials. Thus the near scale--invariance of primordial perturbations emerges as a structural property of the unfolding of the organising centre, providing a potential--independent mechanism for an early phase of accelerated expansion. We discuss the implications of this geometric framework for the interpretation and classification of inflationary models.

</details>


### [18] [Inspiraling binary charged black holes in an external magnetic field: Application of post-Newtonian dynamics in Einstein-Maxwell theory](https://arxiv.org/abs/2512.04806)
*RunDong Tang,Lang Liu,Wen-Biao Han*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a systematic post-Newtonian treatment of binary charged black holes immersed in external magnetic fields within the framework of Einstein-Maxwell theory. By incorporating a uniform external magnetic field into the two-body Lagrangian expanded to first post-Newtonian order, we derive the complete equations of motion that capture both gravitational and electromagnetic interactions. The magnetic Lorentz force fundamentally alters the orbital dynamics, breaking the conservation of linear and angular momentum and inducing transitions from planar to three-dimensional trajectories. Through numerical integration of these equations, we compute the resulting gravitational waveforms and quantify the magnetic field imprints using matched filtering techniques. Our results demonstrate that strong background magnetic fields can substantially modify the orbital evolution and leave distinctive signatures in the gravitational wave signals. These findings provide a promising avenue for detecting charged black holes and probing magnetic field environments through gravitational wave observations.

</details>


### [19] [Detecting relativistic black hole collisions near a massive black hole](https://arxiv.org/abs/2512.04851)
*Yirong Fang,Changfu Shi,Jianwei Mei*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Relativistic black hole collisions are one of the most dramatic astrophysical events that can be imagined. They could provide the ideal condition for searching for possible new physics beyond general relativity. However, such events are presumably rare and difficult to occur under normal conditions. Black holes in a triple system can be accelerated to the relativistic limit and may harbor the chance for a relativistic collision. In this paper, we study the relativistic black hole collisions in a massive black hole background and the capabilities of several current and future gravitational wave detectors in detecting such signals.

</details>


### [20] [Extreme-Mass-Ratio Inspirals Embedded in Dark Matter Halo II: Chaotic Imprints in Gravitational Waves](https://arxiv.org/abs/2512.04848)
*Surajit Das,Surojit Dalui,Bum-Hoon Lee,Yi-Fu Cai*

Main category: gr-qc

TL;DR: The paper examines how chaos in extreme-mass-ratio inspirals affects gravitational wave signatures, showing that chaotic orbits produce broader frequency spectra and enhanced signal characteristics, which could be detectable by future observatories like LISA.


<details>
  <summary>Details</summary>
Motivation: To probe chaotic dynamics in black hole environments and dark matter halos by analyzing gravitational wave imprints, potentially opening new avenues for understanding these systems through upcoming detectors.

Method: Using numerical kludge simulations to generate gravitational waveforms from chaotic and non-chaotic orbits in a Schwarzschild black hole with a Dehnen dark matter halo. Spectral analysis and recurrence analysis were applied to differentiate signal features.

Result: Chaotic systems exhibit broader frequency spectra, higher amplitude and energy emission, and unique time series patterns in gravitational waves compared to non-chaotic systems. These differences are detectable and informative about underlying dynamics.

Conclusion: Chaos in extreme-mass-ratio inspirals leaves detectable gravitational wave signatures, offering a new method to study black hole dynamics and dark matter distributions in galactic nuclei with future space-based observatories.

Abstract: We investigate the imprints of chaos in gravitational waves from extreme-mass-ratio inspirals configuration, where a stellar massive object, confined in a harmonic potential, orbits a supermassive Schwarzschild-like black hole embedded in a Dehnen-type dark matter halo. In our first paper [1], we demonstrated the system's transition from non-chaotic to chaotic dynamics by analyzing Poincaré sections, orbital evolution, and Lyapunov exponents across different energies and dark matter halo parameters. In this work, we compute the gravitational waveforms of the small celestial object along different chaotic and non-chaotic orbits by implementing the numerical kludge scheme. We further perform a spectral analysis of the gravitational waveforms from such orbits. In particular, we show that when the system is in a chaotic state, the gravitational wave signals are characterized by broader frequency spectra with finite widths, enhanced amplitude and energy emission rate, distinctly differentiating them from the signals generated during the system's non-chaotic state. Through recurrence analysis we also show that the time series of gravitational waveforms strain carry unique information on the motion of chaotic dynamics, which can be used to distinctly differentiate from non-chaotic to chaotic motion of the source. Furthermore, we discuss the potential detectability of these orbits for upcoming observatories like LISA, TianQin, and Taiji, emphasizing the significant potential for detecting chaotic imprints in gravitational waves to substantially enhance our understanding of chaotic dynamics in black hole physics and the dark matter environments of galactic nuclei.

</details>


### [21] [Constraints on Genesis Cosmology from the Smeared Null Energy Condition](https://arxiv.org/abs/2512.04934)
*Dong-Hui Yu,Mian Zhu,Yong Cai*

Main category: gr-qc

TL;DR: This paper investigates how the smeared null energy condition (SNEC) impacts Genesis cosmology models, showing that SNEC imposes significant constraints on their viability and serves as a critical tool for evaluating nonsingular cosmological scenarios.


<details>
  <summary>Details</summary>
Motivation: To address theoretical issues with NEC violation in nonsingular cosmologies like Genesis, which avoids the Big Bang singularity, and to assess the role of the SNEC as a quantum-motivated constraint on NEC violation.

Method: Analysis of Genesis models within generalized Galileon theories under the SNEC framework, examining whether these models satisfy the SNEC constraints.

Result: SNEC imposes nontrivial restrictions on Genesis models, limiting their viability and demonstrating the conjecture's effectiveness in constraining nonsingular cosmologies.

Conclusion: The SNEC is a powerful tool for testing and constraining nonsingular cosmological models, emphasizing the need for careful consideration of quantum-motivated energy conditions in theoretical cosmology.

Abstract: The violation of the null energy condition (NEC) is essential for constructing nonsingular cosmological scenarios, such as Genesis cosmology, which avoids the initial singularity by initiating cosmic evolution from an asymptotically Minkowski state. To address theoretical concerns regarding the accumulation of negative energy, the smeared null energy condition (SNEC) has been proposed as a quantum-motivated, semi-local bound on NEC violation. In this work, we examine the implications of the SNEC conjecture for Genesis models, typically constructed within generalized Galileon theories. Our results demonstrate that SNEC imposes nontrivial restrictions on the viability of Genesis models, highlighting the SNEC conjecture as a powerful tool for constraining nonsingular cosmological scenarios.

</details>


### [22] [Multipole decomposition of the gravitational field of a point mass at the black hole horizon](https://arxiv.org/abs/2512.04976)
*João P. B. Brito,Atsushi Higuchi,Luís C. B. Crispino*

Main category: gr-qc

TL;DR: The paper demonstrates that the divergent gravitational energy absorbed by a black hole during radial infall of a point mass originates from the static field's infinite energy near the particle, which flows into the black hole upon horizon crossing. This resolves the divergence by decomposing the gravitational field into multipoles and applying field-theoretical methods.


<details>
  <summary>Details</summary>
Motivation: Investigate the origin of the divergent gravitational energy absorption in perturbation theory, specifically addressing the discrepancy caused by the point-particle model's limitations.

Method: Performed multipole decomposition of the linearized gravitational field near the black hole horizon, analyzing the contribution of each multipole. Applied a field-theoretical approach to compute energy contributions from the particle's field.

Result: Confirmed that the divergent energy arises from the infinite static field energy near the point mass, which consistently matches the constant multipole contributions observed.

Conclusion: The divergence is an artifact of the point-particle model's singularities, not a physical phenomenon. The analysis provides a framework to resolve such divergences using multipole decomposition and field theory methods.

Abstract: The portion of the gravitational energy absorbed by the black hole due to the radial infall of a point mass is known to diverge at leading order in perturbation theory. This divergence is an artifact of the point-particle model, where the contribution of each multipole to the total absorbed energy is observed to be roughly constant. We show explicitly that this divergent energy arises from the infinite energy present in the singular static field arbitrarily close to the point mass, which also flows into the black hole when the particle trajectory crosses the horizon. We perform a multipole decomposition of the linearized gravitational field generated by the point mass near its world line at the black hole horizon. By applying the standard field-theoretical approach to the particle field, we compute the corresponding partial energy and find that it matches the constant multipole contribution.

</details>


### [23] [On the treatment of thermal effects in the equation of state on neutron star merger remnants](https://arxiv.org/abs/2512.05118)
*Davide Guerra,Milton Ruiz,Michele Pasquali,Pablo Cerdá-Durán,Arnau Rios,José A. Font*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present results from long-term, numerical-relativity simulations of binary neutron star mergers modeled using both, fully tabulated, finite-temperature, equations of state and their corresponding hybrid representations. The simulations extend up to 150 ms which allows us to assess the role of the treatment of finite-temperature effects on the dynamics of the hypermassive neutron star remnant. Our study focuses on the analysis of the spectra of the post-merger gravitational-wave signals and on how these are affected by the treatment of thermal effects in the two EOS representations. Our simulations highlight distinct differences in the GW frequency evolution related to the thermal modeling of the EOS, demonstrating that deviations from established quasi-universal relations become significant at late post-merger phases. Furthermore, we investigate the stability of the HMNS against convection. Employing both the Ledoux criterion, necessary condition for the development of convective instabilities, and the Solberg-Høiland criterion, a generalized criterion for axisymmetric perturbations based on a combined analysis of the Brunt-Väisälä frequency and of the epicyclic frequency, we show that differential rotation and thermal stratification in the HMNS give rise to local (yet sustained) convective patterns that persist beyond 100 ms after merger. Those convective patterns, while substantially different between tabulated and hybrid EOS treatments, trigger the the excitation of inertial modes with frequencies smaller than those attained by the fundamental quadrupolar mode, and are potentially within reach of third-generation GW detectors. The late-time excitation of inertial modes, previously reported in studies based on hybrid EOS, is fully supported by the tabulated, finite-temperature EOS simulations presented here, which account for thermal effects in a more consistent way.

</details>


### [24] [Thermodynamics vs Teleodynamics: A Cosmological Divide?](https://arxiv.org/abs/2512.04977)
*Oem Trivedi,Venkat Venkatasubramanian*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We show that stationary black holes and the evolving universe belong to fundamentally different thermodynamic regimes: black holes obey ordinary Bekenstein Hawking thermodynamics, whereas cosmology necessarily follows memory-bearing teleodynamics. We show that teleodynamics is not valid for black holes, but is unavoidable in an expanding cosmology. This provides a dynamical, semi-classical realization of the thermodynamic split conjecture and identifies memory accumulation as the natural source of deviations from the area law in cosmology. Our results suggest that quantum gravity should not seek to extrapolate black hole thermodynamics to the universe, but instead must incorporate horizon memory as a fundamental microscopic ingredient and consider cosmological constructions consistent with that.

</details>


### [25] [Schwarzschild Black Hole Turbulence: Scalar Probe](https://arxiv.org/abs/2512.05003)
*Alex Kehagias,Antonio Riotto*

Main category: gr-qc

TL;DR: The paper examines how energy redistributes between scalar modes of a Schwarzschild black hole perturbation, leading to turbulent-like cascades using an averaging method. It identifies the dominant difference-frequency mixing mechanism in high multipole scenarios, mapping instability regions and explaining energy transfer in ringdowns.


<details>
  <summary>Details</summary>
Motivation: To understand energy redistribution in black hole perturbations and identify conditions under which turbulent behaviors can emerge through linear probes on weakly perturbed backgrounds.

Method: Employs the van der Pol-Krylov-Bogoliubov averaging method to derive coupled mode equations, analyzing near-resonant interactions between multipoles. Compares two instability routes: difference-frequency mixing and Mathieu self-modulation.

Result: Shows that at high multipole numbers, difference-frequency mixing dominates, creating a unidirectional cascade from high to low frequencies. Maps the instability regions' detuning dependence quantitatively.

Conclusion: Establishes a framework explaining energy transfer mechanisms in black hole ringdowns, clarifying when turbulent signatures arise in linear regimes of weak perturbations.

Abstract: We explore how perturbations of a Schwarzschild black hole can redistribute energy among scalar modes and seed turbulent like cascades. We make use of the van der Pol-Krylov-Bogoliubov averaging method and derive coupled mode equations that describe near-resonant interactions between neighbouring multipoles. We compare two routes to instability, namely the difference-frequency mixing between adjacent modes and the diagonal (Mathieu) self-modulation channel. We show that, at high multipole number (eikonal limit), the difference-frequency route dominates and drives a one-way cascade from higher to lower frequencies. We chart the corresponding instability regions ("tongues") and quantify their detuning dependence. The framework provides a simple, quantitative mechanism for energy transfer in black hole ringdowns and clarifies when and how turbulent signatures can arise within linear probes on a weakly perturbed background.

</details>


### [26] [Emergence of ER=EPR from non-local gravitational energy](https://arxiv.org/abs/2512.05022)
*Kimet Jusufi,Francisco S. N. Lobo,Emmanuel N. Saridakis,Douglas Singleton*

Main category: gr-qc

TL;DR: The paper proposes a novel class of wormhole geometries derived from non-local gravitational self-energy, which regularizes spacetime's particle and black-hole sectors. These wormholes emerge from entangled particles or particle-black-hole pairs under T-duality-inspired frameworks, avoiding exotic matter by using quantum-gravity effects to violate the strong energy condition. Only zero-throat geometries meet ER=EPR's non-traversability and no macroscopic throat criteria, offering a regular spacetime realization of entanglement-induced Einstein-Rosen bridges. Implications for ER networks, Hawking radiation via replica wormholes, and entanglement-driven dark energy are explored.


<details>
  <summary>Details</summary>
Motivation: To address the need for exotic matter in traditional wormhole models and to provide a quantum-gravity framework that realizes the ER=EPR conjecture without ad hoc assumptions, ensuring spacetime regularity in both particle and black-hole sectors.

Method: Constructing wormhole geometries using non-local gravitational self-energy inspired by T-duality, analyzing their Einstein-Rosen-type structures, classifying them based on horizons and throats, and applying ER=EPR constraints (non-traversability, no macroscopic throat).

Result: Demonstrates that entanglement-induced Einstein-Rosen bridges can arise from quantum-gravity effects without exotic matter, with only zero-throat geometries fulfilling ER=EPR requirements. Identifies exotic energy at minimal surfaces and discusses implications for ER networks, Hawking radiation interpretations, and dark energy scenarios.

Conclusion: ER=EPR can be concretely realized in regular spacetime through entanglement-driven wormholes without exotic matter, advancing quantum gravity's interface with spacetime geometry and motivating further studies on entanglement's role in cosmological phenomena.

Abstract: We construct a class of wormhole geometries supported by the non-local gravitational self-energy that regularizes the particle and black-hole sectors of spacetime. Using this framework, inspired by T-duality, we show that two entangled particles (or particle-black-hole pairs) naturally source an Einstein-Rosen-type geometry in which the required violation of the strong energy condition arises from intrinsic quantum-gravity effects rather than from ad hoc exotic matter, which is matter that violates the null energy condition. We classify the resulting wormholes, analyze their horizons, throat structure and embedding properties, and we identify the exotic energy needed at the minimal surface. Imposing the ER=EPR requirement of non-traversability and the absence of a macroscopic throat, we find that only the zero-throat geometry is compatible with an entanglement-induced Einstein-Rosen bridge, providing a concrete realization of ER=EPR within a fully regular spacetime. Finally, we briefly discuss possible implications for microscopic ER networks from vacuum fluctuations, replica-wormhole interpretations of Hawking radiation, and possible links to entanglement-driven dark-energy scenarios.

</details>


### [27] [Effective delta sources and Newtonian limit in nonlocal gravity](https://arxiv.org/abs/2512.05061)
*Thomas M. Sangy,Nicolò Burzillà,Breno L. Giacchini,Tibério de Paula Netto*

Main category: gr-qc

TL;DR: The paper examines the Newtonian limit of nonlocal gravity models with exponential form factors, focusing on weak-field solutions, showing oscillations in the Newtonian potential for N_s > 1 and confirming regularity of solutions.


<details>
  <summary>Details</summary>
Motivation: To compare different nonlocal gravity models within the same family by analyzing their weak-field behaviors using effective source formalism, with potential applications in quantum corrections.

Method: Utilizes effective source formalism to derive delta sources, mass functions, and Newtonian potentials through series, integrals, and special functions, while validating parameters N_s and μ_s. Includes analysis of quantum corrections.

Result: Derived various representations of key quantities, showed oscillations in Newtonian potential only when N_s > 1, proved positive effective masses despite oscillations, confirmed solution regularity, and calculated leading quantum corrections.

Conclusion: Nonlocal gravity models exhibit distinct weak-field features based on N_s and μ_s parameters; results are applicable beyond gravity models in quantum-corrected weak-field scenarios.

Abstract: We investigate the Newtonian limit of a class of nonlocal gravity models with exponential form factors $f_s (\Box) = \exp [(-\Box/μ_s^2)^{N_s}]$. Our main goal is to identify similarities and differences between models in this family in regard to weak-field solutions. To this end, we use the effective source formalism to compare the related effective delta sources, mass functions, and Newtonian potentials. We obtain a variety of representations for these quantities in terms of series, integrals, and special functions, as well as simple approximations that capture the relevant dependence on the parameters $N_s$ and $μ_s$ - which can be used to explore the weak-field phenomenology of nonlocal gravity. We explain why only for $N_s>1$ the Newtonian potential oscillates and prove that, despite the oscillations, the effective masses are positive. Moreover, we verify that these linearized solutions are regular (without curvature singularities). Finally, we also calculate the form of the leading logarithmic quantum correction to the Newtonian potential in these models. In all our considerations, we assume that $N_s$ is a positive real parameter. The cases of non-integer $N_s$ might be applied beyond nonlocal gravity, in effective approaches to implement quantum corrections in the weak field regime.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [28] [Minuet: A Diffusion Autoencoder for Compact Semantic Compression of Multi-Band Galaxy Images](https://arxiv.org/abs/2512.04145)
*Alexander T. Gagliano,Yunyi Shen,V. A. Villar*

Main category: astro-ph.IM

TL;DR: Minuet is a low-dimensional diffusion autoencoder designed to process multi-band galaxy images from the Vera C. Rubin Observatory's Legacy Survey, achieving semantic latent representations with only five dimensions while maintaining high-fidelity reconstructions. It enables efficient analysis for galaxy evolution studies and transient host characterization.


<details>
  <summary>Details</summary>
Motivation: The large dataset from the Rubin Observatory poses challenges in interpretability due to high-dimensional latent spaces from existing models. Minuet addresses this by reducing dimensions to five, facilitating mechanistic understanding and diverse scientific applications.

Method: Minuet combines a transformer-based autoencoder with a diffusion model for image reconstruction. It is trained on 6M galaxies' $grz$ band images (72x72 pixels) with $z<1$, producing semantically meaningful five-dimensional latent embeddings. Classifiers and a conditional flow are applied to these latent features for morphological analysis and posterior estimation of astrophysical parameters.

Result: Achieves high-fidelity image reconstructions with five latent dimensions, demonstrates strong correlations between latent features and Galaxy Zoo morphological labels, and enables effective posterior estimation for redshifts, stellar masses, and star-formation rates. Also shows utility in nearest neighbor searches.

Conclusion: Minuet proves the intrinsic low dimensionality of galaxy imaging data and offers a versatile model for compact representations in astrophysics, supporting multiple science goals like galaxy evolution and transient studies efficiently.

Abstract: The Vera C. Rubin Observatory is slated to observe nearly 20 billion galaxies during its decade-long Legacy Survey of Space and Time. The rich imaging data it collects will be an invaluable resource for probing galaxy evolution across cosmic time, characterizing the host galaxies of transient phenomena, and identifying novel populations of anomalous systems. While machine learning models have shown promise for extracting galaxy features from multi-band astronomical imaging, the large dimensionality of the learned latent space presents a challenge for mechanistic interpretability studies. In this work, we present Minuet, a low-dimensional diffusion autoencoder for multi-band galaxy imaging. Minuet is trained to reconstruct 72x72-pixel $grz$ image cutouts of 6M galaxies within $z<1$ from the Dark Energy Camera Legacy Survey using only five latent dimensions. By using a diffusion model conditioned on the transformer-based autoencoder's output for image reconstruction, we achieve semantically-meaningful latent representations of galaxy images while still allowing for high-fidelity, probabilistic reconstructions. We train a series of binary classifiers on Minuet's latent features to quantify their connection to morphological labels from Galaxy Zoo, and a conditional flow to produce posterior distributions of SED-derived redshifts, stellar masses, and star-formation rates. We further show the value of Minuet for nearest neighbor searches in the learned latent space. Minuet provides strong evidence for the low intrinsic dimensionality of galaxy imaging, and introduces a class of astrophysical models that produce highly compact representations for diverse science goals.

</details>


### [29] [Machine Phenomenology: A Simple Equation Classifying Fast Radio Bursts](https://arxiv.org/abs/2512.04204)
*Yang Liu,Yuhao Lu,Rahim Moradi,Bo Yang,Bing Zhang,Wenbin Lin,Yu Wang*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This work shows how human physical reasoning can guide machine-driven symbolic regression toward discovering empirical laws from observations. As an example, we derive a simple equation that classifies fast radio bursts (FRBs) into two distinct Gaussian distributions, indicating the existence of two physical classes. This human-AI workflow integrates feature selection, dimensional analysis, and symbolic regression: deep learning first analyzes CHIME Catalog 1 and identifies six independent parameters that collectively provide a complete description of FRBs; guided by Buckingham-$π$ analysis and correlation analysis, humans then construct dimensionless groups; finally, symbolic regression performed by the machine discovers the governing equation. When applied to the newer CHIME Catalog, the equation produces consistent results, demonstrating that it captures the underlying physics. This framework is applicable to a broad range of scientific domains.

</details>


### [30] [LEBS Toolkit for Addressing Development Challenges through Astronomy](https://arxiv.org/abs/2512.04224)
*Joyful E. Mdhluli*

Main category: astro-ph.IM

TL;DR: The LEBS Toolkit offers a framework for astronomers and scientists to contribute to the Sustainable Development Goals by enhancing communication between science and development, with four key components addressing leadership, externalities, barriers, and market institutions.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between scientific knowledge and practical development actions, ensuring that astronomy and scientific research contribute effectively to global development goals through structured guidance.

Method: The toolkit's framework is structured around four pillars—Leadership, Externalities, Break Barriers to Entry, and Support Functioning Markets & Institutions (LEBS). Each component provides actionable strategies for scientists to engage in development initiatives, such as fostering leadership, managing externalities, reducing entry barriers, and improving market efficiency.

Result: scientists can better disseminate accurate information, encourage positive community impacts, overcome monopolistic barriers, and enhance market efficiency and institutional effectiveness, aligning with SDGs.

Conclusion: The LEBS Toolkit serves as a practical guide for the scientific community to translate knowledge into actionable development outcomes, thereby advancing global development objectives.

Abstract: The LEBS Toolkit provides a comprehensive framework for astronomers and natural scientists to address development challenges through their field. The toolkit aligns with the Sustainable Development Goals (SDGs) and offers practical actions to achieve development outcomes. It emphasises the importance of effective communication between astronomy and development, highlighting four key components: Leadership, Externalities, Break Barriers to Entry and Support Functioning Markets & Institutions (LEBS). Using these components, scientists can promote accurate information dissemination, encourage positive community impacts, overcome monopolistic barriers, and improve market efficiency and institutional settings. The LEBS Toolkit serves as a guide for the scientific community in bridging the gap between scientific knowledge and practical development actions, ultimately contributing to global development goals.

</details>


### [31] [A review on fundamental bounds and estimators for photometry and astrometry of celestial point sources using array detectors, from first principles](https://arxiv.org/abs/2512.04326)
*Sebastián Espinosa,Rene A. Mendez,Jorge F. Silva,Marcos Orchard*

Main category: astro-ph.IM

TL;DR: This paper reviews the evolution of observational models in astronomy for astrometric and photometric measurements, focusing on the transition from empirical methods to probabilistic pixel-level approaches. It evaluates theoretical limits like the Cramér-Rao Lower Bound (CRLB) and practical estimators (ML, LS, WLS), noting their performance under varying SNR. Key findings include the importance of jointly estimating flux and background for better photometry and the ongoing need for statistical tools in future surveys.


<details>
  <summary>Details</summary>
Motivation: To summarize advancements in astrometric/photometric estimation, analyze theoretical bounds and estimator performance, and address challenges posed by modern large-scale astronomical surveys requiring reliable inference methods.

Method: Review and analysis of seminal works on CRLB, ML, LS, WLS estimators, and their performance across SNR conditions. Also discusses joint estimation of flux and background versus sequential approaches.

Result: Practical estimators approach CRLB only at specific SNRs, with gaps at high SNR. Joint estimation improves photometric precision. Future challenges require statistical tools for robust algorithms.

Conclusion: Theoretical statistical frameworks remain essential for guiding algorithm design in next-gen astronomical surveys, ensuring accurate measurements amidst growing data complexity and dynamic conditions.

Abstract: Precise astrometric and photometric measurements of celestial point sources are fundamental to modern astronomy. These measurements, used to determine object positions, motions, and fluxes, are based on observational models that have evolved from empirical centroiding rules to rigorous probabilistic formulations at the pixel level. This review summarizes key contributions that formalized this transition and analyzes seminal works addressing both the theoretical limits and the empirical performance of estimators. Central to these developments is the derivation of fundamental bounds, such as the Cramér-Rao Lower Bound (CRLB), and the assessment of widely used estimators, including Maximum Likelihood (ML), Least Squares (LS), and Weighted Least Squares (WLS). These studies show that, while the CRLB sets a theoretical benchmark, practical estimators achieve it only under specific signal-to-noise ratio (SNR) regimes, with notable discrepancies in high-SNR conditions. Moreover, recent results demonstrate that jointly estimating source flux and background significantly improves photometric precision compared to sequential approaches. Looking ahead, the increasing complexity of astronomical surveys, driven by massive data volumes, dynamic observational conditions, and the integration of machine learning, poses new challenges to reliable inference. In this context, tools from statistical theory, including performance bounds and theoretically grounded estimators, remain critical to guide algorithm design and ensure robust astrometric and photometric pipelines.

</details>


### [32] [Design and dynamics experiment of filter wheel mechanism of space coronagraph](https://arxiv.org/abs/2512.04372)
*Wei Guo,Jiangpei Dou,Mingming Xu,Linyi Kong,Baolu Liu,Bo Chen,Shu Jiang*

Main category: astro-ph.IM

TL;DR: The paper presents a compact filter wheel mechanism for space coronagraphs, ensuring high image contrast through precise, stable, and reliable performance.


<details>
  <summary>Details</summary>
Motivation: To achieve multi-spectral imaging in space coronagraphs while meeting stringent requirements for high image contrast and stability of the optical system.

Method: Designing a compact filter wheel using small modulus worm gear and worm传动 to enable high stiffness, unidirectional 360-degree rotation, and reverse self-locking. Analyzing precision, stiffness, mechanical properties, and reliability through modal analysis (first-order mode at 313Hz) and vibration testing.

Result: The filter wheel achieves position accuracy within 0.5mm, passes vibration tests, and meets stiffness and dynamic performance requirements.

Conclusion: The designed filter wheel ensures reliable multi-spectral imaging under complex space conditions.

Abstract: In order to realize multi-spectral imaging of space coronagraph, a compact filter wheel mechanism is designed. The filters with different spectral transmittance can be cut into the optical path at different times by this mechanism. Because the image contrast of space coronagraph is very high, the high stability requirement for the optical unit of coronagraph is put forward. Small modulus worm gear and worm are taken by the mechanism, in order to realize compact structure, high stiffness, the unidirectional 360 degrees rotation and reverse self-locking function. The precision, stiffness, mechanical properties and reliability of the mechanism are analyzed in the paper. The results show that the position accuracy of the filter wheel can meet the requirement of 0.5mm. The first order modal of the mechanism is 313Hz. The results of vibration test indicate that stiffness, dynamic performance and reliability of the mechanism can be meet. Therefore, the design of filter wheel in this paper can ensure the multi-spectral imaging requirements under complex spatial conditions.

</details>


### [33] [Towards Baikal-Top: Feasibility study of an onshore detector system for the joint registration of EAS with Baikal-GVD](https://arxiv.org/abs/2512.04549)
*E. A. Kravchenko,G. I. Rubtsov,D. S. Zhadan*

Main category: astro-ph.IM

TL;DR: The paper explores the feasibility of using an onshore detector array near Lake Baikal to register high-energy extensive air showers (EAS) in sync with the Baikal-GVD neutrino telescope. This enables muon count estimation for EAS modeling validation and atmospheric neutrino flux calculations, as well as cross-calibration between detectors.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of placing detectors permanently on Lake Baikal's surface and to enable verification of EAS models, neutrino flux calculations, and cross-calibration between the onshore detectors and Baikal-GVD telescope.

Method: Simulations using CORSIKA for EAS and PROPOSAL for muon propagation through water. Calculations of minimal detector area for different cosmic ray energy thresholds (starting at 1 PeV) and joint event registration estimates between onshore and Baikal-GVD systems.

Result: Established parameters for an onshore detector array to estimate high-energy muons in EAS, validate models/calculations, and enable cross-calibration. Presented event count estimates for different detector areas and energy thresholds.

Conclusion: The proposed onshore detector setup is viable for synergistic use with Baikal-GVD, enhancing neutrino research capabilities through simultaneous EAS and neutrino detection.

Abstract: We study the possibility of registering high-energy extensive air showers (EAS) by the onshore detector facility simultaneously with the trigger of the Baikal-GVD neutrino telescope. The location of the surface detector array on the shore of Lake Baikal is motivated by the fact that permanent placement of detectors on the surface of the lake is challenging. Within the given geometry, simultaneous registration is possible for EAS with a zenith angle of about 76 degrees within the limited solid angle. The corresponding inclined EAS are dominated by muons and significantly attenuated. The installation will make it possible to obtain an estimate of the number of high-energy muons in EAS. This, subsequently, would make it possible to verify EAS modeling and calculations of the atmospheric neutrino flux. The detector may also be used for cross-calibration of energy and direction measurements by the neutrino telescope. We use the CORSIKA program to simulate the registration of EAS on the shore close to the Baikal-GVD. The propagation of ultra-high energy muons produced by EAS through 3.5 km of water and their registration by Baikal-GVD is simulated using the PROPOSAL package. We calculate the minimal total area of the onshore detectors suitable for several cosmic ray energy thresholds, starting from 1 PeV. The report presents estimates of the number of events jointly registered by the onshore installation and the Baikal-GVD the EAS registration detector systems with different areas.

</details>


### [34] [Progress towards a microchannel plate detector with AlGaN photocathode and cross-strip anode for ultraviolet astronomy](https://arxiv.org/abs/2512.04669)
*S. Diebold,J. Barnstedt,L. Conti,H. R. Elsener,L. Hanke,M. Höltzli,C. Kalkuhl,D. Rau,D. Schaadt,T. Schanz,B. Stelzer,K. Werner*

Main category: astro-ph.IM

TL;DR: The paper discusses advancements in MCP-based detectors for UV astronomy, focusing on AlGaN photocathode coating on MCPs and FPGA-implemented centroiding algorithm for improved performance and efficiency.


<details>
  <summary>Details</summary>
Motivation: The motivation is to enhance the quantum detection efficiency in far- and extreme-UV ranges and optimize detector performance through efficient signal processing, while reducing size, weight, and power consumption for space instruments.

Method: The methods include direct coating of AlGaN photocathodes onto MCPs to improve sensitivity and the development of a non-iterative centroiding algorithm implemented in an FPGA for real-time signal processing.

Result: The results show improved quantum detection efficiency in UV ranges and successful FPGA implementation of the centroiding algorithm, contributing to compact, low-power detector systems for future UV instruments.

Conclusion: These advancements address major challenges in UV detector technology, paving the way for more sensitive, compact, and efficient instruments in upcoming space missions.

Abstract: Microchannel plates (MCPs) were the driving detector technology for ultraviolet (UV) astronomy over many years, and still today MCP-based detectors are the baseline for several planned UV instruments. The development of advanced MCP detectors is ongoing and pursues the major goals of maximizing sensitivity, resolution, and lifetime, while at the same time decreasing weight, volume, and power consumption.
  Development efforts for an MCP-based detector system for the UV are running at IAAT at the University of Tübingen. In this publication, we present our latest results towards coating aluminum gallium nitride (AlGaN) photocathodes directly on MCPs, to improve quantum detection efficiency in the far- and extreme-UV. Furthermore, we report on the implementation of a non-iterative centroiding algorithm for our coplanar cross-strip anode directly in an FPGA.

</details>


### [35] [Spaceflight KID Readout Electronics for PRIMA](https://arxiv.org/abs/2512.04816)
*Thomas Essinger-Hileman,C. Matt Bradford,Patrick Brown,Sean Bryan,Jesse Coldsmith,Jennifer Corekin,Sumit Dahal,Thomas Devlin,Marc Foote,Draisy Friedman,Alessandro Geist,Jason Glenn,Christopher Green,Tracee Jamison-Hooks,Kevin Horgan,Jared Lucey,Philip Mauskopf,Lynn Miles,Sanetra Bailey Newman,Gerard Quilligan,Cody Roberson,Adrian Sinclair,Salman Sheikh,Eric Weeks,Christopher Wilson,Travis Wise*

Main category: astro-ph.IM

TL;DR: This paper discusses the design and testing of a prototype readout electronics system for the PRIMA space mission's detectors, capable of multiplexing over 1000 KIDs across two instruments with different frequency bands, while meeting power and operational constraints at L2.


<details>
  <summary>Details</summary>
Motivation: To enable the PRIMA mission's scientific goals by developing electronics that can effectively handle the high-channel-count detectors required for far-infrared astrophysics observations in space.

Method: The system uses SpaceCube Mini v3.0 boards with Kintex KU060 FPGAs, custom high-speed digitizer boards, and RF electronics for filtering/power conditioning. Designs address multiplexing, bandwidth, power consumption, and compatibility with both PRIMAger (2.6-4.9 GHz) and FIRESS (0.4-2.4 GHz) instruments.

Result: The prototype meets key requirements: multiplexing >1000 detectors over 2.5 GHz bandwidth with ~30W per chain, switching between instruments, and radiation tolerance. Testing validates system functionality and performance.

Conclusion: The developed readout system successfully satisfies PRIMA's technical needs, demonstrating readiness for space application through prototyping and validation.

Abstract: We present the design and testing of a prototype multiplexing kinetic inductance detector (KID) readout electronics for the PRobe far-Infrared Mission for Astrophysics (PRIMA) space mission. PRIMA is a Probe-class astrophysics mission concept that will answer fundamental questions about the formation of planetary systems, the co-evolution of stars and supermassive black holes in galaxies, and the rise of heavy elements and dust over cosmic time. The readout electronics for PRIMA must be compatible with operation at Earth-Sun L2 and capable of multiplexing more than 1000 detectors over 2.5 GHz bandwidth while consuming around 30 W per readout chain. The electronics must also be capable of switching between the two instruments, which have different readout bands: the hyperspectral imager (PRIMAger, 2.6-4.9 GHz) and the spectrometer (FIRESS, 0.4-2.4 GHz). The PRIMA readout electronics use high-heritage SpaceCube digital electronics with a build-to-print SpaceCube Mini v3.0 board using a radiation-tolerant Kintex KU060 field programmable gate array (FPGA) and a custom high-speed digitizer board, along with RF electronics that provide filtering and power conditioning. We present the driving requirements for the system, as well as the hardware, firmware, software, and system-level design that meets those requirements.

</details>


### [36] [aim-resolve: Automatic Identification and Modeling for Bayesian Radio Interferometric Imaging](https://arxiv.org/abs/2512.04840)
*Richard Fuchs,Jakob Knollmüller,Jakob Roth,Vincent Eberle,Philipp Frank,Torsten A. Enßlin,Lukas Heinrich*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Modern radio interferometers deliver large volumes of data containing high-sensitivity sky maps over wide fields-of-view. These large area observations can contain various and superposed structures such as point sources, extended objects, and large-scale diffuse emission. To fully realize the potential of these observations, it is crucial to build appropriate sky emission models which separate and reconstruct the underlying astrophysical components. We introduce aim-resolve, an automatic and iterative method that combines the Bayesian imaging algorithm resolve with deep learning and clustering algorithms in order to jointly solve the reconstruction and source extraction problem. The method identifies and models different astrophysical components in radio observations while providing uncertainty quantification of the results. By using different model descriptions for point sources, extended objects, and diffuse background emission, the method efficiently separates the individual components and improves the overall reconstruction. We demonstrate the effectiveness of this method on synthetic image data containing multiple different sources. We further show the application of aim-resolve to an L-band (856 - 1712 MHz) MeerKAT observation of the radio galaxy ESO 137-006 and other radio galaxies in that environment. We observe a reasonable object identification for both applications, yielding a clean separation of the individual components and precise reconstructions of point sources and extended objects along with detailed uncertainty quantification. In particular, the method enables the creation of catalogs containing source positions and brightnesses and the corresponding uncertainties. The full decoupling of sky emission model and instrument response makes the method applicable to a wide variety of instruments or wavelength bands.

</details>


### [37] [Improving Posterior Inference of Galaxy Properties with Image-Based Conditional Flow Matching](https://arxiv.org/abs/2512.05078)
*Mikaeel Yunus,John F. Wu,Benne W. Holwerda*

Main category: astro-ph.IM

TL;DR: The paper proposes a conditional flow matching (CFM) framework that combines pixel-level imaging with photometry to enhance the estimation of galaxy properties, outperforming photometry-only methods by better recovering scaling relations and reducing dust-age degeneracy.


<details>
  <summary>Details</summary>
Motivation: Spectroscopy is expensive, and traditional photometry lacks morphological data crucial for understanding galaxy properties like mass and star formation. Integrating morphology could improve posterior inference.

Method: The CFM framework uses ~10^5 SDSS galaxies, comparing models trained on photometry alone vs. photometry plus images. It leverages both data types to infer physical properties more accurately.

Result: The image+photometry model performs better in posterior inference, reliably recovers known scaling relations, and mitigates dust-age degeneracy more effectively than photometry-only models.

Conclusion: Incorporating morphology via CFM improves photometric SED fitting, offering a pathway for more accurate galaxy property estimation in future surveys.

Abstract: Estimating physical properties of galaxies from wide-field surveys remains a central challenge in astrophysics. While spectroscopy provides precise measurements, it is observationally expensive, and photometry discards morphological information that correlates with mass, star formation history, metallicity, and dust. We present a conditional flow matching (CFM) framework that leverages pixel-level imaging alongside photometry to improve posterior inference of galaxy properties. Using $\sim10^5$ SDSS galaxies, we compare models trained on photometry alone versus photometry plus images. The image+photometry model outperforms the photometry-only model in posterior inference and more reliably recovers known scaling relations. Morphological information also helps mitigate the dust--age degeneracy. Our results highlight the potential of integrating morphology into photometric SED fitting pipelines, opening a pathway towards more accurate and physically informed constraints on galaxy properties.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [38] [How large can lepton mixing be?](https://arxiv.org/abs/2512.04148)
*J. de Blas,C. Giuliano,G. Guedes,R. Sánchez López,J. Santiago*

Main category: hep-ph

TL;DR: The paper demonstrates that charged leptons can mix with heavier fermions at up to 20% level through dimension-6 operator effects suppressed by symmetries. It analyzes model constraints and shows that future colliders like FCC-ee/hh could achieve mille-level precision, surpassing current theoretical limits.


<details>
  <summary>Details</summary>
Motivation: To challenge common assumptions about lepton mixing with heavy fermions, explore symmetry-protected mixing mechanisms, and assess experimental vs. theoretical constraints.

Method: Uses effective field theory framework with a model realizing symmetry-induced cancellation of tree-level mixing. Analyzes direct/indirect experimental constraints and evaluates FCC sensitivity via precision estimates.

Result: Experimental constraints are weak compared to theoretical ones; FCC experiments could achieve 0.1% precision in mixing squared, potentially surpassing current theoretical bounds.

Conclusion: Future lepton colliders (FCC-ee/hh) may outperform theoretical predictions in measuring charged lepton mixing, necessitating improved theoretical understanding.

Abstract: We show that, contrary to common expectations, the observed charged leptons can have a substantial mixing with new heavier fermions, at the level of 20$\%$. This can happen, in the language of effective theories, when the effect of mixing with heavier fermions vanishes at tree level in operators of mass-dimension 6 (or it is suppressed by the small charged lepton masses), a cancellation that can be naturally ensured by symmetries. Using a model that realizes this scenario we consider all current direct and indirect constraints and show that experimental constraints on the mixing are so mild that, given the current direct limit on the mass of the heavy fermions, theoretical considerations become the leading current constraints on the mixing. We also estimate the sensitivity to the mixing at future experiments, including the high-luminosity phase of the LHC and, most notably, the FCC-ee, and FCC-hh. We find a pattern in which the reach of direct searches in hadron machines makes theoretical considerations lead the limits while the precision of lepton machines can beat these theoretical considerations. We find that the FCC can finally reach per mille precision in the mixing squared of the charged leptons

</details>


### [39] [Enhancing next token prediction based pre-training for jet foundation models](https://arxiv.org/abs/2512.04149)
*Joschka Birk,Anna Hallin,Gregor Kasieczka,Nikol Madzharova,Ian Pang,David Shih*

Main category: hep-ph

TL;DR: The paper introduces improvements to next token prediction for jet foundation models by using hybrid setups with continuous features and combining pre-training objectives, enhancing classification performance without sacrificing generative capabilities.


<details>
  <summary>Details</summary>
Motivation: To enhance the performance of jet foundation models in downstream classification tasks while maintaining their generative capabilities, leveraging a simulation-free pre-training approach.

Method: The authors propose a hybrid setup that uses continuous feature vectors as model inputs alongside token-IDs targets and employ a combined pre-training strategy with masked particle modeling and generative learning objectives.

Result: These modifications significantly boost downstream classification performance without any decline in generative performance.

Conclusion: The proposed hybrid approach and combined pre-training objectives are effective for improving jet foundation models' versatility and performance in both generative and classification tasks.

Abstract: Next token prediction is an attractive pre-training task for jet foundation models, in that it is simulation free and enables excellent generative capabilities that can transfer across datasets. Here we study multiple improvements to next token prediction, building on the initial work of OmniJet-$α$. Instead of tokenizing particles and subsequently only using the token-ID as the model input for both the generative and the classification task, we adopt a hybrid setup, which allows us to use continuous feature vectors as model input while only using token-IDs in the next token prediction target. Secondly, we explore a combined pre-training strategy that combines masked particle modeling and generative learning objectives. Taken together, these changes greatly improve the performance in downstream classification tasks without any loss in generative performance.

</details>


### [40] [Data-Driven Predictions for Dark Photon and Millicharged Particle Production](https://arxiv.org/abs/2512.04153)
*Elizabeth Allison,Nikita Blinov*

Main category: hep-ph

TL;DR: The paper proposes a data-driven framework using normalized flow models to predict the production of dark photons and millicharged particles by leveraging the correspondence between their amplitudes and measurable off-shell photon production, eliminating reliance on theoretical models.


<details>
  <summary>Details</summary>
Motivation: Theoretical uncertainties in hadronic production of dark photons and millicharged particles are significant, necessitating a model-independent approach to accurately predict signal characteristics for new physics searches.

Method: The framework uses normalized flow models to learn production distributions from measured dilepton events by exploiting the amplitude relationship between dark sector particles and off-shell SM photon production. This allows direct data-driven predictions without assuming specific theoretical production models.

Result: Demonstrates that normalized flow models can effectively learn the required distributions and function as a fast, realistic Monte Carlo generator for simulating dark sector signals.

Conclusion: This method provides a robust, data-driven alternative to traditional theoretical models, enhancing accuracy in interpreting and optimizing fixed-target searches for dark photon and millicharged particle signals.

Abstract: Accurate signal predictions are essential for interpreting and optimizing fixed-target searches for new physics. Even in minimal models such as the dark photon ($A'$) or millicharged particles (mCPs), theoretical uncertainties in hadronic production can be substantial. We introduce a data-driven framework that predicts both the rate and kinematic distributions of $A'$ and mCP production directly from measured dilepton events, without relying on specific theoretical production models. This method uses the close correspondence between amplitudes for emission of $A'$ or mCPs, and for off-shell Standard Model photon production, the latter being experimentally measurable in full differential form. We demonstrate that normalizing flow models can learn these distributions from data and serve as a fast, realistic Monte Carlo generator for dark sector signal simulations.

</details>


### [41] [A new connection between WIMP dark matter and the hierarchy problem](https://arxiv.org/abs/2512.04158)
*Maximilian Detering,Thomas Steingasser,Tevong You*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This work proposes a direct link between the hierarchy problem and Weakly Interacting Massive Particles (WIMPs): we suggest that the small mass of the Higgs boson arises from being dynamically driven to the scale of the WIMP. Such a special electroweak vacuum is singled out by lying close to the critical boundary of a phase transition, as recently explored in a new class of cosmological solutions to the hierarchy problem. They generically predict the Higgs potential to be destabilised just above the weak scale. Intriguingly, the requirement for new physics to achieve this coincides with two independently well-motivated expectations: a split spectrum of light fermions and heavy bosons, as anticipated from naturalness, and the so-called "WIMP miracle". A WIMP with mass around the weak scale not only happens to have the correct thermal relic abundance to be the dark matter (DM), it can also give rise to the necessary critical boundary at the TeV scale through its Yukawa couplings to the Higgs. We use a higgsino-like singlet-doublet model to illustrate our Higgs-DM criticality scenario and show that if this WIMP DM mass is observed to be greater than ~1.2 TeV then it necessarily implies a strong bound on the Higgs mass and an upper bound on the scale of heavy new physics that restores vacuum stability. It can be thoroughly probed in direct detection experiments, astrophysical signals and future collider searches, further motivating a comprehensive exploration of the remaining heavy WIMP parameter space.

</details>


### [42] [Minimal Flavor Protection for TeV-scale New Physics](https://arxiv.org/abs/2512.04159)
*Admir Greljo,Ajdin Palavrić,Ben A. Stefanek*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We determine how much TeV-scale new physics can deviate from flavor universality, $U(3)^5$, while respecting stringent bounds on flavor-changing neutral currents. The minimal continuous subgroup that must be approximately preserved is identified as $SU(2)_{q} \times U(1)_{X}$. With only a few symmetry-breaking spurions of $\mathcal{O}(10^{-2})$, all observed fermion hierarchies may be reproduced, offering a new perspective on the SM flavor puzzle. Remarkably, this framework provides structural flavor protection for generic TeV-scale new physics within the SMEFT, enlarging the space of collider-accessible scenarios beyond MFV and $U(2)^5$ and allowing for richer patterns of flavor violation.

</details>


### [43] [Resummed Distribution Functions: Making Perturbation Theory Positive and Normalized](https://arxiv.org/abs/2512.04160)
*Rikab Gambhir,Radha Mastandrea*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Fixed-order perturbative calculations for differential cross sections can suffer from non-physical artifacts: they can be non-positive, non-normalizable, and non-finite, none of which occur in experimental measurements. We propose a framework, the Resummed Distribution Function (RDF), that, given a perturbative calculation for an observable to some finite order in $α_s$, will ``resum'' the expression in a way that is guaranteed to match the original expression order-by-order and be positive, normalized, and finite. Moreover, our ansatz parameterizes all possible finite, positive, and normalized completions consistent with the original fixed-order expression, which can include N$^n$LL resummed expressions. The RDF also enables a more direct notion of perturbative uncertainties, as we can directly vary higher-order parameters and treat them as nuisance parameters. We demonstrate the power of the RDF ansatz by matching to thrust to $\mathcal{O}(α_s^3)$ and extracting $α_s$ with perturbative uncertainties from fitting the RDF to ALEPH data.

</details>


### [44] [Electroweak phase transition in SMEFT: Gravitational wave and collider complementarity](https://arxiv.org/abs/2512.04168)
*Sahabub Jahedi,Indrajit Saha,Abhik Sarkar*

Main category: hep-ph

TL;DR: The paper examines the electroweak phase transition using SMEFT dimension-6 operators, exploring correlations between di-Higgs production at future LHC runs and gravitational wave detections to probe first-order electroweak phase transitions.


<details>
  <summary>Details</summary>
Motivation: To investigate the feasibility of probing FO-EWPT through combined analysis of di-Higgs production at upgraded LHC experiments and gravitational wave observations, leveraging SMEFT operators that affect both phenomena.

Method: Analyzes three dimension-6 SMEFT operators affecting Higgs potential and di-Higgs production, evaluates their suppressions at current LHC runs, and models future HL/HE LHC sensitivity. Assesses correlations between operators in FO-EWPT context, emphasizing collider-GW complementarity.

Result: Highlights the enhanced sensitivity of future LHC runs and gravitational wave detectors in constraining SMEFT operators, demonstrating the necessity of combining both approaches for robust probing of FO-EWPT.

Conclusion: Future LHC upgrades and gravitational wave observations are complementary tools for studying electroweak phase transitions via SMEFT operators, requiring joint analysis to fully explore beyond Standard Model physics in this sector.

Abstract: We study the electroweak first-order electroweak phase transition (FO-EWPT) within the Standard Model Effective Field Theory (SMEFT) framework induced by dimension-6 operators. Such phenomena can be probed independently via \textit{di}-Higgs production at the collider experiments as well as via the detection of gravitational waves (GW). There are three dimension-6 SMEFT operators that simultaneously modify the Higgs potential at tree level and contribute to the \textit{di}-Higgs production at the hadron colliders. With \textit{di}-Higgs production being suppressed at current LHC runs, we aim to probe this production at high luminosity (HL) and high energy (HE) runs of the LHC to achieve better sensitivity of dimension-6 SMEFT operators. The correlations among these operators are analyzed in the context of probing FO-EWPT, emphasizing the complementarity between future GW observations and upgraded LHC searches.

</details>


### [45] [Detecting light axions from supernovae in nearby galaxies](https://arxiv.org/abs/2512.04185)
*Francesca Lecce,Alessandro Lella,Giuseppe Lucente,Maurizio Giannotti,Alessandro Mirizzi*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Axion-like particles (ALPs) coupled to nucleons can be efficiently produced in core-collapse supernovae (SNe) and then, if they couple to photons, convert into gamma rays in cosmic magnetic fields, generating short gamma-ray bursts. Though ALPs from a Galactic SN would induce an intense and easily detectable gamma-ray signal, such events are exceedingly rare. In contrast, a few SNe per year are expected in nearby galaxies within $\mathcal{O}(10)$ Mpc, where strong magnetic fields can enable more efficient ALP-photon conversions than in the Milky Way, offering a promising extragalactic target. This circumstance motivates full-sky gamma-ray monitoring, ideally combined with deci-hertz gravitational-wave detectors to enable time-triggered searches from nearby galaxies. We show that, under realistic conditions, a decade of coverage could reach sensitivities to ALP-photon coupling $g_{a γ} \gtrsim 10^{-16} \rm{GeV}^{-1}$ for ALP masses $m_a \lesssim 10^{-9} $ eV and assuming an ALP-nucleon coupling close to SN 1987A cooling bound. This sensitivity would allow one to probe a large, currently-unexplored region of the parameter space below the longstanding SN 1987A bound.

</details>


### [46] [Z' portal dark matter from post-inflationary reheating: WIMPs, FIMPs, and UFOs](https://arxiv.org/abs/2512.04229)
*Stephen E. Henrich,Yann Mambrini,Keith A. Olive*

Main category: hep-ph

TL;DR: The paper investigates the production of dark matter (DM) through a heavy Z' mediator during post-inflationary reheating, covering three interconnected mechanisms: WIMP-like freeze-out, FIMP-like freeze-in, and ultra-relativistic freeze-out (UFO). It highlights that UFO is a robust mechanism for cold DM when the Z' mass is above both DM mass and reheating temperature, allowing stronger interactions compared to standard freeze-in.


<details>
  <summary>Details</summary>
Motivation: To systematically explore Z' portal DM scenarios including UFO, which prior studies had not included, to understand parameter spaces for keV to TeV DM and evaluate UFO's role in cold DM production with stronger couplings.

Method: The study analyzes three production mechanisms (freeze-out, freeze-in, UFO) connected during reheating, focusing on Z' mediator dynamics. It models DM production efficiency based on mediator mass (M_Z'), DM mass, and reheating temperature relationships.

Result: Significant parameter space for keV-TeV DM exists in the UFO regime when M_Z' ranges from 1 TeV to 1 PeV. UFO produces initially 'hot' DM that becomes cold before structure formation, allowing stronger couplings than freeze-in.

Conclusion: UFO via Z' mediators provides a viable and robust pathway for cold DM production, expanding allowed parameter space with stronger interactions. This challenges prior assumptions and opens new regions for experimental searches.

Abstract: We investigate the production of dark matter (DM) via a heavy $Z'$ mediator during the post-inflationary reheating epoch. In particular, we study production from three mechanisms which are smoothly connected to one another: WIMP-like freeze-out, FIMP-like freeze-in, and ultra-relativistic freeze-out (UFO). This is the first systematic study of $Z'$ portal DM which includes UFO. We find that much of the available parameter space for keV to TeV DM lies in the UFO regime for $ 1 \text{ TeV}\lesssim M_{Z'} \lesssim 1 \text{ PeV}$. When the mediator mass $M_{Z'}$ is greater than both the DM mass and the reheating temperature, UFO is a robust mechanism for producing cold DM. Although UFO DM is initially "hot" after freeze-out, it can easily become cold before structure formation if freeze-out occurs during post-inflationary reheating. Compared to standard freeze-in, UFO can accommodate significantly stronger interaction strengths (stronger couplings and/or smaller mediator masses).

</details>


### [47] [Gravitational Waves from Isocurvature Perturbations of Spectator Scalar Fields](https://arxiv.org/abs/2512.04240)
*Marcos A. G. Garcia,Sarunas Verner*

Main category: hep-ph

TL;DR: The paper investigates how isocurvature perturbations in spectator scalar fields during inflation can generate a gravitational wave (GW) background. This mechanism produces detectable GW signals across a wide frequency range, offering a novel probe of early universe physics linking inflationary dynamics, dark matter, and reheating.


<details>
  <summary>Details</summary>
Motivation: To explore a new mechanism for GW production that avoids Large-Scale Structure (LSS) constraints while providing testable signals at observable scales, and to connect early universe phenomena with detectable GW signatures.

Method: Comprehensive numerical and analytical calculations of isocurvature spectrum evolution, including gravitational particle production, reheating dynamics, and scalar-induced GW generation. Studied both unstable (curvaton-like) and stable (dark matter) spectator fields with varying parameters.

Result: GW energy densities of Ω_GW h² ~10^-20 to 10^-12 across frequencies 10^-20–1 Hz, detectable by pulsar timing arrays, space interferometers, and future CMB experiments. GW constraints exceed current isocurvature bounds, showing sensitivity to reheating temperature and couplings.

Conclusion: Isocurvature-sourced GWs provide a versatile probe of early universe physics, enabling multi-messenger constraints on inflation, dark matter, and reheating when combining multi-frequency GW observations.

Abstract: We present a mechanism for gravitational wave (GW) production from isocurvature perturbations in spectator scalar fields during inflation. These energetically subdominant fields develop blue-tilted power spectra through inflationary dynamics, generating second-order scalar perturbations that source a stochastic GW background. The mechanism naturally satisfies CMB constraints at large scales while producing enhanced signals at smaller scales across a broad frequency range $10^{-20} - 1$ Hz. We perform comprehensive numerical and analytical calculations of the complete isocurvature spectrum evolution, including gravitational particle production, reheating dynamics, and scalar-induced GW generation. For spectator fields with effective masses $0.5 \lesssim m_{χ,\mathrm{eff}}/H_I$, the resulting GW energy density reaches $Ω_{\text{GW}} h^2 \sim 10^{-20}$-$10^{-12}$, accessible to pulsar timing arrays, space-based interferometers, and next-generation CMB experiments. Our analysis reveals that GW-induced constraints exceed current isocurvature bounds. We examine both unstable (curvaton-like) and stable (dark matter) spectator fields, demonstrating strong sensitivity to reheating temperature, inflaton-spectator coupling, and decay dynamics. This framework establishes isocurvature-sourced GWs as a powerful probe of early universe physics, enabling simultaneous constraints on inflationary dynamics, dark matter production, and reheating through coordinated multi-frequency GW observations.

</details>


### [48] [A thrust to trust minimum thrust](https://arxiv.org/abs/2512.04244)
*Matteo Cacciari*

Main category: hep-ph

TL;DR: The paper determines the minimum thrust values for various N-particle configurations, achieving exact results for N=5 in 3D and using numerical optimization and statistical methods for larger N across different dimensions.


<details>
  <summary>Details</summary>
Motivation: To establish precise minimum thrust values for particle configurations, advancing understanding in high-energy physics and optimization techniques, especially for higher N where exact solutions are elusive.

Method: For N=5 in 3D, an exact analytical solution was derived. For larger N, numerical optimization was employed. When exact values were uncertain, Extreme Value Theory, along with Maximum Likelihood Estimation and Bayesian analysis, was applied. Analyses were conducted in 3D, 2D, and selected higher dimensions.

Result: Exact minimum thrust for N=5 in 3D was found. Numerical results for larger N showed reliability through statistical methods. Thrust values were characterized across different spatial dimensions.

Conclusion: The study provides foundational data on minimum thrust configurations, validates statistical approaches for complex systems, and opens avenues for further exploration in higher dimensions and related optimization problems.

Abstract: We determine the minimum value of thrust for a number of N-particle configurations. For N=5 in three dimensions an exact result is found for the first time. For larger N we obtain numerical results through optimisation. When a definite value cannot be reliably identified, the results are analysed in the context of Extreme Value Theory, using a Maximum Likelihood Estimate and a Bayesian analysis. Results are given for three spatial dimensions, two dimensions, and selected cases in d dimensions.

</details>


### [49] [Powerful Yukawas](https://arxiv.org/abs/2512.04270)
*Timothy Cohen,Matthew McCullough,Neal Weiner*

Main category: hep-ph

TL;DR: The paper presents a theoretical framework where the light Standard Model fermions' masses arise from a high-dimension Effective Field Theory operator, termed 'Powerful Yukawa', with a UV completion via 'Sprouted Symmetry Breaking' leading to an enhanced Higgs coupling to light fermions.


<details>
  <summary>Details</summary>
Motivation: To explain the origin of light Standard Model fermion masses through beyond-the-Standard-Model dynamics without introducing additional low-energy parameters or ad-hoc hierarchies.

Method: Introduces a novel Effective Field Theory approach using high-dimension operators (beyond dimension-4) and a collective symmetry breaking mechanism ('Sprouted Symmetry Breaking') to UV-complete the model, ensuring consistency with observed fermion mass patterns.

Result: Predicts an enhanced Higgs coupling to light fermions as the unique signature, providing a testable prediction for collider experiments like the LHC.

Conclusion: Demonstrates a viable UV-complete framework for generating light fermion masses through high-dimension operators, offering a new direction for probing physics beyond the Standard Model via precision Higgs measurements.

Abstract: We introduce a class of models where the masses of the light Standard Model fermions are due to an Effective Field Theory operator that appears beyond dimension-4 in the power counting expansion, resulting in a `Powerful Yukawa'. The effective Yukawa coupling structure is UV-completed using a collective symmetry breaking pattern in the flavour sector, which we dub `Sprouted Symmetry Breaking.' The irreducible signature is an enhanced Higgs coupling to the light Standard Model fermions.

</details>


### [50] [LHC Shines on Positivity](https://arxiv.org/abs/2512.04336)
*Zhen Liu,Kun-Feng Lyu,Tong Arthur Wu*

Main category: hep-ph

TL;DR: The paper demonstrates that hadron colliders like the LHC and FCC-hh can effectively test positivity bounds on dimension-8 diphoton operators involving colored particles using differential distributions, probing scales up to 2 TeV and 5 TeV respectively.


<details>
  <summary>Details</summary>
Motivation: To explore the reach of hadron colliders in testing positivity constraints on higher-dimensional operators, which are less constrained by helicity selection rules compared to lower-dimensional ones.

Method: The authors analyze kinematic differential distributions of diphoton final states from hadron collider experiments, employing a χ² analysis and global fitting techniques to probe the effective energy scales of dimension-8 operators.

Result: Probes using HL-LHC data can reach effective scales up to ~2 TeV, while future 100 TeV FCC-hh could extend this to over 5 TeV at 95% confidence level.

Conclusion: Hadron colliders provide a powerful method to test quantum gravity and UV completeness through positivity bounds, offering insights into physics beyond the Standard Model at multi-TeV scales.

Abstract: We show that hadron colliders have an excellent reach for positivity tests on a class of diphoton operators. Due to the helicity selection rules, the relevant dimension-6 operators either do not contribute or are highly constrained by other experimental observables. We show, for the first time, that the LHC can probe the positivity of the dimension-8 operators involving colored particles. The kinematic differential distributions of the diphoton final states are exploited to perform the $χ^2$ analysis. Through a global fit, the effective scale for these operators can be inclusively probed up to around 2 TeV at HL-LHC and over 5 TeV at future 100 TeV FCC-hh at 95% C.L., providing a powerful test of the positivity bounds up to multi-TeV scale.

</details>


### [51] [New avenues for tau flavor violation](https://arxiv.org/abs/2512.04375)
*Julian Heeck*

Main category: hep-ph

TL;DR: The paper explores tau lepton flavor violation through non-standard decay channels, highlighting theoretical motivations and experimental opportunities.


<details>
  <summary>Details</summary>
Motivation: To investigate potential new physics beyond the Standard Model by examining rare tau decays that violate flavor conservation.

Method: Analyzes non-standard tau decay channels and their theoretical frameworks, possibly involving particle physics models and experimental data interpretation.

Result: Highlights the significance of these decays in uncovering new physics and identifies key opportunities for future research and experiments.

Conclusion: Emphasizes the importance of studying tau flavor violation as a pathway to discover beyond Standard Model physics through experimental observation of rare decays.

Abstract: I present a concise overview of tau flavor violation and the broad opportunities it offers, with a focus on non-standard decay channels and their underlying theoretical motivations.

</details>


### [52] [Nucleon to Roper transition amplitudes and electromagnetic form factors](https://arxiv.org/abs/2512.04493)
*G. Ramalho*

Main category: hep-ph

TL;DR: The paper examines the Roper resonance's properties and the nucleon-to-Roper electromagnetic transition using quark degrees of freedom, especially at large $Q^2$. It also analyzes low-$Q^2$ transition amplitudes and the role of baryon-meson states in interpreting data and understanding the Roper's nature.


<details>
  <summary>Details</summary>
Motivation: The Roper resonance's unique properties differ from other low-lying nucleon resonances and complicate baryon structure understanding in QCD. The study aims to clarify its nature and electromagnetic transitions across different $Q^2$ regimes.

Method: Relies on quark degrees of freedom for high $Q^2$ analysis and considers baryon-meson contributions for low/intermediate $Q^2$ to model transition amplitudes and interpret experimental data.

Result: The analysis of transition amplitudes' analytic structure and the necessity of baryon-meson states to explain low/intermediate $Q^2$ data shed light on the Roper's composite nature.

Conclusion: The findings highlight the importance of quark and baryon-meson degrees of freedom at different $Q^2$ scales for understanding the Roper's role in baryon structure, suggesting a composite origin for the resonance.

Abstract: The second excitation of the nucleon, the Roper, has properties differentiated from other low-lying nucleon resonances. Their properties challenge our understanding of the structure of the baryons in terms of the degrees of freedom from QCD. In the present work we discuss the properties of the Roper resonance and the nucleon to Roper electromagnetic transition, based on the quark degrees of freedom, that are expected to dominate for large square momentum transfer $Q^2$. We also discuss the analytic structure of the transition amplitudes in the low-$Q^2$ region, and how the contributions of baryon-meson states can help to describe the low and intermediate $Q^2$ data, and the nature of the Roper.

</details>


### [53] [Probing Hard Scattering Processes via Multiple Weak Gauge Boson Production at the Future Colliders](https://arxiv.org/abs/2512.04553)
*Ijaz Ahmed,M. S. Amjad,Jamil Muhammad*

Main category: hep-ph

TL;DR: The paper investigates weak gauge boson production in proton-proton collisions at multi-TeV energies to detect new physics. It focuses on triple gauge boson scattering (W⁺W⁻W⁺) with optimized signal/background ratios, showing that kinematic features allow effective signal isolation despite low cross-sections.


<details>
  <summary>Details</summary>
Motivation: To explore new physics phenomena by analyzing weak gauge boson production in high-energy collisions, particularly through higher-order scattering processes which could reveal discrepancies from Standard Model predictions.

Method: Computed cross-sections for pair, triple, and quartic gauge boson scattering at energies from 8 TeV to 100 TeV, evaluated background suppression using optimized signal-to-background ratios, and analyzed decay channel efficiencies for W/Z bosons.

Result: Demonstrated a methodology to suppress backgrounds using kinematic selections, showing that even processes with low cross-sections can be effectively isolated at future colliders due to distinct kinematic features.

Conclusion: Higher-order gauge boson scattering processes, though with low cross-sections, provide viable signatures for new physics searches at future colliders when optimized analysis techniques are applied.

Abstract: One of the possible ways to detect the new physics phenomena particles is to investigate the weak gauge boson production as a result of hadron-hadron scattering. This study comprises the production of multiple weak gauge bosons as a result of hard scattering between the proton-proton beams at multi-TeV energies and integrated luminosity $\mathcal L =$ 3000 $fb ^{-1}$. The effective production cross-sections for pair, triple, and quartic scattering mechanisms have been computed as a function of $\sqrt s$. The center of mass energy has been varied from 8 TeV to 100 TeV to encompass the future collider capabilities. Out of all the studied processes, the triple scattering process $W^+W^-W^+$ has been chosen as the signal process based on the dominant cross-section. The background channels ZZZ, ZZZZ, $W^-ZZ$, $W^+ZZ$, $W^+W^-Z$, $W^+W^-ZZ$, $W^+W^-W^+W^-$, having comparatively lower cross-sections, have been selected from possible scattering mechanisms to investigate the effect of higher luminosity on the low production cross-section processes. We have investigated the different decay modes. For both lepton and hadron-specific decays of W and Z, the cumulative efficiencies for each signal and background process have been computed. In this study, we have successfully demonstrated an effective methodology for background suppression by systematically optimizing the signal-to-background ratio. The results indicate that, despite lower cross-sections for higher-order scattering, the distinct kinematic features enable effective signal isolation at future colliders.

</details>


### [54] [Spontaneous Symmetry Breaking and the Higgs Mechanism](https://arxiv.org/abs/2512.04741)
*Gustavo Burdman*

Main category: hep-ph

TL;DR: This paper provides a pedagogical overview of the Higgs mechanism and boson within the Standard Model, covering spontaneous symmetry breaking, the Goldstone theorem, and the electroweak sector, while highlighting unresolved questions in the Higgs sector.


<details>
  <summary>Details</summary>
Motivation: To explain the foundational role of the Higgs sector in generating elementary particle masses and address lingering questions introduced by its inclusion in the Standard Model.

Method: Systematically introduces concepts starting from global symmetry breaking and Goldstone bosons, extends to gauge symmetry breaking (Higgs mechanism), and applies this to the electroweak theory.

Result: Clarifies the theoretical framework behind the Higgs mechanism, confirms its role in mass generation, and identifies open problems like the hierarchy problem or potential extensions beyond the Standard Model.

Conclusion: While the Higgs mechanism successfully explains mass generation, its introduction raises profound questions requiring further research, such as the nature of the Higgs potential's stability or possible new physics beyond the Standard Model.

Abstract: The Higgs sector of the standard model of particle physics plays a central role in the generation of all the masses of elementary particles known so far. Here we give a pedagogical introduction to all the elements leading ot the Higgs mechanism and the Higgs boson, starting with the spontaneous symmetry breaking of global symmetries and the Goldstone theorem. We then consider the case of gauge symmetries, i.e. the Higgs mechanism, and its application to the electroweak sector of the standard model. We close with a reflection on the possible open questions that the very introduction of the Higgs sector in the standard model posses.

</details>


### [55] [The next-to-next-to-leading-order QCD corrections to $e^+e^-\to η_c/χ_{cJ}+γ$ at B factories](https://arxiv.org/abs/2512.04758)
*Cong Li,Wen-Long Sang,Hong-Fei Zhang*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the processes $e^+e^-\to η_c+γ$ and $e^+e^-\to χ_{cJ}+γ$ at B factories within the NRQCD factorization framework, computing the corresponding helicity amplitudes through $\mathcal{O}(α_s^2)$. The short-distance coefficients are obtained as series expansions in $r=\frac{4m_c^2}{s}$ around $r=0, 1/3, 2/3, 1$, using the method of differential equations. By combining the expansions from all four points, we construct composite asymptotic expressions that reproduce the exact results accurately over the full range $0 \leq r\leq 1$, with relative errors below $0.1\%$ over most of the domain and remaining under $1\%$ elsewhere. Analytic expressions for the leading and next-to-leading logarithmic terms are extracted in the limit $r\to 0$. Using these results, we compute the unpolarized cross sections and observe that the perturbative corrections are small for $χ_{c0}+γ$, moderate for $χ_{c1}+γ$, and substantial for $η_c+γ$ and $χ_{c2}+γ$. Theoretical prediction for $χ_{c1}+γ$ is consistent with the {\tt Belle} measurement within $2σ$, showing good agreement between theory and experiment. We also predict the angular distribution parameters $α^H_θ$, which are insensitive to NRQCD matrix elements and exhibit small theoretical uncertainties. These parameters further display good stability across different perturbative orders. With the high luminosity anticipated at {\tt Belle 2}, future experimental measurements will thus provide a clear test of NRQCD factorization.

</details>


### [56] [Optimal Transport Event Representation for Anomaly Detection](https://arxiv.org/abs/2512.04839)
*Aditya Bhargava,Tianji Cai,Benjamin Nachman*

Main category: hep-ph

TL;DR: The paper proposes using optimal transport (OT) as a physics-based intermediate event representation for weakly supervised anomaly detection in LHC datasets, achieving significant improvement in performance with minimal signal injection compared to traditional methods.


<details>
  <summary>Details</summary>
Motivation: The motivation is to enhance anomaly detection in high-energy physics data with limited signal samples, addressing the challenge that end-to-end deep learning struggles in low-signal regimes and standard observables are suboptimal.

Method: The method involves incorporating OT-based representations as intermediate features, augmented with high-level observables, using small percentages (0.5%) of resonant signals in LHC Olympics datasets.

Result: The OT-augmented features achieve nearly double the significance improvement over standard methods, and outperform end-to-end deep learning models under low-signal conditions across various signal types and classifiers.

Conclusion: Structured representations like optimal transport are critical for effective machine learning in anomaly detection, especially when signal samples are scarce.

Abstract: We introduce optimal transport (OT) as a physics-based intermediate event representation for weakly supervised anomaly detection. With only $0.5\%$ injection of resonant signals in the LHC Olympics benchmark datasets, the OT-augmented feature set achieves nearly twice the significance improvement of standard high-level observables, while end-to-end deep learning on low-level four-momenta struggles in the low-signal regime. The gains persist across signal types and classifiers, underscoring the value of structured representations in machine learning for anomaly detection.

</details>


### [57] [Pion physics with dressed quark-gluon vertices](https://arxiv.org/abs/2512.04853)
*Mauricio N. Ferreira,Angel S. Miramontes,Jose M. Morgado,Joannis Papavassiliou,Jan M. Pawlowski*

Main category: hep-ph

TL;DR: The paper proposes a truncated approach within an existing theoretical framework to simplify the quark-gluon Schwinger-Dyson equation while preserving chiral symmetry. This results in a manageable Bethe-Salpeter equation with one-loop diagrams and a critical two-loop diagram, ensuring pion masslessness in the chiral limit and validating key quark-pion correlations with high precision.


<details>
  <summary>Details</summary>
Motivation: To develop a computationally feasible method that maintains chiral symmetry preservation when incorporating full quark-gluon vertices in meson dynamics, addressing complexity issues in existing frameworks.

Method: The authors introduce a specific truncation method that simplifies the Schwinger-Dyson equation without losing accuracy, leading to a reduced Bethe-Salpeter equation. This equation includes one-loop diagrams with full vertices and a two-loop diagram crucial for the pion's chiral behavior. Numerical analysis was used to validate the approach.

Result: The two-loop diagram is essential for achieving the correct eigenvalue (unity), and the key relation between quark mass function and pion wave function holds with ~1% precision. The truncation successfully reduces complexity while maintaining accuracy.

Conclusion: The truncation method effectively balances computational manageability with theoretical accuracy, ensuring chiral symmetry constraints. This lays groundwork for extending analyses beyond the chiral limit, offering a promising pathway for future QCD studies.

Abstract: Recently, a theoretical framework was set up in [1], which allows for the symmetry-preserving inclusion of full quark-gluon vertices in the description of the meson dynamics. In the present work, we develop a special truncation within this approach, which leads to a tractable set of functional equations that satisfy the fundamental chiral Ward-Takahashi identities. Specifically, the truncation allows us to simplify considerably the quark-gluon Schwinger-Dyson equation, without significant loss of quantitative accuracy. Importantly, this implies a substantial reduction of complexity of the renormalized Bethe-Salpeter equation: it is composed by a pair of one-loop diagrams that contain the full quark-gluon vertex, and a single two-loop diagram that is instrumental for the masslessness of the pion in the chiral limit. A detailed numerical analysis reveals that the incorporation of the aforementioned two-loop diagram is instrumental for the corresponding eigenvalue to reach unity. The key relation between the quark mass function and the pion wave function is shown to be satisfied to within the numerical precision of the loop integrals, which is at the level of about one percent or better. The field-theoretic ingredients required for the extension of this analysis beyond the chiral limit are briefly discussed.

</details>


### [58] [Towards a Fully Automated Differential $\text{NNLO}_\text{EW}$ Generator for Lepton Colliders](https://arxiv.org/abs/2512.04959)
*Alan Price,Frank Krauss*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Future proposed lepton collider experiments will reach unprecedented levels of accuracy. To ensure the success of these experiments, and to fully exploit their wealth of data, the precision of theory calculations must reach comparable or even better levels. One bottleneck in achieving this precision target lies in the systematic, process-independent inclusion of higher-order corrections at Next-to-Next-to-Leading Order in the electroweak coupling $\text{NNLO}_\text{EW}$ while ensuring the correct matching with modern all-orders resummation techniques. Here, we present a solution to this problem, based on the Yennie-Frautschi-Suura theorem, which employs a local infrared (IR) subtraction to remove divergences and its matching to an all-order resummation of the soft and soft-collinear logarithms.

</details>


### [59] [Isolating chirality-breaking SMEFT operators with Drell-Yan angular analysis](https://arxiv.org/abs/2512.05018)
*Samuele Grossi,Xu Li,Lorenzo Rolla,Riccardo Torre*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a comprehensive strategy to isolate the effect of a class of chirality-breaking interactions in the Standard Model Effective Field Theory (SMEFT) by exploiting Drell-Yan angular analysis and the violation of the Lam-Tung relation. Unlike most SMEFT interpretation of Drell-Yan measurements, dominated by growing-with-energy effects generated by the interference of SMEFT-induced and SM amplitudes, this method isolates operators that contribute only quadratically in the Wilson coefficients, allowing for an independent probe of non-interfering operators. Denoting with $v$ the electroweak vev, with $\sqrt{s}$ the center-of-mass energy, and with $Λ$ the scale of new physics, the non-interfering contributions to the amplitude generated by the chirality-breaking operators can be proportional to $v\sqrt{s}/Λ^{2}$ or $s/Λ^{2}$. We argue that these two classes can be further distinguished by analyzing the angular observables of the lepton pair in the transverse momentum and in the invariant mass distribution of the lepton pair. We therefore present an analysis of the lepton-pair angular observables in both these distributions. Based on a precise estimate of the Standard Model contribution to the relevant observables for the $pp\to l^{+}l^{-}+X$ process up to $O(α_{S}^{2})$, we present realistic projections for the sensitivity of the LHC with $300$ fb$^{-1}$ and for the HL-LHC with $3$ ab$^{-1}$ to chirality-breaking interactions, demonstrating that angular observables provide an independent and clean handle on SMEFT effects, especially in regions where the Standard Model contribution is naturally suppressed thanks to the Lam-Tung relation. This analysis becomes crucial to go beyond single parameter global fits, since it helps breaking degeneracies with chirality preserving operators and to disentangle overlapping directions in the EFT parameter space.

</details>


### [60] [Lévy sources in UrQMD in Ar+Sc collisions at SPS energies](https://arxiv.org/abs/2512.05019)
*Barnabas Porfy,Mate Csanad*

Main category: hep-ph

TL;DR: The paper explores three-dimensional two-pion pair source distributions from central Ar-40 plus Sc-45 collisions at SPS energies using the Ultra-Relativistic Quantum Molecular Dynamics model, fitting the data with Lévy-stable distributions to analyze the source's spatial characteristics.


<details>
  <summary>Details</summary>
Motivation: To interpret experimental femtoscopy data through theoretical simulations and extract parameters describing the spatial scale, shape, and strength of the pion emission source.

Method: Generated three-dimensional two-pion pair source distributions using the Ultra-Relativistic Quantum Molecular Dynamics (UrQMD) Monte-Carlo event generator for central Ar-40+Sc-45 collisions at SPS energies. Fitted the distributions with Lévy-stable distributions to extract parameters.

Result: Confirmed that Lévy-stable distributions accurately describe the two-pion source, allowing extraction of parameters that characterize the spatial properties of the emission source.

Conclusion: The application of Lévy-stable distributions provides a robust framework for interpreting femtoscopy data from heavy-ion collisions, offering insights into the dynamic spatial features of the pion emission source.

Abstract: Over the past few decades, progress in femtoscopy has been driven by the interplay between experimental measurements and theoretical calculations. Measurements provide data for the theory to understand it, while theoretical predictions guide new measurements. In the recent decade, several experiments have confirmed that the two-particle pion emitting source is well described by Lévy alpha-stable distributions. To enable theoretical interpretation, phenomenological simulations have been done at RHIC and LHC energies, using various available heavy-ion collision models. In this paper, we investigate three-dimensional two-pion pair source distributions from $^{40}$Ar+$^{45}$Sc central collisions at SPS energies, generated with the Ultra-Relativistic Quantum Molecular Dynamics Monte-Carlo event generator. We fit the pair source with Lévy-stable distributions, and discuss the extracted Lévy parameters describing the spatial scale, shape and strength of the source.

</details>


### [61] [CNN on `Top': In Search of Scalable & Lightweight Image-based Jet Taggers](https://arxiv.org/abs/2512.05031)
*Rajneil Baruah,Subhadeep Mondal,Sunando Kumar Patra,Satyajit Roy*

Main category: hep-ph

TL;DR: The paper proposes a lightweight EfficientNet-based model combined with global jet features for accurate and computationally efficient top-quark jet tagging, outperforming traditional Transformer and GNN methods.


<details>
  <summary>Details</summary>
Motivation: To reduce computational requirements while maintaining high performance in jet classification tasks, especially for distinguishing top-quark jets from light-quark and gluon jets.

Method: Adapting the EfficientNet architecture as a lightweight alternative to Transformers and GNNs, incorporating global jet features into the model.

Result: The proposed method achieves competitive performance in tagging top-quark jets with significantly lower computational cost.

Conclusion: EfficientNet-based models with global features provide an effective and scalable solution for high-energy physics jet classification tasks.

Abstract: While Transformer-based and standard Graph Neural Networks (GNNs) have proven to be the best performers in classifying different types of jets, they require substantial computational power. We explore the scope of using a lightweight and scalable version of the EfficientNet architecture, along with global features of the jet. The end product is computationally inexpensive but is capable of competitive performance. We showcase the efficacy of our network for tagging top-quark jets in a sea of other light-quark and gluon jets.

</details>


### [62] [Exploring asymmetries in three-body cLFV lepton decays: probing CP violation in HNL extensions of the SM](https://arxiv.org/abs/2512.05032)
*Adrian Darricau,Jonathan Kriewald,Ana M. Teixeira*

Main category: hep-ph

TL;DR: The paper explores how additional CP violating phases in Standard Model extensions with Majorana sterile neutrinos affect charged lepton flavor violating (cLFV) decays, focusing on angular observables (parity and time-reversal asymmetries) in 3-body τ/μ decays. It highlights correlations between observables and shows they could provide testable predictions to validate or falsify the model if cLFV signals are detected.


<details>
  <summary>Details</summary>
Motivation: To investigate the impact of CP violation and sterile neutrinos on cLFV processes, and to identify observables that can constrain or validate such extensions of the Standard Model.

Method: The authors analyze parity and time-reversal asymmetries in generic 3-body cLFV decays (ℓₐ⁺ → ℓ_β⁺ℓ_γ⁺ℓ_δ⁻), study correlations between angular observables, and evaluate their sensitivity to CP phases in the extended model framework.

Result: Significant asymmetries in angular distributions are found, which can be utilized to probe CP phases and sterile neutrino effects. Distinct angular patterns are predicted that may allow experimental validation or exclusion of the model upon observation of cLFV events.

Conclusion: These observables offer a promising avenue to test Standard Model extensions with sterile neutrinos, particularly through their unique angular signatures that could either support the model or require modifications if discrepancies arise with observed cLFV signals.

Abstract: In the context of Standard Model extensions via Majorana sterile fermions, the presence of additional CP violating phases (Dirac and Majorana) has been shown to be at source of important effects in charged lepton flavour violating (cLFV) transitions and decays. Here we will consider further angular observables that can be studied for polarised $τ$ and $μ$ cLFV decays. These include, among others, parity asymmetries and time-reversal asymmetries for generic cLFV 3-body decays, $\ell_α^+ \to \ell_β^+ \ell_γ^+ \ell_δ^-$. We address relevant correlations between the different classes of observables, and show that one can have sizeable asymmetries, which can be used to further probe this interesting class of SM extensions. Our study leads to the prediction of particular patterns of angular observables, which would allow to potentially falsify the model, should a cLFV signal be observed.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [63] [The dispersion in pulsar $γ$-ray efficiency](https://arxiv.org/abs/2512.04181)
*Daniel Íñiguez-Pascual,Daniele Viganò,Diego F. Torres*

Main category: astro-ph.HE

TL;DR: Analysis of gamma-ray pulsar observational efficiency shows intrinsic emission mechanism efficiency is the main factor in observed dispersion, peaking at 5-15%, with geometrical effects and distance uncertainties contributing less.


<details>
  <summary>Details</summary>
Motivation: To identify the primary factors contributing to the wide range of pulsar observational efficiencies in the gamma-ray spectrum, specifically the role of beaming, geometries, distance uncertainties, moment of inertia, and emission efficiency.

Method: Estimated distributions of moment of inertia and distance errors, used a geometric/spectral model to fit gamma-ray pulsar light curves and spectra, calculated a priori distributions for beaming, orientation angles, and distance errors to derive the a posteriori intrinsic efficiency distribution.

Result: Intrinsic efficiency peaks at 5-15% with one order of magnitude dispersion. The majority of observational dispersion comes from intrinsic efficiency rather than geometrical factors or measurement uncertainties. Results are robust to distance error assumptions and spin-down correlations.

Conclusion: Gamma-ray emission mechanism inefficiency is the dominant source of observational efficiency variation among pulsars. The methodology provides a framework for testing other emission geometry models.

Abstract: The observational efficiency of pulsars, defined as the ratio of the observationally derived isotropic-equivalent luminosity, $4πd_{obs}^2 F_{obs}$, where $F_{obs}$ is the average pulsed energy flux of a pulsar and $d_{obs}$ is its estimated distance, to its energy budget, shows a wide range of values. This dispersion is believed to be a combination of beaming effects, different geometries, and case-by-case variability of the emission mechanism efficiency, but it is not clear in what proportion. In this work we focused on the gamma-ray range and analysed the four main ingredients that likely contribute to this dispersion: the geometrical term arising from the anisotropic emission (beaming), viewing and inclination angles, the uncertainty on the pulsar distance, the uncertainty on the moment of inertia, and the intrinsic efficiency of the mechanism producing the gamma-ray emission. Estimating the expected ranges of the moment of inertia and the distance errors, and considering a geometrical and spectral model that we have recently used to fit the light curves and spectra of the entire gamma-ray pulsar population, we estimate the a priori distribution of the first three ingredients in order to obtain the a posteriori distribution of the intrinsic efficiency of the mechanism. We found the latter to peak at $\sim 5-15 \%$ and to have a dispersion of around one order of magnitude. That is, we found the intrinsic efficiency of the mechanism to be the leading factor in the observed dispersion. In addition, we found little sensitivity of these results on different distributions of the estimated pulsar distance errors, and saw that the weak, alleged correlation with the spin-down power can only explain part of the observed dispersion. This methodology can be easily applied to other geometrical models of the emission, to test the sensitivity of these results on the beaming distribution.

</details>


### [64] [Asymptotic constraints for 1D planar grey photon diffusion from linear transport with special-relativistic effects](https://arxiv.org/abs/2512.04342)
*Ryan T. Wollaeger,Jim E. Morel,Kendra P. Long,Mathew A. Cleveland,Robert B. Lowrie*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We derive a grey linear diffusion equation for photons with respect to inertial (or lab-frame) space and time, using asymptotic analysis in 1D planar geometry. The solution of the equation is the comoving radiation energy density. Our analysis does not make use of assumptions about the magnitude of velocity; instead we derive an asymptotic scaling in the lab frame such that we avoid apparent non-physical pathologies that are encountered with the standard static-matter scaling. We permit the photon direction to be continuous (as opposed to constraining the analysis to discrete ordinates). The result is a drift-diffusion equation in the lab frame for comoving radiation energy density, with an adiabatic term that matches the standard semi-relativistic diffusion equation. Following a recent study for discrete directions, this equation reduces to a pure advection equation as the velocity approaches the speed of light. We perform preliminary numerical experiments comparing solutions to relativistic lab-frame Monte Carlo transport and to the well-known semi-relativistic diffusion equation.

</details>


### [65] [Solar Cycle Variation of Sustained Gamma Ray Emission from the Sun](https://arxiv.org/abs/2512.04360)
*Nat Gopalswamy,Pertti Mäkelä,Seiji Yashiro,Sachiko Akiyama,Hong Xie,G. Sindhuja*

Main category: astro-ph.HE

TL;DR: The study analyzed the sustained gamma-ray emission (SGRE) events from the Sun during solar cycles 24 and the early phase of 25 using Fermi LAT data. Despite increased solar activity indicators (e.g., sunspot number, CMEs, type II bursts) in SC 25, only 15 SGRE events were observed due to instrumental issues. Three estimation methods predicted 45-47, 46, and 42 SGRE events for SC 25, indicating it is stronger than SC 24.


<details>
  <summary>Details</summary>
Motivation: To determine whether solar cycle 25 is more active than cycle 24 by estimating the expected number of SGRE events despite observational limitations caused by the Fermi LAT's malfunction.

Method: The team used three methods: (1) correlating SGRE counts with FW CMEs/DH type II bursts, (2) applying SC24's association rates of FW CMEs/DH bursts with SGREs to SC25 data, and (3) inferring SGRE events during LAT gaps by linking DH type II bursts with long-duration HXR bursts from Fermi GBM.

Result: All three methods estimated ~42-47 SGRE events for SC25, aligning with increased solar activity metrics (SSN, CMEs, type II bursts) and supporting the conclusion of SC25's stronger activity.

Conclusion: Solar cycle 25 exhibits enhanced activity compared to SC24, evidenced by higher SGRE estimates and other solar/geomagnetic indicators like halo CMEs, GLEs, and intense storms.

Abstract: We investigated the occurrence rate of the sustained gamma ray emission (SGRE) events from the Sun using Fermi Large Area Telescope (LAT) data covering solar cycle (SC) 24 and the rising and maximum phases of SC 25. Due to a solar array drive assembly malfunction starting in March 2018, only small number (15) of SGRE events were observed during SC 25. Over the first 61 months, the average sunspot number (SSN) increased from 56.9 in SC 24 to 79.0 in SC 25. Fast and wide (FW) CMEs and decameter-hectometric (DH) type II bursts also increased significantly in SC 25 by 29% and 33%, respectively when normalized to SSN. Therefore, the increase in solar activity should result in a higher number of SGREs in SC 25. We estimated the number of SGREs in SC 25 using three methods. (i) If the SGRE number varies commensurate FW CMEs and DH type II bursts, SC 25 should have 45-47 SGRE events. (ii) In SC 24, ~17% of FW CMEs and 25% of DH type II bursts were associated with SGRE events. At this rate, SC 25 should have 46 SGRE events. (iii) Since SGRE events are invariably associated with >100 keV hard X-ray (HXR) bursts, we identified DH type II bursts associated with >100 keV HXR bursts from Fermi gamma ray burst monitor (GBM) during LAT data gaps. Based on our finding that SGRE events in SCs 24 and 25 were all associated with HXR bursts of duration > ~5 min, we found only 27 of the 79 LAT-gap type II bursts had >100 keV HXR bursts with duration > ~5 min. These DH type II bursts are likely to indicate SGRE, bringing the total number of SGRE events to 42 (15 observed + 27 inferred). Thus, the three methods provide similar estimates of the number of SGRE events in SC 25. We, therefore, conclude that that SC 25 is stronger than SC 24 based on the estimated number SGRE events. Halo CMEs, ground level enhancement (GLE) events, and intense geomagnetic storms are also consistent with a stronger SC 25.

</details>


### [66] [Mini-supernovae from white dwarf-neutron star mergers: Viewing-angle-dependent spectra and lightcurves](https://arxiv.org/abs/2512.04378)
*Yacheng Kang,Jin-Ping Zhu,Lijing Shao,Jiahang Zhong,Jinghao Zhang,Bing Zhang*

Main category: astro-ph.HE

TL;DR: The study explores how the non-spherical ejecta from WD-NS mergers create viewing-angle-dependent thermal transients, with polar vs. equatorial observers seeing up to 4 mag brightness differences and distinct lightcurve timescales.


<details>
  <summary>Details</summary>
Motivation: To address the limited understanding of how the polar-dominated geometry of WD-NS merger ejecta affects the observed properties of radioactive-powered thermal transients.

Method: Used 2D axisymmetric simulations with semi-analytical discretization to model photospheric evolution, spectra, and lightcurves. Modeled 0.3 Msun ejecta with 0.01 Msun 56Ni, incorporating radioactive heating.

Result: Found peak optical magnitudes vary from -12 (polar) to -16 (equatorial). Off-axis observers see deeper ejecta layers and larger photospheres. Peak occurs 3-10 days post-merger. Term 'mini-supernova' proposed for these transients.

Conclusion: Viewing angle significantly impacts observed properties due to ejecta geometry. This provides observational diagnostics for WD-NS merger detection and adds a new astrophysical transient category.

Abstract: Unstable mass transfer may occur during white dwarf-neutron star (WD-NS) mergers, in which the WD can be tidally disrupted and form an accretion disk around the NS. Such an accretion disk can produce unbound wind ejecta, with synthesized $^{56}\mathrm{Ni}$ mixed in. Numerical simulations reveal that this unbound ejecta should be strongly polar-dominated, which may cause the following radioactive-powered thermal transient to be viewing-angle-dependent. This issue has so far received limited investigation.
  We investigate how the intrinsically non-spherical geometry of WD-NS wind ejecta affects the viewing-angle dependence of the thermal transients. Using a two-dimensional axisymmetric ejecta configuration and incorporating heating from the radioactive decay of $^{56}\mathrm{Ni}$, we employ a semi-analytical discretization scheme to simulate the observed viewing-angle-dependent photospheric evolution, as well as the resulting spectra and lightcurves. The observed photosphere evolves over time and depends strongly on the viewing angle: off-axis observers can see deeper, hotter inner layers of the ejecta and larger projected photospheric areas compared to on-axis observers. For a fiducial WD-NS merger producing 0.3 solar mass of ejecta and 0.01 solar mass of synthesized $^{56}\mathrm{Ni}$, the resulting peak optical absolute magnitudes of the transient span from ~ -12 mag along the polar direction to ~ -16 mag along the equatorial direction, corresponding to luminosities of $10^{40}$-$10^{42}$ erg s$^{-1}$. The typical peak timescales are expected to be 3-10 d. We for the first time explore the viewing-angle effect on WD-NS merger transients. Since their ejecta composition and energy sources resemble those of supernovae, yet WD-NS merger transients are dimmer and evolve more rapidly, we propose using "mini-supernovae" to describe the thermal emission following WD-NS mergers.

</details>


### [67] [Chlorine and Potassium Enrichment in the Cassiopeia A Supernova Remnant](https://arxiv.org/abs/2512.04508)
*XRISM collaboration*

Main category: astro-ph.HE

TL;DR: The paper presents X-ray observations of Cassiopeia A using XRISM, detecting P, Cl, and K, especially K at 6σ. Traditional supernova models underpredict these odd-Z elements, but models incorporating rotation, binaries, or mergers match observations, highlighting their role in element synthesis.


<details>
  <summary>Details</summary>
Motivation: Odd-Z elements like P, Cl, K are vital for life but their origins are unclear as standard supernova models fail to reproduce their abundances. Observations are needed to identify missing mechanisms in models.

Method: High-resolution X-ray spectroscopy with XRISM of the Cassiopeia A supernova remnant to measure abundances of P, Cl, K.

Result: Detected P, Cl, K in Cassiopeia A, with K detected at 6σ. Standard models underproduce these elements by an order of magnitude, while models with rotation, binaries, or mergers align with observed abundances.

Conclusion: Stellar processes like rotation and binary interactions are critical for producing odd-Z elements, resolving discrepancies and showing their importance in cosmic element distribution.

Abstract: The elements in the universe are synthesized primarily in stars and supernovae, where nuclear fusion favors the production of even-Z elements. In contrast, odd-Z elements are less abundant and their yields are highly dependent on detailed stellar physics, making theoretical predictions of their cosmic abundance uncertain. In particular, the origin of odd-Z elements such as phosphorus (P), chlorine (Cl), and potassium (K), which are important for planet formation and life, is poorly understood. While the abundances of these elements in Milky Way stars are close to solar values, supernova explosion models systematically underestimate their production by up to an order of magnitude, indicating that key mechanisms for odd-Z nucleosynthesis are currently missing from theoretical models. Here we report the observation of P, Cl, and K in the supernova remnant Cassiopeia A using high-resolution X-ray spectroscopy with XRISM, with the detection of K at above the 6$σ$ level being the most significant finding. Supernova explosion models of normal massive stars cannot explain the element abundance pattern, especially the high abundances of Cl and K, while models that include stellar rotation, binary interactions or shell mergers agree closely with the observations. Our observations suggest that such stellar activity plays a significant role in supplying these elements to the universe.

</details>


### [68] [The role of distant pulsars in the detectability of continuous gravitational waves](https://arxiv.org/abs/2512.04589)
*Kathrin Grunthal,Nataliya Porayko,David J. Champion,Michael Kramer*

Main category: astro-ph.HE

TL;DR: The study investigates how the separation of Earth and pulsar terms in pulsar timing array (PTA) data affects the detection of continuous gravitational waves (CGWs) from supermassive black hole binaries (SMBHBs). It finds that incorporating more distant pulsars can improve CGW detection and parameter estimation under ideal conditions, though real-world factors like pulsar distribution and array configuration may influence this effect.


<details>
  <summary>Details</summary>
Motivation: The goal is to assess whether resolving Earth and pulsar terms (traditionally treated as noise) can enhance CGW detection in PTA data, particularly exploring if distant pulsars reduce biases and improve sensitivity.

Method: Simulations of PTA datasets under ideal and realistic conditions, comparing Bayesian parameter estimation and frequentist optimal statistic approaches. Analyzes effects of pulsar distance, anisotropic distribution, and effective number of pulsars.

Result: Under ideal scenarios, distant pulsars improve CGW detection via better parameter constraints and reduced biases. Realistic simulations show pulsar distribution and array configurations significantly affect the effectiveness of this approach.

Conclusion: Incorporating distant pulsars benefits CGW searches when other PTA configuration factors are optimized, but practical limitations highlight the need for balanced considerations in experimental design.

Abstract: One of the imminent science goals of pulsar timing arrays (PTAs) is the detection of a continuous gravitational wave (CGW) emitted by an individual supermassive black hole binary (SMBHB). SMBHBs that cause CGWs with GW frequencies $f_\mathrm{GW} > 10 \text{nHz}$ have undergone significant orbital evolution, hence a change of $f_\mathrm{GW}$ over time. In PTA data sets with sufficiently long observational time span, this means that the Earth and pulsar terms' contributions to the CGW signal signature can eventually become resolvable. Since the pulsar term is accumulated incoherently and thus often treated as an additional source of noise, this separation can prove to be beneficial for the detection of the CGW signal in the PTA data set. We aim to investigate to what extent resolvable Earth and pulsar terms affect currently used techniques for CGW searches with PTA data sets, that treat the pulsar term as an additional source noise. We focus on the dependency of the pulsar term frequencies on the pulsar's distance. We aim to answer the question of whether adding more distant pulsars to a PTA data set can mitigate biases and improve the detection of CGWs. We show that under ideal conditions, more distant pulsars can facilitate the CGW search with PTA data sets. Bayesian parameter estimation is yielding better parameter constraints and the frequentist per-frequentist optimal statistic search becomes more stable. However, using the realistic data set simulations, it was found that other configuration parameters of a PTA, such as the anisotropic distribution of pulsars and the effective number of pulsars in a PTA, can play a crucial role to the importance of this effect.

</details>


### [69] [Unveiling gravitational waves from core-collapse supernovae with MUSE](https://arxiv.org/abs/2512.04804)
*Alessandro Veutro,Irene Di Palma,Marco Drago,Pablo Cerdá-Durán,Robin van der Laag,Melissa López,Fulvio Ricci*

Main category: astro-ph.HE

TL;DR: This paper introduces the MUSE pipeline, a convolutional neural network-based method for detecting gravitational waves from core-collapse supernovae by analyzing time-frequency images. Trained on phenomenological waveforms and tested on 3D simulations for the Einstein Telescope, it achieves over 90% detection efficiency for Kuroda2016-like signals at 50 kpc using a 2L detector configuration.


<details>
  <summary>Details</summary>
Motivation: Core-collapse supernovae are potential gravitational wave sources, but their stochastic nature complicates traditional detection methods like matched filtering. A model-independent approach is needed to effectively identify these signals.

Method: The MUSE pipeline uses a CNN to classify time-frequency images of gravitational waveforms. It is trained on waveforms mimicking key features from simulations and tested against 3D simulation data for the Einstein Telescope, considering three detector geometries.

Result: The 2L detector geometry with a 45° inclination achieved the best performance, detecting Kuroda2016-like signals with >90% efficiency at 50 kpc.

Conclusion: MUSE demonstrates promising utility for gravitational wave detection in core-collapse supernovae, particularly with optimized detector configurations like 2L, advancing efforts to study these astrophysical events.

Abstract: The core collapse of a massive star at the end of its life can give rise to one of the most powerful phenomena in the Universe. Because of violent mass motions that take place during the explosion, core-collapse supernovae have been considered a potential source of detectable gravitational waveforms for decades. However, their intrinsic stochasticity makes ineffective the use of modelled techniques such as matched filtering, forcing us to develop model independent technique to unveil their nature. In this work we present MUSE pipeline, which is based on a classification procedure of the time-frequency images using a Convolutional Neural Network. The network is trained on phenomenological waveforms that are built to mimic the main common features observed in numerical simulation. The method is finally tested on a representative 3D simulation catalog in the context of Einstein Telescope, a third generation GW telescope. Among the three detector geometries considered here, the 2L with a relative inclination of $45^\circ$ is the one achieving the best results, thus being able to detect a Kuroda2016-like waveform with an efficiency above $90\%$ at 50 kpc.

</details>


### [70] [Probing TeV Afterglow Emission of GRB~221009A with Gaussian Structured jet in Wind-driven medium](https://arxiv.org/abs/2512.04893)
*T. Mondal,S. Chakraborty,L. Resmi,D. Bose*

Main category: astro-ph.HE

TL;DR: The study proposes a Gaussian structured-jet model to explain TeV afterglows from GRBs, particularly GRB 221009A, highlighting the role of jet geometry and environmental factors in detectability with CTA.


<details>
  <summary>Details</summary>
Motivation: To address recent VHE photon detections in GRB afterglows and refine models by incorporating Gaussian jets and wind-driven environments, moving beyond traditional top-hat jets.

Method: Implementing a Gaussian jet model with adiabatic forward shocks in wind mediums, performing multi-band fits including Klein-Nishina effects and EBL attenuation for GRB 221009A.

Result: TeV peak times and flux depend on jet parameters; only ~10% of simulated events meet CTA sensitivity under wind conditions, favoring certain observational conditions (near core alignment, high energy/density). GRB 221009A's light curves are matched with a mildly off-axis model.

Conclusion: Gaussian jets provide a robust framework for understanding TeV afterglows, emphasizing jet structure and environmental parameters as critical for detectability. Observations like GRB 221009A support this model's validity.

Abstract: Recent detections of very high energy (VHE; GeV-TeV) photons from gamma-ray burst (GRB) afterglows, most notably the extreme event GRB 221009A, require refined models that include realistic jet structures and complex circumburst environments. The jet's angular structure is crucial for shaping afterglow emission. Our recent work demonstrates that Gaussian jets, with their smooth angular decline, naturally produce early bright peaks for on-axis observers and delayed, softer, dimmer peaks at higher inclinations. The gradual decline suppresses excessive lateral expansion, unlike the sharp edge in top-hat jets, making Gaussian jets a compelling alternative to both top-hat and other structured-jet models. Here we implement a Gaussian structured-jet model to explain TeV afterglows from adiabatic forward shocks propagating in a wind-driven medium. We show that the TeV peak time and flux depend sensitively on jet geometry, kinetic energy, wind density, and on microphysical parameter ratios that scale the SSC component. We identify the afterglow parameter space that is favourable for detecting sub-TeV photons with the Cherenkov Telescope Array (CTA), finding that only about ten per cent of simulated TeV events exceed CTA sensitivity in a wind medium. These detections arise from near core-aligned views, with high kinetic energy and wind density, moderate initial Lorentz factor and downstream magnetic field, and a relatively large fraction of energy in nonthermal electrons. Applying this model to GRB 221009A, we perform multi-band fits including wind-modified dynamics, Klein-Nishina effects, and EBL attenuation, and find that a mildly off-axis geometry reproduces the observed X-ray and GeV-TeV light curves.

</details>


### [71] [MALLORN: Many Artificial LSST Lightcurves based on Observations of Real Nuclear transients](https://arxiv.org/abs/2512.04946)
*Dylan Magill,Matt Nicholl,Vysakh Anilkumar,Sjoert van Velzen,Xinyue Sheng,Thai Son Mai,Hung Viet Tran,Ngoc Phu Doan,Thomas Moore,Shubham Srivastav,David R. Young,Charlotte R. Angus,Joshua Weston*

Main category: astro-ph.HE

TL;DR: The paper introduces the MALLORN dataset and a Kaggle challenge to develop photometric classifiers for identifying tidal disruption events (TDEs) in LSST data using simulated light curves based on real observations.


<details>
  <summary>Details</summary>
Motivation: The Vera C. Rubin Observatory's LSST will generate a vast number of transients, requiring prioritization based on photometry due to limited spectroscopic resources. TDEs are critical for studying black hole parameters and accretion physics, necessitating accurate photometric identification methods.

Method: MALLORN uses Gaussian process fitting, SNCosmo spectral energy distributions, and Rubin Survey Simulator baselines to create 10,178 simulated LSST light curves from ZTF observations of TDEs, supernovae, and AGN. The dataset supports a Kaggle challenge for algorithm development.

Result: The dataset and challenge provide a platform to test and improve TDE classifiers, adaptable to other surveys with known photometric characteristics, ensuring readiness for LSST's operation.

Conclusion: MALLORN and the classifier challenge enable community-driven advancements in photometric transient classification, ensuring effective TDE identification and maximizing scientific returns from LSST data.

Abstract: The Vera C. Rubin Observatory's 10-Year Legacy Survey of Space and Time (LSST) is expected to produce a hundredfold increase in the number of transients we observe. However, there are insufficient spectroscopic resources to follow up on all of the wealth of targets that LSST will provide. As such it is necessary to be able to prioritise objects for followup observations or inclusion in sample studies based purely on their LSST photometry. We are particularly keen to identify tidal disruption events (TDEs) with LSST. TDEs are immensely useful for determining black hole parameters and probing our understanding of accretion physics. To assist in these efforts, we present the Many Artificial LSST Lightcurves based on the Observations of Real Nuclear transients (MALLORN) data set and the corresponding classifier challenge for identifying TDEs. MALLORN comprises 10178 simulated LSST light curves, constructed from real Zwicky Transient Facility (ZTF) observations of 64 TDEs, 727 nuclear supernovae and 1407 AGN with spectroscopic labels using Gaussian process fitting, empirically-motivated spectral energy distributions from SNCosmo and the baseline from the Rubin Survey Simulator. Our novel approach can be easily adapted to simulate transients for any photometric survey using observations from another, requiring only the limiting magnitudes and an estimate of the cadence of observations. The MALLORN Astronomical Classification Challenge, launched on Kaggle on 15/10/2025, will allow competitors to test their photometric classifiers on simulated LSST data to find TDEs and improve upon their capabilities prior to the start of LSST.

</details>


### [72] [Intertwined birth and death: a Herbig-Haro outflow resolves the distance to Vela Junior](https://arxiv.org/abs/2512.04956)
*Janette Suherli,Ivo R. Seitenzahl,Samar Safi-Harb,Frédéric P. A. Vogt,Wynn C. G. Ho,Parviz Ghavamian,Chuan-Jui Li,Ashley J. Ruiter,Roland M. Crocker,Arpita Roy,Ralph Sutherland*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The distance to the Vela Junior supernova remnant (RX J0852.0-4622 or G266.2-1.2) has long remained uncertain, limiting our understanding of its physical properties. Using VLT/MUSE integral field spectroscopy, we uncover chemical and kinematic connections between the nebula surrounding its Central Compact Object (CXOU J085201.4-461753) and the nearby Herbig-Haro outflow of Ve 7-27 (Wray 16-30), indicating a shared nitrogen-rich, Fe-peak-enhanced environment. This link ties stellar birth and death, with the young star Ve 7-27 embedded in material expelled by Vela Junior's massive progenitor, and the remnant's blast wave is expanding through the same medium. Adopting the Gaia-based distance to Ve 7-27, we revise Vela Junior's distance to $1.41\pm0.14$ kpc. At this distance, the remnant's physical radius is $23.3\pm2.3$ pc, and X-ray proper motions of the northwestern rim correspond to shock speeds of $(2.8\pm0.7)\times10^3$ to $(5.6\pm1.5)\times10^3$ km s$^{-1}$. These imply an age of $\sim$1.6-3.3 kyr and a very low ambient density, indicating that Vela Junior is expanding within a highly rarefied wind-blown cavity carved by a massive progenitor -- consistent with the non-detection of strong thermal X-ray emission. This distance update also resolves long-standing inconsistencies, with major implications for its energy budget, particle acceleration efficiency, and compact object evolution.

</details>


### [73] [Internal superfluid response and torque evolution in the giant glitch of PSR J1718-3718](https://arxiv.org/abs/2512.04972)
*Peng Liu,Zhonghao Tu,Jianping Yuan,Ang Li*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the post-glitch rotational evolution of pulsars by analyzing the 2007 giant glitch of PSR J1718$-$3718 using a vortex creep model that incorporates both inward and outward nonlinear vortex motion, along with a time-varying external torque. A comprehensive fitting framework is developed, constrained by prior knowledge of moment of inertia participation from previous glitch studies. We apply a Markov Chain Monte Carlo approach to quantify uncertainties and parameter correlations. The model reproduces the observed timing data and yields physically consistent values for moment of inertia fractions and creep timescales. Our results indicate that inward creep and a long-term change in external torque dominate the observed increase in spin-down rate, pointing to structural changes within the star-likely triggered by a crustquake that initiated both vortex motion and a change in the moment of inertia. We estimate that the glitch involved approximately $2.4 \times 10^{12}$ inward-moving vortices and $\sim 142$ crustal plates with a typical size of $\sim 0.03$ km. This study demonstrates that detailed post-glitch modeling of sparse timing data can simultaneously constrain internal superfluid dynamics and external torque evolution, providing a quantitative framework to probe the structural properties of neutron star interiors.

</details>


### [74] [Spectrum and anisotropies of Galactic cosmic rays: a laboratory for magnetic fields](https://arxiv.org/abs/2512.05035)
*Philipp Mertsch*

Main category: astro-ph.HE

TL;DR: The paper reviews recent advancements in understanding Galactic cosmic rays, highlighting observational breakthroughs in spectral measurements and directional anisotropies, theoretical progress in modeling spectral breaks, and emphasizes the critical role of Galactic magnetic fields in limiting precision predictions. It proposes using cosmic rays as a tool to study these magnetic fields.


<details>
  <summary>Details</summary>
Motivation: To summarize the current state of knowledge on Galactic cosmic ray spectra and anisotropies, identify gaps in understanding, particularly regarding Galactic magnetic fields, and outline future research opportunities.

Method: Reviews observations from direct detection and air shower array data, discusses theoretical models explaining spectral features, and analyzes the impact of magnetic field uncertainties on cosmic ray studies.

Result: Observations confirm spectral breaks and anisotropies in cosmic ray nuclei; theoretical models offer plausible explanations for these features, but magnetic field uncertainties remain a key challenge. The potential of cosmic rays as probes of Galactic magnetic fields is established.

Conclusion: Advances in cosmic ray studies underscore the need for better knowledge of Galactic magnetic fields. Future research should focus on leveraging cosmic rays to investigate these fields, bridging observational and theoretical gaps for precise predictions.

Abstract: Much has been learned about Galactic cosmic rays in the past decade: On the observational side, the spectra of cosmic ray nuclei have been directly measured with high precision, resolving chemical composition up to TV rigidities. At even higher rigidities, direct detection is making contact with indirect observations from air shower arrays. A number of breaks have been found in the nuclear spectrum, which was previously thought to be a pure power law up to the knee. Data from air shower arrays also show interesting features in the arrival directions of cosmic-ray nuclei. On the theoretical side, more sophisticated models are able to explain the various spectral breaks either with transitions between different classes of sources or with changes in the transport regime. Yet, it has become clear that our ignorance of the structure of the Galactic magnetic fields, both on large and small scales, is limiting precision predictions. Turning this problem into an opportunity though, we can use Galactic cosmic rays as a laboratory for the study of Galactic magnetic fields. In this review talk, delivered at the 39th International Cosmic Ray Conference (ICRC2025), I have summarised what is known about the spectrum and anisotropies of Galactic cosmic rays, what is not known yet and what can be learnt in the future.

</details>


### [75] [PSR J0952-0607: Tightening a Record-High Neutron Star Mass](https://arxiv.org/abs/2512.05099)
*Roger W. Romani,Maya Beleznay,Alexei V. Filippenko,Thomas G. Brink,WeiKang Zheng*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We report on new orbit-minimum photometry and revised radial-velocity fitting that provide an improved measurement of the mass of the neutron star (NS) in pulsar PSR~J0952$-$0607 at $M_NS = 2.35\pm 0.11 M_\odot$. With its fast spin and unusually low magnetic field, this NS has evidently experienced unusual evolution, likely connected with its high mass, which is now $2.5σ$ above that of the heaviest pulsar with a white dwarf companion, as measured by Shapiro delay techniques. By tightening the mass measurement, we also raise the maximum (commonly called Tolman-Oppenheimer-Volkoff) NS mass to $M_{\rm TOV} > 2.27\,M_\odot$$(2.12\,M_\odot)$ at $1σ$$(3σ)$ confidence, which improves bounds on the dense-matter equation of state. While the statistical error decreases and systematic issues should be modest, uncertainties remain; we comment briefly on these factors and prospects for further improvement.

</details>
