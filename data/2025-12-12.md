<div id=toc></div>

# Table of Contents

- [astro-ph.IM](#astro-ph.IM) [Total: 8]
- [gr-qc](#gr-qc) [Total: 23]
- [hep-ph](#hep-ph) [Total: 28]
- [astro-ph.HE](#astro-ph.HE) [Total: 18]


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [1] [Decisively Demonstrating Roman CGI's TTR5 Requirement by Reimaging a Newly-Discovered Brown Dwarf Orbiting a Bright Accelerating Star](https://arxiv.org/abs/2512.09977)
*Thayne Currie,Brianna Lacy,Mona El Morsy,Masayuki Kuzuhara,Naoshi Murakami,Danielle Bovie*

Main category: astro-ph.IM

TL;DR: The Roman Coronagraph project's HLC/575 nm observations target HIP 71618 B, a newly-discovered brown dwarf from the Subaru/OASIS survey, to fulfill TTR5 requirements. This detection would be the first optical detection of a companion at <1e-6 contrast. The study recommends using nearby bright reference stars within the Roman Continuous Viewing Zone to ensure high SNR and successful tech demo, with future OASIS targets enhancing CGI flexibility.


<details>
  <summary>Details</summary>
Motivation: The motivation is to meet TTR5 requirements for the Roman Coronagraph's tech demonstration phase by observing HIP 71618 B, a young, accelerating brown dwarf. The need arises from the necessity of high-contrast imaging targets that can be reliably observed with reference stars for calibration, ensuring mission success.

Method: The method involves HLC/575 nm observations of HIP 71618 B using the Roman Coronagraph. They utilize nearby bright PSF reference stars within the Continuous Viewing Zone to achieve high SNR. Collaboration with the CPP team ensures scheduling and vetting of reference stars compatible with HIP 71618 B's observation.

Result: A high SNR detection of HIP 71618 B would fulfill TTR5 and mark the first optical detection at <1e-6 contrast. Future OASIS targets will potentially provide more reference stars, increasing CGI scheduling flexibility and enhancing scientific returns.

Conclusion: This project highlights HIP 71618 B as a critical target for the Roman Coronagraph's tech demo. Close collaboration with CPP for reference star vetting is essential. Continued OASIS surveys will discover more targets, bolstering mission success and flexibility.

Abstract: We propose Roman Coronagraph project HLC/575 nm observations of a newly-discovered brown dwarf (HIP 71618 B) from the Subaru/OASIS survey of young accelerating stars, which is supported by NASA headquarters with the directive to identify targets for the Roman Coronagraph that could fulfill TTR5 requirements and be observed during the technology demonstration phase. The target and multiple bright PSF references are within/close to the Roman Continuous Viewing Zone. A high SNR detection of this companion would singlehandedly fulfill TTR5 and would be the first optical detection of a companion at $<$10$^{-6}$ contrast.
  Roman CPP reference star vetting prioritizing stars that can be paired with HIP 71618 would aid the execution of a successful technology demonstration. Additional similar targets may be discovered from OASIS over the next few years that could increase CGI scheduling flexibility and enhance its scientific and technical return. A close collaborative partnership with the CPP team could ensure that they are schedulable.

</details>


### [2] [The SPace-based InterFerometer Feasibility (SPIFF) Project: Enabling Future High-Resolution Astronomy Across the EM Spectrum](https://arxiv.org/abs/2512.10009)
*Berke Vow Ricketti,Victoria Yankelevich,Chris Benson,Renske Smit,Sebastian Kamann,Ettore Pedretti,Sebastian Marino,Gerard van Belle,Stephen Eales,Chris Bee,Mark Wyatt,Matthew Smith,Tim D. Pearce,Emily Williams,Rebecca Harwin,David Pearson,Andy Vick,Giorgio Savini,Taro Matsuo,Hiroshi Matsuo,Locke Spencer,David T. Leisawitz*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A plethora of astronomical science cases can only be achieved with high angular resolution observations, and we can expect the number of these to grow as astronomers are constrained by the size limitations of single-aperture space telescopes, making space-based interferometry inevitable. However, the enabling technologies do not have flight heritage at the system level, and the concept remains immature to much of the community, meaning no direct-detection synthetic-aperture space-based interferometer has yet flown and an opportunity exists for the UK to take a world leading role. Here we propose the SPace-based InterFerometry Feasibility (SPIFF) Project as a program to address both issues simultaneously by: 1) completing a thorough survey of the science cases across the EM spectrum that would directly benefit from, or be impossible without, space-based interferometry; 2) down selecting key requirements via a Science Traceability Matrix mapping exercise; 3) host a workshop for the UK astronomical community to consolidate these findings; 4) build a technology demonstration mission to raise TRL and achieve flight heritage of critical technologies. Such a program positions the UK as the partner of choice for any future NASA or ESA space-based interferometry mission, allowing the UK to lead groundbreaking scientific discoveries, while also directly benefiting the UK industrial base by advancing domestic exportable technologies and building direct synergy with other UK space priorities. Indeed, the UK is uniquely positioned to lead in space-based interferometry, possessing a rare trifecta of domestic strengths: world-class expertise in ground-based interferometry and space-based instrumentation; commercial entities developing mission-critical technologies; and scientists whose research spans the full range of science cases that would benefit directly from space-based interferometry.

</details>


### [3] [MorphZ: Enhancing evidence estimation through the Morph approximation](https://arxiv.org/abs/2512.10283)
*El Mehdi Zahraoui,Patricio Maturana-Russel,Avi Vajpeyi,Willem van Straten,Renate Meyer,Sergei Gulyaev*

Main category: astro-ph.IM

TL;DR: The paper introduces MorphZ, an efficient method for estimating marginal likelihood using the Morph approximation in optimal bridge sampling. It works with posterior samples and provides accurate results at lower computational costs across various applications.


<details>
  <summary>Details</summary>
Motivation: To develop a method that accurately estimates marginal likelihood with reduced computational cost, compatible with any posterior sampling technique and applicable across a range of problem dimensionalities.

Method: Morph approximation selects low-order disjoint parameter blocks by maximizing total correlations. This approximation is used as an importance distribution in optimal bridge sampling, denoted as MorphZ, requiring only posterior samples, prior, and likelihood.

Result: MorphZ achieves accurate evidence estimation with lower computational costs than standard methods across statistical benchmarks, PTA models, CBC GW simulations, and the GW150914 event. It provides conservative uncertainty estimates and works even with incomplete posterior coverage.

Conclusion: MorphZ complements existing samplers by enabling fast, reliable evidence estimation directly from posterior draws, seamlessly integrating into inference workflows without requiring changes to the sampling process.

Abstract: We introduce the Morph approximation, a class of product approximations of probability densities that selects low-order disjoint parameter blocks by maximizing the sum of their total correlations. We use the posterior approximation via Morph as the importance distribution in optimal bridge sampling. We denote this procedure by MorphZ, which serves as a post-processing estimator of the marginal likelihood. The MorphZ estimator requires only posterior samples together with the prior and likelihood, and is fully agnostic to the choice of sampler. We evaluate MorphZ's performance across statistical benchmarks, pulsar timing array (PTA) models, compact binary coalescence (CBC) gravitational-wave (GW) simulations and the GW150914 event. Across these applications, spanning low to high dimensionalities, MorphZ yields accurate evidence at substantially reduced computational cost relative to standard approaches, and can improve these estimates even when posterior coverage is incomplete. Its bridge sampling relative error diagnostic provides conservative uncertainty estimates. Because MorphZ operates directly on posterior draws, it complements exploration-oriented samplers by enabling fast and reliable evidence estimation, while it can be seamlessly integrated into existing inference workflows.

</details>


### [4] [Estimating stellar atmospheric parameters and elemental abundances using fully connected residual network](https://arxiv.org/abs/2512.10345)
*Shuo Li,Yin-Bi Li,A-Li Luo,Jun-Chao Liang,Hai-Ling Lu,Hugh R. A. Jones*

Main category: astro-ph.IM

TL;DR: The study introduces FCResNet, a neural network that excels at analyzing ultra-low-resolution spectra from the CSST. It outperforms traditional methods in estimating stellar parameters and elemental abundances with high precision and efficiency.


<details>
  <summary>Details</summary>
Motivation: Traditional template matching methods are inadequate for noisy ultra-low-resolution spectra like those from the upcoming CSST, necessitating a more effective analysis tool.

Method: FCResNet was trained on CSST-like spectra (R~200) derived from degraded LAMOST data, using APOGEE labels. It simultaneously estimates $T_\text{eff}$, $\log g$, [Fe/H], and abundance ratios [C/Fe], [N/Fe], [Mg/Fe].

Result: FCResNet achieved superior precision over KNN, XGBoost, SVR, and CNN. For SNR>20 spectra, precisions include 78 K for $T_\text{eff}$ and 0.05–0.15 dex for other parameters. It processes one million spectra in 42 seconds with a compact 348 KB model.

Conclusion: FCResNet is a practical, efficient solution for handling the massive ultra-low-resolution spectral data expected from CSST, offering both accuracy and computational efficiency.

Abstract: Stellar atmospheric parameters and elemental abundances are traditionally determined using template matching techniques based on high-resolution spectra. However, these methods are sensitive to noise and unsuitable for ultra-low-resolution data. Given that the Chinese Space Station Telescope (CSST) will acquire large volumes of ultra-low-resolution spectra, developing effective methods for ultra-low-resolution spectral analysis is crucial. In this work, we investigated the Fully Connected Residual Network (FCResNet) for simultaneously estimating atmospheric parameters ($T_\text{eff}$, $\log g$, [Fe/H]) and elemental abundances ([C/Fe], [N/Fe], [Mg/Fe]). We trained and evaluated FCResNet using CSST-like spectra (\textit{R} $\sim$ 200) generated by degrading LAMOST spectra (\textit{R} $\sim$ 1,800), with reference labels from APOGEE. FCResNet significantly outperforms traditional machine learning methods (KNN, XGBoost, SVR) and CNN in prediction precision. For spectra with g-band signal-to-noise ratio greater than 20, FCResNet achieves precisions of 78 K, 0.15 dex, 0.08 dex, 0.05 dex, 0.10 dex, and 0.05 dex for $T_\text{eff}$, $\log g$, [Fe/H], [C/Fe], [N/Fe] and [Mg/Fe], respectively, on the test set. FCResNet processes one million spectra in only 42 seconds while maintaining a simple architecture with just 348 KB model size. These results suggest that FCResNet is a practical and promising tool for processing the large volume of ultra-low-resolution spectra that will be obtained by CSST in the future.

</details>


### [5] [Near Ultraviolet Transient Explorer (NUTEx): A CubeSat-Based NUV Imaging Payload for Transient Sky Surveys](https://arxiv.org/abs/2512.10538)
*Shubham Ghatul,Rekhesh Mohan,Jayant Murthy,Margarita Safonova,Praveen Kumar,Maheswar Gopinathan,Shubhangi Jain,Mahesh Babu S*

Main category: astro-ph.IM

TL;DR: NUTEx is a CubeSat-based NUV imaging payload for transient sky surveys, featuring a Ritchey-Chretien telescope and MCP detector. It targets sensitivity and wide field of view for detecting events like supernova remnants and flaring stars, with a 2026 launch.


<details>
  <summary>Details</summary>
Motivation: CubeSats offer cost-effective and versatile platforms for space exploration, making NUTEx an economical solution for transient detection in the NUV range, which is currently underserved.

Method: Uses a Ritchey-Chretien telescope with a 146 mm primary mirror, a photon-counting MCP detector with solar-blind photocathode, and custom readout electronics. The design includes structural analysis for the payload's mechanical and electronic subsystems.

Result: Achieves 4-degree FoV, 18 sq cm effective area at 260 nm, and 21 AB magnitude sensitivity. Readiness for 2026 launch is confirmed, with detailed design and subsystem overviews presented.

Conclusion: NUTEx offers a pioneering low-cost approach to NUV transient observation, filling observational gaps. The design supports its scientific goals, and upcoming development will prepare it for its mission objectives.

Abstract: The Near Ultraviolet Transient Explorer (NUTEx) is a CubeSat-based near-ultraviolet (NUV) imaging payload designed for transient sky surveys and is currently under development. CubeSats are compact and cost-effective satellite platforms that have emerged as versatile tools for scientific exploration and technology demonstrations in space. NUTEx is an imaging telescope operating in the 200-300 nm wavelength range, intended for deployment on a micro-satellite bus. The optical system is based on a Ritchey Chretien (RC) telescope configuration, featuring a 146 mm primary mirror. The detector is a photon-counting microchannel plate (MCP) device with a solar-blind photocathode, paired with an in-house developed readout unit. The instrument has a wide field of view (FoV) of 4 deg, a peak effective area of approximately 18 sq cm at 260 nm, and can reach a sensitivity of 21 AB magnitude (SNR = 5) in a 200 second exposure. The primary scientific objective of NUTEx is to monitor the night sky for transient phenomena, such as supernova remnants, flaring M-dwarf stars, and other short-timescale events. The payload is currently scheduled for launch in Q2 2026. This paper presents the NUTEx instrument design, outlines its scientific goals and capabilities, and provides an overview of the electronics and mechanical subsystems, including structural analysis.

</details>


### [6] [FAST-MEPSA: an optimised and faster version of peak detection algorithm MEPSA](https://arxiv.org/abs/2512.10579)
*Manuele Maistrello,Romain Maccary,Cristiano Guidorzi*

Main category: astro-ph.IM

TL;DR: FAST-MEPSA is an optimized version of the MEPSA algorithm designed to efficiently detect peaks in uniformly sampled time series with Gaussian noise. It introduces a sparser scanning strategy for speed improvements (up to 400x faster at high re-binning) and a new 40th pattern to capture sub-threshold peaks on broader structures. Validated on simulated GRB data, it maintains detection efficiency with lower false positives, offering a trade-off between speed and accuracy.


<details>
  <summary>Details</summary>
Motivation: The original MEPSA algorithm, while effective for detecting peaks in gamma-ray burst light curves, faced significant computational costs at large re-binning factors and struggled to detect certain faint, sub-threshold peaks. The motivation was to enhance computational efficiency without sacrificing performance and to improve detection of elusive peak types.

Method: FAST-MEPSA employs two key improvements: (1) a sparser offset-scanning strategy to reduce computational load, achieving near 400x speed-up at high re-binning; and (2) a new 40th pattern targeting sub-threshold peaks on rising edges of broader structures. The algorithm still uses 39 original predefined patterns but adds this additional pattern for enhanced coverage.

Result: Testing on simulated GRB light curves showed FAST-MEPSA retains detection efficiency with only a 4% reduction in detected peaks, while significantly reducing false positives for low-significance events. The new 40th pattern increased recovery of previously missed sub-threshold peaks, offering improved sensitivity for faint events.

Conclusion: FAST-MEPSA provides a critical balance of speed and accuracy for large-scale analyses, especially in scenarios requiring robust detection of both common and faint transient phenomena. The 40-pattern version is recommended when prioritizing detection of subtle peaks, making the algorithm a versatile tool for time series analysis in fields like astrophysics.

Abstract: We present FAST-MEPSA, an optimised version of the MEPSA algorithm developed to detect peaks in uniformly sampled time series affected by uncorrelated Gaussian noise. Although originally conceived for the analysis of gamma-ray burst (GRB) light curves (LCs), MEPSA can be readily applied to other transient phenomena. The algorithm scans the input data by applying a set of 39 predefined patterns across multiple timescales. While robust and effective, its computational cost becomes significant at large re-binning factors. To address this, FAST-MEPSA introduces a sparser offset-scanning strategy. In parallel, building on MEPSA's flexibility, we introduce a 40th pattern specifically designed to recover a class of elusive peaks that are typically sub-threshold and lie on the rising edge of broader structures - often missed by the original pattern set. Both versions of FAST-MEPSA - with 39 and 40 patterns - were validated on simulated GRB LCs. Compared to MEPSA, the new implementation achieves a speed-up of nearly a factor 400 at high re-binning factors, with only a minor (~4%) reduction in the number of detected peaks. It retains the same detection efficiency while significantly lowering the false positive rate of low significance. The inclusion of the new pattern increases the recovery of previously undetected and sub-threshold peaks. These improvements make FAST-MEPSA an effective tool for large-scale analyses where a robust trade-off between speed, efficiency, and reliability is essential. The adoption of 40 patterns instead of the classical 39 is advisable when an enhanced efficiency in detecting faint events is desired. The code is made publicly available.

</details>


### [7] [Reaching diffraction-limited localization with coherent PTAs](https://arxiv.org/abs/2512.10795)
*Anna C. Tsai,Dylan L. Jow,Ue-Li Pen*

Main category: astro-ph.IM

TL;DR: The paper proposes a coherent map-making technique using precise pulsar distances to achieve diffraction-limited angular resolution in pulsar timing array (PTA) analyses, significantly enhancing detection sensitivity and enabling multi-messenger astronomy.


<details>
  <summary>Details</summary>
Motivation: Current PTA analyses underutilize pulsar distance information, limiting angular resolution and missing potential doubled detection sensitivity for gravitational-wave (GW) sources. Improving this could enable identification of electromagnetic counterparts.

Method: Develops a coherent map-making method incorporating precise pulsar distances to reach the diffraction limit ($δθ_{diff} ≈ 2$ arcmin), using SNR and source parameters. Demonstrates improvements with more pulsars with high SNR timing and distances.

Result: Shows that with SNR=10 and ~9 pulsars, diffraction limit is achieved. Resolution improves as $(1/SNR)^{N_{dist}/2}$, with each additional precise-distance pulsar boosting resolution by ~10x. Highlights PSR J0437-4715's sub-parsec distance as a key example.

Conclusion: A coherent PTA analysis fully using pulsar distance data is now feasible and critical for maximizing GW source localization and multi-messenger astronomy potential.

Abstract: Current pulsar timing array (PTA) analyses do not take full advantage of pulsar distance information, thereby missing out on improved angular resolution and on a potential factor-of-two gain in detection sensitivity for individual gravitational-wave (GW) sources. In this work, we investigate the impact of precise pulsar distance measurements on angular resolution as an extension to previous work measuring the angular resolution of a dense, isotropic PTA [Jow et al., 2025]. We present a coherent map-making technique that utilizes precise pulsar distance measurements to reach the diffraction-limited resolution of an individual source: $δθ_{\mathrm{diff}} \sim (1/\mathrm{SNR})(λ_{\mathrm{GW}}/r) \approx 2~\mathrm{arcmin}$, where the SNR refers to the detection strength of the source. With this level of angular resolution, identifying an EM counterpart may become feasible, enabling multi-messenger follow-up. We show that for $\rm SNR=10$, which may be the current sensitivity level using a coherent analysis, the diffraction limit is reached with roughly 9 pulsars. Moreover, angular resolution scales sharply with the number of known pulsar distances as $\sim (1/\mathrm{SNR})^{N_{\mathrm{dist}}/2}$. Thus, each additional pulsar with high signal-to-noise timing and precise distance measurement can improve PTA resolution by an order of magnitude. The distance to the best-timed millisecond pulsar (PSR J0437$-$4715) is already constrained to sub-parsec levels. We argue, therefore, that a coherent analysis of PTA data, fully incorporating pulsar distance information, is timely.

</details>


### [8] [A vision for ground-based astronomy beyond the 2030s: How to build ESO's next big telescope sustainably](https://arxiv.org/abs/2512.10902)
*Laurane Fréour,Mathilde Bouvier,Tony Mroczkowski,Callie Clontz,Fatemeh Zahra Majidi,Vasundhara Shaw,Olivier Absil,Anna Cabré,Olivier Lai,Dylan Magill,Jake D. Turner*

Main category: astro-ph.IM

TL;DR: The paper emphasizes the urgency for astronomers, particularly the European Southern Observatory (ESO), to reduce their carbon footprint by proposing sustainable guidelines for their next-generation facilities under the Expanding Horizons programme, ensuring Earth's protection for future cosmic exploration.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the threat of climate change to Earth, theonly known habitat for life, and safeguard the ability of future generations to continue astronomical research. Astronomical facilities, being a major source of the community's carbon emissions, necessitate immediate action.

Method: The authors propose specific environmental sustainability guidelines for ESO to adopt when planning new astronomical infrastructure. These guidelines likely focus on reducing carbon emissions, promoting renewable energy use, and integrating environmental impact assessments into facility development.

Result: The proposed guidelines aim to minimize the carbon footprint of ESO's next-generation facilities, setting a precedent for sustainable practices in astronomy. This could lead to reduced environmental harm while advancing astronomical research.

Conclusion: The paper concludes that prioritizing sustainability in astronomical projects is both ethically imperative and essential for preserving Earth's habitability. By implementing these guidelines, the astronomy community can ensure it does not contribute to the very environmental crises that threaten its future.

Abstract: Astronomy is the study of the Universe and all the objects that it comprises. Our attention is therefore usually focused beyond Earth, home to the only form of life known today. However, how can we continue to explore the secrets of the Universe, if we stand by and watch our only home burn? We know that there is no Planet B. It is therefore urgent that, as astronomers, we collectively work to protect the Earth, allowing future generations the opportunity to continue to uncover the secrets of the cosmos. As astronomical facilities account for the majority of our community's carbon footprint, we propose guidelines that we hold crucial for the European Southern Observatory (ESO) to consider in the context of the Expanding Horizons programme as it plans a next-generation, transformational facility.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [9] [Blandford-Znajek Jets and the Total Angular Momentum Evolution of a Black Hole Connected to a Cosmic String](https://arxiv.org/abs/2512.09966)
*Ishan Swamy,Deobrat Singh*

Main category: gr-qc

TL;DR: The paper explores the impact of cosmic strings on rotating black hole jet dynamics via the Blandford-Znajek mechanism, showing inverse μ² dependence in jet energy flux and potential observational signatures for cosmic string detection.


<details>
  <summary>Details</summary>
Motivation: To understand how cosmic strings influence rotational energy extraction from black holes, their effect on jet properties, and possible observational evidence for cosmic strings.

Method: Analytical modeling of black hole-cosmic string systems, considering accretion, jets, cosmic string interaction, and Bardeen-Petterson effects. Derived jet energy flux dependence on cosmic string tension μ and analyzed black hole spin-down conditions.

Result: Jet energy flux inversely proportional to μ²; spin-down possible for both small and large μ (more likely at high μ). Found jet alignment with cosmic strings and disk warping via Bardeen-Petterson effect. Proposed observational detection method for cosmic strings through these effects.

Conclusion: Cosmic string interactions significantly alter black hole jet dynamics and spin evolution, offering a viable pathway for indirect cosmic string detection via astrophysical observations.

Abstract: Rotating black holes with strong magnetic fields lead to an outward energy flux in the form of jets governed by the Blandford-Znajek mechanism. These jets depend on factors such as accretion rate, magnetic flux and the spin of the black hole. When such rotating black holes get attached to a cosmic string, it leads to a further rotational energy extraction, leading to a reduced spin. We consider such a system and investigate the effect this reduced spin has on the jet power and its dependence on the cosmic string tension, $μ$. It is shown that for a constant magnetic flux and accretion rate, the jet energy flux is inversely proportional to $μ^2$. Interestingly, the rate of this energy flux varies with time and is again dependent on $μ$. We also study the total angular momentum evolution of the black hole by considering four major effects: accretion, jets, cosmic string energy extraction and the Bardeen-Petterson effect. Further, we attempt to analyse the condition for the spin-down of a black hole due to these effects and find out that it is possible for both small and large string tensions, with a higher possibility for larger string tensions. Another interesting phenomenon that has been proposed is the alignment of the jet with the cosmic string. Additionally, the Bardeen-Petterson effect also leads to alignment or misalignment of the inner and outer disks depending on the alignment of the string. In this manuscript we propose that these results might have an observable effect and hence could serve as a potential detection method for cosmic strings.

</details>


### [10] [Gravitational-wave parameter estimation to the Moon and back: massive binaries and the case of GW231123](https://arxiv.org/abs/2512.09978)
*Francesco Iacovelli,Jacopo Tissino,Jan Harms,Emanuele Berti*

Main category: gr-qc

TL;DR: The Lunar Gravitational-Wave Antenna (LGWA) is a proposed deci-Hz detector that would significantly enhance observations of binary black holes (BBHs), enabling multiband astronomy and improving measurements of intermediate-mass BBH parameters. It could detect ~90 BBH mergers annually out to redshifts z~3-5, with strong synergy between LGWA and next-generation ground-based detectors.


<details>
  <summary>Details</summary>
Motivation: The paper aims to evaluate LGWA's potential to complement existing and future ground-based gravitational-wave detectors, assess its ability to detect BBHs observed in GWTC-4.0 and beyond, and explore opportunities for multiband observations and early warnings for targeted follow-up.

Method: The study assesses LGWA's detectability of past BBH events (up to GWTC-4.0) and simulated populations. Injection studies for a massive BBH (GW231123-like) are performed to quantify parameter measurement capabilities. Comparisons are made with current and future ground-based detectors (design sensitivity, 3G systems).

Result: LGWA alone could detect >1/3 of past BBH events. With 100% duty cycle, ground-based detectors could find thousands/year with hundreds of multiband counterparts. 3G detectors can jointly observe most BBHs in their frequency band. LGWA provides precise chirp mass, sky localization, and inclination even alone, crucial for intermediate-mass BBH studies.

Conclusion: LGWA's deci-Hz band opens new observational windows, improves BBH parameter estimation, enables systematic multiband analysis of hundreds of events annually, and supports early warnings for EM follow-up. It is critical for advancing intermediate-mass BBH astronomy through synergies with ground-based detectors.

Abstract: We study the prospects of the Lunar Gravitational-Wave Antenna (LGWA), a proposed deci-Hz GW detector, to observe binary black holes (BBHs) and enable multiband science with ground-based detectors. We assess the detectability of the events observed by current instruments up to the GWTC-4.0 data release, and of simulated populations consistent with the latest reconstruction by the LIGO-Virgo-KAGRA Collaboration. We find that LGWA alone would have been able to observe more than one third of the events detected so far, and that it could detect $\sim\!90$ events merging in the ground-based band per year out to redshifts $z\sim3-5$. Current detectors at design sensitivity and 100% duty cycle could detect thousands of BBHs per year, with one to a few hundred multiband counterparts in LGWA. Third-generation (3G) detectors can observe most of the BBHs detected by LGWA merging in their frequency band in the simulated mass range $7\,{\rm M}_\odot\lesssim M_{\rm tot}\lesssim 600\,{\rm M}_\odot$, enabling systematic joint analyses of hundreds of events. The short time to merger from the deci-Hz band to the Hz-kHz band (typically months to a year) allows for early warning, targeted follow-up, and archival searches. Multiband observations of intermediate-mass BBHs in the deci-Hz band are particularly promising. We perform an injection study for a GW231123-like system (the most massive BBH detection to date, which accumulates $\sim 10^5$ inspiral cycles in LGWA) and show that deci-Hz observations can measure the chirp mass even better than 3G instruments and yield good sky localization and inclination measurement, even with a single observatory. Opening the deci-Hz band would substantially improve the prospects of GW astronomy for intermediate-mass BBHs.

</details>


### [11] [Dark matter mounds from the collapse of supermassive stars: a general-relativistic analysis](https://arxiv.org/abs/2512.09985)
*Roberto Caiozzo,Gianfranco Bertone,Piero Ullio,Rodrigo Vicente,Bradley J. Kavanagh,Daniele Gaggero*

Main category: gr-qc

TL;DR: This paper develops a general-relativistic formalism for modeling dark matter 'mounds' around supermassive black holes formed from non-adiabatic collapse, showing significant phase-space distribution changes compared to adiabatic spike models. This advances efforts to use EMRI observations for dark matter and black hole evolution studies.


<details>
  <summary>Details</summary>
Motivation: Existing relativistic treatments of gravitational wave dephasing from dark matter overdensities in EMRIs rely on adiabatic black hole growth models ('spikes'). However, non-adiabatic collapse scenarios producing shallower 'mounds' are more realistic for supermassive black hole formation. A relativistic formalism for this case is needed to accurately predict dark matter distributions and improve observational interpretations.

Method: The authors model the coupled evolution of a supermassive star's collapse into a black hole and the collisionless dark matter dynamics using general relativity. They track phase-space distribution changes during non-adiabatic conditions, focusing on how the distribution function responds to rapid black hole growth disruptions.

Result: Non-adiabatic collapse leads to significant reshaping of the dark matter distribution function, particularly depleting low-binding-energy regions of phase space. This differs from adiabatic models and provides a more realistic distribution for calculating gravitational wave dephasing effects in EMRIs.

Conclusion: The derived distribution function improves predictions for dark matter environments around supermassive black holes, enabling better use of upcoming EMRI observations to probe dark matter properties and black hole formation histories.

Abstract: Recent work has highlighted the importance of a fully relativistic treatment of the dephasing of gravitational waves induced by dark-matter overdensities in extreme mass-ratio inspirals (EMRIs). However, a general-relativistic description of the dark matter phase-space distribution is currently available only for the case of a dark matter "spike" arising from adiabatic black hole growth. Here we develop a fully general-relativistic formalism for the more realistic scenario in which a supermassive stellar progenitor collapses to a black hole and produces a shallower dark matter overdensity, or "mound". We follow self-consistently the evolution of the supermassive star, its collapse, and the subsequent growth of the resulting black hole, together with the collisionless dark matter orbits. We find that in the regime where the collapse becomes non-adiabatic, the dark matter distribution function is significantly reshaped, with a clear depletion in the low-binding-energy region of phase space. Our results provide a more realistic prediction for the dark matter phase-space distribution around supermassive black holes, which is an essential step in our programme to use future EMRI observations to extract information about both the nature of dark matter and the formation history of the black hole.

</details>


### [12] [Formation of extremal Reissner-Nordström black holes: insights from numerics](https://arxiv.org/abs/2512.10008)
*Maxime Gadioux,Harvey S. Reall,Jorge E. Santos*

Main category: gr-qc

TL;DR: Numerical analysis of characteristic gluing in the gravitational collapse of a charged scalar field shows that a minimum black hole mass and maximum scalar field mass-to-charge ratio are required for extremal Reissner-Nordström black hole formation with or without a cosmological constant.


<details>
  <summary>Details</summary>
Motivation: Determine the role of initial scalar field Ansatz and various parameters (mass, cosmological constant) in enabling extremal black hole formation through characteristic gluing.

Method: Numerically investigate characteristic gluing procedure using multiple scalar field Ansätze, analyze effects of scalar mass and cosmological constant on black hole mass and charge requirements.

Result: Gluing feasible only for sufficiently large black hole masses; minimum mass varies per Ansatz. With scalar mass, max allowed mass-to-charge ratio for the scalar field determined per Ansatz. Results hold for nonzero cosmological constants.

Conclusion: Formation of extremal Reissner-Nordström black holes via this mechanism is constrained by both initial data choices and physical parameters, highlighting non-trivial dependencies between Ansatz form and required black hole properties.

Abstract: An extremal Reissner-Nordström black hole can form in finite time in the gravitational collapse of a massless charged scalar field. The proof of this is based on the method of characteristic gluing, which involves making an Ansatz for the scalar field at the horizon. We perform a numerical investigation of the characteristic gluing procedure for several different Ansätze. In each case, gluing is possible only if the final black hole mass is large enough. We find that the minimum required mass varies significantly for different Ansätze. We also consider the effect of including a mass term for the scalar field. In this case, for each Ansatz we determine the maximum mass-to-charge ratio for the scalar field such that gluing is possible. Analogous results are obtained for a non-zero cosmological constant.

</details>


### [13] [Frozen solitonic Hayward-boson stars in Anti-de Sitter Spacetime](https://arxiv.org/abs/2512.10197)
*Shu-Cong Liu,Yong-Qiang Wang,Zhen-Hua Zhao*

Main category: gr-qc

TL;DR: The paper studies solitonic Hayward-boson stars (SHBSs) in AdS spacetime, revealing critical magnetic charge q_c. Solutions termed FSHBSs exhibit frozen states when q ≥ q_c and ω → 0, with matter confined within r_c. q_c depends on Λ and η. High-frequency solutions with higher η approach pure Hayward solutions, while low-frequency solutions show reduced metric components. Extra light rings are found in the second branch.


<details>
  <summary>Details</summary>
Motivation: To explore the properties of SHBSs in AdS spacetime, particularly the influence of magnetic charge q, cosmological constant Λ, and coupling η on their structure and stability, identifying critical behaviors and phase transitions.

Method: Constructed SHBS solutions using the Einstein-Hayward model with a complex scalar field and soliton potential. Analyzed dependence on q, Λ, η, and ω through numerical solutions, focusing on metric components, matter distribution, and effective potential analysis.

Result: Critical charge q_c determines frozen state existence (q ≥ q_c). Matter confinement within r_c and metric suppression beyond. q_c depends on Λ and η. High-frequency solutions with large η yield pure Hayward metrics, while low-frequency solutions show metric component reductions. Extra light rings found in second solution branch.

Conclusion: SHBSs exhibit rich structure influenced by q, Λ, and η, with phase transitions at q_c. The presence of frozen states and additional light rings highlights new phenomena in AdS spacetime, offering insights into gravity-scalar field couplings and potential astrophysical applications.

Abstract: We construct solitonic Hayward-boson stars (SHBSs) in Anti-de Sitter (AdS) spacetime, which consists of the Einstein-Hayward model and a complex scalar field with a soliton potential. Our results reveal a critical magnetic charge $q_c$. For $q\geq q_c$ in the limit of $ω\rightarrow 0$, the matter field is primarily distributed within the critical radius $r_c$, beyond which it decays rapidly, while the metric components $-g_{tt}$ and $1/g_{rr}$ become very small at $r_c$. These solutions are termed ``frozen solitonic Hayward-boson stars" (FSHBSs). Continuously decreasing $Λ$ disrupts the frozen state. However, we did not find a frozen solution when $q<q_c$. The value of $q_c$ depends both on the cosmological constant $Λ$ and the self-interaction coupling $η$. We also found that for high frequency solutions, increasing $η$ can yield a pure Hayward solution. However, for low frequency solutions, increasing $η$ reduces both $1/g_{rr}$ and $-g_{tt}$. Furthermore, we analyzed the effective potential of SHBSs and identified an extra pair of light rings in the second solution branch.

</details>


### [14] [Symmetries of extremal horizons](https://arxiv.org/abs/2512.10200)
*Alex Colling*

Main category: gr-qc

TL;DR: The paper establishes an intrinsic rigidity theorem for extremal horizons in arbitrary dimensions, showing compact cross-sections of rotating extremal horizons under certain energy conditions must admit a Killing vector field. It also demonstrates that under the dominant energy condition, the near-horizon geometry has an enhanced isometry group, leading to modified Aretakis instability effects in specific theories.


<details>
  <summary>Details</summary>
Motivation: To generalize Hawking's rigidity theorem to extremal horizons and understand symmetry enhancements in spacetimes with extremal horizons, particularly how matter fields interact with these symmetries.

Method: The authors used geometric and analytical techniques to derive the rigidity result under null energy conditions. They analyzed near-horizon geometries under dominant energy conditions to identify enhanced isometry groups, explored Aretakis instability shifts in specific theories, and validated their framework using examples like Einstein-Maxwell-Chern-Simons and Yang-Mills theories with charged matter.

Result: Proved compact cross-sections of rotating extremal horizons have Killing symmetries under null energy conditions. Established SO(2,1) or Poincaré group extensions in dominant energy scenarios. Showed Aretakis instability shifts in specific models and confirmed matter fields inherit spacetime symmetries.

Conclusion: The study confirms extremal horizons exhibit enhanced symmetries under standard energy conditions, with implications for black hole uniqueness theorems and stability properties. The inherited matter symmetries suggest deeper connections between spacetime geometry and field behaviors.

Abstract: We prove an intrinsic analogue of Hawking's rigidity theorem for extremal horizons in arbitrary dimensions: any compact cross-section of a rotating extremal horizon in a spacetime satisfying the null energy condition must admit a Killing vector field. If the dominant energy condition is satisfied for null vectors, it follows that an extension of the near-horizon geometry admits an enhanced isometry group containing $SO(2,1)$ or the 2D Poincaré group $\mathbb{R}^2 \rtimes SO(1,1)$. In the latter case, the associated Aretakis instability for a massless scalar field is shifted by one order in the derivatives of the field transverse to the horizon. We consider a broad class of examples including Einstein-Maxwell(-Chern-Simons) theory and Yang-Mills theory coupled to charged matter. In these examples we show that the symmetries are inherited by the matter fields.

</details>


### [15] [Higher curvature corrections to the black hole Wheeler-DeWitt equation and the annihilation to nothing scenario](https://arxiv.org/abs/2512.10272)
*Takamasa Kanai*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We revisit Yeom's annihilation-to-nothing scenario using a modified Wheeler-DeWitt (WDW) equation, incorporating higher curvature corrections. By taking these corrections into account, we show that singularity resolution does not occur within low-energy effective field theory (EFT). Since general relativity (GR) is itself only a low-energy EFT of an underlying ultraviolet (UV) theory, it is unlikely that true singularity resolution can emerge within its domain of validity. Our analysis does not contradict Yeom's conjecture but clarifies that any true resolution of the black hole singularity necessarily requires the inclusion of UV degrees of freedom beyond the scope of GR.

</details>


### [16] [Stationary Stars Are Axisymmetric in Higher Curvature Gravity](https://arxiv.org/abs/2512.10343)
*Nitesh K. Dubey,Sanved Kolekar,Sudipta Sarkar*

Main category: gr-qc

TL;DR: This paper demonstrates that stationary stellar configurations in a broad class of metric theories, including those with higher curvature corrections, must be axisymmetric, extending the axisymmetry theorem beyond general relativity.


<details>
  <summary>Details</summary>
Motivation: To address the gap in understanding axisymmetry for stationary stars in modified gravity theories, as previous results were limited to black holes and general relativity.

Method: Assuming asymptotic flatness and standard smoothness conditions, the authors prove that the interior Killing symmetry (from thermodynamic equilibrium) extends to the exterior, enforcing rotational invariance.

Result: Axisymmetry of stationary stars is a universal property in generally covariant theories, not limited to Einstein gravity, even with higher curvature terms.

Conclusion: The axisymmetry theorem's extension confirms this property is fundamental across gravitational theories, reinforcing its significance in relativistic astrophysics.

Abstract: The final equilibrium stage of stellar evolution can result in either a black hole or a compact object such as a white dwarf or neutron star. In general relativity, both stationary black holes and stationary stellar configurations are known to be axisymmetric, and black hole rigidity has been extended to several higher curvature modifications of gravity. In contrast, no comparable result had previously been established for stationary stars beyond general relativity. In this work we extend the stellar axisymmetry theorem to a broad class of diffeomorphism invariant metric theories. Assuming asymptotic flatness and standard smoothness requirements, we show that the Killing symmetry implied by thermodynamic equilibrium inside the star uniquely extends to the exterior region, thereby enforcing rotational invariance. This demonstrates that axisymmetry of stationary stellar configurations is not a feature peculiar to Einstein gravity but a universal property of generally covariant gravitational theories, persisting even in the presence of higher curvature corrections.

</details>


### [17] [A Nonlocal Realization of MOND that Interpolates from Cosmology to Gravitationally Bound Systems](https://arxiv.org/abs/2512.10513)
*C. Deffayet,R. P. Woodard*

Main category: gr-qc

TL;DR: This paper presents a unified model combining nonlocal modifications of gravity to explain both MOND in galactic systems and cosmological phenomena typically attributed to dark matter, addressing their connection from quantum gravity effects.


<details>
  <summary>Details</summary>
Motivation: To reconcile the observed gravitational effects in galaxies (MOND) with cosmological dark matter phenomena using a single nonlocal gravity framework that stems from quantum gravitational corrections.

Method: Develop a phenomenological model that interpolates between MOND regimes (for bound systems) and cosmological dark matter-like behavior (for large-scale structure and CMB/BAO), leveraging nonlocal gravitational modifications derived from quantum stress tensor corrections.

Result: The model successfully unifies explanations for both galactic dynamics and cosmological observations without requiring dark matter, showing consistency with CMB, BAO, and structure formation data.

Conclusion: Nonlocal gravity modifications originating from quantum effects can unify MOND and dark matter phenomena, offering a pathway to a theory of quantum gravity that addresses multiple observational puzzles in one theoretical framework.

Abstract: Nonlocal modifications of gravity derive from corrections to the quantum gravitational stress tensor which grow nonperturbatively strong during primordial inflation and may persist to the current epoch. Phenomenological constructions have been given that realize MOND in gravitationally bound systems and, separately, reproduce all the cosmological phenomena usually ascribed to dark matter, including the cosmic microwave background radiation, baryon acoustic oscillations and linearized structure formation. In this work we exhibit a single model that interpolates between the two regimes.

</details>


### [18] [BinaryGFH-v2: Improved method to search for gravitational waves from sub-solar-mass, ultra-compact binaries using the Generalized Frequency-Hough Transform](https://arxiv.org/abs/2512.10539)
*Andrew L. Miller,Lorenzo Pierini*

Main category: gr-qc

TL;DR: This paper proposes a new method called BinaryGFH-v2 to detect gravitational waves from sub-solar-mass compact binaries, addressing a previously unexplored mass range using modified pattern-recognition techniques.


<details>
  <summary>Details</summary>
Motivation: To search for primordial black holes via gravitational waves from sub-solar-mass binaries, which have been undetectable with existing methods due to signal duration constraints.

Method: Improves the Generalized frequency-Hough (GFH) technique to handle rapidly spinning-up binaries and enhance statistical robustness, creating BinaryGFH-v2. Designs a hypothetical search and compares empirical/theoretical sensitivities.

Result: Demonstrates the method's effectiveness in detecting signals in the unconstrained mass range and projects constraints on primordial black hole formation rates and dark matter fraction.

Conclusion: BinaryGFH-v2 enables new gravitational-wave searches for sub-solar-mass binaries, opening a observational window into primordial black holes and dark matter.

Abstract: Observing gravitational waves from sub-solar-mass, inspiraling compact binaries would provide almost smoking-gun evidence for primordial black holes. Here, we develop a method to search for ultra-compact binaries with chirp masses ranging from $[10^{-2},10^{-1}]M_\odot$. This mass range represents a previously unexplored gap in gravitational-wave searches for compact binaries: it was thought that the signals would too long for matched-filtering analyses but too short for time-frequency pattern-recognition techniques. Despite this, we show that a pattern-recognition technique, the Generalized frequency-Hough (GFH), can be employed with particular modifications that allow us to handle rapidly spinning-up binaries and to increase the statistical robustness of our method, and call this improved method BinaryGFH-v2. We then design a hypothetical search for binaries in this mass regime, compare the empirical and theoretical sensitivities of this method, and project constraints on formation rate densities and the fraction of dark matter that primordial black holes could compose in both current- and future-generation gravitational-wave detectors. Our results show that our method can be used to search for sub-solar-mass, ultra-compact objects in a mass regime that remains to-date unconstrained with gravitational waves.

</details>


### [19] [Nonlinear evolution of the ergoregion instability: Turbulence, bursts of radiation, and black hole formation](https://arxiv.org/abs/2512.10526)
*Nils Siemonsen,William E. East*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Spacetimes with an ergoregion that is not connected to a horizon are linearly unstable. While the linear regime has been studied in a number of settings, little is known about the nonlinear evolution of this ergoregion instability. Here, we investigate this by numerically evolving the unstable growth of a massless vector field in a rapidly spinning boson star in full general relativity. We find that the backreaction of the instability causes the star to become more gravitationally bound, accelerating the growth, and eventually leading to black hole formation. During the nonlinear growth phase, small scale features develop in the unstable mode and emitted radiation as nonlinear gravitational interactions mediate a direct turbulent cascade. The gravitational wave signal exhibits bursts, akin to so-called gravitational wave echoes, with increasing amplitude towards black hole formation.

</details>


### [20] [Cosmological and lunar laser ranging constraints on evolving dark energy in a nonminimally coupled curvature-matter gravity model](https://arxiv.org/abs/2512.10530)
*Riccardo March,Miguel Barroso Varela,Orfeu Bertolami,Giada Bargiacchi,Marco Muccino,Simone Dell'Agnello*

Main category: gr-qc

TL;DR: This paper explores a modified gravity model where curvature and matter are nonminimally coupled, explaining accelerated cosmic expansion via a cosmological constant and an effective dark energy equation of state. It uses a tracking solution based on scalar field potentials, constrained by DESI, Pantheon+, and Dark Energy Survey data, which support dynamical dark energy. The model predicts a fifth force violating the equivalence principle, conflicting with lunar laser ranging data but仍 compatible with some parameter ranges.


<details>
  <summary>Details</summary>
Motivation: To address unresolved issues in cosmology such as dark energy's nature and the equivalence principle's validity, the paper investigates a nonminimally coupled modified gravity model that could explain cosmic acceleration and potential deviations from general relativity predictions.

Method: The model employs a tracking solution following the effective potential's minimum for a scalar field representing modified gravity effects. Parameters are constrained using DESI, Pantheon+, Dark Energy Survey supernova data, and lunar laser ranging data for equivalence principle tests.

Result: Analysis shows compatible cosmological constraints indicating dynamical dark energy behavior similar to DESI results. However, the model's fifth force violates the equivalence principle, though some parameter sets satisfy both cosmological and local constraints.

Conclusion: The modified gravity model offers a viable explanation for cosmic acceleration with dynamical dark energy, but requires strict parameter limitations to align with both large-scale cosmological data and local equivalence principle tests, suggesting potential paths for future observational discrimination.

Abstract: We analyze a cosmological solution to the field equations of a modified gravity model where curvature and matter are nonminimally coupled. The current Universe's accelerated expansion is driven by a cosmological constant while the impact of the nonminimal coupling on the expansion history is recast as an effective equation of state for evolving dark energy. The model is analyzed under a tracking solution that follows the minimum of the effective potential for a scalar field that captures the modified theory's effects. We determine the conditions for the existence of this minimum and for the validity of the tracking solution. Cosmological constraints on the parameters of the model are obtained by resorting to recent outcomes of data from the DESI collaboration in combination with the Pantheon+ and Dark Energy Survey supernovae compilations, which give compatible results that point to the presence of a dynamical behavior for dark energy. The gravity model violates the equivalence principle since it gives rise to a fifth force that implies the Earth and Moon fall differently towards the Sun. The cosmological constraints are intersected with limits resulting from a test of the equivalence principle in the Earth-Moon system based on lunar laser ranging data. We find that a variety of model parameters are consistent with both of these constraints, all while producing a dynamical evolution of dark energy with similarities to that found in recent DESI results.

</details>


### [21] [Neutrino oscillations in a Kalb-Ramond black hole background](https://arxiv.org/abs/2512.10557)
*Yuxuan Shi,A. A. Araújo Filho,K. E. L. de Farias,V. B. Bezerra,Amilcar R. Queiroz*

Main category: gr-qc

TL;DR: The paper investigates neutrino behavior near a Kalb-Ramond field sourced black hole under spontaneous Lorentz symmetry breaking, analyzing deviations in annihilation energy, oscillation phases, and flavor conversion due to gravitational lensing. Numerical simulations for two and three-flavor models with different mass orderings are performed.


<details>
  <summary>Details</summary>
Motivation: To explore observable effects of Lorentz violation in spacetime caused by Kalb-Ramond fields, focusing on neutrino interactions under such geometric conditions.

Method: Studied observable consequences first, including energy output changes, oscillation phase shifts, and flavor conversion distortions from gravitational lensing. Linked these to Lorentz-violating spacetime structure affecting neutrino propagation. Conducted numerical simulations for 2-flavor and 3-flavor models with both normal and inverted mass hierarchies.

Result: Numerical results demonstrated measurable differences in neutrino behavior caused by Lorentz violation, showing distinct patterns for mass ordering scenarios.

Conclusion: Lorentz-violating Kalb-Ramond black hole spacetimes produce detectable neutrino propagation anomalies, offering observational tests for spontaneous symmetry breaking theories.

Abstract: The analysis examines how neutrinos behave when their trajectories unfold around a black hole sourced by a Kalb-Ramond field, where spontaneous Lorentz symmetry breaking reshapes the surrounding geometry. Instead of following the conventional order, the study focuses first on the observable consequences: alterations in the neutrino-antineutrino annihilation energy output, shifts in the oscillation phase accumulated along the path, and distortions in flavor conversion probabilities induced by gravitational lensing. These features are then tied to the Lorentz-violating spacetime structure, which governs the propagation of the neutrinos. Numerical simulations are carried out for both two- and three-flavor descriptions, with normal and inverted mass orderings.

</details>


### [22] [Subtracting compact binary foregrounds utilizing anisotropic statistic for third-generation gravitational-wave detectors](https://arxiv.org/abs/2512.10648)
*Soichiro Kuwahara,Atsushi Nishizawa,Lorenzo Valbusa Dall'Armi*

Main category: gr-qc

TL;DR: The paper proposes using anisotropies in BNS signals to improve foreground estimation in third-generation gravitational wave detectors, finding that shot noise from unresolved BNS is too faint to observe after loud signal subtraction, thus justifying treating the foreground as isotropic and discussing required angular resolution for effective subtraction.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of removing the astrophysical foreground, particularly from subthreshold BNS, which hinders the detection of subdominant stochastic GWBs like a primordial one.

Method: The authors simulate BNS populations, compute angular power spectra and shot noise, and analyze the detectability of these components with third-generation detectors considering their angular resolution limits.

Result: Shot noise from unresolved BNS is too faint to observe post-subtraction of loud signals, validating the isotropic approximation for the unresolved foreground. The required angular resolution for effective foreground subtraction is discussed.

Conclusion: The study justifies treating the unresolved BNS foreground as isotropic and highlights necessary angular resolution capabilities for third-generation detectors to enable successful foreground cleaning.

Abstract: The astrophysical foreground from compact-binary coalescence signals is expected to be a dominant part of total gravitational wave (GW) energy density in the frequency band of the third-generation detectors. The detection of any other subdominant stochastic GW background (GWB), especially a primordial GWB, will be disturbed by the astrophysical foreground, which needs to be cleaned for further studies of other stochastic GWB. Although previous studies have proposed several cleaning methods, the foreground from subthreshold binary neutron stars (BNS) has been a major obstacle to remove. In this paper, we propose the novel idea to acquire better estimation of the unresolved foreground, by using the information about its anisotropies. We simulate the BNS population and compute its angular power spectrum and shot noise. We find that the shot noise from BNS is too faint to observe after subtracting loud signals due to the limited angular resolution of the third-generation detectors. This justifies the approximation regarding the unresolved foreground as an isotropic component. We also discuss the angular resolution necessary to make our method valid for the foreground subtraction.

</details>


### [23] [Master Variables and Darboux Symmetry for Axial Perturbations of the Exterior and Interior of Black Hole Spacetimes](https://arxiv.org/abs/2512.10664)
*Michele Lenzi,Guillermo A. Mena Marugán,Andrés Mínguez-Sánchez,Carlos F. Sopuerta*

Main category: gr-qc

TL;DR: The paper examines axial perturbations in Kantowski-Sachs spacetime, unifying interior/exterior black hole geometries via Hamiltonian formalism and explores Darboux transformations as canonical symmetries in the axial sector.


<details>
  <summary>Details</summary>
Motivation: To clarify the relationship between axial perturbative gauge invariants from canonical analysis and established BH master functions, and to geometrically interpret Darboux transformations within the Hamiltonian framework.

Method: Revisits Kantowski-Sachs spacetime analysis for axial perturbations, extends results to exterior BH geometry, and applies Hamiltonian formalism to characterize Darboux transformations as canonical transformations between axial master function Hamiltonians.

Result: Unified Hamiltonian framework linking interior/exterior BH geometries, identification of Darboux transformations as canonical symmetries in axial sector, and clarified connections between perturbative invariants and master functions.

Conclusion: The Hamiltonian approach provides a coherent geometric interpretation for both axial perturbations and Darboux symmetries across BH interior/exteriors, offering a deeper understanding of black hole dynamics.

Abstract: Recent efforts have shown that Kantowski-Sachs spacetime provides a useful framework for analyzing perturbations inside a Schwarzschild black hole (BH). In these studies, the adoption of a Hamiltonian formulation offers an insightful perspective. The aim of this work is twofold. First, we revisit and elaborate the results obtained so far in Kantowski-Sachs, with the focus placed on axial perturbations. In particular, by exploiting the relation between this spacetime and the interior of a nonrotating BH, we consider the extension of those results to the exterior geometry of the BH. In this way, we clarify the relation between the axial perturbative gauge invariants emerging from the canonical analysis and the already well-established axial BH invariants, often referred to as master functions. We do so by providing a unified picture of the Hamiltonian formalism, which does not distinguish, formally, between exterior and interior geometries. The second objective is to explore the role of Darboux transformations, which were found as hidden symmetries in the context of BH perturbations, and their appearance in the Hamiltonian setting. Within this framework, the Hamiltonian formulation provides a clear geometric interpretation and characterization of Darboux transformations within the axial sector, viewing them as the set of canonical transformations between Hamiltonians for axial master functions.

</details>


### [24] [Master functions and hybrid quantization of perturbed nonrotating black hole interiors](https://arxiv.org/abs/2512.10692)
*Michele Lenzi,Guillermo A. Mena Marugán,Andrés Mínguez-Sánchez*

Main category: gr-qc

TL;DR: The paper extends a Hamiltonian approach based on Kantowski-Sachs geometry to both interior and exterior regions of nonrotating black holes, linking perturbative invariants to master functions and enabling hybrid quantization.


<details>
  <summary>Details</summary>
Motivation: To provide a complementary perspective to Lagrangian methods and enable quantum treatment of black hole geometries by unifying interior/exterior descriptions through Hamiltonian formulation.

Method: 1. Extend Hamiltonian framework from interior to exterior regions of Schwarzschild-like black holes. 2. Establish correspondence between canonical perturbative invariants and standard master functions. 3. Develop hybrid quantization method using this unified framework.

Result: Successful correspondence established between Hamiltonian invariants and master functions, providing foundation for consistent quantum treatment of black hole perturbations across event horizon.

Conclusion: Demonstrates viability of Hamiltonian formalism for unified quantum analysis of black hole spacetimes, offering new tools for gravitational wave studies and quantum gravity explorations.

Abstract: Master functions of black holes are fundamental tools in gravitational-wave physics and are typically derived within a Lagrangian framework. Starting from the Kantowski-Sachs geometry, one can instead construct a perturbative Hamiltonian description for the interior region of an uncharged and nonrotating black hole. This approach provides a complementary perspective and enables a quantum treatment of the background geometry and its perturbations. In this work, we extend the application of this formulation to the exterior region and establish a correspondence between the perturbative invariants of the canonical approach and the master functions commonly used in black hole analyses. Once a consistent Hamiltonian description for their canonical counterparts is obtained, a hybrid quantization of the master functions follows naturally.

</details>


### [25] [A simplified proof of a cosmological singularity theorem](https://arxiv.org/abs/2512.10699)
*Gregory J. Galloway,Eric Ling*

Main category: gr-qc

TL;DR: The paper presents a more streamlined proof of a singularity theorem for cosmological models with a positive cosmological constant by utilizing the virtual positive first Betti number conjecture, and examines its rigidity under null geodesic completeness.


<details>
  <summary>Details</summary>
Motivation: To provide a more unified and efficient proof of the earlier singularity theorem, previously dependent on the surface subgroup conjecture, by leveraging the virtual positive first Betti number conjecture's resolution.

Method: Applies the positive resolution of the virtual positive first Betti number conjecture [1] to rederive the singularity theorem, avoiding the need for the surface subgroup conjecture and offering a streamlined approach. Examples are provided and the theorem's rigidity under null geodesic completeness is analyzed.

Result: Demonstrates that using the virtual positive first Betti number conjecture leads to a more unified proof of the singularity theorem. The analysis of rigidity clarifies conditions under which null geodesic completeness holds or fails.

Conclusion: The approach via the virtual positive first Betti number conjecture not only simplifies the original proof but also enhances understanding of the theorem's rigidity properties in specific spacetime models.

Abstract: In a previous paper [9], we proved the following singularity theorem applicable to cosmological models with a positive cosmological constant: if a four-dimensional spacetime satisfying the null energy condition contains a compact Cauchy surface which is expanding in all directions, then the spacetime is past null geodesically incomplete unless the Cauchy surface is topologically a spherical space. The proof in [9] made use of the positive resolution of the surface subgroup conjecture [15]. In this note, we demonstrate how the less-broadly-known positive resolution of the virtual positive first Betti number conjecture [1] provides a more streamlined and unified approach to the proof. We illustrate the theorem with some examples and analyze its rigidity under null geodesic completeness.

</details>


### [26] [Macroscopic backreaction of the trace anomaly on classical vacuum backgrounds](https://arxiv.org/abs/2512.10710)
*Raúl Carballo-Rubio,Francesco Di Filippo,Shinji Mukohyama,Kazumasa Okabayashi*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study the backreaction of quantum fields in the Boulware vacuum state on the Schwarzschild geometry, using the Riegert--Mottola--Vaulin renormalized stress-energy tensor derived from the conformal anomaly. An order-reduction procedure is applied to the first order, paying special attention to the conservation of the resulting stress-energy tensor. The results obtained in these different situations are compared between them, and also to recent works in the literature using other approximations for the renormalized stress-energy tensor.

</details>


### [27] [Efficient pulsar distance measurement with multiple nanohertz gravitational-wave sources](https://arxiv.org/abs/2512.10729)
*Si-Ren Xiao,Ji-Yu Song,Yue Shao,Ling-Feng Wang,Jing-Fei Zhang,Xin Zhang*

Main category: gr-qc

TL;DR: The paper proposes a new method for estimating pulsar distances using pulsar-term phase information from nanohertz gravitational waves. By constructing two-dimensional distance posteriors for pulsar pairs and combining them, the method reduces uncertainties from source parameters, achieving sub-parsec precision for pulsars within 1.4 kpc over 15 years with a 20-pulsar PTA.


<details>
  <summary>Details</summary>
Motivation: Accurate pulsar distance measurements are essential to fully utilize pulsar-term data in gravitational wave observations, which improves sky localization of GW sources. Existing one-dimensional methods are limited by uncertainties in source parameters, necessitating a more robust approach.

Method: The method involves creating 2D distance posterior distributions for pairs of pulsars based on simulated GW signals. These posteriors are combined to constrain individual distances, leveraging cross-pulsar correlations to reduce dependence on uncertain GW source parameters.

Result: Simulations with four GW sources and a 20-pulsar array (20 ns white noise) show that ~1.4 kpc distant pulsars can achieve sub-parsec distance precision over 15 years, outperforming existing methods by mitigating source parameter uncertainties.

Conclusion: The proposed 2D method significantly enhances pulsar distance accuracy, enabling better exploitation of pulsar-term data for precise gravitational wave source localization. This improves the overall capability of pulsar timing arrays in detecting and studying supermassive black hole binaries.

Abstract: In recent years, pulsar timing arrays (PTAs) have reported evidence for a nanohertz gravitational-wave (GW) background. As radio telescope sensitivity improves, PTAs are also expected to detect continuous gravitational waves from individual supermassive black hole binaries. Nanohertz GWs generate both Earth and pulsar terms in the timing data, and the time delay between the two terms encodes the pulsar distance. Precise pulsar distance measurements are critical to fully exploiting pulsar-term information, which can improve the measurement precision of GW sources' sky position parameters and thus enhance the GW sky-localization capability. In this work, we propose a new pulsar distance estimation method by using pulsar-term phase information from GWs. We construct two-dimensional distance posteriors for pulsar pairs based on the simulated GW signals and combine them to constrain individual pulsar distances. Compared with the existing one-dimensional method, our approach reduces the impact of source-parameter uncertainties on pulsar distance measurements. Considering four GW sources and a PTA of 20 pulsars with a white-noise level of 20 ns, we find that a significant fraction of pulsars at distances $\lesssim 1.4$ kpc can achieve sub-parsec distance precision over a 15-year observation.

</details>


### [28] [Detection of GW200105 with a targeted eccentric search](https://arxiv.org/abs/2512.10803)
*Khun Sang Phukon,Patricia Schmidt,Gonzalo Morras,Geraint Pratten*

Main category: gr-qc

TL;DR: This paper presents an eccentric search for the NSBH binary GW200105, finding it has a significant signal with a false alarm rate <1/1000 yr. The eccentric method improves detection significance compared to non-eccentric templates.


<details>
  <summary>Details</summary>
Motivation: Matched-filter searches using non-eccentric templates may miss or weaken signals like GW200105 which have significant orbital eccentricity, reducing detection sensitivity and candidate significance.

Method: A targeted eccentric search was conducted specifically for GW200105 using templates accounting for orbital eccentricity, analyzing gravitational-wave data around 20 Hz.

Result: The search identified GW200105 with a signal-to-noise ratio of 13.4 and a false alarm rate <1 in 1000 years, finding template parameters consistent with Bayesian inference.

Conclusion: The results support the NSBH origin of GW200105 formed via dynamical mechanisms rather than isolated binary evolution, highlighting the importance of eccentric templates for accurate detection.

Abstract: The neutron star -- black hole (NSBH) binary GW200105 was recently found to have significant residual orbital eccentricity at a gravitational-wave frequency of 20 Hz~\cite{Morras:2025xfu}. The event was originally identified with moderate significance by matched-filter searches that employ non-eccentric templates. The neglect of relevant physical effects, such as orbital eccentricity, can severely reduce the sensitivity of the search and, consequently, also the significance of an event candidate. Here, we present a targeted eccentric search for GW200105. The eccentric search identifies GW200105 as the most significant event with a signal-to-noise ratio of $13.4$ and a false alarm rate of less than 1 in 1000 years.
  The best-matching template parameters are consistent with the Bayesian inference result, supporting the interpretation of GW200105 as an NSBH that formed through dynamical mechanisms and not isolated binary evolution.

</details>


### [29] [F(R,..) theories from the point of view of the Hamiltonian approach: non-vacuum Anisotropic Bianchi type I cosmological model](https://arxiv.org/abs/2512.10850)
*J. Socorro,Juan Luis Pérez,Luis Rey Díaz-Barrón,Abraham Espinoza García,Sinuhé Pérez Payán*

Main category: gr-qc

TL;DR: The paper examines the effects of F(R) gravity theories using an anisotropic Bianchi Type I model with a barotropic fluid, deriving classical solutions in two gauges (N=1 and N=6ABCD=6η³D) and presenting vacuum solutions for completeness.


<details>
  <summary>Details</summary>
Motivation: To explore F(R) theories in an anisotropic cosmological context, providing classical solutions that can serve as ansatz for solving Einstein field equations and extending understanding beyond isotropic models.

Method: Employed the Bianchi Type I model with a barotropic fluid (P=γρ) under F(R) gravity. Derived classical solutions in two specific gauges and analyzed vacuum scenarios, offering foundational solutions for further study.

Result: Obtained classical solutions under both gauges and identified their applicability as ansatz in Einstein field equations. Vacuum solutions were also characterized to provide a comprehensive framework.

Conclusion: Demonstrated the viability of using Bianchi Type I models for F(R) gravity analysis, highlighting the utility of derived solutions as foundational tools for future work in anisotropic cosmological studies.

Abstract: In this work, we will explore the effects of F(R) theories in the classical scheme using the anisotropic Bianchi Type I cosmological model with standard matter employing a barotropic fluid with equation of state $P=γρ$. In this work we present the classical solutions in two gauge, N=1 and $N=6ABCD=6η^3D$ obtaining some results that are usually used as ansatz to solve the Einstein field equation. For completeness, we present the solutions in vacuum as well.

</details>


### [30] [Measuring the neutron star equation of state from EMRIs in dark matter environments with LISA](https://arxiv.org/abs/2512.10855)
*Theophanes K. Karydas,Gianfranco Bertone*

Main category: gr-qc

TL;DR: The study demonstrates that gravitational-wave observations of EMRIs in dense dark matter environments can reveal the internal structure of the small companion, distinguishing neutron stars from black holes and even different neutron star equations of state based on signal-to-noise ratios.


<details>
  <summary>Details</summary>
Motivation: To investigate whether dense dark matter surroundings around central black holes allow gravitational-wave observations to probe the internal structure of EMRI companions, which is typically hidden in vacuum scenarios.

Method: Computed relativistic dynamical-friction forces on neutron stars moving through collisionless dark matter, simulated EMRI evolution in dark matter spikes, and performed Bayesian parameter estimation on synthetic LISA observations.

Result: EMRIs with SNR ≥20 can distinguish neutron star vs black hole companions, while SNR ≥400 enables differentiation between neutron star equations of state.

Conclusion: Dense dark matter environments enhance the measurability of compact object properties via gravitational waves, offering a new observational tool to study fundamental physics like equations of state for neutron stars.

Abstract: Gravitational-wave observations of extreme mass-ratio inspirals (EMRIs) in vacuum are largely insensitive to the internal structure of the small compact companion. We show that this conclusion can change when the central black hole is surrounded by a dense dark matter environment. We compute, for the first time, the relativistic dynamical-friction force on a neutron star moving through a collisionless medium and its impact on the evolution of EMRIs embedded in dense dark matter spikes. We then perform a Bayesian parameter-estimation analysis of simulated LISA observations to assess the measurability of both spike properties and the companion's internal structure. We find that, in our fiducial dark matter spike models, EMRIs with signal-to-noise ratio (SNR) $\gtrsim 20$ already allow us to distinguish neutron star from black hole companions, while events with SNR $\gtrsim 400$ make it possible to discriminate between different neutron star equations of state.

</details>


### [31] [Twin-paradox and Entanglement](https://arxiv.org/abs/2512.10908)
*K. Hari,Subhajit Barman,Dawood Kothawala*

Main category: gr-qc

TL;DR: This paper explores the quantum twin paradox using quantum detectors and a quantum field, finding that directional changes in acceleration affect detector responses and entanglement, with potential implications for black hole spacetimes.


<details>
  <summary>Details</summary>
Motivation: To extend the classical twin paradox into a quantum framework by replacing twins with detectors and analyzing relativistic effects on quantum fields.

Method: Replace classical twins with quantum detectors, study their transitions and entanglement when coupled to a quantum field, and analyze effects of acceleration direction changes.

Result: Changes in acceleration direction leave detectable imprints on detector responses and entanglement, introducing new phenomena relevant to black hole physics.

Conclusion: Quantum effects in relativistic motion show distinct features from classical scenarios, suggesting importance for understanding quantum phenomena in strong gravitational fields.

Abstract: We study the quantum version of the classical twin paradox in special relativity by replacing the twins with quantum detectors, and studying the transitions and entanglement induced by coupling them to a quantum field. We show that the \textit{changes} in direction of acceleration leave imprints on detector responses and entanglement, inducing novel features which might have relevance in black hole spacetimes.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [32] [Can the 3 neutrino masses really be found using SN 1987A data?](https://arxiv.org/abs/2512.09971)
*Robert Ehrlich*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Neutrino masses remain a significant unsolved problem in physics and their nonzero value proves the Standard Model is incomplete. Currently, the values of the three masses only have upper limits from cosmology and experiments like KATRIN. This paper shows that the SN 1987A neutrino data can remarkably yield values for the three neutrino masses, and not merely upper limits. Although this seemingly preposterous idea was suggested a dozen years ago by the author, here it is demonstrated in a much more convincing manner with many new elements, including a stronger statistical treatment, a theoretical linkage to possible CPT violation, and most importantly, a thorough explanation of why the method used to find the three masses from supernova SN 1987A neutrino data really works. The key to finding the three neutrino masses is realizing why three normally accepted assumotions are unjustified, The three rejected assumptions are:(a) the 5-hr early LSD (Mont Blanc) neutrinos are unrelated to SN 1987A, (b) any masses $>1 eV/c^2$ would be inconsistent with upper limits from KATRIN and other data, and (c) the spread in neutrino emission times from SN 1987A is too great for the method to work.

</details>


### [33] [Searches for electroweak states at future plasma wakefield colliders](https://arxiv.org/abs/2512.09995)
*So Chigusa,Simon Knapen,Toby Opferkuch,Inbar Savoray,Christiane Scherb,Weishuang Linda Xu*

Main category: hep-ph

TL;DR: The paper evaluates future multi-TeV plasma wakefield colliders' potential to discover new electroweak particles, analyzing beam-beam effects in different collider configurations. It suggests that even with technical challenges, some targets might still be accessible.


<details>
  <summary>Details</summary>
Motivation: To assess how realistic beam conditions affect discovery reach for new physics beyond standard model using next-gen colliders.

Method: Compared five collider setups (round/flat beams for e+e−, e−e−, and γγ) incorporating realistic luminosity spectra with beam-beam effects to evaluate their search capabilities.

Result: Beam-beam effects significantly alter optimal search strategies, emphasizing the importance of low-energy luminosity and new initial-state channels. Access to key targets may remain feasible even if positron acceleration or flat-beam delivery faces difficulties.

Conclusion: Accelerator R&D should prioritize realistic beam parameters' impact, as technical challenges in certain areas might not preclude discovery potential for key electroweak particles.

Abstract: We quantify the discovery potential of future multi-TeV plasma wakefield colliders for new electroweak multiplets. We include beam-beam effects through realistic luminosity spectra, comparing five collider configurations: $e^+e^-$ and $e^-e^-$ machines with round- and flat-beams, and a $γγ$ collider. The beam-beam effects qualitatively change search strategies relative to idealized mono-energetic lepton colliders, highlighting the importance of the low-energy part of the luminosity spectrum and additional beam-induced initial-state channels. Our results have implications for accelerator R&D priorities, since key electroweak targets may remain accessible even if efficient positron acceleration and flat-beam delivery prove technically challenging at the multi-TeV scale.

</details>


### [34] [Constraining Gravitational Dark Matter with LHAASO and Fermi-LAT](https://arxiv.org/abs/2512.09997)
*Basabendu Barman,Arindam Das,Prantik Sarmah,Rakesh Kumar SivaKumar*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We use diffuse Galactic high energy gamma ray data from LHAASO and Fermi-LAT to constrain gravitationally produced decaying dark matter (DM). Focusing on four benchmark candidates: a dark photon, a heavy right-handed neutrino (RHN), a pseudo-Nambu-Goldstone boson (pNGB), and a non-minimally coupled scalar we derive bounds on the DM mass and its couplings to the visible sector. For dark photons, RHNs, and pNGBs, the combined data constrain the relevant interaction strength to $\lesssim\mathcal{O}(10^{-30})$ for DM masses $\gtrsim\mathcal{O}$(TeV), while the non-minimally coupled scalar is limited to $\lesssim\mathcal{O}(10^{-10})$. Moreover, photon-dark photon oscillations yield strong constraints for massive dark photon beyond 10 GeV, closing a region of parameter space previously left unconstrained.

</details>


### [35] [The Four Polarizations of the $W$ at High Energies](https://arxiv.org/abs/2512.10015)
*Trina Basu,Richard Ruiz*

Main category: hep-ph

TL;DR: The paper explores polarization-induced interference and off-shell effects in high-energy multi-leg processes involving weak bosons with fixed helicities. It uses truncated propagators and helicity amplitudes to simplify calculations, revealing that polarization interference can be significant and has specific behaviors in high-energy limits. Case studies include charged-current processes like W(+jets), top quark decay, and neutrino scattering.


<details>
  <summary>Details</summary>
Motivation: To address the challenges posed by polarization interference and off-shell effects in high-energy physics calculations involving weak bosons. The study aims to provide a systematic approach using helicity amplitudes and truncated propagators to handle these effects, ensuring accurate predictions while enhancing analytical evaluation and gauge invariance.

Method: The authors use the truncated propagator approach at the level of helicity amplitudes and squared amplitudes. They introduce bookkeeping devices for covariant and axial gauges to simplify calculations and make power counting explicit. They analyze interference effects, their dependence on helicity inversion, and their behavior in high-energy limits for s- and t-channel exchanges.

Result: Key findings include that polarization interference is non-zero even when on-shell, can be negative and comparable to longitudinal contributions, and is suppressed in high-energy limits for s- and t-channel processes due to helicity inversion. The paper also proposes a scheme to reduce gauge dependence in polarized scattering predictions.

Conclusion: The study underscores the importance of considering polarization interference in theoretical predictions for processes involving weak bosons. The proposed methods and analytical tools provide a robust framework to handle these effects, improving accuracy in computations and aiding in reducing gauge dependence. Applications to specific charged-current processes validate the approach's effectiveness.

Abstract: We investigate polarization-induced interference and off-shell effects in predictions for high-energy, multi-leg processes with intermediate weak bosons carrying fixed helicities. Building on the ``truncated propagator'' paradigm, we carry out our analysis at the level of helicity amplitudes and squared amplitudes. We introduce bookkeeping devices, suitable for covariant and axial gauge choices, that simplify the analytical evaluation of polarized amplitudes, and make power counting of mass-over-energy factors more manifest. Among other results, we show that polarization interference (i) is generally non-zero, even in on-shell limits, (ii) can be negative and comparable to longitudinal contributions, and (iii) is generated by helicity inversion and therefore suppressed (or zero) in high-energy limits for $s$- and $t$-channel exchanges. Connections between gauge invariance and the scalar polarization are also discussed, as is a scheme for reducing gauge dependence in predictions for polarized scattering rates. As case studies, we consider charged-current processes, including $W$(+jets), top quark decay, and neutrino deep-inelastic scattering.

</details>


### [36] [Living on the edge: radius effects in the angular substructure of heavy-ion jets](https://arxiv.org/abs/2512.10026)
*Carlota Andres,Jack Holguin,Benjamin Kimelman,Raghav Kunnawalkam Elayavalli,Jussi Viinikainen,Zhong Yang*

Main category: hep-ph

TL;DR: The paper investigates edge effects in jet substructure observables, specifically the two-point energy correlator, in heavy-ion collisions. It finds that distortions scale with the average angular separation ⟨φ⟩ and vary between p-p and Pb-Pb collisions, necessitating correction for accurate QCD dynamics interpretation.


<details>
  <summary>Details</summary>
Motivation: Edge effects complicate the interpretation of jet substructure data by obscuring QCD dynamics when correlated particles are outside the jet radius. The study aims to understand and quantify these effects to improve analysis accuracy.

Method: Phenomenological analysis using Pythia8, Herwig7 (p-p), and JEWEL/CoLBT (Pb-Pb) simulations. Focus on two-point energy correlator (EEC) as a case study, analyzing ⟨φ⟩ scaling and Pb-Pb/p-p ratios.

Result: Edge effects scale linearly with ⟨φ⟩, are suppressed by (R_L/R)^4 in p-p but more pronounced in Pb-Pb with (R_L/R)^2 and (R_L/R)^4 terms. Pb-Pb/p-p ratios reduce but don't eliminate distortions.

Conclusion: Edge effects must be accounted for in heavy-ion analyses. ⟨φ⟩ distribution offers a tool to benchmark and constrain event generators, improving interpretation of jet substructure measurements.

Abstract: Jet substructure observables serve as essential tools for probing the quark-gluon plasma produced in relativistic heavy-ion collisions. Their interpretation, however, is often complicated by edge effects, which arise when correlated particles fall outside the reconstructed jet radius, introducing distortions that obscure the underlying QCD dynamics. In this work, we present a comprehensive phenomenological study of edge effects in soft-insensitive angular observables, taking the two-point energy correlator (EEC) as a representative example. We argue that these distortions scale linearly with the average angular separation between the winner-take-all and $E$-scheme axes $\langle φ\rangle$, and validate this behavior across proton-proton (p-p) simulations with Pythia8 and Herwig7, as well as lead-lead (Pb-Pb) simulations using JEWEL and CoLBT. In p-p collisions, edge effects are strongly suppressed, scaling as $(R_L/R)^4$, whereas medium-modified jets can exhibit larger distortions, with contributions scaling as $(R_L/R)^2$ and $(R_L/R)^4$. Taking Pb-Pb/p-p ratios of the EEC substantially reduces, but does not completely eliminate, these distortions, highlighting the need of accounting for edge effects in the interpretation of heavy-ion jet substructure measurements. Since edge effects are largely governed by the $\langle φ\rangle$ distribution, studying this distribution provides a new handle for benchmarking and constraining the modeling of edge effects in heavy-ion event generators.

</details>


### [37] [Constraining non-commutative geometry with W/Z+jet production at the LHC](https://arxiv.org/abs/2512.10028)
*Achwaq Ghezal,Yazid Delenda,Mekki Aouachria*

Main category: hep-ph

TL;DR: The paper examines W/Z+jet production under the non-commutative Standard Model (NCSM), revealing observable first-order (O(Θ)) effects in production amplitudes but second-order (O(Θ²)) effects in leptonic decays. Numerical comparisons with Standard Model predictions and analysis of ATLAS data allow tighter constraints on the non-commutative scale Λ up to multi-TeV.


<details>
  <summary>Details</summary>
Motivation: To explore non-commutative geometry effects in particle physics processes, testing the NCSM framework against experimental data to probe physics beyond the Standard Model at higher energy scales.

Method: Calculation of squared matrix elements for all partonic channels in W/Z+jet production within NCSM, incorporating O(Θ) vertex corrections and new interactions. Numerical predictions for angular distributions and asymmetries compared to MCFM SM results. Particle-level analysis of ATLAS Z+jet data to constrain Λ.

Result: First-order O(Θ) effects found in production amplitudes (unlike other processes at O(Θ²)), while decays only affected at O(Θ²). Data analysis yields stringent lower bounds on non-commutative scale Λ (~multi-TeV).

Conclusion: NCSM predictions show measurable deviations from the Standard Model at O(Θ), enabling improved sensitivity to non-commutative parameters. The study establishes robust bounds on Λ and highlights the importance of differential observables in testing modified geometries at colliders.

Abstract: We present a comprehensive calculation of the squared matrix elements for all partonic channels contributing to $W^\pm/Z$+jet production at hadron colliders within the framework of the non-commutative Standard Model (NCSM), including leptonic decays $W\to eν$ and $Z\to e^+e^-$. Our computation incorporates both $\mathcal{O}(Θ)$ corrections to the Standard Model vertices and additional interaction terms inherent to the NCSM. A key finding is that the production amplitudes receive first-order corrections at $\mathcal{O}(Θ)$, a distinctive feature compared to many other processes where non-commutative effects enter only at $\mathcal{O}(Θ^2)$. The leptonic decay widths, in contrast, are modified solely at $\mathcal{O}(Θ^2)$. This $\mathcal{O}(Θ)$ enhancement provides improved sensitivity to non-commutative geometry, allowing us to probe for and constrain the non-commutative energy scale in the multi-TeV range. We provide numerical predictions for angular (azimuthal and rapidity) distributions and the forward--backward asymmetry, and compare them to state-of-the-art Standard Model predictions at leading and next-to-leading order from the \texttt{MCFM} Monte Carlo program. Finally, we test the NCSM with experimental data by analyzing an unbinned, particle-level $Z$+jet dataset from the ATLAS experiment. From this data, we calculate the azimuthal spectrum and forward-backward asymmetry, which are then used to derive stringent lower bounds on the non-commutative scale $Λ$.

</details>


### [38] [Potential for the discovery of the protophobic boson at the STCF](https://arxiv.org/abs/2512.10084)
*Althaf M.,Triparno Bandyopadhyay*

Main category: hep-ph

TL;DR: The paper studies the suitability of the MDC detector at the STCF facility for discovering the 17 MeV protophobic boson (X17) linked to nuclear transition anomalies. Simulations show STCF can detect the boson despite ~10^4 background events in key parameter regions.


<details>
  <summary>Details</summary>
Motivation: To verify if the STCF MDC detector can effectively search for the hypothetical X17 boson, which explains nuclear transition anomalies observed at ATOMKI. This is the first feasibility study for such light boson searches at STCF.

Method: Used TrackEff framework to simulate MDC detector performance; evaluated displaced-vertex sensitivity across mass-coupling parameters; analyzed visible and dark decay channels with likelihood-based significance estimates.

Result: STCF MDC can achieve 5σ discovery of X17 boson in specific parameter regions around 17 MeV peak even with ~10^4 background events. This supports proceeding to full Geant4 simulations.

Conclusion: Demonstrates STCF's potential to detect the protophobic boson, confirming the need formore detailed Geant4-based simulations to confirm feasibility and guide future experimental designs.

Abstract: We study the morphology of the main drift chamber (MDC) proposed to be built around the collision point at the upcoming Super tau-charm facility (STCF), to check for its suitability in discovering the 17 MeV protophobic boson (X17 boson), hypothesised as a solution to the persistent ATOMKI nuclear-transition anomalies. These anomalies, observed in the excited $^8$Be, $^4$He, $^{12}$C, $^{16}$O nuclear transitions, have been interpreted as evidence for a $\sim$17 MeV, protophobic vector boson. Using the TrackEff framework, we perform detector-level simulations of the STCF MDC, and evaluate displaced-vertex sensitivities towards the protophobic boson, across the relevant mass-coupling parameter space. We study benchmark scenarios with visible and dark decay channels to perform likelihood-based significance estimates in order to determine the 5$σ$ discovery reach for the protophobic boson. We find that STCF can discover the protophobic boson while tolerating $\sim 10^4$ background events for specific regions of the parameter space around the 17 MeV peak. Our analysis establishes the first feasibility study of displaced light-boson searches at the STCF, motivating a full Geant-4 simulation.

</details>


### [39] [Unpolarized GPDs at small $x$ and non-zero skewness](https://arxiv.org/abs/2512.10086)
*Yuri V. Kovchegov,M. Gabriel Santiago,Huachen Sun*

Main category: hep-ph

TL;DR: The paper investigates the small-$x$ behavior of unpolarized GPDs and GTMDs with non-zero skewness and non-linear evolution effects, linking them to dipole amplitudes governed by BK/JIMWLK equations and odderon contributions, finding that skewness modifies the evolution parameter to depend on the minimum of $\ln(1/|x|)$ and $\ln(1/|ξ|)$.


<details>
  <summary>Details</summary>
Motivation: To extend previous studies on small-$x$ GPD/GTMD asymptotics by incorporating non-zero skewness and non-linear evolution effects, which were neglected before, to provide a more accurate theoretical framework.

Method: Derives relationships between GPDs/GTMDs and dipole/odderon amplitudes, modifying the evolution parameter $Y$ based on skewness $ξ$, using non-linear BK/JIMWLK equations and known odderon evolution equations.

Result: Shows that non-zero skewness alters the evolution parameter to $Y = \ln \min \left\{1/x, 1/|ξ| \right\}$, unifying the treatment of $x$ and $ξ$ in small-$x$ asymptotics.

Conclusion: Non-linear effects and skewness must be considered together in small-$x$ GPD/GTMD evolution, highlighting the interplay between dipole and odderon dynamics at high energies.

Abstract: We study the small-$x$ asymptotics of unpolarized generalized parton distributions (GPDs) and generalized transverse momentum distributions (GTMDs). Unlike the previous works in the literature, we consider the case of non-zero (but small) skewness while allowing for non-linear contributions to the evolution equations. We show that unpolarized GPDs and GTMDs at small $x$ are related to the eikonal dipole amplitude $N$, whose small-$x$ evolution is given by the BK/JIMWLK evolution equations, and to the odderon amplitude $\cal O$, whose evolution is also known in the literature. We show that the effect of non-zero skewness $ξ\neq 0$ is to modify the value of the evolution parameter (rapidity) in the arguments for the dipole amplitudes $N$ and $\cal O$ from $Y = \ln (1/x)$ to $Y = \ln \min \left\{ 1/|x| , 1/|ξ| \right\}$.

</details>


### [40] [Towards the Direct Detection of Composite Ultraheavy Dark Matter in Quantum Sensor Arrays](https://arxiv.org/abs/2512.10124)
*Dorian W. P. Amaral,Erqian Cai,Andrew J. Long,Juehang Qin,Christopher D. Tunnell*

Main category: hep-ph

TL;DR: The paper explores the sensitivity of quantum sensor arrays to composite ultraheavy dark matter interacting via gravity and a Yukawa force, analyzing different density profiles to differentiate from point-like dark matter.


<details>
  <summary>Details</summary>
Motivation: To understand how composite ultraheavy dark matter, which has a finite spatial extent and interacts via both gravity and a Yukawa force, affects detection signals in quantum sensor arrays, moving beyond the point-like assumption.

Method: Monte Carlo analysis using three density profiles (tophat, Gaussian, exponential) to model dark matter interactions, comparing signals against the point-like limit while accounting for thermal and quantum noise.

Result: Identified complex relationships between dark matter's scale radius, sensor spacing, and Yukawa screening length. Future arrays could determine dark matter's mass and size, aiding in distinguishing theoretical models.

Conclusion: Quantum sensor arrays are promising for probing composite ultraheavy dark matter properties, offering insights into their mass, size, and interaction mechanisms through measurable signal differences.

Abstract: Quantum sensor arrays have recently been proposed as a promising platform for the direct detection of ultraheavy dark matter, which is typically assumed to behave as a point-like particle. However, particles with masses at or above the Planck scale cannot be elementary; instead, they must exist as composite objects with finite spatial extent. Such spatially extended dark matter models lead to distinctive phenomenology in these detectors, particularly when the dark matter also interacts through long-range forces with their own characteristic length scales. In this work, we study the sensitivity of quantum sensor arrays to composite, ultraheavy dark matter interacting via both gravity and a novel Yukawa force. We consider three phenomenologically motivated density profiles -- a tophat, a Gaussian, and an exponential -- and contrast their signals with the point-like limit. Using a Monte Carlo analysis based on the predicted impulse signals and estimates of thermal and quantum noise, we obtain sensitivity projections for a future realization of a quantum sensor array. We find a non-trivial interplay between the dark-matter scale radius, the inter-sensor spacing, and the Yukawa screening length. Future accelerometer arrays would provide valuable information about the mass and size of composite ultraheavy dark matter, and our work will help to characterize the signatures of different theoretical models of ultraheavy dark matter.

</details>


### [41] [Hadronic contributions to $a_μ$ within Resonance Chiral Theory](https://arxiv.org/abs/2512.10161)
*Emilio J. Estrada,Alejandro Miranda,Pablo Roig*

Main category: hep-ph

TL;DR: The paper reviews recent advancements in calculating the hadronic contributions to the muon's anomalous magnetic moment using Resonance Chiral Theory. It covers the hadronic vacuum polarization using $e^+e^-$ and $τ$ decay data and evaluates new contributions like the pseudoscalar box in the hadronic light-by-light sector. Results align with White Paper 2 values.


<details>
  <summary>Details</summary>
Motivation: To update and refine theoretical predictions of the muon's anomalous magnetic moment, addressing discrepancies between experimental measurements and Standard Model calculations, by improving hadronic contributions through Resonance Chiral Theory.

Method: Uses Resonance Chiral Theory to analyze hadronic vacuum polarization from $e^+e^-$ and $τ$ decay data. Evaluates the hadronic light-by-light contribution, including pseudoscalar box, tensor-poles, and other subleading terms like scalar and axial-pole pieces.

Result: Results are consistent with White Paper 2 values, achieving comparable precision. New contributions like the pseudoscalar box were successfully incorporated, enhancing the theoretical framework's accuracy.

Conclusion: Resonance Chiral Theory effectively captures hadronic contributions to the muon g-2, reducing uncertainties. Further experimental data and refined theoretical models are recommended to address remaining gaps towards resolving the muon g-2 anomaly.

Abstract: We review the recent progress achieved, using Resonance Chiral Theory, in the hadronic contributions to the muon anomalous magnetic moment. These include the hadronic vacuum polarization, either using $e^+e^-$ or $τ$ decays into hadron final states as input; and the hadronic light-by-light part, where in addition to previous results on the lightest pseudoscalar and tensor-poles contributions, we first present the evaluation of the pseudoscalar box using this formalism. We also discuss the scalar, axial-pole and other subleading pieces. The results obtained are consistent with the White Paper 2 values, with comparable precision.

</details>


### [42] [Perturbative limits on axion-SU(2) gauge dynamics during inflation from the energy density of spin-2 particles](https://arxiv.org/abs/2512.10184)
*Koji Ishiwata,Eiichiro Komatsu*

Main category: hep-ph

TL;DR: The paper examines when the perturbative approach fails in modeling spin-2 particle backreaction on an axion-SU(2) system during inflation, finding failure occurs when spin-2 energy density exceeds the background, often overlapping but sometimes preceding the strong backreaction regime identified earlier, thus highlighting the need for non-perturbative methods like lattice simulations.


<details>
  <summary>Details</summary>
Motivation: To determine the conditions under which perturbative methods break down in studying the backreaction of spin-2 particles on the axion-SU(2) system during cosmic inflation, as previous studies may have incompletely characterized the strong backreaction regime.

Method: Analyzes the ratio of spin-2 particle energy density (from SU(2) gauge field) to background field energy density, identifying breakdown when the ratio exceeds 1. Compares results to prior strong backreaction parameter spaces.

Result: The perturbative breakdown condition aligns with previous strong backreaction regimes but in some cases occurs earlier. This shows perturbation theory is insufficient for such studies.

Conclusion: Non-perturbative methods like 3D lattice simulations are essential for accurately modeling the strong backreaction regime in this system.

Abstract: We investigate the conditions under which the perturbative treatment of the backreaction of spin-2 particles on the dynamics of an axion-SU(2) gauge field system breaks down during cosmic inflation. This condition is based on the ratio of the energy density of spin-2 particles from the SU(2) gauge field to that of the background field. The perturbative treatment breaks down when this ratio exceeds unity. We show that this occurs within a parameter space nearly identical to the strong backreaction regime identified in previous studies. However, in some cases, the ratio exceeds unity even before the system enters the strong backreaction regime. Our results suggest that attempts to study the strong backreaction regime using perturbation theory are necessarily limited. Reliable calculations require non-perturbative treatments, such as three-dimensional lattice simulations.

</details>


### [43] [Studies on quark-mass dependence of the $N^*(920)$ pole from $πN$ $χ$PT amplitudes](https://arxiv.org/abs/2512.10241)
*Xu Wang,Kai-Ge Kang,Qu-Zhi Li,Zhiguang Xiao,Han-Qing Zheng*

Main category: hep-ph

TL;DR: The study examines how quark mass affects the $N^*(920)$ resonance pole using the $K$-matrix method and chiral perturbation theory. The pole moves toward the real energy axis, crossing the $u$-cut at $m_	ext{π}=526$ MeV in the $O(p^2)$ case. At $O(p^3)$, the approach slows but likely crosses eventually, aligning with linear σ model predictions.


<details>
  <summary>Details</summary>
Motivation: Investigate the quark-mass dependence of the $N^*(920)$ resonance pole to understand its behavior in different quark mass regimes and its connection to theoretical models like the linear σ model.

Method: The $K$-matrix method is applied with $πN$ scattering amplitudes computed up to $O(p^3)$ in chiral perturbation theory to track the $N^*(920)$ pole's trajectory in the complex energy plane.

Result: At $O(p^2)$, the pole crosses the $u$-cut at $m_	ext{π}=526~	ext{MeV}$, entering another Riemann sheet. At $O(p^3)$, the crossing is delayed but expected to occur eventually. Results align qualitatively with linear σ model calculations.

Conclusion: The $N^*(920)$ resonance's pole behavior under quark mass variations is consistent with theoretical expectations, supporting its interpretation as a dynamically generated state that transitions between Riemann sheets with increasing pion mass.

Abstract: The quark-mass dependence of the $N^*(920)$ pole is analyzed using $K$-matrix method, with the $πN$ scattering amplitude calculated up to $O(p^3)$ order in chiral perturbation theory. As the quark mass increases, the $N^*(920)$ pole gradually approaches the real axis in the complex $w$-plane (where $w=\sqrt{s}$). Eventually, in the $O(p^2)$ case, it crosses the $u$-cut on the real axis and enters the adjacent Riemann sheet when the pion mass reaches $526~{\rm MeV}$. At order $O(p^3)$, the rate at which it approaches the real axis slows down; however, we argue that it will ultimately cross the $u$-cut and enter the adjacent Riemann sheet as well. Additionally, the trajectory of the \(N^*(920)\) pole is in qualitative agreement with the results from the linear $σ$ model calculation.

</details>


### [44] [A unified approach for the hadronic weak decays of $Λ$ and $Σ^{\pm}\to Nπ$](https://arxiv.org/abs/2512.10346)
*Ye Cao,Ming-Xiao Duan,Zhong Tao,Qiang Zhao*

Main category: hep-ph

TL;DR: The study applies a non-relativistic quark model to analyze S=-1 hyperon decays, finding that final state interactions correct Λ→nπ⁰ results, while pole terms and Λ(1405) resonance are crucial for accuracy.


<details>
  <summary>Details</summary>
Motivation: To develop a unified approach for understanding hyperon decays using the NRCQM framework and investigate the role of final state interactions and intermediate states.

Method: Analysis of decay channels using direct pion emission, color-suppressed internal W emission, and pole terms, withFSIs modeled via coupled-channel rescatterings for Λ→nπ⁰.

Result: FSIs significantly impact Λ→nπ⁰, pole terms (especially Λ(1405)) are necessary for certain decay accuracy, and radial excitations like N(1710) are dynamically excluded.

Conclusion: Hyperon decays provide insights into weak decay mechanisms and constrain intermediate baryon resonances with FSIs crucial for certain channels.

Abstract: We provide a unified approach for the two-body hadronic weak decays of hyperons with $S=-1$, i.e. $Λ$ and $Σ^\pm$, in the framework of the non-relativistic constitute quark model (NRCQM). A combined analysis shows that the branching ratios and asymmetry parameters of the decay channels $Λ\to pπ^-$ and $Σ^\pm\to Nπ$ can be well described in the same framework with the direct pion emission, color suppressed internal $W$ emission, and pole terms included. However, the channel $Λ\to nπ^0$ indicates significant deviations from the experimental data based on these mentioned transition mechanism. We demonstrate that the final state interactions (FSIs) via the coupled-channel rescatterings play a crucial role in $Λ\to nπ^0$. Namely, the dominant decay channel of $Λ\to pπ^-$ can contribute to $Λ\to nπ^0$ via the $pπ^-\to nπ^0$ rescatterings. This is a leading correction effect for $Λ\to nπ^0$ at the one-loop level. We find that such FSIs only become the leading effects in $Λ\to nπ^0$, but contribute as subleading contributions in other channels. We also demonstrate that the pole terms are indispensable in these hyperon decays. In particular, for $Σ^-\to nπ^-$ and $Σ^+\to nπ^+$, it shows that $Λ(1405)$ as the intermediate state in the pole term amplitude is necessary for reproducing the experimental data. We also find that a dynamic selection rule forbids the radial excitation state $N(1710)$ of the quark model multiplet $|70, ^28,2,0^+,1/2^+\rangle$ from contribution. To some extent, the hyperon hadronic weak decays serve as a special probe for the underlying transition mechanisms and can provide some constraints on the intermediate $J^P=1/2^\pm$ baryon resonances.

</details>


### [45] [Electromagnetic leptogenesis -- an EFT-consistent analysis via Wilson coefficients. Part III. Probing light-neutrino masses and low-energy observables](https://arxiv.org/abs/2512.10444)
*Rin Takada*

Main category: hep-ph

TL;DR: The paper examines the compatibility of electromagnetic leptogenesis with constraints from light neutrino masses and low-energy observables, finding that the model remains robust against current experimental limits.


<details>
  <summary>Details</summary>
Motivation: To ensure the EFT analysis of electromagnetic leptogenesis is consistent with observed neutrino masses and low-energy constraints, particularly addressing how neutrino masses arise and avoiding conflicts with experimental data.

Method: The authors start from a UV-completed model and a one-loop matched Wilson coefficient for the dipole operator $O_{NB}$, calculate radiative neutrino masses, explore leptogenesis mechanisms, derive charged lepton dipole operators, and use RG equations to evolve Wilson coefficients down to lower energies.

Result: The dipole operator alone generates neutrino masses orders of magnitude below observed values, necessitating additional mass terms like seesaw mechanisms. The resulting constraints from dipole observables like μ→eγ and electron EDM are far below current experimental sensitivities.

Conclusion: Electromagnetic leptogenesis within this EFT framework remains viable as it satisfies neutrino mass and low-energy experimental constraints without requiring extreme parameter choices, reinforcing its validity against present data.

Abstract: In this third part of our EFT-consistent analysis of electromagnetic leptogenesis, we confront the dipole operator that sources the baryon asymmetry with constraints from light-neutrino masses and low-energy observables. Starting from the UV completion and one-loop-matched Wilson coefficient $C_{NB}$ of the gauge-invariant operator $O_{NB}=(\bar{L}σ^{μν}P_RN)\tilde{H}B_{μν}$, we compute the radiatively induced Weinberg operator $O_5$ and derive the light Majorana mass matrix generated by a double insertion of $O_{NB}$. For the benchmarks that realise successful resonant electromagnetic leptogenesis at the electroweak scale, these contributions yield neutrino masses far below the scale implied by neutrino oscillation data, so that the observed neutrino masses must originate from additional interactions such as one of the seesaw mechanisms, and only in extreme corners of parameter space do they saturate the cosmological bound on $\sum m_ν$. We also show that no additional Dirac neutrino mass is generated at one loop by the dipole operator alone. Furthermore, we derive the charged-lepton dipole operator $O_{eγ}$ in LEFT, accounting for one-loop operator mixing in the symmetric phase and two-loop Barr--Zee--type graphs in the broken phase, and evolve its Wilson coefficient $C_{eγ}$ down to the muon and electron mass scales using QED renormalisation-group equations. The resulting analytic upper bounds on $\mathrm{BR}(μ\to eγ)$, the electron EDM, and $(g-2)_μ$ lie many orders of magnitude below current experimental sensitivities throughout the BAU-compatible region. Electromagnetic leptogenesis in this EFT framework is therefore robust against present constraints from light-neutrino masses and low-energy dipole probes.

</details>


### [46] [Probing the di-$J/Ψ$ interaction and the nature of $X(6200)$ with femtoscopic correlation functions](https://arxiv.org/abs/2512.10459)
*Zhi-Wei Liu,Jia-Ming Xie,Jun-Xu Lu,Li-Sheng Geng*

Main category: hep-ph

TL;DR: The paper proposes using femtoscopic correlation functions to determine whether the X(6200) near the di-J/Ψ threshold is a resonant, bound, or virtual state, by analyzing differences in correlation behaviors across scenarios, particularly for small source sizes.


<details>
  <summary>Details</summary>
Motivation: To resolve the nature of the X(6200) state near the di-J/Ψ threshold, which remains ambiguous due to insufficient knowledge of di-J/Ψ interactions.

Method: Predicts di-J/Ψ and J/ΨΨ(2S) femtoscopic correlations using the Koonin-Pratt formula with Gaussian source and coupled-channel dynamics; examines sensitivity to source size, quantum statistics, and off-shell effects.

Result: Correlation functions show distinct behavior differences between scenarios (resonant/bound/virtual states) at small source sizes (~1 fm); results are robust against quantum statistical effects and coupled-channel dynamics, with minimal off-shell ambiguity impact.

Conclusion: The proposed correlation analysis provides a clear experimental probe to determine X(6200)'s nature. High LHC J/Ψ production rates and clean detection channels enable testing these predictions, aiding understanding of vector charmonium interactions and tetraquark dynamics.

Abstract: Recent re-analyses of the di-$J/Ψ$ invariant mass spectra reveal a state near the di-$J/Ψ$ threshold, referred to as the $X(6200)$. Yet the nature of this near-threshold pole--whether it is a resonant, bound, or virtual state--remains unresolved due to our limited understanding of the di-$J/Ψ$ interaction. To address this question, we predict the di-$J/Ψ$ and $J/ΨΨ(2S)$ femtoscopic correlation functions based on the Koonin-Pratt formula with a Gaussian source and the coupled-channel dynamics. Our results show that the di-$J/Ψ$ correlation function exhibits distinctly different behaviors in each scenario, especially for small source sizes ($R\sim1$ fm), providing a clear experimental observable to distinguish the nature of $X(6200)$. These distinguishing features persist even when quantum statistical effects and coupled-channel dynamics are included and show negligible sensitivity to off-shell ambiguities. Given the high $J/Ψ$ production rates and clean detection channels at the LHC, we hope that these discoveries will stimulate further experimental studies and help clarify the nature of double-vector-charmonium interactions and the nonperturbative dynamics of fully-heavy tetraquark systems.

</details>


### [47] [Renormalization group evolution induced breaking of $μ-τ$ reflection symmetry in MSSM with effects of variation of $tanβ$](https://arxiv.org/abs/2512.10586)
*Chandan Kumar Borah,Chandan Duarah*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study the renormalization group (RG) evolution induced breaking of $μ$--$τ$ reflection symmetry in the Minimal Supersymmetric Standard Model (MSSM), with a special focus on the effects of varying $\tanβ\equiv v_u/v_d$, the ratio of MSSM Higgs vacuum expectation values. Starting from an exact $μ$--$τ$ reflection symmetry imposed at a high flavor symmetry scale $Λ_{\text{FS}}$, we run the complete set of coupled RGEs for neutrino masses, mixing angles, and CP-violating phases down to the electroweak scale, imparting perturbation to the symmetry. We consider a specific value of the SUSY breaking scale, $Λ_s=7\ TeV$ during the run. By choosing suitable free parameters at the high-energy scale, we reproduce the low-energy experimental constraints on neutrino observables consistent with $3ν$ global analysis data. We then examine how the breaking of $μ$--$τ$ reflection symmetry is influenced by different values of $\tanβ$, considering three benchmark choices. In addition, the analysis is performed for both normal ordering (NO) and inverted ordering (IO) of neutrino masses to highlight potential differences in their RG running behavior.

</details>


### [48] [Quantization of massive Dirac neutrinos in external fields](https://arxiv.org/abs/2512.10587)
*Maxim Dvornikov*

Main category: hep-ph

TL;DR: The paper explores the application of quantum field theory (QFT) to describe massive Dirac neutrinos in external fields, focusing on neutrinos in matter and those with anomalous magnetic moments in magnetic fields. It derives operator-valued wavefunctions, verifies energy-momentum conservation, and calculates propagators, contributing to understanding neutrino oscillations in such environments.


<details>
  <summary>Details</summary>
Motivation: To advance the theoretical framework of QFT in explaining neutrino behavior under external influences, specifically addressing neutrino oscillations in media and magnetic fields which are crucial for precision measurements and astrophysical phenomena.

Method: The study analyzes two external field scenarios: neutrinos in matter and in magnetic fields. It solves the Dirac equation for these cases, derives neutrino wavefunctions adhering to canonical anticommutation relations, and computes propagators using exact solutions.

Result: Derived operator-valued neutrino wavefunctions obeying canonical anticommutation relations, confirmed total energy and momentum conservation, and obtained propagators for Dirac neutrinos in magnetic fields, providing essential tools for QFT applications in neutrino oscillation studies.

Conclusion: The developed formalism enhances QFT's utility in modeling neutrino oscillations within external fields, offering insights for future precision experiments and astrophysical modeling.

Abstract: We review the applications of the quantum field theory (QFT) for the description of massive Dirac neutrinos in external fields. Two particular cases of external background are considered. First, we examine neutrinos in background matter. Then, we study neutrinos with anomalous magnetic moments in a magnetic field. In both situations, we derive the operator valued neutrino wavefunctions, accounting for external fields, which obey the canonical anticommutation relations. Then, we check that the total energy and momentum of a neutrino field have the appropriate forms. Using the exact solution in a Dirac equation in a magnetic field, we also derive the propagator for a massive Dirac neutrino in this external background. The results obtained are of importance for the QFT application to neutrino oscillations in external fields.

</details>


### [49] [Three-body resonances of $ααM$ clusters ($M=φ$, $J/ψ$, $η_c$) in $^{9}_{M}{\mathrm{Be}}$ nuclei](https://arxiv.org/abs/2512.10695)
*Hao Zhou,Xiang Liu*

Main category: hep-ph

TL;DR: The paper explores exotic nuclei $^{9}_φ{	ext{Be}}$, $^{9}_{J/ψ}{	ext{Be}}$, and $^{9}_{η_c}{	ext{Be}}$ as three-body α+α+M systems using HAL QCD potentials. It finds the φ meson strongly binds nuclei into stable states, reducing α-α distances, while J/ψ and η_c form shallow bound states and increase α separation. Weakly bound α-J/ψ states suggest $^{9}_{J/ψ}{	ext{Be}}$ isn't Borromean.


<details>
  <summary>Details</summary>
Motivation: The study is driven by recent HAL QCD potentials for N-φ, N-J/ψ, and N-η_c interactions. The aim is to understand how these mesons affect exotic Be nuclei structures as three-body systems.

Method: Bound/resonant states calculated via Gaussian expansion method, with resonances identified by complex scaling method. Folding potentials modeled using HAL QCD data fitted to Woods-Saxon form, analyzing meson effects on α-α clustering.

Result: φ meson induces strong binding (glue-like effect), stabilizing 0^+_1, 2^+_1, 4^+_1 resonant states and reducing α-α distance. J/ψ/η_c produce shallow bound states, increasing α separation. New weak α-J/ψ states in $^4S_{3/2}/^2S_{1/2}$ channels indicate non-Borromean $^{9}_{J/ψ}{	ext{Be}}$. The $^{9}_φ{	ext{Be}}$ 4^+_1 state's stability depends subtly on α radius.

Conclusion: Different mesons dynamically modify nuclear clustering. φ strongly binds nuclei while charmonium mesons weakly interact. These predictions guide experimental searches for exotic hadron-nucleus systems, emphasizing φ's unique role.

Abstract: Motivated by the recently obtained HAL QCD potentials for the $N$-$φ$, $N$-$J/ψ$, and $N$-$η_c$ interactions. interactions, we investigate the structure of the exotic nuclei $^{9}_φ{\text{Be}}$, $^{9}_{J/ψ}{\text{Be}}$, and $^{9}_{η_c}{\mathrm{Be}}$ as $α+α+M$ three-body systems ($M$ denotes the meson). The bound and resonant states are calculated consistently using the Gaussian expansion method, with resonances identified via the complex scaling method. For the $αφ$ and $α$-charmonium interactions, a folding potential is constructed based on the HAL QCD potentials and fitted to a Woods-Saxon form. We find that the $φ$ meson exhibits a strong "glue-like" effect, binding the $0^+_1$, $2^+_1$, and $4^+_1$ resonant states of $^8$Be into stable states and significantly reducing the $α$-$α$ distance. In contrast, the interactions of $J/ψ$ and $η_c$ with the nucleus are weaker, forming only shallow bound states with the $0^+_1$ state of $^8$Be and even increasing the $α$-$α$ separation. Notably, our analysis predicts weakly bound $α$-$J/ψ$ states in the $^4S_{3/2}$ and $^2S_{1/2}$ channels, a result not reported in prior studies, which suggests that $^{9}_{J/ψ}{\text{Be}}$ may not be a Borromean nucleus. The sensitivity of the $^{9}_φ{\text{Be}}(4^+_1)$ state-transitioning from bound to resonant depending on the $α$-particle radius-highlights the subtle dynamics at play. These results provide a systematic theoretical comparison of how different vector mesons modify nuclear clustering, offering critical predictions for future experimental searches of such exotic hadron-nucleus systems.

</details>


### [50] [Disperon QED](https://arxiv.org/abs/2512.10709)
*Yizhou Fang,Sophie Kollatzsch,Marco Rocco,Adrian Signer,Yannick Ulrich,Max Zoller*

Main category: hep-ph

TL;DR: Disperon QED is a novel method integrating dispersion relations and automated tools to handle hadronic vacuum polarisation in loop processes, demonstrated through ee→ππ analysis in McMule, highlighting its applicability to complex processes.


<details>
  <summary>Details</summary>
Motivation: To address challenges in handling hadronic vacuum polarisation insertions and loop processes in Monte Carlo simulations, particularly in two-loop contributions and pion form factor calculations.

Method: Combines dispersion relations, automated tools (e.g., OpenLoops), effective field theory, and threshold subtraction. Applied to ee→ππ in McMule for vector form factor calculations under scalar QED approximation.

Result: Successfully applied to the specified processes, showing effectiveness in managing hadronic contributions and paving the way for more complex loop calculations.

Conclusion: Disperon QED offers a versatile approach for loop process simulations, particularly useful for intricate hadronic interactions, with potential extension to other complicated scenarios.

Abstract: We present disperon QED, a method to deal with data input in loop processes in Monte Carlo codes. It relies on dispersion relations, automated tools such as OpenLoops, effective field theory methods and a threshold subtraction. We motivate this method and apply it to the process $ee\toππ$ in McMule to deal with hadronic vacuum polarisation insertions in two-loop contributions as well as the vector form factor of the pion within the form-factor scalar QED approximation. The generality of this method for more complicated processes is emphasised.

</details>


### [51] [Approximate N$^2$LO and N$^3$LO QCD Predictions for $tW$ Production](https://arxiv.org/abs/2512.10711)
*Jia-Le Ding,Hai Tao Li,Jian Wang*

Main category: hep-ph

TL;DR: The paper calculates approximate N²LO and N³LO QCD corrections for tW production at the LHC, incorporating large logarithmic terms and delta functions using two-loop and three-loop functions. These corrections enhance the NLO cross-section by over 10% and improve agreement with experimental data, enabling a direct determination of |V_tb| without assuming CKM unitarity.


<details>
  <summary>Details</summary>
Motivation: To improve the precision of theoretical predictions for tW production at the LHC by including higher-order QCD corrections, which are necessary for precise comparisons with experimental data and for determining fundamental parameters like |V_tb| without relying on CKM unitarity assumptions.

Method: The authors compute approximate N²LO corrections using two-loop hard and soft functions to capture log^n terms and delta functions at O(α_s²). For N³LO, they include logarithmic terms at O(α_s³) via renormalization group equations and the three-loop soft anomalous dimension, though delta terms are only partially accurate. Numerical evaluations were performed to assess impacts.

Result: The corrections increase the NLO cross-section by over 10%. When included, they improve agreement with LHC data, allowing a determination of |V_tb| = 0.99 ± 0.03 (exp.) ± 0.03 (theo.) without assuming CKM unitarity.

Conclusion: Higher-order QCD corrections are crucial for precise tW production predictions. The results validate the approach's effectiveness in enhancing theoretical precision and directly determining |V_tb|, reducing reliance on CKM matrix unitarity assumptions.

Abstract: We report a calculation of approximate next-to-next-to-leading-order (N$^2$LO) and next-to-N$^2$LO (N$^3$LO) QCD corrections to associated $tW$ production at the LHC, which constitute the dominant contributions to full perturbative predictions. The approximate N$^2$LO corrections consist of the large logarithmic terms $\ln^n (1-Q^2/\hat{s})$ (with $\sqrt{\hat{s}}$ being the partonic center-of-mass energy and $Q$ the invariant mass of the $tW$ system) and the terms proportional to $δ(1-Q^2/\hat{s})$ at $\mathcal{O}(α_s^2)$, which are obtained by utilizing the newly obtained two-loop hard and soft functions. The approximate N$^3$LO corrections further include the large logarithms at $\mathcal{O}(α_s^3)$ by using renormalization group evolution equations and the three-loop soft anomalous dimension, while the $δ(1-Q^2/\hat{s})$ term is only partially accurate at this order. Numerical evaluation reveals that they increase the NLO cross section by more than $10\%$. The inclusion of these higher-order corrections leads to improved agreement with the experimental data at the LHC, resulting in a direct determination of the CKM matrix element $|V_{tb}|=0.99\pm 0.03({\rm exp.})\pm 0.03({\rm theo.})$ without assuming unitarity of the matrix.

</details>


### [52] [Partial $A_4$ flavor symmetry of the leptonic 3HDM](https://arxiv.org/abs/2512.10736)
*Bartosz Dziewit,Marek Zrałek,Joris Vergeest*

Main category: hep-ph

TL;DR: The paper explores the use of $A_4$ symmetry in a three-Higgs-doublet model (3HDM) to accurately reproduce lepton mass hierarchies and experimental neutrino mixing angles (PMNS matrix), showing that $A_4$ symmetry uniquely achieves this without requiring specific Higgs vev configurations.


<details>
  <summary>Details</summary>
Motivation: To find a flavor symmetry group that can precisely account for observed lepton masses and mixing angles, particularly the PMNS matrix, while maintaining correct mass orderings for charged and neutral leptons (Dirac neutrinos with normal hierarchy).

Method: The authors implement an $A_4$ triplet representation for Higgs doublets in a 3HDM, derive lepton mass matrices under this symmetry, and compare predictions to experimental data. They also survey symmetry groups of order ≤600 to confirm the uniqueness of $A_4$'s solution.

Result: The $A_4$ model reproduces neutrino mixing angles and mass orderings accurately even with non-canonical Higgs vacua. No smaller groups (≤600 elements) provide better fit or alternative solutions.

Conclusion: $A_4$ symmetry is uniquely effective in the studied group set for simultaneously describing lepton mass spectra and PMNS parameters, suggesting its theoretical preference in flavor models.

Abstract: When the Higgs doublets in the 3HDM transform as a flavor triplet of the $A_4$ group, the lepton mass matrices accommodate the experimental neutrino mixing angles at arbitrary precision while maintaining the correct mass ordering of the charged and neutral leptons, the latter being Dirac neutrinos in the normal spectrum. Under $A_4$ symmetry, also agreement of the lepton masses with experimental data is obtained for Higgs vacua differing from those for fitting $U_{\text{PMNS}}$. For groups of order equal or less than 600 no contractions different from the one found for $A_4$ yield better agreement with experimental data, and the solution structure presented is unique within the set of groups studied.

</details>


### [53] [Exploring New Propagation Scales With Galactic Neutrinos](https://arxiv.org/abs/2512.10744)
*Miller MacDonald,Kiara Carloni,Carlos A. Argüelles,Ivan Martínez-Soler,Rafael Alves Batista*

Main category: hep-ph

TL;DR: The analysis of Galactic neutrinos from IceCube and KM3NeT can probe quasi-Dirac neutrino mass-squared differences and neutrino decay parameters beyond current limits.


<details>
  <summary>Details</summary>
Motivation: To explore new physics affecting neutrino propagation at cosmic distances using high-energy Galactic neutrinos observed by IceCube and future KM3NeT data.

Method: Assessed sensitivity of IceCube and KM3NeT to quasi-Dirac neutrinos and neutrino decays by analyzing neutrino propagation over $10^9-10^{15}$ km/GeV scales.

Result: Joint measurements can probe $δm^2$ ranges of $10^{-13.5}$ to $10^{-11.9}$ eV² for quasi-Dirac neutrinos and $m/τ>10^{-12.3}$ eV² for neutrino decays at 90% CL.

Conclusion: Global neutrino telescope networks can effectively test neutrino mass models through Galactic neutrino observations.

Abstract: The recent observation of high-energy Galactic neutrinos by IceCube allows for searches of new physics affecting neutrino propagation on scales of $O(10^9-10^{15})\,\mathrm{km/GeV}$ in distance over energy. We assess the sensitivity of upcoming measurements of Galactic neutrinos by IceCube and KM3NeT to such new phenomena. We focus on two scenarios: quasi-Dirac neutrinos and neutrino decays. In the quasi-Dirac scenario, we find that joint measurements by IceCube and KM3NeT are sensitive to the mass-squared differences $δm^2 \in \left(10^{-13.5}~\mathrm{eV^2}, 10^{-11.9}~\mathrm{eV^2}\right)$ at the $90\%$ confidence level. For neutrino decays, the same measurements are sensitive to mass over lifetime ratios $m / τ> 10^{-12.3}~\mathrm{eV^2}$ at the same significance. Our results demonstrate that measurements of Galactic neutrinos by a global network of neutrino telescopes can probe signatures of neutrino mass models.

</details>


### [54] [Electroweak right-handed neutrino portal dark matter](https://arxiv.org/abs/2512.10762)
*Wan-Zhe Feng,Ao Li,Zong-Huan Ye,Zi-Hui Zhang*

Main category: hep-ph

TL;DR: This paper explores dark matter interacting with the Standard Model via electroweak-scale right-handed neutrinos in a Type-I seesaw framework, considering a minimal dark sector with a fermion and scalar. It uses Particle Swarm Optimization to find viable parameters consistent with neutrino data and calculates relic abundance using coupled Boltzmann equations, highlighting the importance of internal dark sector interactions in freeze-in scenarios.


<details>
  <summary>Details</summary>
Motivation: The study aims to connect neutrino physics with dark matter cosmology, addressing the need for a well-motivated framework that links particle physics, neutrino data, and cosmological observations. It seeks to accurately compute dark matter relic abundance accounting for internal dark sector interactions, which simpler models may misestimate.

Method: The authors analyze three realizations of electroweak right-handed neutrinos with varying couplings (small, large, ultraweak) to the Standard Model, leading to freeze-out or freeze-in production mechanisms. They employ Particle Swarm Optimization to determine parameter sets compliant with neutrino oscillation data and other constraints, then solve coupled Boltzmann equations for dark sector particles' evolution.

Result: The paper demonstrates that internal dark sector interactions in freeze-in scenarios can change the predicted relic density by up to 95%, showing that independent freeze-in component treatments overestimate abundance. Valid benchmark scenarios are identified where observed dark matter abundance is achieved, reinforcing the model's viability.

Conclusion: Electroweak right-handed neutrino portal dark matter offers a robust, testable framework linking neutrino physics, collider searches, and cosmology. The work underscores the necessity of coupled Boltzmann equation solutions for accuracy and provides a benchmark for multi-messenger experiments at high-energy facilities.

Abstract: We study dark matter coupled to the standard model via electroweak scale right-handed neutrinos in a Type-I seesaw framework. We consider a minimal dark sector containing a fermion $χ$ and a complex scalar $φ$ whose only connection to the standard model is through renormalizable Yukawa interactions with right-handed Majorana neutrinos, thus realizing a neutrino portal after seesaw mixing. We discuss three representative realizations of electroweak right-handed neutrinos arising from the Type-I seesaw mechanism, spanning small, large, and ultraweak couplings to the standard model sector, so that the dark particles can either undergo secluded freeze-out or be produced via freeze-in. Instead of merely estimating the order of magnitude of the seesaw couplings, we use the Particle Swarm Optimization algorithm to obtain viable seesaw parameter sets consistent with neutrino data and other constraints, and then compute the coupled evolution of the dark particles and right-handed neutrinos, reproducing the observed dark matter relic abundance in representative benchmark scenarios. For the freeze-in case, we show that internal dark sector interactions can significantly modify the predicted relic density: treating each hidden particle as an independent freeze-in component and simply adding late decays can misestimate the final dark matter abundance by $30\%$, or even $95\%$, depending on the type of internal interactions, compared to a full solution of the coupled Boltzmann equations for all dark species, including the dark sector temperature. Electroweak right-handed neutrino portal dark matter thus provides a robust, testable framework that tightly connects neutrino physics, collider searches for heavy neutral leptons, and the cosmological dark matter relic density, offering a well-motivated benchmark for multi-messenger probes at the high energy frontier.

</details>


### [55] [Additional results on the four-loop flavour-singlet splitting functions in QCD](https://arxiv.org/abs/2512.10783)
*G. Falcioni,F. Herzog,S. Moch,A. Pelloni,A. Vogt*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We have extended our previous computations, performed analytically for a general gauge group, of the even-$N$ moments $γ_{\rm ik}^{\,(3)}(N)$ of the four-loop flavour-singlet splitting functions $P_{\rm ik}^{\,(3)}(x)$ to $N = 22$. The numerical QCD results perfectly agree with all predictions resulting from the approximations for $P_{\rm ik}^{\,(3)}(x)$ that we obtained before from the moments $N \leq 20 $ and endpoint constraints, confirming their reliability for collider-physics applications. Due to the additional analytical constraints provided by our new $N = 22$ results, we are now closing in on determining the all-$N$ forms of all non-rational ($ζ$-function) contributions to $γ_{\rm ik}^{\,(3)}(N)$: only the $n_f^{0} ζ_3$ parts of the quark-to-gluon (gq) and the $n_f^{1} ζ_3$ parts of the gluon-to-gluon (qg) cases still need to be completed. Finally we extend our approximations for all $P_{\rm ik}^{\,(3)}(x)$ to $n_f^{} = 6$ light flavours and update those for $P_{\rm gq}^{\,(3)}(x)$ at lower $n_f^{}$.

</details>


### [56] [Nonlocal form factor of chromomagnetic penguin in $B\to K\ell^+\ell^-$ from QCD light-cone sum rules](https://arxiv.org/abs/2512.10868)
*T. Hurth,A. Khodjamirian,F. Mahmoudi,D. Mishra,Y. Monceaux,S. Neshatpour*

Main category: hep-ph

TL;DR: The paper presents the first complete calculation of the nonlocal form factor at spacelike $q^2$ for the chromomagnetic operator $O_{8g}$ in $B 	o Katellcorr{	o}	o{	o}	o	o	o	o	o}	o}$\fatellcorr{	o}	o}	o	o	o\" for general covariance)


<details>
  <summary>Details</summary>
Motivation: The branching fraction of the $B \to K\ell^+\ell^-$ decay measured by the LHC experiments shows deviations from Standard Model predictions, with nonlocal hadronic effects being a major source of uncertainty. These effects are encapsulated in a nonlocal form factor requiring accurate computation to resolve discrepancies.

Method: The authors use Light-Cone Sum Rules (LCSRs) with $B$-meson distribution amplitudes to compute the nonlocal form factor at $q^2<0$, specifically for the $O_{8g}$ operator. They calculate OPE diagrams with hard-gluon exchanges, analyze their structure/hierarchy, and derive the spectral density needed for combining with soft-gluon contributions via LCSR.

Result: The first complete analytic and numerical results for the nonlocal $O_{8g}$ form factor at all spacelike $q^2$ values are obtained. Key terms in the OPE hierarchy and their $q^2$-dependence are characterized, providing essential inputs for future combined calculations.

Conclusion: This work establishes critical groundwork for future comprehensive predictions of the $B \to K\ell^+\ell^-$ form factor, especially the inclusion of dominant charm-loop contributions. It advances the precision of Standard Model predictions needed to interpret experimental deviations.

Abstract: The branching fraction of the $B \to K\ell^+\ell^-$ decay has been measured recently by the LHC experiments, showing a deviation from theory predictions based on the Standard Model (SM). A major challenge in achieving a complete SM prediction and interpreting this discrepancy lies in the treatment of nonlocal hadronic effects. In $B \to K\ell^+\ell^-$, these effects are cast in a single nonlocal form factor, a function of squared momentum transfer $q^2$ to the lepton pair. One of the previously used methods provides this form factor in the region of spacelike momentum transfer, $q^2<0$, matching the result to the hadronic dispersion relation, which is then continued to the physical region. The calculation done so far was a combination of QCD factorisation for hard-gluon contributions with light-cone sum rules (LCSRs) for soft-gluon ones. In this work, we calculate for the first time the complete nonlocal form factor at $q^2<0$ for one of the effective operators, the chromomagnetic operator $O_{8g}$, applying the method of LCSRs with $ B$-meson distribution amplitudes. We compute, both analytically and numerically, the operator-product expansion (OPE) diagrams with hard-gluon exchanges, analyse their structure and hierarchy, and obtain their spectral density entering the LCSR together with soft-gluon contributions. This study paves the way for our next task, a complete calculation of nonlocal $B \to K\ell^+\ell^-$ form factor at spacelike $q^2$, including the dominant contributions of current-current operators, known as charm-loops.

</details>


### [57] [Standard Model Benchmarks for $D^0\to K^- K^+, π^-π^+, K^0_{\rm S} K^0_{\rm S}$ Decays](https://arxiv.org/abs/2512.10911)
*Robert Fleischer,Maria Laura Piscopo,K. Keri Vos,B. Yağmur Zubaroğlu*

Main category: hep-ph

TL;DR: The paper explores non-leptonic D^0 decays to probe the Standard Model using lattice QCD, showing that non-factorisable contributions and U-spin breaking effects (around 50%) explain measured branching ratios. The D^0→K_S^0K_S^0 decay, governed by exchange topologies and vanishing in the U-spin limit, is analyzed, with CP violation in this channel constrained to a few per mille.


<details>
  <summary>Details</summary>
Motivation: To test the Standard Model predictions for charm quark decays and understand U-spin symmetry breaking effects, which are crucial for validating the model and identifying potential new physics. The unique nature of D^0→K_S^0K_S^0 provides a sensitive probe of non-factorisable interactions and symmetry violations.

Method: Lattice QCD calculations of colour-allowed tree amplitudes in factorisation, combined with extrapolations using isospin symmetry. The study incorporates non-factorisable contributions and U-spin breaking effects to model measured branching ratios, focusing on D^0→K^-K^+, π^-π^+ and D^0→K_S^0K_S^0 decays.

Result: The measured branching ratios for D^0→K_S^0K_S^0 are accommodated with U-spin breaking effects (∼50%) and exchange amplitudes (∼50% of colour-allowed tree contributions). For CP violation in D^0→K_S^0K_S^0, upper bounds of a few per mille are derived, aligning with experimental data and providing targets for future measurements.

Conclusion: The Standard Model adequately explains the observed decays when including sizable non-factorisable and U-spin breaking effects. The D^0→K_S^0K_S^0 decay serves as a critical probe for testing these effects. Future experiments targeting CP violation in this channel may further constrain or challenge the Standard Model predictions.

Abstract: The non-leptonic $D^0\to K^- K^+$ and $D^0\to π^-π^+$ decays are powerful probes of the Standard Model and are related to each other through the $U$-spin symmetry of the strong interaction. Using lattice QCD inputs we calculate the corresponding colour-allowed tree amplitudes in factorisation and demonstrate that non-factorisable contributions and $U$-spin-breaking effects at the level of 50% allow us to accommodate the measured branching ratios in the Standard Model. An exciting direct probe of such non-factorisable and $U$-spin breaking effects is provided by the $D^0\to K^0_{\rm S} K^0_{\rm S}$ channel. This decay is governed by non-factorisable exchange topologies and essentially vanishes in the $U$-spin limit, although it is experimentally well established with a prominent branching ratio. Extrapolating our $D^0\to K^- K^+$ results using the isospin symmetry, we find a consistent benchmark picture. Specifically, we can accommodate the measured $D^0\to K^0_{\rm S} K^0_{\rm S}$ branching ratio with $U$-spin-breaking effects at the 50% level and exchange amplitudes at the level of 50% of the colour-allowed $D^0\to K^- K^+$, $D^0\to π^-π^+$ tree contributions. Finally, we explore the resulting range for direct CP violation in $D^0\to K^0_{\rm S} K^0_{\rm S}$, obtaining upper bounds in our benchmark scenarios of a few per mille, offering an exciting target for future measurements.

</details>


### [58] [Hiding a Light Vector Boson from Terrestrial Experiments: A Chargephobic Dark Photon](https://arxiv.org/abs/2512.10916)
*Haidar Esseili,Graham D. Kribs*

Main category: hep-ph

TL;DR: The paper explores a generalized vector boson interacting with electromagnetic and B-L currents, focusing on the 'chargephobic dark photon' which evades many standard experimental constraints due to suppressed couplings to electrons and protons, leaving neutrino and neutron interactions as key probes. Key constraints come from supernova, cosmology, and COHERENT-like experiments, with future detectors like SHiP opening new parameter space.


<details>
  <summary>Details</summary>
Motivation: To investigate a light vector boson's viable parameter space beyond dark photons, analyzing how suppressed couplings to charged particles lead to unique phenomenology and constraints primarily via neutrino/neutron interactions.

Method: The study performs a comprehensive analysis across terrestrial (neutrino scattering), astrophysical (supernova neutrinos), and cosmological (effective number of neutrinos) constraints, varying the dark mixing angle parameter space between 1 MeV to 60 GeV vector boson masses.

Result: Chargephobic vector bosons are strongly constrained by supernova emission and cosmological ΔN_eff, not traditional experiments. New regions of lower masses/mixing angles are accessible with future experiments like SHiP. These particles represent the least constrained among anomaly-free bosons in this coupling scheme.

Conclusion: The chargephobic regime offers a robust framework for testing beyond-Standard-Model physics, highlighting the necessity of next-gen experiments targeting neutrino/nucleon interactions. Astrophysical/cosmological probes are critical for model-independent constraints where direct detection faces challenges.

Abstract: We calculate the terrestrial, astrophysical and cosmological constraints on a light vector boson that couples to an arbitrary combination of the electromagnetic and $B-L$ currents of the Standard Model. The dark photon and a vector boson coupling to $B-L$ are special cases of our generalized flavor-universal anomaly-free vector boson, requiring just one additional parameter (the "dark mixing angle" corresponding to the linear combination of the electromagnetic and $B-L$ currents) beyond that of the overall coupling strength and the vector boson mass, where we focus on the range $1\, {\rm MeV}$ to $60\, {\rm GeV}$. We perform a detailed investigation of a unique combination where the vector boson couplings to electrically charged leptons and protons are highly suppressed: the "chargephobic dark photon". A chargephobic vector boson is very weakly constrained by current terrestrial experiments including beam dumps and collider experiments, since they rely on couplings to electrons and protons. Instead, neutrino scattering experiments (such as COHERENT), astrophysical sources (supernova emission), and cosmology ($ΔN_{\rm eff}$) provide the strongest constraints due to the nonzero couplings of the chargephobic vector boson to neutrinos and neutrons. Indeed, we find that supernova emission and $ΔN_{\rm eff}$ provide constraints throughout the space of dark mixing angles, demonstrating their importance to provide model-independent constraints. For nearly all of the parameter space, a chargephobic vector boson is the most weakly constrained anomaly-free vector boson that couples to flavor-independent or flavor-dependent combinations of Standard Model currents. Finally, we highlight the importance of future experiments, including SHiP, that are able to probe new regions of the chargephobic parameter space due to the significantly improved detector capabilities.

</details>


### [59] [Heterogeneous Cosmological Phase Transitions: Seeded by Domain Walls and Junctions](https://arxiv.org/abs/2512.10917)
*Yang Bai,Yifu Xu,Yiming Yang*

Main category: hep-ph

TL;DR: The paper shows that domain-wall junctions in theories with Zₙ (n≥3) symmetry significantly enhance heterogeneous nucleation, leading to more efficient completion of cosmological phase transitions at higher temperatures compared to homogeneous nucleation or nucleation seeded by domain walls alone.


<details>
  <summary>Details</summary>
Motivation: Heterogeneous nucleation's role in first-order phase transitions is crucial, especially in cosmology. Existing studies focus on simpler cases (e.g., Z₂ symmetry without junctions), but theories with higher symmetries (Zₙ≥3) naturally form domain-wall junctions, which may dominate nucleation dynamics.

Method: Analyzes nucleation seeded by preexisting domain walls and their junctions using a two-scalar-field model. Derives bubble solutions as spherical caps with contact angles determined by tension ratios. Calculates critical nucleation actions and compares nucleation temperatures for homogeneous/heterogeneous channels.

Result: Domain-wall junctions seed nucleation more efficiently than individual walls. Junction-seeded bubbles form at higher temperatures, completing phase transitions earlier. For Zₙ≥3 theories, junction-dominated heterogeneous nucleation is the dominant mechanism, lowering critical action and increasing transition temperatures.

Conclusion: Cosmological phase transitions with Zₙ symmetry are predominantly driven by junction-seeded nucleation. This challenges previous assumptions relying on homogeneous nucleation or wall-seeded processes, highlighting the importance of multi-wall junctions in determining cosmological dynamics and observables like gravitational wave signatures.

Abstract: Heterogeneous nucleation is central to many familiar first-order phase transitions such as the freezing of water and the solidification of metals, and it can also play a crucial role in cosmology. We examine nucleation seeded by preexisting domain walls and demonstrate its strong impact on the dynamics of cosmological phase transitions. The bubble solutions take the form of spherical caps, and the contact angle is fixed by the ratio of the domain-wall tension to the bubble-wall tension. A larger domain-wall tension, or equivalently a smaller contact angle, reduces the wall-seeded bubble volume and lowers the critical nucleation action. For theories with $\mathbb{Z}_{n\geq 3}$ symmetry, domain-wall junctions naturally appear and we find that they seed nucleation even more efficiently than the walls themselves. Using a two-scalar-field model as an illustration, we compute nucleation temperatures for both homogeneous and heterogeneous channels and show that junction-seeded nucleation occurs at a higher temperature and is the dominant mechanism that completes the first-order cosmological phase transition.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [60] [Formation of circumstellar material during double-white-dwarf mergers and the early excess emissions in Type Ia supernovae](https://arxiv.org/abs/2512.10014)
*Yusuke Inoue,Keiichi Maeda,Takashi Nagao,Tatsuya Matsumoto*

Main category: astro-ph.HE

TL;DR: The study investigates how circumstellar matter (CSM) formed during double white-dwarf (WD) mergers interacts with supernova Ia ejecta, particularly in the context of carbon-ignited violent mergers (C-ignited VM). Simulations show the CSM density distribution and reproduce early optical/UV flux excesses observed in 03fg/02es-like SNe Ia, supporting the VM origin. Helium-ignited VM scenarios are also considered, with CSM formation via tidal disruption during mass transfer.


<details>
  <summary>Details</summary>
Motivation: To understand the origin of early excess emissions in Type Ia supernovae, which are poorly explained by standard models. The study aims to link these observations to violent merger scenarios of double WD systems, specifically examining CSM-ejecta interactions.

Method: Combines orbital evolution models of double WD systems undergoing super-Eddington mass transfer, hydrodynamical simulations of SN-CSM interaction, and light-curve modeling. Assumes C-ignited VM with prompt SN Ia explosion; explores both C-ignited and He-ignited merger scenarios.

Result: Simulations produced CSM density profiles (ρ_CSM ~ (r/1e14 cm)^-3.5) that, when interacted with SN ejecta, replicate observed early optical/UV flux excesses and color evolution in 03fg/02es-like SNe. Helium-ignited VMs also form CSM through tidal disruption during mass transfer phases.

Conclusion: 03fg/02es-like SNe Ia likely originate from C-ignited violent WD mergers, with their early emission attributed to SN ejecta interacting with CSM. Both C- and He-ignited VM scenarios produce CSM via mass transfer, suggesting violent mergers as a viable progenitor channel for these peculiar SNe Ia.

Abstract: Early excess emission observed in Type Ia supernovae (SNe Ia) within $\sim1$ day of explosion provides a critical window into their progenitor systems. In the present study, we investigate formation of the circumstellar matter (CSM) in double white-dwarf (WD) mergers. We further study the interaction between the CSM and the SN ejecta. We first model the orbital evolution and super-Eddington mass transfer/ejection in the double WD systems. We then conduct hydrodynamical and light-curve (LC) simulations of the SN-CSM interaction, assuming a prompt SN Ia explosion in a context of the carbon-ignited violent merger (C-ignited VM). Our simulations show that at the moment of the merger, the binary system has the CSM distribution following $ρ_{\mathrm{CSM}}\simeq D(r/10^{14}\ \mathrm{cm})^{-3.5}\ (D\simeq 10^{-14}\text{--}10^{-13}\ \rm g\ cm^{-3})$. The simulated LCs reproduce the early flux excesses across optical to UV bands, as well as their color evolution, observed in the VM candidates, i.e., 03fg/02es-like SNe Ia. This supports that 03fg/02es-like objects originate from the VM explosions. We also discuss the case of the helium-ignited VM, which might be realized in some WD-WD mergers depending on the He content in the system. Focused here is the timing when the explosion is initiated, and we find that the explosion is initiated after the companion WD is, at least partially, tidally disrupted also in this case; we thus expect the formation of the CSM through the mass transfer phase also for the helium-ignited VM scenario.

</details>


### [61] [Classification of a New X-ray Catalog of Likely Counterparts to 4FGL-DR4 Unassociated Gamma-ray Sources Using a Neural Network](https://arxiv.org/abs/2512.10023)
*Kyle D. Neumann,Abraham D. Falcone,Stephen DiKerby,Sierra Deppe,Elizabeth C. Ferrara,Jamie A. Kennea,Brad Cenko,Eric Grove*

Main category: astro-ph.HE

TL;DR: The study uses Swift XRT and UVOT data to identify potential low-energy counterparts for unassociated Fermi gamma-ray sources, classifying them as blazars, pulsars, or ambiguous using an MLP neural network.


<details>
  <summary>Details</summary>
Motivation: To identify counterparts for gamma-ray sources not yet associated in the 4FGL catalog, aiding in understanding their nature through multiwavelength analysis.

Method: Analysed 244 unassociated Fermi sources using Swift's XRT/UVOT data. Detected 218 singlet/70 multiplet X-ray sources, calculated X-ray flux/optical magnitudes, then applied an MLP NNC to classify sources into blazar, pulsar, or ambiguous categories.

Result: Classified 173/6 singlets as likely blazars/pulsars, with 34 ambiguous; adding multiplets increased totals to 227 blazars and 16 pulsars. Results align with prior classifications where available.

Conclusion: The neural network method effectively classifies unknown gamma-ray sources, providing a reliable approach for associating future unassociated Fermi sources through multiwavelength data fusion.

Abstract: Our survey of the fourth $\mathit{Fermi}$ Large Area Telescope catalog (4FGL) unassociated gamma-ray source regions using the X-Ray Telescope (XRT) and Ultraviolet/Optical Telescope (UVOT) aboard the Neil Gehrels $\mathit{Swift}$ Observatory ($\mathit{Swift}$) provides new XRT and UVOT source detections and localizations to help identify potential low-energy counterparts to unassociated $\mathit{Fermi}$ gamma-ray sources. We present a catalog of 218 singlet and 70 multiplet $\mathit{Swift}$ X-ray sources detected within the positional uncertainty ellipses of 244 unassociated $\mathit{Fermi}$ gamma-ray sources from the 4FGL-DR4 catalog, 144 of which are not previously cataloged by Kerby et al. (2021b). For each X-ray source, we derive its X-ray flux and photon index, then use simultaneous UVOT observations with optical survey data to estimate its $V$-band magnitude. We use these parameters as inputs for a multi-layer perceptron (MLP) neural network classifier (NNC) trained to classify sources as blazars, pulsars, or ambiguous gamma-ray sources. For the 213 singlet sources with X-ray and optical data, we classify 173 as likely blazars ($P_\mathrm{bzr} > 0.99$) and 6 as likely pulsars ($P_\mathrm{bzr} < 0.01$), with 34 sources yielding ambiguous results. Including 70 multiplet X-ray sources, we increase the number of $P_\mathrm{bzr} > 0.99$ to 227 and $P_\mathrm{bzr} < 0.01$ to 16. For the subset of these classifications that have been previously studied, a large majority agree with prior classifications, supporting the validity of using this NNC to classify the unknown and newly detected gamma-ray sources.

</details>


### [62] [Spectrally Resolved Gas Kinematics in Cygnus A: XRISM Detects AGN Jet-induced Velocity Dispersion in Multi-temperature Gas](https://arxiv.org/abs/2512.10167)
*Anwesh Majumder,T. Heckman,J. Meunier,A. Simionescu,B. R. McNamara,L. Gu,A. Ptak,E. Hodges-Kluck,M. Yukita,M. W. Wise,N. Roy*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We report spectral analysis on a 170 ks XRISM \textit{Resolve} exposure of the core of Cygnus A. Analyzing the full field of view spectrum in the $1.7-12.0$ keV band, we find evidence for two-temperature cluster gas. The hotter ($kT = 5.53 \pm 0.13$ keV) gas has a velocity dispersion of $261 \pm 13$ km s$^{-1}$ and a bulk velocity of $120 \pm 20$ km s$^{-1}$ with respect to the central galaxy. The cooler gas ($kT = 2.0^{+0.4}_{-0.3}$ keV) has an even broader velocity dispersion of $440 \pm 130$ km s$^{-1}$, with a systematic uncertainty of $120$ km s$^{-1}$. The relative line-of-sight velocity between the hotter and cooler gas can be as high as $450 \pm 140$ km s$^{-1}$. We interpret the high velocity dispersions as a combination of turbulence and bulk motion due to the cocoon shock. The upper limit on the non-thermal pressure fraction for the hotter gas is $7.7 \pm 0.7\%$. We associate the cooler gas with the central region ($<35$ kpc) and the hotter phase with the gas surrounding it ($35-100$ kpc). The total energy due to the kinetic motion is $5.1 \times 10^{60}$ erg, consistent with the energy associated with the central radio source. The kinetic energy injection rate is $6.9 \times 10^{44}-7.4 \times 10^{45}$ erg s$^{-1}$ under varying assumptions of injection timescales. The range of injection power is higher than the cooling luminosity, and thus the heating and cooling rates in Cygnus A are unbalanced.

</details>


### [63] [FEADME: Fast Elliptical Accretion Disk Modeling Engine](https://arxiv.org/abs/2512.10228)
*Nicholas Earl,K. Decker French,Jason T. Hinkle,Yashasvi Moon,Margaret Shepherd,Margaret E. Verrico*

Main category: astro-ph.HE

TL;DR: FEADME is a GPU-accelerated Python framework for modeling broad Balmer-line emission in accretion disks. Applied to 237 DPEs and 5 TDEs, it reveals similar disk geometries between AGN and TDEs except TDEs have more circular disks. Most systems require both disk and additional broad-line components, showing shared physical processes in disk emission.


<details>
  <summary>Details</summary>
Motivation: The motivation is to enable efficient, large-sample analysis of accretion disk emission-line profiles using GPU acceleration and Bayesian methods, comparing AGN and TDE disk properties to understand common physical processes.

Method: FEADME uses Jax/NumPyro for differentiable modeling and Bayesian inference. It fits three model families per spectrum from 237 DPEs and 5 TDEs, using approximate LOO cross-validation to select the best model.

Result: AGN show diverse disk geometries/kinematics. TDE disks are statistically similar but more circular. Most systems favor models with both disk and extra broad-line components.

Conclusion: Accretion disk spectroscopy in AGN and TDEs follows similar physical mechanisms once disks form. FEADME is effective for population studies in galactic nuclei.

Abstract: We present FEADME (Fast Elliptical Accretion Disk Modeling Engine), a GPU-accelerated Python framework for modeling broad Balmer-line emission using a relativistic elliptical accretion-disk formalism. Leveraging Jax and NumPyro for differentiable forward modeling and efficient Bayesian inference, FEADME enables large-sample, reproducible analyses of disk-dominated emission-line profiles. We apply the framework to 237 double-peaked emitters (DPEs) from the literature and to five tidal disruption events (TDEs) with disk-like H$α$ emission, fitting three physically motivated model families per spectrum and selecting the preferred model using approximate leave-one-out (LOO) cross-validation. We find that AGN exhibit a broad, continuous distribution of disk geometries and kinematics, with significant diversity in disk parameters. Most TDE disk parameter distributions are statistically indistinguishable from those of the AGN, with the sole robust difference being that TDE disks are significantly more circular, consistent with rapid debris circularization in tidal disruption events. The majority of both AGN and TDEs favor models that include both a disk and an additional broad-line component, suggesting that disk emission commonly coexists with more isotropic or wind-driven gas. These results indicate that once a line-emitting disk forms, its spectroscopic appearance is governed by similar physical processes in both persistent AGN and transient TDE accretion flows, and they demonstrate the utility of FEADME for population-level studies of disk structure in galactic nuclei.

</details>


### [64] [EP250827b/SN 2025wkm: An X-ray Flash-Supernova Powered by a Central Engine and Circumstellar Interaction](https://arxiv.org/abs/2512.10239)
*Gokul P. Srinivasaragavan,Dongyue Li,Xander J. Hall,Ore Gottlieb,Genevieve Schroeder,Heyang Liu,Brendan O'Connor,Chichuan Jin,Mansi Kasliwal,Tomás Ahumada,Qinyu Wu,Christopher L. Fryer,Annabelle E. Niblett,Dong Xu,Maria Edvige Ravasio,Grace Daja,Wenxiong Li,Shreya Anand,Anna Y. Q. Ho,Hui Sun,Daniel A. Perley,Lin Yan,Eric Burns,S. Bradley Cenko,Jesper Sollerman,Nikhil Sarin,Anthony L. Piro,Amar Aryan,M. Coleman Miller,Jie An,Tao An,Moira Andrews,Jule Augustin,Eric C. Bellm,Aleksandra Bochenek,Malte Busmann,Krittapas Chanchaiworawit,Huaqing Chen,Alberto J. Castro-Tirado,Ali Esamdin,Jennifer Faba-Moreno,Joseph Farah,Shaoyu Fu,Johan P. U. Fynbo,Julius Gassert,Estefania Padilla Gonzalez,Matthew Graham,Daniel Gruen,D. Andrew Howell,Linbo He,Jingwei Hu,Abdusamatjan Iskandar,Joahan Castaneda Jaims,Ji-An Jiang,Ning Jiang,Shuaijiao Jiang,Runduo Liang,Zhixing Ling,Jialian Liu,Xing Liu,Yuan Liu,Frank J. Masci,Curtis McCully,Megan Newsome,Kanthanakorn Noysena,Kangrui Ni,Antonella Palmese,Han-Long Peng,Josiah Purdum,Yu-Jing Qin,Sam Rose,Ben Rusholme,Cassie Sevilla,Roger Smith,Yujia Song,Niharika Sravan,Robert Stein,Constantin Tabor,Giacomo Terreran,Samaporn Tinyanont,Pablo Vega,Letian Wang,Tinggu Wang,Xiaofeng Wang,Xuefeng Wu,Kathryn Wynn,Yunfei Xu,Shengyu Yan,Weimin Yuan,Binbin Zhang,Chen Zhang,Zipei Zhu,Xiaoxiong Zuo,Gursimran Bhullar*

Main category: astro-ph.HE

TL;DR: The paper presents EP250827b/SN 2025wkm, a new X-ray Flash paired with a broad-line Type Ic supernova. The XRF shows low luminosity and long duration, while the SN has a double-peaked light curve powered by a magnetar engine. The model suggests a central engine combining magnetar winds and disk outflows explains the observed emission and lack of radio jet signatures.


<details>
  <summary>Details</summary>
Motivation: The discovery of EP250827b/SN 2025wkm provides new insights into the connection between X-ray flashes and supernovae, particularly the role of central engines in powering supernova energy. The study aims to understand the physical mechanisms behind the observed X-ray and optical properties, and the interplay between magnetars and circumstellar material.

Method: The analysis combines X-ray data from the Einstein Probe with optical observations from ground-based telescopes. Spectral and photometric analysis of the supernova light curve and spectrum were performed. Theoretical models involving magnetar-driven winds and disk accretion were compared with observational data to explain the energy injection, X-ray emission mechanisms, and late-time luminosity plateau.

Result: The XRF's low peak energy and long duration distinguish it from typical gamma-ray bursts. The SN's light curve plateau phase (20 days) and blueshifted spectral features confirm central engine activity. The absence of radio emission suggests no high-energy on-axis jets. The magnetar-wind/disk-outflow model successfully explains X-ray breakout emission, early-peaked light curves, and late-time luminosity driven by magnetar spin-down and radioactive decay.

Conclusion: EP250827b/SN 2025wkm demonstrates that XRF-SNe systems can be powered by long-lived magnetars, offering a new paradigm for understanding low-luminosity GRB counterparts. The findings support a central engine mechanism involving magnetars and circumstellar interaction, and highlight the Einstein Probe's capability in uncovering rare transient events bridging different astrophysical phenomena.

Abstract: We present the discovery of EP250827b/SN 2025wkm, an X-ray Flash (XRF) discovered by the Einstein Probe (EP), accompanied by a broad-line Type Ic supernova (SN Ic-BL) at $z = 0.1194$. EP250827b possesses a prompt X-ray luminosity of $\sim 10^{45} \, \rm{erg \, s^{-1}}$, lasts over 1000 seconds, and has a peak energy $E_{\rm{p}} < 1.5$ keV at 90% confidence. SN 2025wkm possesses a double-peaked light curve (LC), though its bolometric luminosity plateaus after its initial peak for $\sim 20$ days, giving evidence that a central engine is injecting additional energy into the explosion. Its spectrum transitions from a blue to red continuum with clear blueshifted Fe II and Si II broad absorption features, allowing for a SN Ic-BL classification. We do not detect any transient radio emission and rule out the existence of an on-axis, energetic jet $\gtrsim 10^{50}~$erg. In the model we invoke, the collapse gives rise to a long-lived magnetar, potentially surrounded by an accretion disk. Magnetically-driven winds from the magnetar and the disk mix together, and break out with a velocity $\sim 0.35c$ from an extended circumstellar medium with radius $\sim 10^{13}$ cm, generating X-ray breakout emission through free-free processes. The disk outflows and magnetar winds power blackbody emission as they cool, producing the first peak in the SN LC. The spin-down luminosity of the magnetar in combination with the radioactive decay of $^{56}$Ni produces the late-time SN LC. We end by discussing the landscape of XRF-SNe within the context of EP's recent discoveries.

</details>


### [65] [Irregularity in Active Fast Radio Burst Repeaters and Magnetar Periodic Radio Pulses: Time, Energy, and Frequency Analyses](https://arxiv.org/abs/2512.10249)
*Ellen C. C. Lin,Shotaro Yamasaki,Tomotsugu Goto,Tetsuya Hashimoto*

Main category: astro-ph.HE

TL;DR: This study compares repeating Fast Radio Bursts (FRBs) and magnetar pulses by analyzing temporal, energy, and frequency characteristics. Both show similar randomness in arrival times and chaos levels, suggesting a shared origin. Energy fluctuations differ, possibly due to beaming or emission efficiency variations.


<details>
  <summary>Details</summary>
Motivation: To determine if repeating FRBs and magnetars share underlying mechanisms by comparing their burst temporal, energy, and frequency behaviors.

Method: Analyzed time-series data from 3 FRB sources and magnetar SGR J1935+2154 using Pincus Index (PI) for randomness and Lyapunov Exponent (LLE) for chaos in waiting times, energy, and frequency shifts.

Result: FRB and magnetar waiting times have high PI (randomness) and low LLE (chaos). Energy fluctuations show higher scatter, differing from magnetar patterns.

Conclusion: Common triggering mechanism likely exists for FRBs and magnetars in timing behavior. Energy disparity hints at differences in emission processes like beaming effects.

Abstract: Fast Radio Bursts (FRBs) are millisecond-duration radio pulses with largely unknown origins, with a subset exhibiting repeating behavior. Magnetars highly magnetized neutron stars and a leading progenitor candidate for FRBs also produce similar but much fainter millisecond radio pulses, suggesting a possible connection between the two phenomena. The irregularity of the time series of repeating FRBs and magnetar pulses may provide insight into the underlying progenitor activity. In this study, we analyze time-series data from three repeating FRB sources (four datasets) and the Galactic magnetar SGR J1935+2154 to investigate potential patterns in burst arrival times, energy fluctuations, and peak-frequency shifts. We quantify the degree of randomness (Pincus Index; PI) and chaos (Largest Lyapunov Exponent; LLE) for these three parameters. We find that waiting times across all repeating FRBs exhibit high PI (high randomness) and low LLE (low chaos), consistent with the behavior of magnetar radio pulses. This similarity suggests that both may share a common triggering mechanism. In contrast, the energy fluctuations of both repeating FRBs and magnetar pulses occupy the same region in PI-LLE phase space but display much larger scatter than the other two domains. We discuss the possibility that beaming effects or strong variability in radio-emission efficiency may explain their distinct behavior in the energy domain.

</details>


### [66] [Relaxation of time-variable neutron-loaded relativistic jets across the photosphere and their GeV-TeV neutrino counterparts](https://arxiv.org/abs/2512.10253)
*Kanako Nakama,Kazumi Kashiyama,Nobuhiro Shimizu*

Main category: astro-ph.HE

TL;DR: The paper investigates the relationship between GRB central engine variability and GeV-TeV neutrino production through neutron-inclusive simulations, showing neutrino emission characteristics depend on jet inhomogeneity and radiative efficiency


<details>
  <summary>Details</summary>
Motivation: To understand how inhomogeneous jet structures produced by variable central engines influence dissipation processes both below and above the photosphere, and their implications for detectable neutrino signals

Method: Neutron-inclusive shell simulations based on collapsar scenarios, linking jet inhomogeneity at breakout to multi-regime dissipation and calculating neutrinos from neutron-proton interactions consistent with gamma-ray emission

Result: Neutrino peak energy remains 10-30 GeV regardless of baryon loading, with TeV tails under high variability. Neutrino efficiency ranges 0.1-10% for high gamma-ray efficiency GRBs but can reach 20% in low radiative efficiency jets typical of X-ray rich transients.

Conclusion: GRBs with low gamma-ray luminosities and X-ray rich transients are promising neutrino sources, highlighting the role of jet inhomogeneity in multi-messenger astrophysics.

Abstract: Both observational and theoretical studies indicate that the central engine of a gamma-ray burst (GRB) is intrinsically time-variable, implying jet inhomogeneity. A jet with an inhomogeneous Lorentz factor distribution develops internal shocks both below and above the photosphere, relaxing toward homologous expansion. Below the photosphere, neutrons, whose mean free paths are much longer than those of charged particles, play an essential role in the dissipation process. Using neutron-inclusive shell simulations with initial conditions based on the collapsar scenario, we link the statistical inhomogeneity of the jet at the breakout of the progenitor to the dissipation that occurs inside and outside the photosphere, and calculate the GeV-TeV neutrino counterpart originated from inelastic neutron-proton interactions consistently with the prompt gamma-ray emission. We find that the peak energy of the GeV-TeV neutrinos is in 10-30 GeV irrespective to the baryon loading factor of the jet, with the high-energy tail extending into the TeV range as the amplitude of the time variability becomes stronger. When gamma-ray emission is efficient as in typical GRBs (i.e., the gamma-ray radiation efficiency with respect to the total jet power is approximately 100%, the radiative efficiency of GeV-TeV neutrinos remains 0.1-10%. By contrast, when the gamma-ray radiation efficiency is relatively low (< 10%) for jets where a large fraction of the energy is dissipated below the photosphere, the neutrino efficiency can increase up to 20%. This suggests that GRBs with relatively low gamma-ray luminosities, as well as X-ray-rich transients, can be promising targets for ongoing and future GeV-TeV neutrino transient searches.

</details>


### [67] [Hybrid corona and transient soft X-ray lags in Fairall 9](https://arxiv.org/abs/2512.10261)
*K. Khanthasombat,P. Chainakun,W. Luangtip,J. Jiang,A. J. Young*

Main category: astro-ph.HE

TL;DR: The study analyzes Fairall 9, a massive Seyfert galaxy, using XMM-Newton data to investigate soft X-ray reverberation lags and black hole properties. Results show a rapidly spinning black hole, coexisting hot and warm coronae, and evolving lag behavior over time, suggesting a stabilizing disc-corona configuration.


<details>
  <summary>Details</summary>
Motivation: To probe the soft X-ray reverberation lags in Fairall 9, despite its large black hole mass leading to long intrinsic timescales, and to understand the disc-corona geometry and black hole spin.

Method: Fitted XMM-Newton spectra with a hybrid reXcor model combining hot and warm coronae. Performed wavelet coherence analysis on light curves in 0.3-1 keV and 1-4 keV bands across five observations.

Result: Rapidly spinning black hole (a=0.99), warm corona optical depth ~10-30, and hot corona at 5 or 20 rg. Transient soft lags in early observations evolved to persistent lags (~1000s amplitude) in later ones at ~9e-6-2.5e-5 Hz.

Conclusion: The stable disc-corona configuration in later observations aligns with X-ray reverberation expectations, supporting coexisting coronae and disc extension near the event horizon.

Abstract: Fairall 9 is among the most massive Seyfert galaxies exhibiting a strong soft X-ray excess, but it is challenging to probe soft X-ray reverberation lags (if any) due to the long intrinsic timescales expected from its large black hole mass of $\sim 2.55 \times 10^8 M_\odot$. We fit five XMM-Newton spectra of Fairall 9 using the hybrid reXcor model taking into account both hot and warm corona. The soft excess is explained by a combination of a physically motivated warm corona and the disc reflection. Then, we perform a wavelet coherence analysis of the light curves between 0.3 - 1 and 1 - 4 keV bands. The spectral fits are consistent with a rapidly spinning black hole ($a = 0.99$), a warm corona with optical depth $\sim$10 - 30, and a hot lamp-post corona located at either 5 or $20~r_{\rm g}$. This configuration supports a coexisting hot and warm corona scenario, allowing the disc to extend almost to the event horizon. Our wavelet analysis on combined observations reveals signatures of transient soft X-ray lags, confined to specific time-frequency intervals. The earlier observations exhibit more variable and transient lag behavior. In contrast, the later observations display more persistent soft X-ray lags at the frequencies of $\sim 9\times 10^{-6}$ - $2.5 \times 10^{-5}$ Hz, with amplitudes reaching $\sim$1000 s. The results indicate a progressively stable disc-corona configuration in later observations. Given the mass and geometry of Fairall 9, the observed soft lags appears plausibly consistent in both size and timescales with expectations from X-ray reverberation.

</details>


### [68] [A Systematic Study of Magnetic Fields Impacts on Neutrino Transport in Core-Collapse Supernovae](https://arxiv.org/abs/2512.10417)
*Yudong Luo,Shuai Zha,Toshitaka Kajino*

Main category: astro-ph.HE

TL;DR: Magnetic fields with strengths above $10^{16}$ G significantly alter neutrino transport and supernova dynamics, enhancing electron fraction and neutrino luminosities while modifying neutrino energy spectra in core-collapse supernovae.


<details>
  <summary>Details</summary>
Motivation: To investigate how intense magnetic fields influence neutrino transport mechanisms and subsequent dynamics in core-collapse supernovae simulations.

Method: The study uses the M1 neutrino transport scheme withGR1D simulations, incorporating magnetic-dependent effects like quantized electron/positron momenta and modified cross sections for neutrino interactions.

Result: Strong magnetic fields diminish $arν_e$ mean energy but increase neutrino number luminosities. Enhanced electron density behind the shock raises $ν_e$ energy, leading to amplified $L_{ν_e}$ and minimal change in $L_{arν_e}$. Thresholds at $B_0 ≥ 2.7×10^{16}$ G (for significant effects) and ≤7.4×10^{15}$ G (for negligible effects) are identified.

Conclusion: Magnetic fields of sufficient strength critically impact post-supernova neutrino properties and shock behavior, suggesting their importance in modeling CCSNe under dense magnetic environments.

Abstract: We quantify the impact of strong magnetic fields (assuming $B=B_0\cdot r_0^3/r^3$ with $B_0\gtrsim 10^{16}$ G) on the neutrino transport in core-collapse supernovae (CCSNe). Magnetic fields quantize the momenta of electrons and positrons, resulting in an enhanced absorption cross section for low-energy neutrinos and suppressed chemical potentials for $e^\pm$. We include these changes in the M1 scheme for neutrino transport and perform 1-D CCSNe simulations with \texttt{GR1D}. The increased low-energy cross sections reduce the $\barν_e$ mean energy $\langle E_{\barν_e}\rangle$ while elevating the neutrino number luminosities $\mathcal{L_ν}$ for both $ν_e$ and $\barν_e$ due to the lower energy weighted spectra. The reduction of chemical potential enhances the $\barν_e$ emission while suppressing that of $ν_e$, thereby driving an increase in the electron fraction behind the stalled shock at $\sim30$--$100$ km. This further amplifies $\langle E_{ν_e}\rangle$ through an increased electron density. Consequently, magnetic fields amplify $L_{ν_e}$ by increasing both $\mathcal{L}_{ν_e}$ and $\langle E_{ν_e}\rangle$ whereas for $\barν_e$, the rise in $\mathcal{L}_{\barν_e}$ is offset by a decreased $\langle E_{\barν_e}\rangle$, leading to a minimal change in $L_{\barν_e}$. A systematic parameter scan of dipole field configurations suggests that, for $r_0 > 30$ km, $\langle E_{\barν_e} \rangle$ is significantly suppressed and $L_{ν_e}$ is enhanced if $B_0 \geq {2.7} \times 10^{16}$ G. These magnetic effects become negligible for $B_0$ below $\sim {7.4} \times 10^{15}$ G.

</details>


### [69] [Multi-wavelength emission in resistive pulsar magnetospheres](https://arxiv.org/abs/2512.10479)
*Jérôme Pétri*

Main category: astro-ph.HE

TL;DR: Investigated the effects of resistivity on neutron star magnetosphere structures using resistive Maxwell simulations, affecting multi-wavelength emission properties.


<details>
  <summary>Details</summary>
Motivation: To understand how resistivity influences neutron star magnetosphere geometry and radiation across wavelengths.

Method: Time-dependent pseudo-spectral simulations of Maxwell equations with resistive Ohm's law. Analyzed magnetosphere properties like Poynting flux and field line bending under varying magnetic obliquity and conductivity.

Result: Resistivity significantly alters Poynting flux and magnetic field structure near the light-cylinder, impacting γ-ray peak separation and radio/γ-ray time lags. X-ray profiles are also notably affected.

Conclusion: Results provide a framework to compare with upcoming γ-ray pulsar data, aiding in quantifying magnetic energy distribution between particle acceleration and radiation.

Abstract: In this paper, we compute a full set of neutron star magnetosphere structures from the basic vacuum regime to the dissipation-less force-free regime by implementing a resistive prescription for the plasma. A comparison to the radiation reaction limit is also discussed. We investigated the impact of these resistive magnetospheres onto the multi-wavelength emission properties based on the polar cap model for radio wavelengths, on the slot gap model for X-rays and on the striped wind model for $γ$-rays.} % methods heading (mandatory) {We performed time-dependent pseudo-spectral simulations of the full Maxwell equations including a resistive Ohm's law. We deduced the polar cap shape and size, the Poynting flux, the magnetic field structure and the current sheet surface, depending on the magnetic obliquity~$χ$ and on the conductivity~$σ$. We found that the geometry of the magnetosphere close to the stellar surface is not impacted by the amount of resistivity. Polar cap rims remain very similar in shape and size. However the Poynting flux varies significantly as well as the magnetic field sweep-back in the vicinity of the light-cylinder. This bending of field lines reflects into the $γ$-ray pulse profiles, changing the $γ$-ray peak separation~$Δ$ as well as the time lag~$δ$ between the radio pulse and $γ$-ray peaks. X-ray pulse profiles are also drastically affected by the resistivity. A full set of multi-wavelength light-curves can be compiled for future comparison with the third $γ$-ray pulsar catalogue. This systematic study will help to constrain the amount of magnetic energy flowing into particle kinetic energy and shared by radiation.

</details>


### [70] [nDspec: a new Python library for modelling multi-dimensional datasets in X-ray astronomy](https://arxiv.org/abs/2512.10615)
*Matteo Lucchini,Benjamin Ricketts,Phil Uttley,Daniela Huppenkothen*

Main category: astro-ph.HE

TL;DR: The paper introduces an alpha release of nDspec, a Python library for modeling one- and multi-dimensional datasets in X-ray astronomy. It focuses on time-averaged and Fourier spectral-timing data, with plans to expand to other dimensions, demonstrated through an example with NICER black hole binary data.


<details>
  <summary>Details</summary>
Motivation: The growing need for simultaneous analysis of multi-dimensional X-ray data (time, energy, polarization) requires new models, analysis methods, and software frameworks to advance physical understanding.

Method: Development of the nDspec library with modular design to handle multi-dimensional datasets. The alpha release supports time-averaged and Fourier spectral-timing modes, using NICER black hole binary data as a use case example.

Result: Successfully demonstrated nDspec's capability through analysis of NICER observation data, showing its potential for multi-dimensional X-ray studies. Framework is extensible for future dimension additions and features.

Conclusion: nDspec addresses the critical need for integrated multi-dimensional analysis tools in X-ray astronomy. Future updates will expand supported dimensions and improve functionality, encouraging broader community adoption.

Abstract: The current fleet of X-ray telescopes produces a wealth of multi-dimensional data, allowing us to study sources in time, photon energy and polarization. At the same time, it has become increasingly clear that progress in our physical understanding will only come from studying these sources in multiple dimensions simultaneously. Enabling multi-dimensional studies of X-ray sources requires new theoretical models predicting these data sets, new methods to analyse them and a software framework to combine data, models and methods efficiently. In this paper, we introduce the alpha release of nDspec, a new python-based library designed to allow users to model one- and multi-dimensional datasets common to X-ray astronomy. In the alpha release, we focus on modelling time-averaged data as well as Fourier spectral-timing mode, but highlight how additional dimensions can be added. We discuss design philosophy and current features, and showcase an example use case by characterizing a NICER observation of a black hole X-ray binary. We also highlight current plans for extensions to other dimensions and new features.

</details>


### [71] [Scintillating insights into PSR~J0737$-$3039A and the interstellar plasma of the Gum Nebula from MeerKAT](https://arxiv.org/abs/2512.10489)
*J. Askew,D. J. Reardon,R. M. Shannon,M. Bailes,F. Camilo,A. Corongiu,M. Kramer,M. E. Lower,A. Parthasarathy,A. Possenti,V. Venkatraman Krishnan*

Main category: astro-ph.HE

TL;DR: The study analyzes the double pulsar system PSR J0737-3039A/B using MeerKAT observations to test strong-field gravity, determining the scattering screen's properties, Gum Nebula expansion velocity, and orbital parameters. Results align with parallax distance measurements.


<details>
  <summary>Details</summary>
Motivation: To perform precise tests of strong-field gravity and study interstellar scattering plasma and orbital geometry through scintillation analysis.

Method: Analyzed 18-month MeerKAT radio telescope data of the pulsar system, characterizing scintillation patterns to infer scattering screen characteristics and orbital parameters.

Result: Identified a scattering screen at 360 pc (anisotropic axial ratio 2.4) near the Gum Nebula, determined nebula expansion velocity (35 km/s) and age (~1 Myr). Orbital parameters: Ω=40°, i>90°. Distance estimate matches VLBI parallax data.

Conclusion: Scintillation models can improve understanding of interstellar medium structures and pulsar properties, guiding future research on intervening astrophysical environments.

Abstract: The double pulsar system PSR~J0737$-$3039A/B has enabled some of the most precise tests of strong-field gravity to date. Here, we present a scintillation analysis of the system based on an 18-month observation campaign with the MeerKAT radio telescope. We characterise this interference pattern to infer properties of scattering plasma and the orbital geometry of the system. Our preferred model supports a scattering screen located at a distance of $D_s = 360^{+30}_{-40}$ pc. This moderately anisotropic screen of ionized gas (axial ratio $A_R = 2.4 \pm 0.2$) lies near the edge of the Gum Nebula, which is believed to be a supernova remnant (SNR) or an \HII\, region. We estimate the expansion velocity of the nebula to be $V_{\textrm{s}} = 35 \pm 5$ km s$^{-1}$, implying a SNR age of $t \approx 1$ Myr. We also constrain the orbital orientation and inclination sense of the double pulsar to be $Ω= 40^{\circ} \pm 3^{\circ}$ and $i > 90^{\circ}$, respectively. Assuming standard scattering geometry, our model yields a distance estimate consistent with the parallax-derived value of $D = 770 \pm 70$ pc from very long baseline interferometry. We conclude by discussing how future models of pulsar scintillation can enhance our understanding of the IISM and the properties of pulsars embedded within or lying behind such intervening structures.

</details>


### [72] [Application of time-series analysis methods to a multiple-sector TESS observations: the case of the radio-loud blazar 3C 371](https://arxiv.org/abs/2512.10533)
*Ashutosh Tripathi,Paul J. Wiita,Ryne Dingler,Krista Lynne Smith,R. A. Phillipson,Matthew J. Graham,Lang Cui*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present various time series analysis methods to analyze multiple-sector observations of bright AGN from the Transiting Exoplanet Survey Satellite (TESS) and examine whether issues such as gaps and noise in these data can be mitigated. We determine variability timescales and search for quasi-periodicity using these methods and assess any differences. In this paper, we present an analysis of the $\approx$300-day TESS observation of a blazar 3C 371 using power spectrum density, structure-function, and weighted wavelet Z-transform approaches. To reduce the effect of gaps and noise, Continuous auto-regressive moving averages, Bartlett periodogram, and wavelet decomposition methods are used. We have also used recurrence analysis to account for the nonlinearity present in the data and to quantify variability or periodicity as the recurrent state. Considering the entirety of the TESS observations, we derive the variability timescale to be around 4.5 days. Sector-wise analysis found variability timescales in the range of 3.0--7.0 days, values that are found to be consistent using different methods. When analyzing multiple sectors together, significant variability, which could be quasi-periodic oscillations (QPOs), of duration 3--6 days in individual segments, is detected. These may be attributed to the kink instabilities developed in the jet or the existence of mini-jets inside a jet undergoing precession. We find that these methods, when applied appropriately, can be used to study the variability in TESS data. The noise present in these TESS observations can be minimized using Bartlett's periodogram and wavelet decomposition to recover the real stochastic variability.

</details>


### [73] [Wind-mediated Eddington-limited emission in a 1e4 Black Hole Tidal Disruption Event](https://arxiv.org/abs/2512.10564)
*Paola Martire,Elena Maria Rossi,Nicholas Chamberlain Stone,Elad Steinberg,Konstantinos Kilmetis,Itai Linial*

Main category: astro-ph.HE

TL;DR: The study presents the first 3D end-to-end simulation of a TDE by a 10^4 M☉ IMBH using radiation-hydrodynamics code RICH. It reveals inefficient circularization of debris, a radiation-driven wind, and peak luminosity exceeding Eddington before settling. Observatories like LSST and ULTRASAT could detect similar events up to specific redshifts.


<details>
  <summary>Details</summary>
Motivation: To understand the origin of early luminosity peaks in TDEs and the energy dissipation mechanisms, especially for IMBH systems, which are under-explored compared to supermassive black hole TDEs.

Method: 3D radiation-hydrodynamics simulations using RICH code with realistic IMBH parameters (10^4 M☉), simulating TDE debris dynamics, radiation processes, and wind formation. Three resolutions tested for numerical convergence.

Result: Debris fails to efficiently circularize; low-density radiation-driven wind forms near pericenter, expanding quasi-spherically. Photosphere reaches 10^13 cm and ~10^4 K at peak luminosity, temporarily exceeding Eddington limit. Global results are qualitatively converged, though nozzle shock may need higher resolution.

Conclusion: Simulations highlight wind-driven energy dissipation as a key factor in early TDE flares. Future observatories (LSST, ULTRASAT) can detect such IMBH TDEs up to z≈0.1 and z≈0.06, aiding in studying these events' physics and IMBH populations.

Abstract: Observations of tidal disruption events (TDEs) have already produced tens of strong candidate flares, and their number will greatly increase with upcoming wide field surveys. Nevertheless, the origin of the measured luminosity peak at early times is still unknown, and the ultimate sources of energy dissipation in TDEs are not fully understood. Here we present the first three-dimensional end-to-end simulation of a TDE by a $10^{4}M_\odot$ intermediate mass black hole (IMBH) with realistic parameters, run with the radiation-hydrodynamics code RICH. We find that the stellar debris fails to circularize efficiently, while a low-density, radiation-driven wind forms near pericenter and expands quasi-spherically. Radiation is advected by this outflow and released at the photosphere, which expands to radii of $\approx10^{13}$ cm and reaches temperatures of ~few $10^{4}$K at the peak of the light curve. The resulting luminosity briefly exceeds the Eddington limit before settling near that value. We systematically test the numerical convergence of our simulation by running it at three resolutions. While the nozzle shock at pericenter may be under-resolved, we find that global results are qualitatively converged and, largely, quantitatively robust. The upcoming Vera Rubin Observatory's LSST (g and r band) and ULTRASAT (near UV) will be able to observe events like our simulated IMBH TDE up to redshifts of z$\approx$0.1 and z$\approx$0.06, respectively.

</details>


### [74] [Can accreting isolated neutron stars be detected?](https://arxiv.org/abs/2512.10666)
*Marina Afonina,Anton Biryukov,Sergei Popov*

Main category: astro-ph.HE

TL;DR: The paper analyzes the population synthesis modeling of isolated neutron stars in the Milky Way, highlighting uncertainties in propeller stage spin-down rates and accretion efficiency, which significantly affect predicted numbers of accreting neutron stars detectable by eROSITA (~a few thousand potential). Future Gaia observations of wide low-mass binaries may resolve these uncertainties.


<details>
  <summary>Details</summary>
Motivation: To better understand the population of isolated neutron stars in the Milky Way and address limitations of prior studies lacking detailed interstellar medium models and magneto-rotational evolution. The aim is to quantify uncertainties affecting observable neutron star counts.

Method: Population synthesis modeling incorporating advanced interstellar medium models and neutron star magneto-rotational evolution. The study specifically examines propeller stage spin-down rates and accretion efficiency's impact on neutron star population predictions.

Result: Shows that propeller stage spin-down rates are the key uncertainty affecting accreting neutron star numbers. High accretion efficiency could yield ~thousands in eROSITA data, but uncertainties could reduce this. Identifies Gaia-discovered binaries as critical for future study.

Conclusion: Accurate predictions require resolving propeller stage physics and accretion efficiencies. Observations of wide low-mass binaries via Gaia are suggested to clarify these uncertainties and improve neutron star population models.

Abstract: We perform population synthesis modeling of isolated neutron stars in the Milky Way over its lifetime. Compared with previous studies, we use more detailed models of the interstellar medium and the magneto-rotational evolution of neutron stars. We demonstrate that presently, the spin-down rate at the propeller stage is the main uncertain factor that influences the number of accreting isolated neutron stars. If the propeller stage duration allows neutron stars to begin accreting matter from the interstellar medium and if the efficiency of accretion is high, then the number of accreting isolated neutron stars in eROSITA data can reach ~a few thousand. Still, uncertainties in spin-down at the propeller stage and in the accretion process can drastically decrease this number. We suggest that future observations of neutron stars in wide low-mass binaries recently discovered by Gaia can clarify these issues.

</details>


### [75] [Constraints on the Population of Common Sources of Gravitational Waves and High-Energy Neutrinos with IceCube During the Third Observing Run of the LIGO and Virgo Detectors](https://arxiv.org/abs/2512.10707)
*Doğa Veske,Zsuzsa Márka,Albert Zhang*

Main category: astro-ph.HE

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The discovery of joint sources of high-energy neutrinos and gravitational waves has been a primary target for the LIGO, Virgo, KAGRA, and IceCube observatories. The joint detection of high-energy neutrinos and gravitational waves would provide insight into cosmic processes, such as progenitor dynamics and outflows. The joint detection of multiple cosmic messengers can also elevate the significance of the observation when some or all of the constituent messengers are sub-threshold, not significant enough to declare their detection individually. Leveraging data from the LIGO, Virgo, and IceCube observatories, we conducted an archival investigation of sub-threshold multimessenger events. Complementing previous analyses, we used minimal assumptions to search for common sources of sub-threshold gravitational-wave and high-energy neutrino candidates during the third observing run (O3) of the Advanced LIGO and Advanced Virgo detectors. Our search did not identify significant joint sources. We therefore derive constraints on the rate density of joint sources for each compact binary merger population as a function of the energy emitted in neutrinos. Only a fraction of the gravitational-wave sources emit neutrinos, if the neutrino emission has high bolometric energy ($>10^{52}$ to $10^{54}$ erg).

</details>


### [76] [The LISA Astrophysics "Disc-IMRI" Code Comparison Project: Intermediate-Mass-Ratio Binaries in AGN-Like Discs](https://arxiv.org/abs/2512.10893)
*Andrea Derdzinski,Alexander J. Dittmann,Alessia Franchini,Alessandro Lupi,Noé Brucy,Pedro R. Capelo,Frédéric S. Masset,Raphaël Mignon-Risse,Michael Rizzo Smith,Edwin Santiago-Leandro,Martina Toscani,David A. Velasco-Romero,Robert Wissing,Mudit Garg,Lucio Mayer,Roberto Serafinelli,Lazaros Souvaitzis,Daniel J. D'Orazio,Jonathan Menu*

Main category: astro-ph.HE

TL;DR: The paper analyzes the interaction between EMRIs/IMRIs and accretion discs using eight hydrodynamical codes, finding agreement in thick discs but discrepancies in thin discs, highlighting the need for further code development and advanced computational methods.


<details>
  <summary>Details</summary>
Motivation: To prepare for LISA's detection of EMRIs/IMRIs, the study assesses how different hydrodynamical codes model these systems in accretion discs, crucial for accurate data interpretation and avoiding biased results.

Method: A comparative analysis of eight hydrodynamical codes simulating a 10^{-4} mass ratio binary in accretion discs. Both 2D and 3D simulations were conducted, focusing on disc thickness effects and code performance.

Result: Thick discs show code agreement with analytical models, while thin discs reveal discrepancies in torque magnitude/sign between codes and dimensions. Moving mesh/grid-based methods and GPU use were proposed for efficiency.

Conclusion: Current codes need improvement for thin discs and high-resolution simulations. Energy-efficient computational strategies are essential for future LISA data analysis.

Abstract: Upcoming space-based gravitational wave detectors such as LISA, the Laser Interferometer Space Antenna, will be sensitive to extreme- and intermediate-mass-ratio inspirals (EMRIs and IMRIs). These binaries are comprised of a supermassive black hole and a stellar-mass object or intermediate-mass black hole. Their detection will probe the structure of galactic nuclei and enable tests of general relativity. As these events will be observed over thousands of orbital cycles, they will be extremely sensitive to both the underlying spacetime and astrophysical environment, demanding exquisite theoretical models on both fronts to avoid biased or even erroneous results. In particular, many (E/)IMRIs are expected to occur within accretion discs around supermassive black holes, and the nonlinearities present when modeling these systems require numerical simulations. In preparation for future modeling of LISA sources, we have conducted a comparison between eight different hydrodynamical codes and applied them to the problem of a q = 10^{-4} mass ratio binary interacting with an accretion disc. Thicker discs appear more lenient, and all codes at sufficiently high resolutions are in good agreement with each other and analytical predictions. For thinner discs, beyond the reach of analytical models, we find substantial disagreement between 2D and 3D simulations and between different codes, including both the magnitude and sign of the torque. With time and energy efficiency in mind, codes that leverage moving meshes or grid-based Lagrangian remapping seem preferable, as do codes that can leverage graphical processing units and other energy-efficient hardware.

</details>


### [77] [Detection prospects for heavy WIMP dark matter near supermassive black holes, particularly in M31](https://arxiv.org/abs/2512.10923)
*Andrei E. Egorov*

Main category: astro-ph.HE

TL;DR: The paper examines the potential of detecting WIMPs in dark matter spikes around nearby supermassive black holes (SMBHs), specifically MW* and M31*, using gamma-ray observations with the Cherenkov Telescope Array (CTA). It finds that CTA could probe a significant portion of the TeV-scale WIMP parameter space, especially under optimistic spike conditions in M31*, potentially outperforming MW* in some scenarios.


<details>
  <summary>Details</summary>
Motivation: To explore viable targets for detecting thermal s-wave annihilating WIMPs up to the 100 TeV mass scale, leveraged through dark matter density spikes around SMBHs, which offer a unique opportunity for discovery.

Method: Evaluated all relevant SMBHs to identify suitable candidates (MW* and M31*), estimated CTA's sensitivity to heavy WIMPs in M31*, and analyzed systematic uncertainties affecting detection prospects.

Result: CTA is capable of probing a major part of the TeV-scale WIMP parameter space in M31* under optimistic spike density assumptions. In certain scenarios, M31* could provide stronger constraints than MW*.

Conclusion: Dark matter spikes around SMBHs like M31* represent promising targets for heavy WIMP detection with CTA, highlighting the importance of examining spike density uncertainties and observational strategies to maximize discovery potential.

Abstract: This work analyzes the detection prospects for weakly interacting massive particles (WIMPs) in dark matter (DM) density spikes around nearby supermassive black holes (SMBHs) by observations in very high energy gamma-ray band. Such spikes are unique targets, which provide a possibility to discover the basic thermal s-wave annihilating WIMP with any mass up to the theoretical unitarity limit ~ 100 TeV. All relevant SMBHs were checked, and only MW* and M31* were identified as worthwhile objects. Cherenkov Telescope Array (CTA) sensitivity to heavy WIMPs in M31* was estimated. It was obtained that CTA will be able to probe a major part of TeV-scale WIMP parameter space in case of optimistic spike density configuration in M31*. In certain scenarios, M31* may yield even stronger constraints than MW*. Relevant systematic uncertainties were explored.

</details>
