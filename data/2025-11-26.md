<div id=toc></div>

# Table of Contents

- [astro-ph.HE](#astro-ph.HE) [Total: 9]
- [astro-ph.IM](#astro-ph.IM) [Total: 9]
- [gr-qc](#gr-qc) [Total: 25]
- [hep-ph](#hep-ph) [Total: 21]


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [1] [X-ray, optical, and radio follow-up of five thermally emitting isolated neutron star candidates](https://arxiv.org/abs/2511.19591)
*J. Kurpas,A. M. Pires,A. D. Schwope,B. Li,D. Yin,F. Haberl,M. Krumpe,S. Sheth,I. Traulsen,Z. L. Zhang*

Main category: astro-ph.HE

TL;DR: The paper presents follow-up observations of five neutron star candidates found in eROSITA data, confirming four as thermal-emitting isolated neutron stars, with one remaining ambiguous. Key findings include thermal X-ray spectra, narrow absorption features in two, and lack of pulsations, supporting their classification but requiring further study.


<details>
  <summary>Details</summary>
Motivation: To characterize newly discovered neutron star candidates from eROSITA's all-sky survey and assess their nature, contributing to the understanding of Galactic neutron star populations.

Method: Used XMM-Newton, VLT/FORS2, and FAST for multi-wavelength observations, analyzing X-ray spectra, optical counterparts, and timing data to determine thermal emissions, absence of non-thermal components, and pulsation limits.

Result: Four sources confirmed as INS via thermal spectra and high X-ray/optical flux ratios; one candidate remains uncertain. Two show absorption features, all lack detected pulsations, and exhibit stable long-term X-ray emission.

Conclusion: eROSITA's survey is effective in identifying new INS, expanding the Galactic census. Further observations are needed to classify the ambiguous source and refine neutron star demographics.

Abstract: We report on follow-up observations with XMM-Newton, the FORS2 instrument at the ESO-VLT, and FAST, aiming to characterise the nature of five thermally emitting isolated neutron star (INS) candidates recently discovered from searches in the footprint of the Spectrum Roentgen Gamma (SRG)/eROSITA All-sky Survey. We find that the X-ray spectra are predominantly thermal and can be described by low-absorbed blackbody models with effective temperatures ranging from 50 to 210 eV. In two sources, the spectra also show narrow absorption features at $300 - 400$ eV. Additional non-thermal emission components are not detected in any of the five candidates. The soft X-ray emission, the absence of optical counterparts in four sources, and the consequent large X-ray-to-optical flux ratios $>3000 - 5400$ confirm their INS nature. For the remaining source, eRASSU J144516.0-374428, the available data do not allow a confident exclusion of an active galactic nucleus nature. However, if the source is Galactic, the small inferred X-ray emitting region is reminiscent of a heated pulsar polar cap, possibly pointing to a binary pulsar nature. X-ray timing searches do not detect significant modulations in all candidates, implying pulsed fraction upper limits of 13 - 19% ($0.001-13.5$ Hz). The absence of pulsations in the FAST observations targeting eRASSU J081952.1-131930 and eRASSU J084046.2-115222 excludes periodic magnetospheric emission at 1 - 1.5 GHz with an $8σ$ significance down to 4.08 $μ$Jy and 2.72 $μ$Jy, respectively. The long-term X-ray emission of all sources does not imply significant variability. Additional observations are warranted to establish exact neutron star types. At the same time, the confirmation of the predominantly thermal neutron star nature in four additional sources highlights the power of SRG/eROSITA to complement the Galactic INS population.

</details>


### [2] [Role of magnetic reconnection in blazar variability using numerical simulation](https://arxiv.org/abs/2511.19605)
*Chandan Kumar Das,Bhargav Vaidya,Amit Shukla,Giancarlo Mattia,Karl Mannheim*

Main category: astro-ph.HE

TL;DR: The study explores magnetic reconnection in blazar jets using 3D simulations, identifying current sheets and plasmoid formation that could explain rapid γ-ray flares through Doppler boosting.


<details>
  <summary>Details</summary>
Motivation: To address the unresolved issue of fast γ-ray variability in blazars challenging existing shock acceleration models by investigating magnetic reconnection as an alternative mechanism.

Method: 3D relativistic magnetohydrodynamic (RMHD/ResRMHD) simulations with PLUTO code, analyzing kink instabilities, current sheets, and plasmoid formation. A novel analysis technique combines hierarchical structure analysis and reconnection diagnostics.

Result: Identified reconnecting current sheets aligned with jet axis, producing relativistic plasmoids that match observed fast flares via Doppler boosting. Supports jet-in-jet model and magnetic reconnection's role in γ-ray variability.

Conclusion: Magnetic reconnection via current-driven instabilities is a viable mechanism for blazar γ-ray flares, advancing understanding of relativistic jet dynamics and dissipation processes.

Abstract: Fast $γ$-ray variability in blazars remains a central puzzle in high-energy astrophysics, challenging standard shock acceleration models. Blazars, a subclass of active galactic nuclei (AGN) with jets pointed close to our line of sight, offer a unique view into jet dynamics. Blazar $γ$-ray light curves exhibit rapid, high-amplitude flares that point to promising alternative dissipation mechanisms such as magnetic reconnection. This study uses three-dimensional relativistic magnetohydrodynamic (RMHD) and resistive relativistic magnetohydrodynamic (ResRMHD) simulations with the PLUTO code to explore magnetic reconnection in turbulent, magnetized plasma columns. Focusing on current-driven kink instabilities, we identify the formation of current sheets due to magnetic reconnection, leading to plasmoid formation. We develop a novel technique combining hierarchical structure analysis and reconnection diagnostics to identify reconnecting current sheets. A statistical analysis of their geometry and orientation reveals a smaller subset that aligns closely with the jet axis, consistent with the jet-in-jet model. These structures can generate relativistically moving plasmoids with significant Doppler boosting, offering a plausible mechanism for the fast flares superimposed on slowly varying blazar light curves. These findings provide new insights into the plasma dynamics of relativistic jets and strengthen the case for magnetic reconnection as a key mechanism in blazar $γ$-ray variability.

</details>


### [3] [Optical and cm follow-ups of the Changing-Look event in Mkn 590](https://arxiv.org/abs/2511.19660)
*Biswaraj Palit,Abhijeet Borkar,Agata Różańska,Alex Markowitz,Marzena Śniegowska,Swayamtrupta Panda,David Homan,Krystian Iłkiewicz*

Main category: astro-ph.HE

TL;DR: The study examines the rejuvenated Changing-Look AGN Mkn 590 by analyzing new optical and radio data, showing correlated X-ray/radio flux increases and evolving Balmer line emission, indicating connections between accretion and jet activity.


<details>
  <summary>Details</summary>
Motivation: To explore the circumnuclear gas evolution and relationships between accretion and ejection processes in this transitioning AGN.

Method: New optical spectra (Nordic Optical Telescope) and radio continuum measurements (GMRT) were analyzed to track Balmer line changes and radio/X-ray flux correlations.

Result: Clear rise in Balmer line emission and radio fluxes that align with X-ray variability, suggesting accretion-jet coupling.

Conclusion: Observed correlations imply a direct link between accretion flow changes and jet activity in Mkn 590, providing insights into AGN feedback mechanisms.

Abstract: The Changing-Look active galactic nucleus Mkn 590 is currently in a rejuvenated state, exhibiting a contemporaneous flux rise across X-rays, UV, optical and cm wavelengths. In this study, we present three new optical spectra obtained with the Nordic Optical Telescope, alongside three 1.4 GHz continuum measurements from the Giant Meterwave Radio Telescope, acquired since Nov. 2024. We identified a clear increase in the broad hydrogen Balmer line emission in the most recent observational epochs. Additionally, the core radio flux densities appear to track the overall X-ray variability, suggesting a possible connection between the accretion flow and jet activity. Based on these data, we aim to explore the evolution of the circumnuclear gas in this source and potential links between accretion and ejection activity.

</details>


### [4] [Alignment of radio jets in the microquasar V4641 Sagittarii with its high-energy structures](https://arxiv.org/abs/2511.19695)
*Josep Martí,Pedro Luis Luque-Escamilla*

Main category: astro-ph.HE

TL;DR: The paper presents observational evidence that the radio jets and gamma-ray emissions from V4641 Sgr align along a common axis, suggesting they originate from a single relativistic outflow. This challenges previous diffusion models and positions the system as a potential PeVatron, a source of ultra-high-energy particles within our Galaxy.


<details>
  <summary>Details</summary>
Motivation: To investigate the alignment and origin of radio jets and gamma-ray emissions in V4641 Sgr, a Galactic microquasar with a unique geometry puzzling astrophysicists.

Method: Analyzing observational data showing the radio jet and VHE/UHE gamma rays share the same axis, implying a shared origin in a collimated outflow.

Result: Alignment confirmed, supporting in-situ particle acceleration up to hundreds of TeV, which contradicts prior models reliant on large-scale diffusion.

Conclusion: The study positions V4641 Sgr as a PeVatron candidate, advancing understanding of jet dynamics and magnetic fields in microquasars.

Abstract: V4641 Sagittarii (V4641 Sgr) is a unique Galactic microquasar system featuring a stellar-mass black hole accreting matter from a massive companion. One of its intriguing features is the presence of relativistic radio jets almost perpendicular to the observed extended gamma-ray emission, implying significant propagation effects or interactions with the Galactic magnetic field. Here we report observational evidence that the radio jet and the very high-energy (VHE) and ultra high-energy (UHE) gamma-ray emission could be aligned along a common axis, indicating a co-spatial or co-directional origin. This alignment supports a model where synchrotron radio emission, VHE and UHE gamma rays are produced within a single, highly collimated relativistic outflow. Our findings favor scenarios of in-situ particle acceleration up to hundreds of TeV, challenge previous interpretations involving large-scale particle diffusion, and simplify the geometric modeling of the source. This case highlights the potential of V4641 Sgr as a PeVatron candidate within our Galaxy and provides a benchmark for understanding jet composition and magnetic structure in microquasars.

</details>


### [5] [Spatially Resolved Plasma Diagnostics of the Supernova Remnant DEM L71 using the Reflection Grating Spectrometer](https://arxiv.org/abs/2511.20112)
*Yuki Amano,Yuken Ohshiro,Hiromasa Suzuki,Kotaro Fukushima,Hiroya Yamaguchi*

Main category: astro-ph.HE

TL;DR: The study uses XMM-Newton's RGS to perform high-resolution X-ray spectroscopy of the supernova remnant DEM L71, revealing spatially resolved emission lines and unusual O VII Heα line ratios indicative of additional physical processes like charge exchange. This highlights the RGS's potential for studying moderately diffuse objects.


<details>
  <summary>Details</summary>
Motivation: To investigate spatially resolved X-ray emission features and diagnostics in DEM L71, leveraging the RGS's large dispersion angle to resolve individual lines and assess contributions from processes beyond standard plasma models.

Method: Spatially resolved high-resolution X-ray spectroscopy with RGS/XMM-Newton, including measurement of line fluxes across regions, analysis of forbidden-to-resonance O VII Heα ratios, and plasma diagnostics.

Result: High forbidden-to-resonance O VII Heα ratios in some regions suggest contributions from charge exchange/resonance scattering. Demonstrates RGS capability for imaging spectroscopy of diffuse sources.

Conclusion: RGS is effective for spatially resolving X-ray emission in moderately extended remnants, providing insights into non-thermal processes and offering a valuable tool for future studies of diffuse celestial objects.

Abstract: We present a spatially resolved high-resolution X-ray spectroscopy of the supernova remnant DEM L71 using the Reflection Grating Spectrometer (RGS) aboard XMM-Newton. Because of the large dispersion angle of the RGS, we are able to resolve individual emission lines and examine their spatial distributions within this moderately extended remnant. We derive line fluxes across different regions of DEM L71 and perform quantitative plasma diagnostics. Our analysis reveals that some regions have high forbidden-to-resonance ratios of O\emissiontype{VII} He$α$ lines, suggesting a non-negligible contribution from additional physical processes, such as charge exchange and/or resonance scattering. Our results demonstrate that the RGS has potential to serve as an outstanding X-ray imaging spectrometer for moderately diffuse objects.

</details>


### [6] [Search for Radio Pulsations from Neutron Star Candidates in Detached Binaries](https://arxiv.org/abs/2511.20242)
*Shi-Jie Gao,Xiang-Dong Li,Song Wang,Kareem El-Badry,De-Jiang Zhou,Yi-Xuan Shao,Zhen Yan,Pei Wang,Ping Zhou,Jin-Lin Han*

Main category: astro-ph.HE

TL;DR: Targeted radio observations of 31 neutron star candidates in detached binary systems using FAST and other telescopes found no radio emissions, suggesting either geometric beaming or extreme old age as reasons for non-detection.


<details>
  <summary>Details</summary>
Motivation: Confirm the neutron star nature of candidates identified by optical surveys by detecting radio emissions, which are characteristic of pulsars.

Method: Conducted 46.65 hours of radio observations on 31 neutron star candidates using FAST, Green Bank Telescope, and TianMa Telescope, searching for periodic and single-pulse emissions.

Result: No radio emissions detected; upper flux limits set at ~4 μJy (periodic) and ~10 mJy (single pulses) with FAST, which are below typical pulsar fluxes.

Conclusion: Non-detections imply either pulsar signals are outside our line of sight (geometric beaming) or the NSs are too old (>10 Gyr) to emit detectable radio waves, highlighting challenges in confirming old NSs via radio methods.

Abstract: Recent optical astrometric and spectroscopic surveys have identified numerous neutron star (NS) candidates in non-accreting detached binary systems, but their compact-object nature remains unconfirmed. In this work, we present targeted radio observations of 31 such candidates using the Five-hundred-meter Aperture Spherical radio Telescope (FAST), the Robert C. Byrd Green Bank Telescope, and the Shanghai TianMa Radio Telescope. Over a total of 46.65 hours of observing time, we detected neither periodic nor single-pulse radio emissions. These nondetections place stringent upper limits on the flux densities of any potential radio signals, reaching ~4 $μ$Jy for periodic emission and ~10 mJy for single pulses with FAST. Since our observations are highly sensitive and the flux density upper limits are well below the median fluxes of known Galactic pulsars, this suggests that geometric beaming is the most likely explanation for the non-detections if these objects are indeed pulsars. Alternatively, the NSs may be sufficiently old ($\gtrsim$ 10 Gyr) and have become intrinsically radio-quiet. In this case, our findings highlight the inherent difficulty of confirming NSs in such old detached binary systems through radio pulsation searches.

</details>


### [7] [From Empirical to Physical Model: Direct Fits of Optically Thin Inverse Compton Scattering to Prompt GRB Spectra](https://arxiv.org/abs/2511.20310)
*Pragyan Pratim Bordoloi,Shubh Mittal,Shabnam Iyyani*

Main category: astro-ph.HE

TL;DR: The paper demonstrates that optically thin inverse-Compton (IC) scattering provides a viable mechanism for explaining the prompt emission of a subset of bright gamma-ray bursts (GRBs), particularly those showing quasi-thermal low-energy spectral slopes. By analyzing 4 out of 41 selected GRBs, the study derives consistent constraints on the electron and photon populations at the dissipation region, indicating a mildly relativistic, photon-dominated environment with specific Comptonisation parameters.


<details>
  <summary>Details</summary>
Motivation: The motivation is to test the under-evaluated optically thin IC model against GRB prompt emission data, especially for bursts with spectral characteristics (quasi-thermal low-energy slopes and constrained high-energy indices) that could reconcile theoretical predictions with observational constraints.

Method: The authors selected GRBs using Band-function criteria for quasi-thermal spectra (α > -0.5, β ranging from -3.3 to -1.7), then analyzed time-integrated and time-resolved spectra to fit IC models. They derived parameters like bulk Lorentz factor (Γ), seed photon energy, electron energies, non-thermal fraction, and Comptonisation parameters (y, τ) to characterize the dissipation environment.

Result: The analysis showed 4 GRBs fit the IC model consistently, yielding seed photon peaks ~0.05-0.2 keV, electron thermal energies ~20-300 keV, and a small non-thermal electron fraction (0.1%-20%). Comptonisation parameters (y ~1-3, τ~0.2-0.6) indicate dissipation near the photosphere in photon-dominated regions with low magnetic fields. These results align with mildly relativistic electron distributions.

Conclusion: The findings validate the optically thin IC model for certain bright GRBs, providing observational support for IC processes in their prompt emission. This underscores the model's relevance and encourages its broader application in future GRB studies, especially for constraining environments where thermal components are sub-dominant or below detection thresholds.

Abstract: Gamma-ray burst (GRB) prompt emission is commonly attributed to non-thermal radiation processes operating in the optically thin regions of a relativistic outflow. Among these, optically thin inverse-Compton (IC) scattering remains an important yet under-tested mechanism. From an initial set of 41 bursts selected using empirical Band-function criteria that highlight quasi-thermal low-energy slopes ($α> -0.5$) and constrained high-energy indices ($-1.7 > β> -3.3$), only four events satisfy these conditions consistently in both time-integrated and time-resolved spectra. The IC fits yield self-consistent constraints on the seed-photon field and the electron population at the dissipation site. For bulk Lorentz factors $Γ\sim 170$-$550$, we infer seed thermal peaks of $\sim 0.05$-$0.2$ keV and electron thermal energies of $\sim 20$-$300$ keV in the co-moving frame. A fraction of only $0.1\%$-$20\%$ of electrons are accelerated into a non-thermal tail with an average index value of $δ\sim 1.8$. The derived Comptonisation parameters indicate moderate $y$ values ($\sim 1$-$3$), optical depths $τ\sim 0.2$-$0.6$, and dissipation radii just above the photosphere, consistent with mildly relativistic ($γ_{\min} \sim 1.2$-$2.6$), photon-dominated, low-magnetic-field dissipation environments. Furthermore, the framework allows us to constrain even sub-dominant thermal components that lie below the detector's low-energy threshold. Taken together, our results show that optically thin IC scattering offers a physically consistent and observationally viable explanation for the prompt emission in a subset of bright GRBs, motivating the application of IC models in future GRB studies.

</details>


### [8] [Impact of Spectral Coverage on Parameter recovery in Blazar Modeling](https://arxiv.org/abs/2511.20336)
*N. Sahakyan,D. Bégué,P. Giommi,H. Dereli-Bégué,Asaf Pe'er*

Main category: astro-ph.HE

TL;DR: This study evaluates how different spectral coverage affects parameter estimation in blazar models, finding that LSP, ISP, and HSP subclasses require varying levels of multi-wavelength data for accurate parameter recovery, emphasizing the importance of specific observational bands.


<details>
  <summary>Details</summary>
Motivation: To determine how spectral data gaps impact the reliability of physical parameter estimation in blazar SSC models and provide guidelines for optimizing observational campaigns.

Method: Synthetic SED generation and 1,000 fits per configuration for three blazar subclasses (using OJ 287, TXS 0506+056, and Mrk 421 as exemplars) across 21 observational setups. Evaluated coverage probabilities for parameters like magnetic field and electron luminosity.

Result: LSPs need minimal coverage (optical/UV, X-ray, GeV γ-rays); ISPs require two band combinations (X-ray/HE-VHE γ-rays or optical/UV/X-ray/HE γ-rays); HSPs require optical/UV/X-ray/VHE γ-rays. VHE data critical for HSPs. Different subclasses show distinct sensitivities to spectral gaps.

Conclusion: Spectral coverage requirements vary by blazar subclass. Results guide optimized observing strategies and model validation under incomplete data, stressing VHE observations' role for HSPs.

Abstract: Understanding the impact of spectral coverage on parameter recovery is critical for accurate interpretation of blazar spectra. In this study, we examine how the data coverage influences the reliability of parameter estimation within the one-zone synchrotron self-Compton (SSC) framework. Using OJ 287, TXS 0506+056, and Mrk 421 as representative of the low-, intermediate- and high synchrotron peak classes (LSP, ISP and HSP), respectively, we generate synthetic SEDs based on their best-fit models and perform 1,000 fits for each of the 21 observational configurations per source type. Our analysis quantifies the coverage probability for all model parameters, such has the magnetic field strength and the electron luminosity, and reveals that different blazar subclasses exhibit distinct sensitivities to spectral gaps. For LSPs, a minimal dataset comprising optical/UV, X-ray, and GeV $γ$-ray bands is sufficient for robust parameter inference. In contrast, ISPs and HSPs require broader spectral coverage to constrain the physical parameters. For ISP, we find that reliable parameter recovery can be achieved with two different minimal band combinations: \textit{(i)} X-ray, high energy $γ$-ray, and very high energy $γ$-ray data, or \textit{(ii)} optical/UV, X-ray, and high energy $γ$-ray data. For HSPs, the minimal configuration enabling reliable parameter recovery includes the optical/UV, X-ray, and very high energy $γ$-ray bands. We discuss the role of very high energy $γ$-ray observations, showing that they significantly enhance parameter recovery for HSPs. Our results provide practical guidelines for designing optimized multi-wavelength observation campaigns and for assessing the robustness of SSC model inferences under incomplete spectral coverage.

</details>


### [9] [What do gravitational-wave observations tell us about Luminous Red Novae?](https://arxiv.org/abs/2511.19243)
*Dhruv Jain,Shasvath J. Kapadia,Kuntal Misra,Dimple,L. Resmi,Ajay Kumar Singh,K. G. Arun*

Main category: astro-ph.HE

TL;DR: The study analyzes the relationship between Luminous Red Novae (LRNe) and the formation of compact binary mergers detectable by gravitational-wave (GW) observatories. By comparing observed LRNe rates from ZTF with GW merger rates from LVK's GWTC-4 catalog, it concludes that only about 0.1% of LRNe likely lead to merging compact binaries (BNS/NSBH), suggesting most LRNe result in non-merging outcomes like stellar mergers.


<details>
  <summary>Details</summary>
Motivation: To determine how many LRNe events produce compact binaries (BNS/NSBH) that merge within a Hubble time, using observed merger rates from GW detectors. This helps understand the evolutionary pathways of LRNe and their role in forming merging binaries.

Method: 1. Used ZTF data to obtain LRNe volumetric rates. 2. Applied delay time distributions assuming LRNe rates follow star formation. 3. Compared calculated merger rates with LVK's GWTC-4 observed rates. 4. Derived constraints on the fraction of LRNe leading to merging binaries.

Result: The fraction of LRNe resulting in BNS/NSBH mergers is ~0.1% (median). This indicates most LRNe do not form merging compact binaries but instead form other objects like merged stars.

Conclusion: The low fraction suggests LRNe are not dominant progenitors of GW-detected mergers. Most LRNe systems likely end as non-merging compact objects, highlighting diversity in CE ejection outcomes and the need for further observational studies to clarify LRNe endpoints.

Abstract: Luminous Red Novae (LRNe) have been argued to be related to the ejection of common envelopes (CEs) in binary star systems. Ejection of CEs leads to tightened stellar orbits capable of forming compact binaries that merge in Hubble time. As these mergers are seen by gravitational-wave (GW) detectors such as LIGO, Virgo and KAGRA (LVK), we ask what the merger rates of compact binaries in LVK tell us about the fraction of LRNe that lead to the formation of compact binaries that merge in Hubble time. Using the observed volumetric rates of LRNe from the Zwicky Transient Facility (ZTF) and of compact binary mergers from LVK observations, we derive limits on the fraction of LRNe that produce compact binaries that merge in Hubble time. Assuming the LRNe rate closely follows the star formation rate at any redshift, we use the delay time distribution models for compact binaries to compute the compact binary merger rate. A comparison of this merger rate with the latest volumetric rates of compact binary mergers from the fourth GW transient catalog (GWTC-4) at the present epoch of LVK allows us to constrain the above fraction. We find that only a fraction as small as $\sim 10^{-3}$ (median) of the LRNe correspond to the GW-observed binary neutron star (BNS) and neutron star-black hole (NSBH) mergers. This potentially implies that the majority of the LRNe population will not lead to mergers of compact objects, but other end products, such as stellar mergers.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [10] [Measuring Cometary Nuclei Behind Bright Comae: PSF Delta Decomposition with Bicubic Resampling and an Application to Interstellar Comet 3I/ATLAS C/2025 N1](https://arxiv.org/abs/2511.19467)
*Toni Scarmato*

Main category: astro-ph.IM

TL;DR: A method is presented to measure cometary nuclei sizes by separating the unresolved nucleus from its coma using PSF convolution and a Dirac Delta function, applied to 3I/ATLAS with results aligning with Hubble data.


<details>
  <summary>Details</summary>
Motivation: Cometary nuclei measurements are difficult due to their small size and bright comae, requiring a new method to accurately estimate sizes without direct resolution.

Method: The method uses bicubic resampling to stabilize the core, applies PSF+convolution, and combines a Dirac Delta function with a Rho^-1 law to separate nucleus and coma. It fits the profile with two amplitudes for nucleus and coma, providing residual diagnostics.

Result: When applied to comet 3I/ATLAS, the method derives nucleus radius between 0.16-2.8 km (for albedo 0.04), consistent with Hubble's upper limits. It's suitable for Rubin LSST surveys and follow-up observations.

Conclusion: The technique offers a reliable pipeline for cometary nuclei size estimation in unresolved cases, enhancing survey capabilities for interstellar and other comets.

Abstract: Measuring cometary nuclei is notoriously difficult because they are usually unresolved and embedded within bright comae, which hampers direct size measurements even with space telescopes. We present a practical, instrumental method that, stabilises the inner core through bicubic resampling, performs forward point-spread function PSF+convolution, and separates the unresolved nucleus from the inner-coma profile via an explicit Dirac Delta function added to a Rho^-1 surface brightness law. The method yields the nucleus flux by fitting an azimuthal averaged profile with two amplitudes only PSF core and convolved coma, with transparent residual diagnostics. As a case study, we apply the workflow to the interstellar comet 3I/ATLAS alias C/2025 N1, incorporating Hubble Space Telescope constraints on the nucleus size. We find that radius solutions consistent with 0.16 <= Rn <= 2.8 km for Pv = 0.04 are naturally recovered, in line with the most recent HST upper limits. The approach is well-suited for survey pipelines Rubin LSST and targeted follow up.

</details>


### [11] [Sequential Convex Programming for Multimode Spacecraft Trajectory Optimization](https://arxiv.org/abs/2511.19505)
*Jack Yarndley*

Main category: astro-ph.IM

TL;DR: This paper proposes a sequential convex programming (SCP) method using sparse automatic differentiation for optimizing multi-mode and multi-propulsion spacecraft trajectories, addressing the complexity of trajectory design for spacecraft with multiple propulsion systems.


<details>
  <summary>Details</summary>
Motivation: The motivation is to enhance trajectory optimization efficiency for spacecraft with multiple propulsion modes/systems, which offer better performance but are computationally challenging due to complex manual formulations and constraints.

Method: The method extends SCP by employing sparse automatic differentiation to dynamically linearize system equations, allowing efficient inclusion of multiple propulsion modes. It also introduces new constraints to select a single mode per time interval and limit total modes used.

Result: Case studies (Earth-67P rendezvous with 20 SPT-140 modes and Earth-Mars transfer with low-thrust/solar sail) show the method effectively computes optimal trajectories while maintaining computational efficiency.

Conclusion: The proposed SCP approach with sparse AD effectively and efficiently handles multi-mode propulsion trajectory optimization without requiring manual reformulations, expanding applicability to complex spacecraft configurations.

Abstract: Spacecraft equipped with multiple propulsion modes or systems can offer enhanced performance and mission flexibility compared with traditional configurations. Despite these benefits, the trajectory optimization of spacecraft utilizing such configurations remains a complex challenge. This paper presents a sequential convex programming (SCP) approach for the optimal design of multi-mode and multi-propulsion spacecraft trajectories. The method extends the dynamical linearization within SCP using sparse automatic differentiation, enabling efficient inclusion of multiple propulsion modes or systems without complex manual reformulation while maintaining comparable computational efficiency. New constraint formulations are introduced to ensure selection of a single propulsion mode at each time step and limit the total number of modes used. The approach is demonstrated for (i) a low-thrust Earth-67P rendezvous using the SPT-140 thruster with 20 discrete modes, and (ii) an Earth-Mars transfer employing both a low-thrust engine and a solar sail. Results confirm that the proposed method can efficiently compute optimal trajectories for these scenarios.

</details>


### [12] [Pixellated Posterior Sampling of Point Spread Functions in Astronomical Images](https://arxiv.org/abs/2511.19594)
*Connor Stone,Ronan Legin,Alexandre Adam,Nikolay Malkin,Gabriel Missael Barco,Laurence Perreaul-Levasseur,Yashar Hezaveh*

Main category: astro-ph.IM

TL;DR: The paper proposes a novel Bayesian framework for upscaled PSF modeling using a combination of Gaussian likelihood and a generative diffusion prior, achieving superior accuracy and uncertainty quantification compared to traditional methods, even for faint or masked sources.


<details>
  <summary>Details</summary>
Motivation: Accurate PSF characterization is essential for precision measurements in astrophysics (e.g., weak lensing, astrometry), but existing methods like Moffat profiles or template-based approaches fail to capture complex PSF structures or handle faint/masked sources effectively.

Method: The method constructs the PSF posterior via Bayesian inference, combining an analytic Gaussian likelihood (modeling photon noise) with a diffusion model prior trained on HST ePSF templates. This allows flexible modeling of high-resolution PSFs while maintaining physical plausibility.

Result: Compared to traditional methods, the approach achieves orders-of-magnitude higher log-likelihood, residual noise一致性, and visually realistic PSF estimates, even in challenging cases with low signal-to-noise or masked regions.

Conclusion: This method enables reliable propagation of PSF uncertainty into astrophysical analyses, which was previously infeasible. The framework advances PSF modeling capabilities and provides a publicly available implementation for community use.

Abstract: We introduce a novel framework for upsampled Point Spread Function (PSF) modeling using pixel-level Bayesian inference. Accurate PSF characterization is critical for precision measurements in many fields including: weak lensing, astrometry, and photometry. Our method defines the posterior distribution of the pixelized PSF model through the combination of an analytic Gaussian likelihood and a highly expressive generative diffusion model prior, trained on a library of HST ePSF templates. Compared to traditional methods (parametric Moffat, ePSF template-based, and regularized likelihood), we demonstrate that our PSF models achieve orders of magnitude higher likelihood and residuals consistent with noise, all while remaining visually realistic. Further, the method applies even for faint and heavily masked point sources, merely producing a broader posterior. By recovering a realistic, pixel-level posterior distribution, our technique enables the first meaningful propagation of detailed PSF morphological uncertainty in downstream analysis. An implementation of our posterior sampling procedure is available on GitHub.

</details>


### [13] [Asgard/NOTT: L-band nulling interferometry at the VLTI - III. The mid-infrared integrated optics beam combiner for NOTT](https://arxiv.org/abs/2511.19790)
*A. Sanny,L. Labadie,S. Gross,K. Barjot,R. Laugier,G. Garreau,M. -A. Martinod,D. Defrère,M. J. Withford*

Main category: astro-ph.IM

TL;DR: The paper describes the successful fabrication and laboratory testing of a four-telescope integrated optics beam combiner (4T-nuller) for the NOTT instrument. It achieved a self-calibrated nulling ratio of 1.14e-3 at 3.8 µm, demonstrating broadband L'-band nulling capability for exozodiacal dust and planet detection at the water snowline.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop a mid-infrared beam combiner enabling VLTI's NOTT instrument to characterize hot exozodiacal dust and young Jupiter-like planets by achieving deep nulling at the water snowline through L'-band nulling interferometry.

Method: The team manufactured a double-Bracewell architecture IOBC using Ultrafast Laser Inscription in GLS glass, tested with a double Michelson interferometer simulating four VLTI telescopes. They analyzed modal, chromatic, and polarization properties, measured throughput (37% including Fresnel losses), and quantified differential birefringence. Raw and self-calibrated nulling ratios were measured.

Result: Achieved 8.13e-3 raw null and 1.14e-3 self-calibrated null at 3.8 µm with 200 nm bandwidth. Directional couplers showed stable 40/60 and 50/50 splitting ratios across 3.65-3.85 µm. Demonstrated theta^6 null behavior and confirmed first broadband L'-band four-telescope nulling.

Conclusion: The 4T-nuller successfully meets NOTT's requirements for broadband deep nulling. Future steps include cryogenic testing and optimizing coatings to improve throughput, advancing VLTI's capability for exoplanet and dust disk observations.

Abstract: The NOTT visitor instrument at the VLTI will characterize hot exozodiacal dust and young Jupiter-like planets at the water snowline via L' band nulling interferometry. The beam combination will be achieved by a four-telescope integrated optics beam combiner (IOBC) that fulfills specific requirements. Our goal was to manufacture the mid-infrared IOBC for NOTT based on the double-Bracewell architecture and run a detailed laboratory characterization in the L' band. We focus on the achievable raw and self-calibrated nulling ratios. We use a double Michelson interferometer to produce four broadband coherent beams simulating the four telescopes of the VLTI and perform broadband nulling at room temperature. We analyze the modal, chromatic, and polarization behavior of the IOBC, and measure its total throughput. We were able to manufacture a single-mode four-telescope double-Bracewell IOBC in GLS mid-infrared transparent glass using Ultrafast Laser Inscription. We show that the directional couplers forming the four-telescope IOBC (4T-nuller) have an achromatic splitting ratio across the band 3.65-3.85 um with a 40/60 and 50/50 splitting for the side couplers and the central coupler, respectively. We report a total throughput of 37%, including the Fresnel losses that will be mitigated with anti-reflection coatings, and quantify differential birefringence. Operating at room temperature, with 200 nm bandwidth centered at 3.8 um and without polarization control, we measure an average raw null of 8.13+/-0.03x10-3 and a self-calibrated null of 1.14+/-0.01x10-3. Finally, we show that a theta^6 broad null can be experimentally reproduced in these conditions. This is, to our knowledge, the first measurement of a broadband L' deep null obtained with a four-telescope integrated optics beam combiner. The next step foresees testing the 4T-nuller in cryogenic conditions.

</details>


### [14] [Pile-up simulator for XRISM/Xtend onboard the X-ray Imaging and Spectroscopy Mission (XRISM)](https://arxiv.org/abs/2511.19967)
*Tomokage Yoneyama,Tsubasa Tamba,Hirokazu Odaka,Aya Bamba,Hiroshi Murakami,Koji Mori,Yukikatsu Terada,Masayoshi Nobukawa,Tsunefumi mizuno*

Main category: astro-ph.IM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In X-ray astronomy, most observatories utilize multi-pixel photon-counting devices. When a photon counting device observes a bright source, we face an unavoidable problem called pile-up. Pile-up leads to mistakes in the observational properties of the source, mainly an apparent decrease in the X-ray flux. X-Ray Imaging and Spectroscopy Mission (XRISM) has two X-ray telescopes, one of which is Xtend, a CCD camera with a wide field-of-view (FOV) of 38 arcmin square. Xtend has three operating modes: full window mode with a frame exposure of ~4 s, 1/8 window mode with ~0.5s and reduced FOV, and 1/8 window mode with burst option, whose frame exposure is reduced to ~0.06 s. Observers need to select the operating mode according to their target fluxes. We develop the pile-up simulator for Xtend to provide a quantitative assessment of pile-up according to the fluxes, spectra, and shapes of X-ray sources. We derived the 10% pile-up limits for a point source of 7.8, 66.2, and 447.9 counts/s for full window, 1/8 window, and 1/8 window mode with burst option, respectively, by assuming the Crab spectrum. We present further simulations for a diffuse source and monochromatic spectra.

</details>


### [15] [A laboratory plasma experiment for X-ray astronomy using a compact electron beam ion trap (EBIT)](https://arxiv.org/abs/2511.20135)
*Yuki Amano,Leo Hirata,Moto Togawa,Hiromasa Suzuki,Hiroyuki A. Sakaue,Naoki Kimura,Nobuyuki Nakamura,Makoto Sawada,Masaki Oura,Jonas Danisch,Joschka Goes,Marc Botz,José R. Crespo López-urrutia,Hiroya Yamaguchi*

Main category: astro-ph.IM

TL;DR: The JAXA-EBIT successfully generates highly charged ions and produces accurate atomic data through dielectronic recombination measurements and resonant photoexcitation spectroscopy, enhancing astrophysical research.


<details>
  <summary>Details</summary>
Motivation: Accurate atomic data are essential for interpreting high-resolution X-ray spectra from astrophysical plasmas, necessitating controlled laboratory experiments.

Method: The JAXA-EBIT measures dielectronic recombination in highly charged Ar ions and uses synchrotron radiation (BL17SU at SPring-8) for resonant photoexcitation spectra of He-like O$^{6+}$ and Ne-like Fe$^{16+}$.

Result: Achieved performance comparable to the Heidelberg EBIT, detected resonance transitions in oxygen and iron ions, validating its precision for atomic data measurement.

Conclusion: JAXA-EBIT is a reliable tool for obtaining precise atomic data, advancing astrophysical studies through laboratory experiments that benchmark theoretical models.

Abstract: We present the basic performance and experimental results of an electron beam ion trap (JAXA-EBIT), newly introduced to the Japanese astronomical community. Accurate atomic data are indispensable for the reliable interpretation of high-resolution X-ray spectra of astrophysical plasmas. The JAXA-EBIT generates highly charged ions under well-controlled laboratory conditions, providing experimental benchmarks for atomic data. The JAXA-EBIT shows performance comparable to the Heidelberg compact EBIT through dielectronic recombination measurements of highly charged Ar ions. Furthermore, we conducted resonant photoexcitation spectroscopy of highly charged ions using the soft X-ray beamline BL17SU at the synchrotron radiation facility SPring-8. As a result, we successfully detected resonance transitions of He-like O$^{6+}$ and Ne-like Fe$^{16+}$. These results demonstrate the capability of the JAXA-EBIT for precise measurement of atomic data and show that it serves as a powerful tool for advancing astrophysical research.

</details>


### [16] [Ionospheric VLF Radio Reflection Analysis System](https://arxiv.org/abs/2511.20137)
*George Dan Chita*

Main category: astro-ph.IM

TL;DR: The paper proposes a cost-effective, terrestrial system using VLF radio signals for detecting solar flares, avoiding reliance on expensive satellites or telescopes.


<details>
  <summary>Details</summary>
Motivation: Traditional solar flare detection methods are costly due to reliance on satellites or specialized equipment. The authors aim to provide an affordable, accessible alternative using ground-based technology.

Method: The system uses a magnetic loop antenna with a low noise amplifier, analog-to-digital converter, and spectrum analyzer to monitor VLF signals from distant stations. Changes in the ionosphere caused by solar flares affect signal reception, enabling detection.

Result: Data collected over several days in a low-interference environment validated the method's effectiveness, demonstrating reliable detection without costly infrastructure.

Conclusion: This approach offers significant advantages in cost, simplicity, and accessibility over conventional methods, making solar flare monitoring more widely available.

Abstract: Historically, solar flare detection has been dependent on methods that require the presence of expensive satellites or other Earth based costly equipment. In this paper, we propose a cost effective, terrestrial alternative that enables reliable solar flare detection. We will discuss the design, practical implementa- tion, and demonstration of a monitoring system for VLF (Very Low Frequency, 3 kHz to 30 kHz) radio signals transmitted by stations located thousands of kilometers away. This frequency range was selected because VLF radio waves are efficiently reflected by the lower ionospheric layers, and any changes in these layers lead to corresponding variations in the received signal. We have used a magnetic loop antenna for signal reception along with a low noise amplifier, analog-to-digital converter, and spectrum analyzer. Data was collected over the course of a few days, from a remote location with minimal electromagnetic interference. From the viewpoint of cost, simplicity and accessibility, this method far surpasses traditional methods of detecting solar flares, using satellites, telescopes, etc.

</details>


### [17] [Simulating the Stellar Bycatch: Constraining the Prevalence of Extraterrestrial Transmitters within Radio SETI Surveys](https://arxiv.org/abs/2511.20231)
*Louisa A. Mason,Michael A. Garrett,Andrew P. V. Siemion*

Main category: astro-ph.IM

TL;DR: The paper explores using the Besançon Galactic Model to improve constraints on extraterrestrial transmitters by accounting for stellar populations beyond Gaia's limitations, applying it to Breakthrough Listen's survey to set prevalence limits of ≤0.000995% within 2.5kpc, and challenges the notion that SETI is heavily anthropocentrically biased.


<details>
  <summary>Details</summary>
Motivation: To address Gaia's limitations in magnitude, distance accuracy, and crowded regions, and provide a more accurate statistical framework for SETI surveys to better constrain the prevalence of extraterrestrial transmitters.

Method: Simulated stellar populations using the Besançon Galactic Model to model 6,182,364 stars across 1229 pointings up to 25kpc, applied to Breakthrough Listen's Enriquez/Price survey, and provided a calculator tool for other researchers.

Result: Placed limits on high duty cycle transmitters within 2.5kpc with prevalence ≤0.000995% (EIRP ≥5×10¹⁶W), enabling more robust statistical estimations of probed systems' numbers and stellar types.

Conclusion: Enhanced methods reduce biases and improve SETI constraints, demonstrating that such surveys are less anthropocentrically biased than commonly perceived.

Abstract: Searches for radio technosignatures place constraints on the prevalence of extraterrestrial transmitters in our Galaxy and beyond. It is important to account for the complete stellar population captured within a radio telescope's field of view, or stellar 'bycatch'. In recent years, catalogues from ESA's Gaia mission have enabled SETI surveys to place tighter limits on extraterrestrial transmitter statistics. However, Gaia remains restricted by magnitude limits, astrometric uncertainty at large distances, and confusion in crowded regions. To address these limitations, we investigate the use of the Besançon Galactic Model to simulate the statistical underlying stellar population to derive more realistic constraints on the occurrence of extraterrestrial transmitters. We apply this method to Breakthrough Listen's Enriquez/Price survey, modelling 6,182,364 stellar objects within 1229 individual pointings and extending the search out to distances $\leq 25$kpc. We place limits on the prevalence of high duty cycle transmitters within 2.5kpc, suggesting $\leq (0.000995 \pm 0.000002)\%$ of stellar systems contain such a transmitter (for near-zero drift rates and EIRP$_{\mathrm{min}} \gtrsim 5 \times 10^{16}$W). In support of broader adoption, we provide a simple calculator tool that enables other researchers to incorporate this approach into their own SETI analyses. Our results enable a more complete statistical estimation of the number and stellar type of systems probed, thereby strengthening constraints on technosignature prevalence and guiding the analysis of future SETI efforts. We also conclude that SETI surveys are, in fact, much less biased by anthropocentric assumptions than is often suggested.

</details>


### [18] [Performance Calibration of the Wavefront Sensor's EMCCD Detector for the Cool Planets Imaging Coronagraph Aboard CSST](https://arxiv.org/abs/2511.20386)
*Jiangpei Dou,Bingli Niu,Gang Zhao,Xi Zhang,Gang Wang,Baoning Yuan,Di Wang,Xingguang Qian*

Main category: astro-ph.IM

TL;DR: This paper evaluates the EMCCD detector of the CPI-C's wavefront sensor, optimizing its performance for exoplanet imaging by assessing EM gain and noise characteristics to meet CSST's high-contrast requirements.


<details>
  <summary>Details</summary>
Motivation: To ensure the EMCCD detector meets the stringent requirements for high-contrast exoplanet imaging by the CPI-C on the CSST, precise calibration and optimization are essential.

Method: The study used multi-stage screening to select an EMCCD chip with high resolution and low noise. They analyzed EM gain's effect on signal amplification and noise, determining the optimal operational range and investigating readout noise properties.

Result: The optimized EMCCD detector successfully met CPI-C's initial requirements, achieving high resolution and low noise levels.

Conclusion: The findings provide theoretical and experimental validation for using EMCCD-based wavefront sensors in adaptive optics and space-based astronomical imaging, ensuring their reliability for future missions.

Abstract: The wavefront sensor (WFS), equipped with an electron-multiplying charge-coupled device (EMCCD) detector, is a critical component of the Cool Planets Imaging Coronagraph (CPI-C) on the Chinese Space Station Telescope (CSST). Precise calibration of the WFS's EMCCD detector is essential to meet the stringent requirements for high-contrast exoplanet imaging. This study comprehensively characterizes key performance parameters of the detector to ensure its suitability for astronomical observations. Through a multi-stage screening protocol, we identified an EMCCD chip exhibiting high resolution and low noise. The electron-multiplying gain (EM Gain) of the EMCCD was analyzed to determine its impact on signal amplification and noise characteristics, identifying the optimal operational range. Additionally, noise properties such as readout noise were investigated. Experimental results demonstrate that the optimized detector meets CPI-C's initial application requirements, achieving high resolution and low noise. This study provides theoretical and experimental foundations for the use of EMCCD-based WFS in adaptive optics and astronomical observations, ensuring their reliability for advanced space-based imaging applications

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [19] [Hodge-Dirac wave systems and structure-preserving discretizations of the linearized Einstein equations](https://arxiv.org/abs/2511.19441)
*Marien-Lorenzo Hanot,Kaibo Hu*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We derive a reformulation of the linearized Arnowitt-Deser-Misner (ADM) equations as a Hodge-Dirac wave system with the divdiv complex, addressing challenges in numerical relativity such as gauge fixing, constraint propagation, and tensor symmetries. The differential and algebraic structures of the divdiv complex ensure the well-posedness of the formulation and facilitate structure-preserving discretization via finite element exterior calculus. We establish the well-posedness of this Hodge-Dirac wave equation and develop a discretization scheme applicable to both conforming and non-conforming discrete complexes, deriving error estimates under minimal assumptions.

</details>


### [20] [GREA and Dark Energy: A holographic dual](https://arxiv.org/abs/2511.19546)
*Juan García-Bellido*

Main category: gr-qc

TL;DR: The paper explores the holographic duality between a bulk cosmological model with a cosmological constant and its boundary theory, suggesting that cosmic acceleration might arise from the thermodynamic properties of the de Sitter horizon rather than a fundamental cosmological constant. This opens possibilities for distinguishing between Λ and entropic acceleration through future observations.


<details>
  <summary>Details</summary>
Motivation: To address the mystery of the cosmological constant's origin and test whether cosmic acceleration stems from a constant Λ or thermodynamic boundary effects, potentially guiding future cosmological experiments.

Method: Analyzes the holographic dual of an empty, flat bulk space with Λ, comparing bulk observations of Λ-induced acceleration with those from boundary thermodynamics. Extends the model to include matter, proposing GREA where boundary quantum degrees of freedom cause time-varying entropic acceleration.

Result: Shows that bulk observers cannot distinguish Λ's effects from boundary thermodynamics. Proposes GREA framework where horizon boundary evolution induces variable acceleration, crucial for determining the universe's future fate (de Sitter vs Minkowski).

Conclusion: Future observations are critical to discern if cosmic acceleration originates from the de Sitter horizon's entropy or a cosmological constant, redefining our understanding of dark energy and cosmic destiny.

Abstract: The nature of the cosmological constant is a mystery. We don't understand its quantum origin but we associate it with the actual acceleration of the universe because it is the simplest description we had until recently of the present cosmological observations. However, this may change with the next generation of experiments. If we can convince ourselves that the cosmic acceleration is not due to a constant, this would open up new fascinating avenues. By exploring the simplest cosmological model in the bulk, that of an empty and flat space with a cosmological constant $Λ$, we find that its holographic dual makes sense as a theory of fundamental quantum degrees of freedom at the boundary. Moreover, we find that an observer in the bulk, making long-range (electromagnetic and gravitational) observations, cannot distinguish the acceleration induced by the cosmological constant $Λ$ from that induced by the thermodynamic properties of the boundary, the de Sitter horizon. By including matter in the bulk we extend this holographic principle to GREA, where the quantum d.o.f. associated with the evolving boundary of the causal horizon induces an entropic acceleration that varies in time. Future observations will determine whether our causal horizon is responsible for the present acceleration and whether our universe will end in de Sitter or Minkowski.

</details>


### [21] [Quasinormal modes of scalar, electromagnetic, and gravitational perturbations in slowly rotating Kalb-Ramond black holes](https://arxiv.org/abs/2511.19553)
*Weike Deng,Wentao Liu,Kui Xiao,Jiliang Jing*

Main category: gr-qc

TL;DR: The paper explores quasinormal mode behavior in slowly rotating Kalb-Ramond black holes, showing that Lorentz violation affects oscillation and damping rates across scalar, electromagnetic, and gravitational perturbations, with axial gravitational modes setting a theoretical bound on the Lorentz-violating parameter.


<details>
  <summary>Details</summary>
Motivation: To investigate how spontaneous Lorentz symmetry breaking due to a Kalb-Ramond field influences quasinormal mode frequencies in black holes, and to establish observational constraints through gravitational-wave spectroscopy.

Method: Derivation of master equations for scalar, electromagnetic, and axial gravitational perturbations in first-order rotating KR black holes, using continued-fraction and matrix methods to compute QNM spectra.

Result: Lorentz-violating parameter ℓ increases real frequency parts and enhances damping (more negative imaginary parts). Axial gravitational modes show strongest effect, indicating ℓ < 0.5 limit before extremal behavior occurs.

Conclusion: Gravitational-wave observations could detect Lorentz violation in KR gravity, with the derived bounds on ℓ providing testable predictions for future experiments.

Abstract: We investigate quasinormal modes (QNMs) of scalar, electromagnetic, and axial gravitational perturbations in slowly rotating Kalb-Ramond (KR) black holes, where an antisymmetric tensor field induces spontaneous Lorentz symmetry breaking. Working consistently to first order in the dimensionless spin parameter, we derive the corresponding master equations and compute the QNM spectrum using both the continued-fraction and matrix methods, finding excellent agreement. Lorentz violation modifies the oscillation and damping rates in a unified manner across all perturbative sectors: the real part of the QNM frequency increases monotonically with the Lorentz-violating parameter $\ell$, while the imaginary part becomes more negative. Axial gravitational modes exhibit the strongest response, revealing an intrinsic theoretical bound $\ell< 0.5$, beyond which the spectrum approaches an extremal behavior. Our results highlight the potential of gravitational-wave spectroscopy to probe Lorentz-violating signatures in KR gravity.

</details>


### [22] [On Modelling the Surfaces of Celestial Bodies in Quantum Gravity](https://arxiv.org/abs/2511.19582)
*Xavier Calmet,Marco Sebastianutti*

Main category: gr-qc

TL;DR: The paper addresses the issue of pathological behavior in quantum gravity corrections at the surface of celestial bodies by modifying the Tolman VII density profile to achieve regular quantum corrections.


<details>
  <summary>Details</summary>
Motivation: To ensure the regularity of quantum corrections to classical general relativity solutions at the surfaces of stars, avoiding pathological divergences in metric functions and curvature invariants previously observed with Heaviside profiles.

Method: Uses the Vilkovisky--DeWitt effective action to compute quantum corrections for stellar models with a modified Tolman VII density profile, analyzing the minimal differentiability required for regularity.

Result: Determines that a modified Tolman VII profile with sufficient differentiability suppresses metric and curvature divergences at the star's surface, providing a non-pathological quantum correction framework.

Conclusion: The approach successfully resolves surface regularity issues in quantum gravity corrections, offering a robust method for modeling stellar structures in quantum regimes.

Abstract: We discuss how to model the surface of celestial bodies (such as stars) in quantum gravity to ensure the regularity of quantum corrections to classical solutions of general relativity at the surface of such bodies. Specifically, we use the Vilkovisky--DeWitt unique effective action to calculate universal quantum corrections to the exterior metric for a class of stellar models. Previous descriptions, obtained via a Heaviside density profile, are ``pathological'' at the surface of the star due to the divergence of the metric functions and associated curvature invariants. Introducing a modified version of the Tolman VII density profile, we determine the minimal degree of differentiability required for this function to generate regular quantum corrections at the star's surface.

</details>


### [23] [Searching Stochastic Gravitational Wave Background Landscape Across Frequency Bands](https://arxiv.org/abs/2511.19590)
*Yunjia Bao,Tore Boybeyi,Vuk Mandic,Lian-Tao Wang*

Main category: gr-qc

TL;DR: The paper proposes a model involving hybrid topological defects from a two-step phase transition separated by inflation to explain the pulsar timing array signal and demonstrates how upcoming gravitational wave detectors can test this model through multi-band observations.


<details>
  <summary>Details</summary>
Motivation: To explore the potential of multi-band gravitational wave detectors in analyzing the stochastic GW background and to provide a new physics scenario that could explain observed signals like those from pulsar timing arrays.

Method: Development of a general pipeline for analyzing experimental exclusions applied to a model of hybrid topological defects arising from a two-step phase transition with an intervening inflationary period.

Result: The model offers an explanation for the low-frequency pulsar timing array signal and predicts that future experiments (LISA, Cosmic Explorer, Einstein Telescope) can confirm or rule out the model by probing higher frequencies.

Conclusion: Multi-band GW observations are crucial for validating or refuting new physics scenarios like hybrid topological defects, emphasizing the need for continued detector advancements.

Abstract: Gravitational wave (GW) astrophysics is entering a multi-band era with upcoming GW detectors, enabling detailed mapping of the stochastic GW background across vast frequencies. We highlight this potential via a new physics scenario: hybrid topological defects from a two-step phase transition separated by inflation. We develop a general pipeline to analyze experimental exclusions and apply it to this model. The model offers a possible explanation of the pulsar timing array signal at low frequencies, and future experiments (LISA/Cosmic Explorer/Einstein Telescope) will confirm or rule it out via the higher-frequency probes, showcasing the power of multi-band constraints.

</details>


### [24] [A parametrized model for gravitational waves from eccentric, precessing binary black holes: theory-agnostic tests of General Relativity with pTEOBResumS](https://arxiv.org/abs/2511.19593)
*Danilo Chiaramello,Nicolò Cibrario,Jacob Lange,Koustav Chandra,Rossella Gamba,Raffaella Bonino,Alessandro Nagar*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Gravitational waves from binary black hole (BBH) mergers allow us to test general relativity in the strong-field, high-curvature regime. However, existing gravitational wave-based tests have so far assumed non-eccentric signal sources, limiting their applicability to more general astrophysical scenarios. In this work, we present pTEOBResumS, a new parametrized inspiral-merger-ringdown model for null tests of GR that incorporates both orbital eccentricity and spin precession. Building on the effective-one-body model TEOBResumS-Dalí, we introduce parametrized deviations from GR both in the inspiral and the merger-ringdown regimes. We validate the model via parameter estimation of synthetic signals, including from numerical relativity simulations of BBHs and a boson star binary. These allow us to establish the model's consistency, demonstrate its capability to identify beyond-GR effects, and gauge the impact of eccentricity in tests of GR. We then analyze a set of BBH events from the first three LIGO-Virgo-KAGRA observing runs, testing whether they are best explained by a GR or non-GR waveform, under either the eccentric, spin-aligned or precessing, quasi-circular hypotheses. We find no significant statistical evidence in favor of deviations from GR. Consistent with previous works, we infer a mild preference for longer remnant quasi-normal mode damping times than expected in GR, though the limited sample and potential systematics reduce its significance. In addition, when weighting by signal strength, joint posteriors combining the individual events are still compatible with GR. We find no strong evidence for imprints of orbital eccentricity in the analyzed events, with the exception of GW200129. For this, our analysis finds a strong preference for an eccentric, GR-consistent description, although as previous works have noted this result could be influenced by data quality issues.

</details>


### [25] [Periodic gravitational lensing by oscillating boson stars](https://arxiv.org/abs/2511.19606)
*Xing-Yu Yang,Tan Chen,Rong-Gen Cai*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We show that oscillating (real-scalar) boson stars can act as strictly periodic gravitational lenses and generically host an \emph{oscillating radial caustic}. Sources near this caustic cross it every half period, producing achromatic phase-locked photometric spikes synchronized with an astrometric wobble, providing a promising target for time-domain astronomy. Event-number estimation indicates a measurable discovery space with current astrometric and high-cadence photometric surveys. These predictions rely only on the dynamics of long-lived real-scalar condensates, therefore offering a clean test of self-gravitating quantum fields in curved spacetime. The framework extends naturally to self-interacting real scalars (including axion-like particles) and to ultralight vector bosons.

</details>


### [26] [Effective-one-body modelling of eccentric supermassive black hole binaries for Pulsar Timing Array](https://arxiv.org/abs/2511.19611)
*Sara Manzini,Stanislav Babak*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Pulsar Timing Arrays (PTAs) observations will detect gravitational waves (GWs) from the early inspiral phase of supermassive black hole binaries (SMBHBs) with orbital periods of weeks to years. Current PTA analyses generally assume circular binaries; however, dynamical interactions with the surrounding environment can prevent complete circularisation, allowing SMBHBs to retain appreciable eccentricities. In this work, we present a gravitational waveform model for eccentric binaries based on the Effective-One-Body (EOB) formalism, designed for continuous GW searches in PTA data. The model is accurate up to the second post-Newtonian (2PN) order for the conservative dynamics and up to post-leading order for the radiation-reaction terms. We provide both a numerically precise and a computationally efficient approximate implementation and evaluate the latter's accuracy against the full model over a broad range of eccentricities and initial orbital frequencies. Our results show that a substantial region of the parameter space exhibits pronounced orbital evolution, much stronger than in the circular case. We demonstrate the rich harmonic structure of timing residuals induced by eccentric GWs. Properly characterising eccentric binaries is an essential step toward detecting GWs in PTA data and interpreting the results, ultimately improving our understanding of the supermassive black hole population in the local Universe.

</details>


### [27] [Universal Relations with Dynamical Tides](https://arxiv.org/abs/2511.19626)
*Jayana A. Saes,Abhishek Hegade K. R.,Nicolás Yunes*

Main category: gr-qc

TL;DR: The paper identifies new quasi-universal relations between tidal deformability parameters (Λ^(0), Λ^(2), and Mω_*) for neutron stars, showing minimal equation-of-state dependence (~5% and ~2.5%) and their applicability in gravitational-wave modeling. It also evaluates the effectiveness of two approximation methods for dynamical tides.


<details>
  <summary>Details</summary>
Motivation: To minimize uncertainties from the unknown equation of state (EOS) in neutron star observations and improve gravitational-wave modeling by discovering robust, EOS-insensitive relations between key tidal parameters.

Method: The authors derived quasi-universal relations between static tidal deformability (Λ^(0)), its dynamical correction (Λ^(2)), and the combined parameter Mω_* from the small-frequency expansion of relativistic tidal responses. They tested these relations across 63 diverse EOS models and compared dynamical tide approximations (Taylor expansion vs. effective-one-mode).

Result: The relations showed EOS dependence within 5% for Λ^(0)-Λ^(2) and 2.5% for Λ^(0)-Mω_*, indicating strong universality. Taylor expansion outperformed the effective-one-mode approximation in modeling frequency-dependent tidal deformability.

Conclusion: These quasi-universal relations offer a simplified framework to incorporate dynamical tides into gravitational-wave signals, reducing EOS uncertainties. The Taylor expansion method is recommended for dynamical tide modeling.

Abstract: Observations of neutron stars and the precise measurement of their macroscopic properties have provided valuable insights into fundamental physics, both by constraining the behavior of nuclear matter under extreme conditions and by enabling tests of general relativity in the strong-field regime. In this context, equation-of-state-insensitive or ``quasi-universal'' relations between key observables, such as the compactness, dimensionless static tidal deformability, and moment of inertia, play a crucial role in connecting different measurable observables while minimizing uncertainties due to the yet unknown equation of state. In this work, we identify new quasi-universal relations between the static, dimensionless tidal deformability ($Λ^{(0)}$) and its leading-order dynamical correction ($Λ^{(2)}$), as well as a combination of these parameters ($\sqrt{Λ^{(0)}/Λ^{(2)}} \equiv Mω_*$), obtained from the small-frequency expansion of the relativistic tidal response. We test these relations across a representative set of 63 equations of state, finding that the equation-of-state dependence does not exceed $\sim 5\%$ for the $Λ^{(0)}$-$Λ^{(2)}$ relation and $\sim 2.5\%$ for the $Λ^{(0)}$-$Mω_*$ relation. This indicates a high degree of universality and offers a simplified framework for incorporating dynamical tidal effects into gravitational-wave modeling. Furthermore, we compare the fully dynamical tidal response against different recent strategies (a Taylor expansion and an effective-one-mode approximation) to model the dynamical tide. We find that both models are capable of capturing the frequency-dependent behavior of the fully dynamical tidal deformability, with the Taylor expansion outperforming the effective-one-mode approximation in most of the parameter space.

</details>


### [28] [Microseismic Noise Mitigation with Machine Learning for Advanced LIGO](https://arxiv.org/abs/2511.19682)
*Christina Reissel,Devin Lai,Shivanshu Dwivedi,Edgard Bonilla,Claudia Geer,Christopher Wipf,Richard Mittleman,Philip Harris,Eyal Schwartz,Dovi Poznanski,Brian Lantz,Erik Katsavounidis*

Main category: gr-qc

TL;DR: The paper presents a machine learning-based approach to model and reduce residual seismic motion in gravitational-wave observatories, achieving a significant improvement over traditional methods.


<details>
  <summary>Details</summary>
Motivation: The susceptibility of LIGO detectors to low-frequency microseisms affects their sensitivity and uptime, necessitating more effective mitigation strategies beyond current linear filtering methods.

Method: A neural network is trained using ground and platform sensor data to predict and suppress residual platform motion caused by microseisms, incorporating these predictions into the control system.

Result: The machine learning approach reduces residual motion by up to an order of magnitude compared to conventional linear filters, highlighting the importance of nonlinear couplings in seismic isolation.

Conclusion: Data-driven machine learning control offers a promising pathway to enhance gravitational-wave detector stability, low-frequency sensitivity, and observational capabilities.

Abstract: The unprecedented sensitivity of the Laser Interferometer Gravitational-Wave Observatory, which enables the detection of distant astrophysical sources, also renders the detectors highly susceptible to low-frequency ground motion. Persistent microseisms in the 0.1-0.3 Hz band couple into the instruments, degrade lock stability, and contribute substantially to detector downtime during observing runs. The multi-stage seismic isolation system has achieved remarkable success in mitigating such disturbances through active feedback control, yet residual platform motion remains a key factor limiting low-frequency sensitivity and duty cycle. Further reduction of this residual motion is therefore critical for improving the long-term stability and overall astrophysical reach of the observatories.
  In this work, we develop a data-driven approach that uses machine learning to model and suppress residual seismic motion within the isolation system. Ground and platform sensor data from the detectors are used to train a neural network that predicts platform motion driven by microseismic activity. When incorporated into the control scheme, the network's predictions yield up to an order-of-magnitude reduction in residual motion compared to conventional linear filtering methods, revealing that nonlinear couplings play a significant role in limiting current isolation performance. These results demonstrate that machine-learning-based control can provide a powerful new pathway for enhancing active seismic isolation, improving lock robustness, and extending the low-frequency observational capabilities of gravitational-wave detectors.

</details>


### [29] [General relativity, early galaxy formation and the JWST observations](https://arxiv.org/abs/2511.19736)
*Christos G. Tsagas*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The James Webb Space Telescope has recently detected massive, fully formed, galaxies at redshifts corresponding to few hundred million years after the Big-Bang. However, our current cosmological model cannot produce such massive systems so early in the lifetime of the universe. A number of theoretical solutions have been proposed, but they all appeal to exotic new physics and introduce rather excessive fine-tuning. In this essay, we outline a theoretical answer to the early galaxy-formation question, which operates within standard general relativity and standard cosmology, without appealing to any new physics. Instead, we account for the effect of a well established feature of our universe. This feature, which has so far been kept in the margins of mainstream cosmology, are the peculiar velocities.

</details>


### [30] [Exact Solutions for the Kemmer Oscillator in 1+1 Rindler Coordinates](https://arxiv.org/abs/2511.19748)
*T. Rouabhia,A. Boumali*

Main category: gr-qc

TL;DR: The paper derives exact solutions for the Kemmer equation describing spin-1 particles in (1+1)-dimensional Rindler spacetime, incorporating Unruh effects and acceleration impacts. It introduces a Dirac oscillator interaction leading to modified spectra and energy shifts, recovering standard results in flat spacetime limits.


<details>
  <summary>Details</summary>
Motivation: To understand vector boson behavior under uniform acceleration, explore non-inertial effects like Unruh temperature, and differentiate spin-1 systems from spin-0 and spin-1/2. This addresses gaps in quantum field theory in curved spacetime.

Method: Derived eigenvalue equations from the free Kemmer field in accelerated frames, applied Dirac oscillator interaction via momentum substitution, solved for exact spectra showing acceleration's effect on energy levels and spatial characteristics.

Result: Exact closed-form spectra for the Kemmer oscillator under acceleration, showing modified characteristic lengths, shifted discrete energy levels, and resolved degeneracies. Consistency with Minkowski spacetime (a→0) confirms validity.

Conclusion: Offers a foundational framework for studying acceleration-induced phenomena in quantum field theory, quantum gravity, and analogue gravity systems, advancing understanding of spin-1 particle dynamics in non-inertial frames.

Abstract: This work presents exact solutions of the Kemmer equation for spin-1 particles in $(1+1)$-dimensional Rindler spacetime, motivated by the need to understand vector bosons under uniform acceleration, including non-inertial effects and the Unruh temperature, which distinguish them from spin-0 and spin-1/2 systems. Starting from the free Kemmer field in an accelerated reference frame, we establish eigenvalue equations resembling those of the Klein--Gordon equation in Rindler coordinates. By introducing the Dirac oscillator interaction through a momentum substitution, we derive an exact closed-form spectrum for the Kemmer oscillator, revealing how the acceleration parameter modifies the characteristic length, shifts the discrete energy spectrum, and lifts degeneracies. In the Minkowski limit $a\to 0$, the standard Kemmer oscillator spectrum is recovered, ensuring consistency with flat-spacetime results. These findings provide a tractable framework for analyzing acceleration-induced effects, with implications for quantum field theory in curved spacetime, quantum gravity, and analogue gravity platforms.

</details>


### [31] [Quintessential Inflation in Light of ACT DR6](https://arxiv.org/abs/2511.19898)
*Sayantan Choudhury,Swapnil Kumar Singh,Satish Kumar Sahoo*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We perform a precision investigation of smooth quintessential inflation in which a single canonical scalar field unifies the two known phases of cosmic acceleration. Using a CMB-normalized runaway exponential potential, we obtain sharply predictive inflationary observables: a red-tilted spectrum with $n_s = 0.964241$ and an exceptionally suppressed tensor-to-scalar ratio $r = 7.48 \times 10^{-5}$ at $N=60$, lying near the optimal region of current Planck+ACT constraints. Remarkably, all observable scales exit the horizon within an extremely narrow field interval $Δφ\simeq 0.03\,M_{\rm Pl}$, tightly linking early and late-time dynamics and reducing theoretical ambiguities. While inflationary tensors remain invisible to CMB B-mode surveys, the subsequent stiff epoch-an intrinsic hallmark of quintessential cosmology-imprints a blue-tilted stochastic gravitational-wave background within the discovery reach of future interferometers such as LISA, DECIGO, ALIA, and BBO. Our results demonstrate that this minimal, featureless model not only survives current bounds, but provides concrete, falsifiable predictions across gravitational-wave frequencies spanning over twenty orders of magnitude.

</details>


### [32] [Designing Wormholes in Novel Power-Law $f(R)$: A Mathematical approach with a linear equation of state](https://arxiv.org/abs/2511.19901)
*Subhasis Nalui,Subhra Bhattacharya*

Main category: gr-qc

TL;DR: The paper explores wormhole solutions in f(R) gravity using a novel linear equation of state, yielding four models with varying characteristics, including solid angle deficits and tidal forces, and links photon spheres to complexity factors.


<details>
  <summary>Details</summary>
Motivation: To investigate the viability of wormhole structures in f(R) gravity by examining their cosmological compatibility and connecting them to complexity factors via photon sphere analysis.

Method: Applied Einstein's field equations in metric f(R) gravity to model wormholes, used Brans-Dicke correspondence for scalar-tensor representation, and analyzed photon spheres and complexity factors.

Result: Four wormhole models with different properties (solid angle deficits, asymptotic extendibility) were found. Some NEC-violating models required ghost f(R) terms. All models were validated for cosmological viability. Photon spheres correlated with complexity factors similarly to Einstein gravity.

Conclusion: f(R) gravity supports diverse wormhole solutions, maintains complexity-photon sphere relationships like GR, and cosmologically viable models require careful parameter selection.

Abstract: We consider the inhomogeneous Morris-Thorne wormhole metric with matter tensors characterised by a novel linear equation of state in $f(R)$ gravity. Using the Einstein's field equations in metric $f(R)$ gravity we model solutions for both wormhole as well as $f(R)$ gravity. We obtain four different wormhole models, two wormholes are characterised by solid angle deficit, three are not asymptotically extendible, while one is asymptotically flat with zero tidal force. These are supported by four different power law $f(R)$ models. The parameter space of the models can support both null energy conditions (NEC) satisfying as well as violating wormhole. In case of NEC satisfying matter, the associated $f(R)$ is ghost. The $f(R)$ models obtained have been independently substantiated for cosmological feasibility and valid parameter space was obtained corresponding to cosmologically viable $f(R)$. Suitable scalar-tensor representation of the corresponding $f(R)$ models have been presented using the correspondence of $f(R)$ gravity with Brans-Dicke (BD) theory of gravity. The robustness of the wormhole solutions were further analysed with the BD scalar fields in the hybrid metric-Palatini gravity, which showed excellent results. Lastly as an independent astrophysical probe for the wormhole we have obtained the location of their photon spheres and have connected them with the Herrera Complexity factor in $f(R).$ Our results show that the relation between the complexity factor and existence of photon spheres remains fundamentally unaltered in $f(R)$ as compared to Einstein's gravity.

</details>


### [33] [Search for planetary-mass ultra-compact binaries using data from the first part of the LIGO--Virgo--KAGRA fourth observing run](https://arxiv.org/abs/2511.19911)
*The LIGO Scientific Collaboration,Virgo Collaboration,KAGRA Collaboration*

Main category: gr-qc

TL;DR: The paper presents a search for gravitational waves from planetary-mass ultra-compact binaries using LIGO, Virgo, and KAGRA data. No evidence was found, leading to constraints on primordial black hole mass distributions in the 10^-6 to 10^-3 solar mass range.


<details>
  <summary>Details</summary>
Motivation: To investigate the existence of primordial black holes as dark matter candidates in the planetary-mass range and constrain their mass distributions using gravitational wave observations, complementing microlensing studies.

Method: Analyzed data from LIGO/Virgo/KAGRA's fourth observing run to search for gravitational wave signals from inspiraling ultra-compact binaries. Established merger rate density upper limits and translated these into constraints on primordial black hole mass distributions under the assumption they constitute all dark matter.

Result: No detections were made, allowing derivation of maximum distance reach and merger rate densities. Constraints align with microlensing results in the planetary-mass range, offering a complementary probe for sub-solar mass objects.

Conclusion: Gravitational wave observations provide independent constraints on primordial black hole populations in specific mass ranges, reinforcing consistency with other astronomical probes and narrowing down possible dark matter compositions.

Abstract: We present a search for gravitational waves from inspiraling, planetary-mass ultra-compact binaries using data from the first part of the fourth observing run of LIGO, Virgo and KAGRA. Finding no evidence of such systems, we determine the maximum distance reach for such objects and their merger rate densities, independently of how they could have formed. Then, we identify classes of primordial black-hole mass distributions for which these rate limits can be translated into relevant constraints on the mass distribution of primordial black holes, assuming that they compose all of dark matter, in the mass range $[10^{-6},10^{-3}]M_\odot$. Our constraints are consistent with existing microlensing results in the planetary-mass range, and provide a complementary probe to sub-solar mass objects.

</details>


### [34] [Revisiting black holes and their thermodynamics in Einstein-Kalb-Ramond gravity](https://arxiv.org/abs/2511.19926)
*Zhong-Xi Yu,Hong-Da Lyu,Mandula Huhe,Shoulong Li*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Einstein-Kalb-Ramond gravity is an alternative theory of gravity in which a rank-two antisymmetric tensor field, known as the Kalb-Ramond field, is nonminimally coupled to gravity and can induce spontaneous Lorentz symmetry breaking when it acquires a nonzero vacuum expectation value. In this work, we revisit Einstein-Kalb-Ramond gravity and obtain two classes of exact static black hole solutions with general topological horizons in diverse dimensions within this framework, both with and without a cosmological constant. We further analyze their thermodynamic properties and employ the Wald formalism to compute the Noether mass and entropy, thereby establishing the corresponding first law of black hole thermodynamics. Finally, we discuss the implications of the Noether mass charge for constraining spontaneous Lorentz symmetry breaking within the framework of Einstein-Kalb-Ramond gravity.

</details>


### [35] [Spherically symmetric charged (anti-)de Sitter black hole in $f(R,T)$ gravity coupled with nonlinear electrodynamics](https://arxiv.org/abs/2511.20055)
*Tianyou Ren,Zhenglong Ban,Yaobin Hua,Rong-Jia Yang*

Main category: gr-qc

TL;DR: The paper presents a charged static spherically symmetric solution in f(R,T) gravity with nonlinear electrodynamics, analyzing its horizon structure and black hole shadow effects under magnetic charge and coupling parameters.


<details>
  <summary>Details</summary>
Motivation: To explore modifications to general relativity in the strong-field regime using f(R,T) gravity and nonlinear electrodynamics, investigating how nonlinear electromagnetic effects and matter-geometry coupling alter black hole properties.

Method: Derive and solve gravitational and electromagnetic field equations in f(R,T) gravity coupled with nonlinear electrodynamics. Analyze horizon structures, introduce an effective metric for photon trajectory studies, and examine parameter dependencies on shadow size and photon sphere radius.

Result: Obtained solutions show AdS/dS metrics at large distances but significant strong-field modifications. Multiple horizons occur under specific parameters. Magnetic charge and coupling parameters significantly affect the effective potential shape, photon sphere radius, and black hole shadow morphology.

Conclusion: Nonlinear electromagnetic coupling in f(R,T) gravity produces observable strong-field deviations, offering testable predictions for future astrophysical observations (e.g., Event Horizon Telescope) to constrain gravitational theories beyond Einstein's framework.

Abstract: By deriving and solving the gravitational and electromagnetic field equations in $f(R,T)$ gravity coupled with nonlinear electrodynamics, we obtain a static spherically symmetric charged solution that incorporates higher-order correction terms along with an effective cosmological constant term. This solution reduces to the AdS/dS metric in the far-field region while exhibiting significant modifications in the strong-field regime due to the nonlinear electromagnetic effects and the matter-geometry coupling. We further analyze the black hole's horizon structure, revealing the complex phenomenon of multiple horizons emerging within specific parameter ranges. Additionally, by introducing an effective metric to study photon propagation, we systematically explore the influence of magnetic charge and the coupling parameter on the effective potential, the photon sphere radius, and the black hole shadow.

</details>


### [36] [Relativistic excitation of compact stars](https://arxiv.org/abs/2506.23176)
*Zhiqiang Miao,Xuefeng Feng,Zhen Pan,Huan Yang*

Main category: gr-qc

TL;DR: This paper investigates the excitation of compact stars in strong gravitational fields by analyzing the scattering of waves around the star. It introduces a 'star excitation factor' analogous to the black hole counterpart, derives mode excitation during binary inspiral, and assesses tidal energy effects causing phase changes in neutron star mergers.


<details>
  <summary>Details</summary>
Motivation: To move beyond Newtonian-based models in describing resonant mode excitation of compact stars and to accurately predict gravitational wave signals from binary neutron star inspirals by incorporating relativistic effects.

Method: A relativistic model where a constant-frequency gravitational wave is injected at past null infinity and scattered by the compact star. Analyzes scattering coefficient's structure to define the 'star excitation factor', calculates transient mode excitation during binary inspiral resonance, and compares tidal energy formulas.

Result: Demonstrates that the scattering coefficient's analytical structure validates the 'star excitation factor' concept, identifies phase modulation of ~0.5 radians in late-stage waveforms from tidal energy differences, and provides a relativistic framework improving upon Newtonian decompositions.

Conclusion: A relativistic treatment is essential for accurate modeling of compact star excitations in binaries, offering corrected predictions for gravitational wave signatures and energy dynamics during inspiral phases.

Abstract: In this work, we study the excitation of a compact star under the influence of external gravitational driving in the relativistic regime. Using a model setup in which a wave with constant frequency is injected from past null infinity and scattered by the star to future null infinity, we show that the scattering coefficient encodes rich information of the star. For example, the analytical structure of the scattering coefficient implies that the decay rate of a mode generally plays the role of ``star excitation factor'', similar to the ``black hole excitation factor'' previously defined for describing black hole mode excitations. With this star excitation factor we derive the transient mode excitation as a binary system crosses a generic mode resonance of a companion star during the inspiral stage. This application is useful because previous description of resonant mode excitation of stars still relies on the mode and driving force decomposition based on the Newtonian formalism. In addition, we show that the scattering phase is intimately related to the total energy of spacetime and matter under the driving of a steady input wave from infinity. We also derive the relevant tidal energy of a star under steady driving and compare that with the dynamic tide formula. We estimate that the difference may lead to $\mathcal{O}(0.5)$ radian phase modulation in the late stage of the binary neutron star inspiral waveform.

</details>


### [37] [Quasi-Normal Mode Ringing of Binary Black Hole Mergers in Scalar-Gauss-Bonnet Gravity](https://arxiv.org/abs/2511.20301)
*Zexin Hu,Daniela D. Doneva,Stoytcho S. Yazadjiev,Lijing Shao*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Observations of gravitational waves (GWs) generated by binary black hole (BBH) mergers provide us with a powerful way to explore the strong and highly dynamical regime of gravity theories. The ringdown of BBH merger, consisting of a series of quasi-normal modes (QNMs), is of particular interest for both the black hole (BH) spectroscopy and the inspiral-merger-ringdown consistency check. Unlike the QNM frequencies that only depend on the properties of the remnant BH, the excitation amplitudes and phases of QNMs depend on the progenitor system, and calculating them is beyond the perturbative approach. In this paper, by performing self-consistent fully non-linear simulations of BBH merger in shift-symmetric scalar-Gauss-Bonnet (sGB) gravity as well as in sGB gravity allowing for scalarization, and extracting the QNM excitation, we explore the possible deviations from GR at the ringdown stage. We numerically verify that the mode frequencies are consistent with the theory prediction, and provide the fitting results of mode amplitudes and phases. We find relatively small changes in the mode excitation, considering that the largest coupling we used in the simulations is close to the limit of loss of hyperbolicity. To demonstrate that our results are robust against the eccentricity caused by the imperfect initial data, we also perform eccentricity reduction and estimate the effect caused by the initial eccentricity. These studies are useful for understanding the ringdown in sGB gravity.

</details>


### [38] [Multiscalar-metric gravity: merging gravity, dark energy and dark matter](https://arxiv.org/abs/2511.20393)
*Yu. F. Pirogov,O. V. Zenin*

Main category: gr-qc

TL;DR: The paper presents Spontaneously Broken Relativity (SBR), a modification of General Relativity (GR) that unifies gravity, dark energy, and dark matter using a multiscalar-metric spacetime framework. This theory introduces a basic metric and multiscalar fields that act as geometric coordinates and gravitational Higgs fields, leading to massive gravitons and offering prospects for unifying gravity with matter.


<details>
  <summary>Details</summary>
Motivation: The motivation is to unify gravity with dark energy and dark matter within a single theoretical framework and explore the spontaneous breaking of relativistic symmetry (SSB) to address shortcomings in GR.

Method: The authors develop an effective field theory (EFT) called metagravity, which extends GR through a multiscalar-metric spacetime. This involves incorporating dynamical multiscalar fields that serve both as geometric coordinates and as Higgs-like fields causing SSB.

Result: Key results include the prediction of massive tensor and scalar gravitons, and the demonstration of SBR's potential for unifying gravity with other forces through symmetry breaking mechanisms.

Conclusion: The paper concludes that SBR provides a promising avenue for deeper unification of gravity with matter, though challenges remain in addressing the theory's consequences and experimental verification.

Abstract: The status of a modification of General Relativity (GR) -- Spontaneously Broken Relativity (SBR) -- for merging gravity, dark energy (DE) and dark matter (DM) is presented. The modification is principally grounded on a multiscalar-metric concept of spacetime endowed with two dynamical structures: a basic metric and a set of the reversible multiscalar fields. The latter ones serve geometrically as exceptional dynamical coordinates among arbitrary kinematical/observer's ones and physically as a kind of gravitational Higgs fields producing possible spontaneous breaking of the symmetry (SSB) of relativity. The effective field theory (EFT) of the extended gravity based on the multiscalar-metric spacetime -- the metagravity -- is discussed and some of its particular realizations beyond GR as SBR are explicated. Physically, SBR results in appearance of massive tensor and scalar gravitons. Some of the emerging consequences, problems and prospects for SBR for future deeper unification of gravity with matter in the context of the relativity and internal symmetries breaking are shortly discussed.

</details>


### [39] [Resolving white dwarf binaries within globular clusters with LISA](https://arxiv.org/abs/2511.20435)
*Wouter G. J. van Zeist,Gijs Nelemans,Shu-Xu Yi,Simon F. Portegies Zwart*

Main category: gr-qc

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Context: Globular clusters (GCs) around the Milky Way (MW) are expected to host white dwarf (WD) binaries emitting gravitational waves that could be detectable by LISA.
  Aims: Our aim is to investigate whether LISA can resolve WD binaries in GCs well enough in terms of sky location and distance that they can be distinguished from binaries in the MW disc.
  Methods: We used a sample of 20 of the most massive GCs around the MW and simulated LISA's sky location and distance measurement errors for WD binaries in these GCs using the software package GWToolbox. We did this in the context of a model of the LISA-detectable binaries in the MW from the population synthesis code SeBa.
  Results: We find that for five of the GCs in our sample, binaries in the GC could be easily distinguished from MW disc binaries using the sky location alone; for another five, binaries in the GCs could be distinguished using a combination of LISA's sky location and distance measurements; and for the final ten, binaries in the GCs could not be distinguished from overlapping MW disc binaries. The results depend strongly on the sky locations of the GCs, with GCs far away from the Galactic plane being easy to resolve, while GCs close to the Galactic centre overlap with many MW disc binaries. The most promising GC for finding a WD binary that could be resolved to that GC, based on sky location and GC mass, is 47 Tucanae.

</details>


### [40] [The Inflationary Dynamics with the Scalar-Tensor Model](https://arxiv.org/abs/2511.20464)
*Feyzollah Younesizadeh,Davoud Kamani*

Main category: gr-qc

TL;DR: The paper examines cosmic inflation in scalar-tensor models with non-minimal kinetic couplings, using slow-roll approximations to predict key cosmological observables and compare them with Planck data.


<details>
  <summary>Details</summary>
Motivation: To explore how scalar-tensor models with specific kinetic couplings can explain cosmic inflation and test their consistency with observational data, particularly focusing on the spectral index, tensor-to-scalar ratio, and their parameter dependencies.

Method: Apply inflationary dynamical potentials within the scalar-tensor framework, compute observables using slow-roll approximation, derive parameter constraints, and compare results with Planck data. Sensitivity analyses of observables to free parameters are also performed.

Result: Theoretical predictions for ns, r, and α_s are obtained, parameter limitations are identified, and model outputs are found to align with Planck observations. The sensitivity of observables to model parameters is quantified.

Conclusion: The investigated scalar-tensor models with non-minimal kinetic couplings are viable for describing cosmic inflation, with parameter ranges constrained by observational data, and show sensitive dependencies of key observables on model parameters.

Abstract: We investigate the cosmic inflation within a class of the scalar-tensor model with the scalar-dependent non-minimal kinetic couplings. The inflationary dynamical potential will be applied. Using the slow-roll approximation, we compute theoretical predictions for the key observables, like the spectral indexes $n_s$, scalar-to-tensor ratio $r$ and the running of the scalar spectral index $α_s$ in terms of the free parameters of the model. Besides, we find the limitations of these parameters. In addition, these quantities will be compared with the latest observational data from the Planck data. Furthermore, we analyze the sensitivity of $r$, $n_s$ and $α_s$ in terms of the model's free parameters.

</details>


### [41] [Anisotropic Bianchi-I cosmological model in non-conservative unimodular gravity](https://arxiv.org/abs/2511.20486)
*Marcelo H. Alvarenga,Júlio C. Fabris*

Main category: gr-qc

TL;DR: The paper proposes an anisotropic Bianchi-I cosmological model in non-conservative Unimodular Gravity (NUG), addressing the underdetermined field equations by imposing conditions on the (ρ+p) combination. It finds that for l<0 (where (ρ+p)=l), the model suggests a super-accelerated, ghost-like universe. For (ρ+p) proportional to a^{-3} or a^{-4}, results align with General Relativity (GR), requiring a small anisotropy parameter (~10^-2) to match the universe's age. Anisotropies diminish as the universe expands.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from resolving the underdetermined field equations in NUG when using Bianchi-I metrics. The authors aim to develop a consistent cosmological model, explore the dynamics of (ρ+p), and contrast outcomes with GR predictions while ensuring compatibility with observational data like the universe's age.

Method: The method involves implementing extra conditions on (ρ+p) to solve the underdetermination issue in NUG's field equations. The vacuum case is analyzed to draw parallels with Kasner solutions. A non-homogeneous equation of state (ρ+p)=l is proposed, and cases where (ρ+p) scales as a^{-3} or a^{-4} are examined. Numerical or theoretical constraints on the anisotropy parameter Ω_A (~10^-2) are derived to match observed cosmic age (~12-14 Gyr).

Result: Key results include the identification that l<0 leads to a super-accelerated universe resembling a ghost-like state, whereas scaling (ρ+p) with a^{-3} or a^{-4} aligns with GR anisotropic models. The necessity of a small Ω_A for cosmic age consistency is highlighted. The model shows isotropization as the universe expands, similar to GR's behavior.

Conclusion: The study concludes that NUG's Bianchi-I model requires specific (ρ+p) conditions to produce viable cosmologies. The l<0 case raises intriguing but unresolved questions needing thermodynamic analysis. The agreement with GR under certain conditions and observational data (e.g., universe age) validates the model's framework but calls for further exploration of its implications.

Abstract: In this article, we propose an anisotropic Bianchi-I type cosmological model in non-conservative Unimodular Gravity ($\mathrm{NUG}$). We show that simply using the Bianchi-I type metric does not resolve a striking characteristic of the field equations in $\mathrm{NUG}$: their underdetermination. This fact led us to implement extra conditions on the combination $\left(ρ+p\right)$ and, consequently, obtain a consistent background cosmological analysis. In the vacuum case, we obtain an analogy between the Kasner solutions and the equations in $\mathrm{NUG}$. We also propose a new analysis of a non-homogeneous equation of state, the combination $\left(ρ+p\right)=l$. We identify that the cosmological dynamics are strictly dependent on the value of the constant $l$. The physically interesting case is at the value $l<0$, which seems to indicate a super-accelerated, ghost-like universe. This case still requires a more detailed analysis, for example, from a thermodynamic point of view, keeping in mind that $\left(ρ+p\right)$ may be interpreted as enthalpy of the system. For the cases $\left(ρ+p\right)\propto a^{-3}$ and $\left(ρ+p\right) \propto a^{-4}$, we obtain a description consistent with the anisotropic cosmological model described by $\mathrm{GR}$. In all cases analyzed, a small value for the anisotropic parameter $Ω_{A}$ (on the order of $10^{-2}$) is required in order to have agreement, for example, with the age of the universe to be approximately $12-14\, \mathrm{Gyr}$, agreeing with the age of globular clusters. As the universe expands an isotropization is verified, with the anistropies going to zero asymptotically, similarly with what happens in an anistropic cosmological model based on $\mathrm{GR}$.

</details>


### [42] [Natural inflation in Palatini $F(R)$](https://arxiv.org/abs/2511.20557)
*N. Bostan,R. H. Dejrah,C. Dioguardi,A. Racioppi*

Main category: gr-qc

TL;DR: The study explores how $F(R)$ Palatini gravity can revive natural inflation models by adjusting the parameter n within a specific range, enhancing compatibility with observational data.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the shortcomings of natural inflation models when faced with observational data by incorporating them into the $F(R)$ Palatini gravity framework, which could provide a more viable inflationary scenario.

Method: The authors analyze natural inflation within the $F(R)$ Palatini gravity model, focusing on the function $F(R) = R + αR^n$. They vary the parameter n and assess how different values affect the model's consistency with observational data, particularly examining the range 7/4 ≤ n ≤ 2.

Result: They find that for 7/4 ≤ n ≤ 2, the model aligns well with observational data, restoring natural inflation's viability. However, for n > 2, the improvements are minimal, with only partial agreement near n approaching 2.

Conclusion: The study concludes that embedding natural inflation within $F(R)$ Palatini gravity, especially with n values between 7/4 and 2, offers a promising solution to reconcile theoretical models with observational constraints, though higher n values beyond 2 are less effective.

Abstract: $F(R)$ Palatini gravity provides a robust framework for constructing viable inflationary potentials. In this study, we examine natural inflation and show that its consistency with observational data can be restored when the model is embedded within $F(R)$ Palatini gravity, specifically for $F(R) = R + αR^n$ with $7/4 \lesssim n \leq 2$. For completeness, we also demonstrate that models with $n > 2$ do not yield comparable improvements, achieving partial agreement with the data only in the limit $n \rightarrow 2$.

</details>


### [43] [Gravitational collapse in the vicinity of the extremal black hole critical point](https://arxiv.org/abs/2511.20567)
*William E. East*

Main category: gr-qc

TL;DR: The paper investigates the threshold dynamics of gravitational collapse in charged matter using Einstein-Maxwell-Vlasov equations, revealing that solutions at the critical point transition from horizonless shells to extremal black holes.


<details>
  <summary>Details</summary>
Motivation: To understand how charged matter collapses into black holes or disperses, focusing on the critical threshold and the nature of the solutions there. Motivated by the possibility of forming extremal black holes and implications for extremal Kerr spacetimes.

Method: Numerical construction of solutions to Einstein-Maxwell-Vlasov equations in spherical symmetry. Analyze parameter spaces to identify threshold behavior between black hole formation and dispersal, tracking charge-to-mass ratios and instability timescales.

Result:  Threshold solutions transition from stationary, horizonless shells (with charge-to-mass ratio approaching 1) to extremal black holes beyond a critical point. Dynamical time scaling was measured, showing divergence at criticality. Possible connection to extremal Kerr formation via similar stationary solutions.

Conclusion: Results suggest extremal black holes can emerge at collapse thresholds beyond critical parameters. This framework supports the theoretical possibility of forming extremal spinning black holes if analogous rotating matter solutions exist.

Abstract: We study the threshold of gravitational collapse in spherically symmetric spacetimes governed by the Einstein-Maxwell-Vlasov equations. We numerically construct solutions describing a collapsing distribution of charged matter that either forms a charged black hole or eventually disperses. We first consider a region of parameter space where the solutions at the threshold of black hole formation are stationary, horizonless shells. These solutions terminate at a critical point, with their charge-to-mass ratio approaching unity from below, and the instability timescale diverging. Beyond the critical point, we find a new region of parameter space where the threshold solution is an extremal black hole. We measure the scaling of the dynamical time period of the near threshold solutions and discuss how they are connected in the two regimes. If a similar picture to the one found here holds for known families of stationary solutions of rotating matter that approach the exterior of an extremal Kerr spacetime, they could provide a route to forming an extremal spinning black hole.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [44] [$\mathbb Z_2$-Stable Dark Matter via Broken $\text{SU}(5)$ Gauge Bosons](https://arxiv.org/abs/2511.19462)
*E. J. Thompson*

Main category: hep-ph

TL;DR: The paper presents a dark matter model where the dark matter sector interacts only with broken SU(5) gauge fields (leptoquark vectors X,Y) via a Z₂-symmetric framework. Key results include gauge-covariant projectors, effective operators from integrating out X,Y, loop-induced gluon coupling, color neutrality proof, and cosmological production mechanisms.


<details>
  <summary>Details</summary>
Motivation: To explore a dark matter model that interacts through broken SU(5) symmetries rather than direct Standard Model forces, ensuring stability via Z₂ symmetry and compatibility with cold dark matter observations.

Method: Constructed a Z₂-symmetric dark matter sector coupling only to SU(5)'s broken leptoquark vectors. Used gauge-covariant projectors to isolate interactions, derived effective operators by integrating out mediators, calculated loop-induced gluon couplings, and analyzed cosmological production via freeze-in.

Result: Validated the framework's consistency with cold dark matter constraints, demonstrated color neutrality of dark matter, derived specific effective operators, and identified viable production mechanisms despite highly suppressed interactions.

Conclusion: This model offers a novel approach to dark matter by utilizing broken SU(5) interactions, providing a stable candidate with phenomenologically viable couplings and cosmological production pathways without conflicting with existing astrophysical observations.

Abstract: I construct and analyze a dark matter sector that is neutral under the unbroken Standard Model gauge group and couples only to the broken $\text{SU}(5)$ gauge directions, the leptoquark vectors $X,Y$. An exact $\mathbb Z_2$ renders the dark matter stable. I give a gauge-covariant definition of projectors onto the unbroken Standard Model and broken ($X,Y$) subspaces, demonstrate that the covariant derivative of dark matter selects only $X,Y$, and integrate out $X,Y$ at tree level to obtain the leading effective operators. I also derive the loop-induced $χ^2\,G^a_{μν}G^{aμν}$ coupling to gluons, prove color neutrality, and show consistency with cold dark matter phenomenology. Cosmological production proceeds via UV freeze-in or even more suppressed channels in.

</details>


### [45] [New spectrum of charm-strange meson with constituent quark model $c\bar{s}$ contributions](https://arxiv.org/abs/2511.19534)
*Liu-Lin Wang,Xing-Meng Zhao,Xiao-Hai Liu,Mao-Jun Yan*

Main category: hep-ph

TL;DR: The paper examines S-wave interactions between Nambu-Goldstone bosons and charmed mesons using the chiral unitary approach, identifying multiple poles indicative of bound states and resonances across different spin-parity sectors, and predicting new D_{sJ} states.


<details>
  <summary>Details</summary>
Motivation: To explore the spectrum of D_{sJ} states and understand existing resonances like D_{s0}^*(2317) and D_{s1}(2460) by analyzing NGB-charmed meson interactions.

Method: Chiral unitary approach incorporating Weinberg-Tomozawa term and s/u-channel c\bar{s} exchanges from CQM, with complex energy plane analysis for pole identification.

Result: Identified poles corresponding to bound states/resonances across J^P = 0^+, 1^+, 1^-, 2^- sectors, explaining known resonances and predicting new D_{sJ} states.

Conclusion: The study provides new insights into established charmed-strange mesons and suggests experimental avenues to discover predicted states.

Abstract: We systematically investigate the $S$-wave interactions between Nambu-Goldstone bosons (NGBs) and charmed mesons in the $(S,I)=(1,0)$ sector using the chiral unitary approach. The scattering amplitudes incorporate both the Weinberg-Tomozawa term and additional contributions from $s$- and $u$-channel exchanges of $c\bar{s}$ states predicted by the constituent quark model (CQM). Through analytic continuation of the unitarized amplitudes to the complex energy plane, we identify multiple poles corresponding to bound states and resonances. Our analysis reveals a rich spectrum of $D_{sJ}$ states across $J^P = 0^+, 1^+, 1^-$, and $2^-$ sectors, providing new insights into the nature of established resonances like $D_{s0}^*(2317)$ and $D_{s1}(2460)$, while predicting several new states that could be observed in future experiments.

</details>


### [46] [Stringent Constraints on Gravitational Wave Signatures of Dark Electromagnetism in Neutron Star Binaries](https://arxiv.org/abs/2511.19586)
*Ian Harris,Yonatan Kahn*

Main category: hep-ph

TL;DR: The paper investigates whether gravitational wave observations from neutron star mergers can detect hidden-sector vector forces (dark electromagnetism) but concludes such signatures are likely undetectable without extreme fine-tuning.


<details>
  <summary>Details</summary>
Motivation: To explore the potential of gravitational wave interferometers to detect new physics via dark electromagnetic effects in neutron star binaries, given their increasing precision.

Method: Analyzed mechanisms for neutron stars to accumulate sufficient hidden-sector particles with appropriate couplings, focusing on the repulsive nature of vector forces and their impact on inspiral waveforms.

Result: Found that the repulsive vector forces impose stringent constraints on particle physics models/astrophysical conditions, making detectable signatures unattainable for current/future observatories without fine-tuning parameters.

Conclusion: Concludes that without extreme parameter tuning, gravitational wave observatories cannot detect dark electromagnetic signatures from neutron star mergers due to fundamental constraints.

Abstract: Gravitational wave interferometers have studied compact object mergers and solidified our understanding of strong gravity. Their increasing precision raises the possibility of detecting new physics, especially in a neutron star binary system that may contain hidden-sector particles. In particular, a new vector force between binary constituents, giving rise to dark electromagnetic phenomena, could measurably alter the inspiral waveforms and thus be constrained by gravitational wave observations. In this work, we critically examine the mechanisms for neutron stars to acquire enough hidden-sector particles with requisite couplings to furnish a detectable signature from dark electromagnetism. We demonstrate that the repulsive nature of vector forces imposes stringent constraints on any putative particle physics model or astrophysical environment which could give rise to such gravitational signatures. We argue that absent an extreme fine-tuning of parameters, such signatures are well out of reach of any current or near-future gravitational wave observatory.

</details>


### [47] [Hawking heating of neutron stars by dark matter](https://arxiv.org/abs/2511.19599)
*Akash Kumar Saha,Abhishek Dubey,Nirmal Raj*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Interactions with particle dark matter could brighten old, isolated neutron stars to thermal luminosities detectable at current and next-generation telescopes. We present a novel mechanism for such signals. Non-annihilating (e.g., asymmetric) dark matter capturing in a neutron star could form a small black hole in its core, which could then rapidly evaporate away. If black holes form and evaporate within the cooling timescale of the neutron star, periodic episodes of black hole evaporation could impart a steady-state stellar luminosity, providing a source of heat additional to the kinetic energy of dark matter during capture. Consequently, we obtain sensitivities to dark matter-nucleon cross sections that are stronger than that from dark kinetic heating by a factor of a few for > $10^4$ GeV (> $10^{10}$ GeV) mass of spin-0 (spin-1/2) dark matter.

</details>


### [48] [Enhanced Charged Higgs Signal at the LHC](https://arxiv.org/abs/2511.19604)
*Chenyu Fang,Wei-Shu Hou,Chung Kao,Mohamed Krab*

Main category: hep-ph

TL;DR: The paper explores the potential discovery of a charged Higgs boson (H±) at the LHC through the process cg→bH±→bc b within the General Two Higgs Doublet Model (G2HDM). It highlights that G2HDM enhances the H±cb coupling by factors involving Vtb, improving discovery prospects with b and c-jet tagging at 13/14 TeV LHC runs.


<details>
  <summary>Details</summary>
Motivation: To investigate enhanced charged Higgs discovery channels in G2HDM, where traditional two-Higgs models suppress the H±cb coupling via Vcb. G2HDM's additional Yukawa couplings allow stronger production/decay mechanisms, requiring analysis of collider signatures and background suppression.

Method: Simulated analysis of the cg→bH±→bc b process at 13/14 TeV using G2HDM parameters. Evaluated backgrounds, applied b/c-jet tagging, and mass reconstruction through jet pairing. Considered realistic detector efficiencies and acceptance cuts.

Result: Successful mass extraction of H± via jet pairing, showing promising discovery potential at current and high-luminosity LHC stages. Background suppression via tagging proves effective under modeled conditions.

Conclusion: G2HDM offers viable channels for charged Higgs detection at LHC through gluon-bottom quark interactions. The proposed method provides a pathway for future collider experiments to validate or constrain this model.

Abstract: We investigate the discovery prospects of a charged Higgs boson ($H^\pm$)
  at the Large Hadron Collider (LHC) via the process
  $cg\to bH^\pm \to bc\bar{b}$ within the framework of a general two Higgs
  doublet model (G2HDM).
  In most two Higgs doublet models, the $H^+ cb$ coupling ($g_{H^+cb}$)
  is usually suppressed by the CKM matrix element $V_{cb}$.
  In G2HDM, there are additional Yukawa couplings,
  the process $cg\to bH^\pm \to bc\bar{b}$ is enhanced
  by the coupling $g_{H^+cb} \simeq \rtc V_{tb}$
  in both the production and decay of the charged Higgs boson.
  We study possible physics backgrounds and evaluate the discovery
  potential with realistic acceptance cuts and tagging efficiencies at
  collider energies of $\sqrt{s}=$13 and 14 TeV.
  We apply $b$-tagging and $c$-tagging and show that $m_{H^+}$ can be
  extracted by pairing the tagged $b$ and $c$-jets.
  Our analysis leads to promising results for the current LHC and
  expected high-luminosity LHC.

</details>


### [49] [Naive $T$-odd Drell-Yan angular coefficients as a probe of the dimension-8 SMEFT](https://arxiv.org/abs/2511.19617)
*Frank Petriello,Kaan Şimşek*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose the ``naive" $T$-odd Collins-Soper moments in the Drell-Yan process as probes of previously unexplored directions in the Standard Model Effective Field Theory (SMEFT) parameter space. We show that the moments $A_6$ and $A_7$ in the high invariant mass and transverse momentum region are sensitive to dimension-8 $CP$-odd semi-leptonic four-fermion operators with an additional gluon field strength tensor. Using the projected integrated luminosity of a future high-luminosity LHC, we show that effective ultraviolet scales in the few-TeV range can be probed with this process.

</details>


### [50] [ALP-mediated Dark Matter-Nucleon Scattering](https://arxiv.org/abs/2511.19619)
*Wim Beenakker,Daniël Mikkers,Anh Vu Phan,Susanne Westhoff*

Main category: hep-ph

TL;DR: The paper demonstrates that direct detection experiments like XENONnT and PandaX-4T can detect dark matter via ALP-mediated scattering through two enhancement mechanisms: light ALPs lifting momentum suppression and loop-induced spin-independent scattering with top-quark enhancement, extending sensitivity beyond expectations.


<details>
  <summary>Details</summary>
Motivation: To challenge the conventional belief that ALP-mediated dark matter scattering is undetectable by showing practical experimental sensitivity through new enhancement mechanisms.

Method: Analyzes dark matter-nucleon scattering via ALPs, considering massless mediator effects and loop-induced coherent scattering with top-quark mass enhancement, calculating scattering rates and experimental reach.

Result: Shows current experiments like XENONnT/PandaX-4T are sensitive to ALP-mediated scattering, and next-gen experiments will probe ALP parameter space beyond collider limits.

Conclusion: ALP-mediated dark matter detection is feasible with existing/upcoming experiments, offering competitive tests of dark matter models compared to colliders.

Abstract: We perform a comprehensive analysis of dark matter-nucleon scattering via the exchange of axion-like particles (ALPs). At first sight, this might appear of little practical use, as non-relativistic scattering through pseudo-scalar interactions is momentum-suppressed and spin-dependent, resulting in scattering rates below any experimental sensitivity. We show that the scattering rate can be drastically enhanced in two ways. First, light ALPs with masses below the typical momentum transfer at direct detection experiments lift the momentum suppression by acting as essentially massless mediators. Second, ALP exchange through loops induces coherent spin-independent scattering. If the ALP has flavor-changing couplings to up-type quarks, loop-induced scattering receives an extra strong enhancement by the top-quark mass. We deduce that, contrary to common lore, XENONnT and PandaX-4T are already sensitive to ALP-mediated dark matter-nucleon scattering. The next generation of direct detection experiments will probe far into the parameter space of the ALP effective theory, potentially exceeding the sensitivity of collider searches.

</details>


### [51] [Probing High Reheating Temperatures by Direct Detection Experiments](https://arxiv.org/abs/2511.19621)
*Barmak Shams Es Haghi*

Main category: hep-ph

TL;DR: The paper argues that in dark matter (DM) direct detection experiments using an ultralight dark photon mediator, the visible sector reheating temperature significantly impacts the DM relic abundance. Specifically, high reheating temperatures enhance UV freeze-in production via graviton exchange, which must be combined with IR freeze-in via dark photon interactions. This gravitational contribution allows for smaller DM-Standard Model couplings than previously thought, extending the parameter space consistent with observed relic abundance. Current direct detection exclusions now probe high reheating temperatures and gravitational freeze-in effects.


<details>
  <summary>Details</summary>
Motivation: To address the freeze-in benchmark model's limitations in direct detection experiments, where the DM-Standard Model coupling is pushed to extreme values. The study aims to show that considering gravitational production at high reheating temperatures relaxes these coupling constraints and explains how direct detection limits now probe reheating physics.

Method: The authors analyze the combined effect of UV (graviton-mediated) and IR (dark photon-mediated) freeze-in processes in DM production. They derive relic density expressions accounting for both contributions, consider DM thermalization conditions, and evaluate how varying reheating temperatures modify the required couplings to match the observed DM abundance.

Result: High visible sector reheating temperatures enhance the UV freeze-in yield, allowing for lower DM-SM couplings than IR freeze-in alone. The combined production mechanism evades direct detection exclusions, with current experiments now sensitive to reheating temperatures ~10^9 GeV, probing gravitational DM production beyond standard freeze-in models.

Conclusion: Direct detection experiments not only constrain DM properties but also probe early universe conditions like reheating. The inclusion of gravitational DM production via UV freeze-in opens new parameter space, requiring future experiments to consider high-scale cosmological histories alongside particle interactions.

Abstract: We argue that the benchmark freeze in dark matter (DM) scenario for direct detection experiments, in which a DM candidate interacts with the Standard Model (SM) through an ultralight dark photon, becomes sensitive to the visible sector reheating temperature if it is sufficiently high. At such temperatures, the irreducible ultraviolet (UV) freeze in production of DM through graviton exchange becomes important and must be combined with the infrared (IR) freeze in yield mediated by the dark photon. As long as gravitationally produced DM does not equilibrate through annihilation into dark photons and the subsequent formation of a dark thermal bath, it retains information about the reheating phase. Including this gravitational contribution relaxes the required DM and SM portal coupling and allows smaller values than those that would match the observed relic abundance through IR freeze in alone. Since current direct detection experiments have excluded the benchmark freeze in model over a wide range of DM masses, they are now effectively probing high reheating temperatures and the gravitational freeze in of DM.

</details>


### [52] [Two Puzzles, One Solution: Neutrino Mass and Secluded Dark Matter](https://arxiv.org/abs/2511.19622)
*Mattia Di Mauro*

Main category: hep-ph

TL;DR: The paper presents a minimal secluded dark matter framework with a Dirac DM particle, heavy neutrinos, and a singlet scalar mixing with the Higgs. The model suppresses DM signals through a tiny mixing angle originating from neutrino mass terms, linking DM's invisibility to light neutrino masses. It naturally explains the lack of detectable signals and fits observed relic density with Yukawa couplings similar to WIMPs.


<details>
  <summary>Details</summary>
Motivation: To address long-standing puzzles of the absence of dark matter detection signals and the smallness of neutrino masses within a thermal framework. The model seeks to provide a natural explanation for the suppression of DM interactions while connecting it to neutrino physics.

Method: A model based on an extra U(1)_X symmetry introduces a Dirac DM χ, three heavy neutrinos N_I, and a singlet scalar R mixing with the Standard Model Higgs. The mixing angle α is suppressed at tree level but arises at one loop via Yukawa couplings responsible for active neutrino masses. This leads to a tiny tan(2α) proportional to the sum of neutrino masses and heavy neutrino masses squared, suppressing DM interaction signals.

Result: For multi-TeV heavy neutrinos, the mixing angle is extremely small (∼5e-11), rendering DM undetectable in current experiments. PeV-scale neutrinos may be detectable in future direct detection. The relic density is set by p-wave annihilation to Higgs-like particles in the dark sector with Yukawa couplings ~0.1-1. The mediator decays before nucleosynthesis without disrupting BBN.

Conclusion: The framework successfully connects DM's secluded nature with small neutrino masses, providing a testable thermal model. It offers a natural mechanism for suppressed DM signals and aligns with observed cosmological parameters, highlighting future experimental directions for validation.

Abstract: We present a minimal secluded dark-matter (DM) framework based on an extra $U(1)_X$ gauge symmetry. The model contains a Dirac DM particle $χ$, three heavy neutrinos $N_I$ with masses $M_{N,I}$, and a singlet scalar $R$ that mixes with the Standard Model Higgs doublet $Φ$ by an angle $α$. A symmetry forbids the $Φ$-$R$ portal at tree level; the leading portal then arises at one loop from the same Yukawa structures that generate active neutrino masses $m_{ν,I}$, implying $\tan(2α) \propto \sum_I m_{ν,I} M^2_{N,I}/(v_h m_H^2)$, where $v_h$ and $m_H$ are the SM Higgs VEV and mass. For heavy-neutrino masses in the multi-TeV range, this yields a naturally tiny mixing, $\tan(2α)\sim 5\times 10^{-11}\left(M_N/10~\mathrm{TeV}\right)^2$, which strongly suppresses DM signals in direct, indirect, and collider searches. For PeV-scale heavy neutrinos the DM-nucleon cross section can instead enter the reach of direct-detection experiments. The visible and dark sectors thermalize at temperatures of order a few times the mass of the lightest heavy neutrino, then subsequently decouple, and typically evolve with a slightly hotter dark bath. In the secluded regime, with $\tan(2α)\ll 1$ and $m_χ>m_{H_p}$, the relic density is set by $p$-wave annihilation $χ\barχ\to H_p H_p$ (with $H_p$ the Higgs-like particle of the dark sector), and the dark-sector Yukawa couplings required to reproduce the observed abundance are $\sim(0.1\text{-}1)$, as in the standard WIMP case. For heavy-neutrino masses $\gtrsim 10~\mathrm{TeV}$, the mediator decays before nucleosynthesis without spoiling BBN observables, while the tiny portal suppresses present-day signals below current and near-future sensitivities. This links two long-standing puzzles, the absence of DM signals and the smallness of neutrino masses, within a predictive thermal framework.

</details>


### [53] [An NLO-Matched Initial and Final State Parton Shower on a GPU](https://arxiv.org/abs/2511.19633)
*Michael H. Seymour,Siddharth Sule*

Main category: hep-ph

TL;DR: GAPS v2 enables efficient GPU-based simulations of NLO Z production at the LHC, matching the performance of a 96-core CPU cluster while offering energy efficiency and scalability advantages.


<details>
  <summary>Details</summary>
Motivation: To leverage GPUs for accelerating particle physics simulations and reducing energy consumption compared to traditional CPU clusters.

Method: Porting and optimizing the GAPS event generator to CUDA C++ for GPU execution, maintaining a CPU version for cross-validation. Implemented initial/final state emissions and hard-process matching for NLO Z production simulations.

Result: Demonstrated that a single NVIDIA V100 GPU matches the performance of a 96-core CPU cluster (two Intel Xeon Gold 5220R CPUs), achieving equivalent speed and lower energy consumption.

Conclusion: GPU-based simulation with GAPS v2 provides a viable alternative to CPU clusters, offering comparable performance with improved energy efficiency and scalability for high-energy physics workloads.

Abstract: Recent developments have demonstrated the potential for high simulation speeds and reduced energy consumption by porting Monte Carlo Event Generators to GPUs. We release version 2 of the CUDA C++ parton shower event generator GAPS, which can simulate initial and final state emissions on a GPU and is capable of hard-process matching. As before, we accompany the generator with a near-identical C++ generator to run simulations on single-core and multi-core CPUs. Using these programs, we simulate NLO Z production at the LHC and demonstrate that the speed and energy consumption of an NVIDIA V100 GPU are on par with a 96-core cluster composed of two Intel Xeon Gold 5220R Processors, providing a potential alternative to cluster computing.

</details>


### [54] [Hard exclusive photoproduction of photon-meson pairs: pseudoscalar channels $π$, $η$ and $η'$](https://arxiv.org/abs/2511.19720)
*Nikola Crnković,Goran Duplančić,Saad Nabeebaccus,Kornelija Passek-K.,Bernard Pire,Lech Szymanowski,Samuel Wallon*

Main category: hep-ph

TL;DR: The paper investigates photon-meson pair photoproduction using QCD, focusing on pseudoscalar mesons, revealing significant effects from pion-pole terms and two-gluon contributions, highlighting GPD dependencies and the need for higher-order corrections.


<details>
  <summary>Details</summary>
Motivation: To explore the mechanisms of photon-meson pair production at leading-twist/order in QCD, understand the role of generalized parton distributions (GPDs), and assess theoretical uncertainties for future studies.

Method: Derivation of analytical expressions for photoproduction amplitudes involving quark GPDs, incorporating two-gluon components of η/η' distribution amplitudes. Numerical analysis performed in moderate-ξ region emphasizing valence-quark GPDs.

Result: Strong pion-pole effects in charged meson production, notable neutral meson impacts, and significant two-gluon contributions to γη' production were observed. Process shows sensitivity to GPD shapes, but scale/meson amplitude dependencies introduced uncertainties necessitating NLO corrections.

Conclusion: The study establishes an analytical framework and numerical baseline for photoproduction processes, underscores GPD importance, and identifies key areas requiring refinement through higher-order calculations.

Abstract: We investigate the hard exclusive photoproduction of photon-meson pairs at leading-twist and leading-order in perturbative QCD, and focus on pseudoscalar mesons $\text{M} \in \{π^\pm, π^0, η, η'\}$. Compact analytical expressions are obtained for the amplitudes involving quark generalized parton distributions, with the two-gluon components of the $η$ and $η'$ distribution amplitudes included. The numerical analysis is performed in the moderate-$ξ$ region, where valence-quark GPDs are expected to be important. In this region, we find a strong impact of the pion-pole term in $γπ^\pm$ production, and a non-negligible effect for neutral mesons. We also observe a marked dependence of $γη'$ photoproduction on two-gluon contributions. This process offers enhanced sensitivity to the shape of the GPDs already at leading-order, while the tested dependence on the meson distribution amplitude and the renormalization scale introduces further theoretical uncertainties, the latter emphasizing the need for next-to-leading-order corrections. Our results provide a concise analytical framework and a numerical baseline for future studies.

</details>


### [55] [Strangelet Searches from Neutron Stars, Binary Mergers, and Gamma-Ray Bursts with Current and Future Observatories](https://arxiv.org/abs/2511.19799)
*C. R. Das*

Main category: hep-ph

TL;DR: This paper investigates the possibility of strange quark matter (SQM) being the true ground state of high-density QCD, focusing on strangelets' stability, production, and signatures in γ-ray observations. It uses data from multiple telescopes to set observational limits and emphasizes the need for improved sensitivity to detect monochromatic γ-ray lines indicative of SQM's existence.


<details>
  <summary>Details</summary>
Motivation: To explore whether strange quark matter could form stable strangelets, which might explain cosmic phenomena like HESS J1731-347's neutron star and events like GW170817/GRB 250702B, and to determine observational signatures (γ-ray lines) for SQM's cosmic role.

Method: Analyzes SQM stability, production cross-sections, and mass-to-charge ratios using QCD-based models. Combines multimessenger astrophysics data (H.E.S.S., Fermi-LAT, MAGIC-II, CTA) to set limits on γ-ray spectral features and fluxes. Relates findings to compact star equations of state and cosmological implications.

Result: Established constraints on strangelet parameters using existing observational data. Highlighted that detecting monochromatic γ-ray lines requires next-generation instruments with enhanced sensitivity. Demonstrated SQM's potential impact on understanding compact objects and cosmic-ray phenomena.

Conclusion: SQM remains a viable candidate for exotic astrophysical objects, with strangelets' self-annihilation signatures being key probes. Future missions with improved γ-ray sensitivity are critical to validate SQM's role in cosmology and dense QCD matter.

Abstract: Strange quark matter (SQM) is considered a possible true ground state of QCD at high densities. This idea motivates research on exotic compact objects and certain cosmic-ray phenomena. For instance, the remnant HESS J1731-347 contains a low-mass neutron star, about $0.77^{+0.20}_{-0.17}$ $M_\odot$ and $10.4^{+0.86}_{-0.78}$ km in radius, making it a strong candidate for a strange quark star. Other events, such as GW170817 and GRB 250702B, provide conditions that may favor the formation of strangelets. Strangelets are stable clusters of SQM, potentially created during the phase transition between the 2SC and CFL color-superconducting states. These clusters could generate monochromatic $γ$-ray lines in very-high-energy spectra through self-annihilation. This work analyzes the stability of strangelets, production cross-sections, and mass-to-charge ratios using QCD-based models. Data from H.E.S.S., Fermi-LAT, MAGIC-II, and CTA were used to set limits on spectral features and possible fluxes. Detecting narrow $γ$-ray lines will require improved instrument sensitivity. By integrating evidence from multimessenger astrophysics and dense QCD simulations, this study investigates the equations of state for compact stars and explores the potential cosmological influence of SQM.

</details>


### [56] [New constraints on axion with gamma-ray observations of the Crab Nebula](https://arxiv.org/abs/2511.19848)
*Kazunori Kohri,Haruki Takahashi*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we derive the upper bounds on the coupling of axion-like particles (ALPs) with photon as a function of the mass by considering axion-photon conversion in the Crab Nebula. Previous studies have not considered the influence of the magnetic field within the Crab Nebula. The magnetic field plays a crucial role through the Synchrotron Self-Compton (SSC) process, in which high-energy electrons produce synchrotron radiation that is subsequently up-scattered by the same electrons via inverse Compton scattering to generate gamma rays. Therefore, neglecting the magnetic field in modeling leads to theoretical inconsistencies. In this work, we investigate the significance of the magnetic field effect and demonstrate that even differences in magnetic field modeling can substantially alter the conversion probability. We thus, for the first time, point out that proper consideration of the magnetic field is essential in ALP searches using gamma rays from the Crab Nebula. The resulting constraints reach up to a coupling of $g_{aγγ} \lesssim 1 \times 10^{-11} {\rm GeV}^{-1}$ for ALP masses in the range $10^{-10} {\rm eV} \lesssim m_a \lesssim 10^{-6} {\rm eV}$.

</details>


### [57] [A phenomenological analysis of charmless $B\to PV$ decays in the modified perturbative QCD approach](https://arxiv.org/abs/2511.19951)
*Sheng Lü,Ru-Xuan Wang,Mao-Zhi Yang*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We analyze the charmless two-body decays of the $B$ meson into a pseudoscalar and a vector meson, referred to as $B\to PV$ decay, within the framework of the modified perturbative QCD (PQCD) approach. Based on the conventional PQCD calculations, soft form factors and contributions arising from color-octet quark-antiquark components in the final state are introduced in this study, which involves essentially nonperturbative dynamics. By employing the flavor SU(3) symmetry and its breaking effect, the parameters describing soft contributions are correlated and subsequently reduced into a more concise set of SU(3) parameters. Through a $χ^2$ analysis procedure applied to the experimental data, these parameters are determined, for which the corresponding theoretical results for the branching ratios and $CP$ asymmetries in $B\to PV$ decays are derived. Within this framework, it is demonstrated that the theoretical calculations align well with experimental measurements, thereby offering a solution to several long-standing puzzles. The numerical analysis shows that these soft contributions have significant influence on the theoretical results. Furthermore, more precise experimental data are needed for deeper investigations of the $CP$ asymmetries.

</details>


### [58] [HyperFORM -- a FORM package for parametric integration with hyperlogarithms](https://arxiv.org/abs/2511.19992)
*Adam Kardos,Sven-Olaf Moch,Oliver Schnetz*

Main category: hep-ph

TL;DR: The paper describes an implementation of algorithms for integrating hyperlogarithms multiplied by rational functions in the computer algebra system FORM, which complements existing Maple tools and improves handling of large expressions for applications like Feynman integrals.


<details>
  <summary>Details</summary>
Motivation: The motivation is to enhance computational efficiency for integrating complex symbolic expressions (hyperlogarithms with rational functions) and expand capabilities beyond existing tools like HyperInt in Maple.

Method: The authors implemented algorithms within FORM, focusing on hyperlogarithms with rational letters or arguments. This leverages FORM's strength in managing large expressions, complementing Erik Panzer's HyperInt package.

Result: The implementation successfully enables integration tasks involving hyperlogarithms multiplied by rationals, particularly supporting computations relevant to Feynman integrals which require efficient symbolic computation.

Conclusion: The paper demonstrates that integrating HyperInt-like capabilities into FORM improves scalability for large-scale symbolic calculations, advancing applications in computational physics and mathematics.

Abstract: We present an implementation of algorithms for the symbolic integration of hyperlogarithms multiplied by rational functions in the computer algebra system FORM. This implementation encompasses cases where hyperlogarithms have rational letters or a rational argument. It complements the previous implementation, HyperInt, in MAPLE by Erik Panzer, utilizing the advantages of FORM in the efficient handling of large symbolic expressions. Among a wide range of applications, this approach enables the computation of many Feynman integrals.

</details>


### [59] [Multiplicity dependence of quarkonia production at ultra high energies](https://arxiv.org/abs/2511.20079)
*E. Levin*

Main category: hep-ph

TL;DR: The paper presents a method for calculating inclusive quarkonia production at ultra-high energies using t-channel unitarity and dipole densities from Pomeron loop summation, showing that the ratio of multiplicity distributions with and without quarkonia production scales quadratically with multiplicity.


<details>
  <summary>Details</summary>
Motivation: To understand the multiplicity dependence of quarkonia production in high-energy QCD processes without assuming multiplicity dependence of the saturation scale.

Method: The approach employs t-channel unitarity and dipole densities derived from summing large Pomeron loops. It uses a three-gluon fusion mechanism for quarkonia production and analyzes the multiplicity dependence of accompanying hadrons.

Result: The ratio of multiplicity distributions (with J/Ψ production vs. gluons only) scales as n², consistent with theoretical expectations and prior literature.

Conclusion: The method successfully explains the quadratic scaling, validating the framework and supporting further application in high-energy QCD studies.

Abstract: In this paper we propose an approach in high energy QCD, which allows us to calculate the inclusive quarkonia production at ultra high energies. This approach is based on $t$-channel unitarity and on the expressions for dipole densities from the procedure of summing of large Pomeron loops which we have developed in our previous papers. In the framework of this approach we discuss the dependence of quarkonia production on the multiplicity of the accompanying hadrons. In this paper we used the three gluons fusion mechanism for quarkonia production, without assuming the multiplicity dependence of the saturation scale. We found the multiplicity distribution of produced gluon with ( $ \mathcal{P}^{J/Ψ}_n$) and without ($\mathcal{P}^{gluon}_n$) the quarkonia production. It turns out that $ \frac{\mathcal{P}^{J/Ψ}_n}{\mathcal{P}^{gluon}_n} \propto n^2 $ as has been expected and discussed in corresponding publications.

</details>


### [60] [Is the large uncertainty of $δ_{CP}$ fundamentally encoded in the neutrino quantum state?](https://arxiv.org/abs/2511.20148)
*Michela Ignoti,Claudia Frugiuele,Matteo Paris,Marco Genoni*

Main category: hep-ph

TL;DR: The paper uses quantum estimation theory to analyze the limitations in measuring the CP-violating phase δ_CP in neutrino experiments, finding that the main constraint comes from the information content of flavor measurements rather than experimental factors. It also shows that targeting the second oscillation maximum improves sensitivity to δ_CP.


<details>
  <summary>Details</summary>
Motivation: To determine whether the current limited accuracy in measuring δ_CP arises from intrinsic quantum state properties, measurement constraints, or experimental limitations.

Method: The authors compare quantum and classical Fisher information in neutrino oscillation experiments, considering the fixed probe and measurement setups typical of such experiments.

Result: The large uncertainty in δ_CP is mainly due to the limited information from flavor measurements, not experimental constraints. Focusing on the second oscillation maximum (as in ESSνSB) provides better CP-phase sensitivity than experiments using the first maximum.

Conclusion: Improving δ_CP measurement requires enhancing the information extracted from flavor measurements, with experimental designs targeting later oscillation phases offering a practical path forward.

Abstract: The precise measurement of the leptonic CP-violating phase $δ_{CP}$ remains one of the major open challenges in neutrino physics, as current experiments achieve only very limited accuracy. We address this issue through the lens of quantum estimation theory. A distinctive feature of neutrino oscillation experiments is that they cannot freely optimize the probe or measurement, since both are constrained by the production and detection of flavor eigenstates. We therefore examine whether the large uncertainty in $δ_{CP}$ originates from intrinsic reasons, either of the neutrino quantum state or of flavor measurements, or if it instead stems from experimental limitations. By comparing quantum and classical Fisher information, we demonstrate that the limited sensitivity to $δ_{CP}$ originates primarily from the information content of flavor measurements. Furthermore, we show that targeting the second oscillation maximum, as in the ESS$ν$SB proposal, substantially enhances $δ_{CP}$ information compared to experiments centered on the first maximum.

</details>


### [61] [First determination of fragmentation functions in an exotic-hadron candidate](https://arxiv.org/abs/2511.20217)
*S. Kumano*

Main category: hep-ph

TL;DR: This paper determines fragmentation functions of the $f_0(980)$ hadron using global analysis of Belle experiment data, revealing its $s\bar{s}$ configuration at high energies, contrasting with its tetraquark/$K\bar{K}$ nature at lower energies.


<details>
  <summary>Details</summary>
Motivation: Confirm the exotic nature of $f_0(980)$ beyond global observables by studying its quark/gluon configuration at high energies through fragmentation functions.

Method: Performed a global analysis of $e^+e^- \to f_0(980)+X$ data from Belle collaboration to extract fragmentation functions ($D_q^{f_0}, D_g^{f_0}$) and their second moments.

Result: Found $M_u = M_d ≪ M_s ≈ M_g$ and $D_s^{f_0}(z)$ peaked at higher $z$, indicating dominant $s\bar{s}$ content at high energies.

Conclusion: The $f_0(980)$ transitions from a tetraquark/$K\bar{K}$ state at low energies to a $q\bar{q}$ ($s\bar{s}$) configuration at high energies, challenging previous interpretations and highlighting energy-dependent hadron structure.

Abstract: In recent years, there are experimental reports on exotic-hadron candidates, which have different quark configurations from ordinary $q\bar q$ and $qqq$ constituents. However, it is not easy to confirm their exotic nature from global observables such as masses, spins, parities, and decay widths. At high energies, internal quark and gluon configurations could become more apparent because hadrons should be described by fundamental degrees of freedom of quarks and gluons in quantum chromodynamics. One of such possibilities is to use the fragmentation functions (FFs). In this work, accurate FFs of an exotic hadron candidate $f_0$(980) are determined for the first time by an global analysis of experimental data on $e^+ + e^- \to f_0 (980)+X$ with recent precise measurements of the Belle collaboration. From the global analysis, we found that their second moments have a relation $M_u = M_d \ll M_s \sim M_g $ for up-quark, down-quark, strange-quark, and gluon FFs. Furthermore, the function $D_s^{f_0}(z)$ is distributed in the larger-$z$ region in comparison with the functions $D_{u}^{f_0}(z)$, $D_{d}^{f_0}(z)$, and $D_g^{f_0}(z)$. These facts support that the $f_0 (980)$ has the $s\bar s$ configuration at high energies. This is a new finding that $f_0 (980)$ should be considered mainly as the $s\bar s$ state, which is different from our usual understanding as a tetraquark (or $K\bar K$) hadron from low-energy studies. Our results could indicate the transition of the internal configuration picture that $f_0 (980)$ looks like a $q\bar q$ state at high energies although it is described by tetra-quark or $K\bar K$ molecule state at low energies. It sheds light on a new direction in exotic hadron physics.

</details>


### [62] [Revisiting lepton flavor violation: $τ$ and meson decays](https://arxiv.org/abs/2511.20320)
*Kevin A. Urquía-Calderón,Oleg Ruchayskiy*

Main category: hep-ph

TL;DR: The paper re-examines semileptonic charged lepton flavor violation (cLFV) processes in the minimal type-I seesaw model, finding that certain tau decays like τ→ℓρ could outperform traditional leptonic probes in specific parameter regions, while heavy meson decays are less promising. It identifies experimentally viable cLFV channels for future experiments.


<details>
  <summary>Details</summary>
Motivation: The study addresses gaps in exploring semileptonic cLFV channels within the minimal type-I seesaw model, which is a leading framework for neutrino oscillations. Previous analyses had not fully considered updated form factors, decay constants, or recent oscillation data, motivating a re-evaluation with modern inputs.

Method: The authors analyze τ lepton and meson decays (like τ→ℓρ and related processes) using revised form factors, decay constants, and current neutrino oscillation parameters. They systematically compare branching ratios across the seesaw parameter space, contrasting predictions against experimental sensitivities.

Result: Key results show that semileptonic τ decays such as τ→ℓρ can have larger branching ratios than purely leptonic modes (including τ→3ℓ and τ→ℓγ) in certain parameter regions. Heavy-meson decays are found to be too suppressed to be detectable. The analysis identifies τ-sector decays as leading probes for future experiments.

Conclusion: The work emphasizes the importance of semileptonic cLFV channels like τ→ℓρ as promising avenues for testing the minimal seesaw model. It highlights that next-generation experiments focusing on these τ decay modes could access previously unconstrained parameter regions, offering critical tests of neutrino mass models.

Abstract: The minimal type-I seesaw model provides a simple explanation of neutrino flavor oscillations and induces charged lepton flavor violation (cLFV). Despite extensive previous studies, semileptonic cLFV channels remain underexplored. Using updated form factors, decay constants, and oscillation data, we revisit $τ$ and meson decay channels, performing a systematic comparison across the seesaw parameter space. Surprisingly, we find that decays such as $τ\to \ellρ$ can dominate over purely leptonic $τ$-sector probes, including $τ\to 3\ell$ and even $τ\to\ell\,γ$, in certain regions. In contrast, heavy-meson decays remain far below experimental sensitivity. Considering global constraints on the seesaw parameters, we derive branching ratios for the relevant cLFV processes and identify those within potential reach of next-generation experiments.

</details>


### [63] [Towards the two-loop electroweak corrections to the Drell-Yan process: the infrared structure](https://arxiv.org/abs/2511.20365)
*Tommaso Armadillo,Simone Devoto,Michele Dradi,Alessandro Vicini*

Main category: hep-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We discuss the lepton-pair production process in Quantum Electrodynamics. We present the ultraviolet-renormalised and infrared-subtracted finite contribution of the second-order virtual corrections to the inclusive lepton-pair production cross section $u\bar u\to e^+e^-$. The results are obtained within a new computational framework, OCEANN, developed in view of the evaluation of the exact two-loop electroweak virtual corrections to high-energy scattering processes. One of the key methodological features in this approach is the representation of the scattering amplitude with arbitrary precision at every stage of the calculation. The analysis in QED allows us to address the treatment of the infrared structure of the process and it can be easily extended to the complete electroweak Standard Model case. The perfect agreement with the literature, for this subset of corrections, provides a non trivial validation of the general framework.

</details>


### [64] [A New Framework for Extracting GPDs from Exclusive Photon Electroproduction](https://arxiv.org/abs/2511.20402)
*Jian-Wei Qiu,Nobuo Sato,Zhite Yu*

Main category: hep-ph

TL;DR: The paper extends a framework for studying single-diffractive hard exclusive processes (SDHEP) to real-photon electroproduction off a nucleon, aiming to better access generalized parton distributions (GPDs) for improved extractions from experimental data.


<details>
  <summary>Details</summary>
Motivation: To achieve a cleaner separation of physical mechanisms and enable more systematic, transparent formulation of reaction dynamics for better GPD extraction compared to existing methods.

Method: Expanding the SDHEP formalism to the exclusive real-photon electroproduction process $e + N \to e + N + γ$ which is a key channel for probing GPDs.

Result: The extended framework provides a systematically improved approach for analyzing GPDs in nucleons/nuclei through this reaction.

Conclusion: This advancement supports more accurate extractions of GPDs from experimental data, surpassing previous methodologies.

Abstract: Recently, a new framework for studying generic $2 \to 3$ hard exclusive reactions, referred to as single-diffractive hard exclusive processes (SDHEP), has been introduced to provide a cleaner separation of the underlying physical mechanisms. In this work, we expand this formalism to the case of exclusive real-photon electroproduction off a nucleon, $e(\ell) + N(p) \to e(\ell') + N(p') + γ(q')$, which represents the classical channel for accessing generalized parton distributions (GPDs) in nucleons and nuclei. This extension enables a more systematic and physically transparent formulation of the reaction dynamics, paving the way for improved extractions of GPDs from experimental data as compared to existing approaches.

</details>
